{"meta":{"title":"LITTLEMEEMOON","subtitle":"Every day with dreams is wonderful.","description":"This is my place where I can share my things about life, academic or just for fun, enjoy. :)","author":"Kayleen","url":"https://littlelittlemoon.github.io"},"pages":[{"title":"about","date":"2019-12-12T14:14:36.000Z","updated":"2020-04-07T11:13:12.948Z","comments":false,"path":"about/index.html","permalink":"https://littlelittlemoon.github.io/about/index.html","excerpt":"","text":"[ã•ãã‚‰è˜ã®hojun] ä¸&nbsp; Mashiro&nbsp; ï¼ˆ çœŸï¼ˆã¾ï¼‰ç™½ï¼ˆã—ã‚ï¼‰ ï¼‰ å¯¹è¯ä¸­... bot_ui_ini()","keywords":"å…³äº"},{"title":"bangumi","date":"2019-02-10T13:32:48.000Z","updated":"2020-04-06T16:05:44.917Z","comments":false,"path":"bangumi/index.html","permalink":"https://littlelittlemoon.github.io/bangumi/index.html","excerpt":"","text":"","keywords":null},{"title":"client","date":"2018-12-20T15:13:35.000Z","updated":"2020-04-06T16:22:30.837Z","comments":false,"path":"client/index.html","permalink":"https://littlelittlemoon.github.io/client/index.html","excerpt":"","text":"ç›´æ¥ä¸‹è½½ or æ‰«ç ä¸‹è½½ï¼š","keywords":"Androidå®¢æˆ·ç«¯"},{"title":"donate","date":"2019-12-20T15:13:05.000Z","updated":"2020-04-07T11:12:31.758Z","comments":false,"path":"donate/index.html","permalink":"https://littlelittlemoon.github.io/donate/index.html","excerpt":"","text":"","keywords":"è°¢è°¢é¥²ä¸»äº†å–µ~"},{"title":"comment","date":"2019-12-20T15:13:48.000Z","updated":"2020-04-07T11:12:26.682Z","comments":true,"path":"comment/index.html","permalink":"https://littlelittlemoon.github.io/comment/index.html","excerpt":"","text":"å¿µä¸¤å¥è¯— äººé—²æ¡‚èŠ±è½ï¼Œå¤œé™æ˜¥å±±ç©ºã€‚ æœˆå‡ºæƒŠå±±é¸Ÿï¼Œæ—¶é¸£æ˜¥æ¶§ä¸­ã€‚ ç‹ç»´ Â·ã€Šé¸Ÿé¸£æ¶§ã€‹","keywords":"ç•™è¨€æ¿"},{"title":"categories","date":"2019-12-20T15:13:48.000Z","updated":"2020-04-07T05:10:27.765Z","comments":true,"path":"categories/index.html","permalink":"https://littlelittlemoon.github.io/categories/index.html","excerpt":"","text":"å¿µä¸¤å¥è¯— å™åˆ«æ¢¦ã€æ‰¬å·ä¸€è§‰ã€‚ ã€å®‹ä»£ã€‘å´æ–‡è‹±ã€Šå¤œæ¸¸å®«Â·äººå»è¥¿æ¥¼é›æ³ã€‹","keywords":"æ–‡ç« åˆ†ç±»"},{"title":"links","date":"2018-12-19T15:11:06.000Z","updated":"2020-04-07T11:12:52.882Z","comments":true,"path":"links/index.html","permalink":"https://littlelittlemoon.github.io/links/index.html","excerpt":"","text":"","keywords":"å‹äººå¸"},{"title":"music","date":"2018-12-20T15:14:28.000Z","updated":"2020-04-07T11:12:59.292Z","comments":false,"path":"music/index.html","permalink":"https://littlelittlemoon.github.io/music/index.html","excerpt":"","text":"","keywords":"å–œæ¬¢çš„éŸ³ä¹"},{"title":"lab","date":"2019-01-05T13:47:59.000Z","updated":"2020-04-07T11:12:44.050Z","comments":false,"path":"lab/index.html","permalink":"https://littlelittlemoon.github.io/lab/index.html","excerpt":"","text":"sakuraä¸»é¢˜ balabala","keywords":"Labå®éªŒå®¤"},{"title":"rss","date":"2018-12-20T15:09:03.000Z","updated":"2020-04-06T16:05:44.919Z","comments":true,"path":"rss/index.html","permalink":"https://littlelittlemoon.github.io/rss/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-12-12T14:14:16.000Z","updated":"2020-04-07T11:13:06.637Z","comments":true,"path":"tags/index.html","permalink":"https://littlelittlemoon.github.io/tags/index.html","excerpt":"","text":"","keywords":"æ ‡ç­¾"},{"title":"theme-sakura","date":"2019-01-04T14:53:25.000Z","updated":"2020-04-06T16:05:44.919Z","comments":false,"path":"theme-sakura/index.html","permalink":"https://littlelittlemoon.github.io/theme-sakura/index.html","excerpt":"","text":"Hexoä¸»é¢˜Sakuraä¿®æ”¹è‡ªWordPressä¸»é¢˜Sakuraï¼Œæ„Ÿè°¢åŸä½œè€…Mashiro","keywords":"Hexo ä¸»é¢˜ Sakura ğŸŒ¸"},{"title":"video","date":"2018-12-20T15:14:38.000Z","updated":"2020-04-06T16:05:44.919Z","comments":false,"path":"video/index.html","permalink":"https://littlelittlemoon.github.io/video/index.html","excerpt":"","text":"var videos = [ { img: 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: 'æœèŠ±å¤•èª“â€”â€”äºç¦»åˆ«ä¹‹æœæŸèµ·çº¦å®šä¹‹èŠ±', status: 'å·²è¿½å®Œ', progress: 100, jp: 'ã•ã‚ˆãªã‚‰ã®æœã«ç´„æŸã®èŠ±ã‚’ã‹ã–ã‚ã†', time: 'æ”¾é€æ—¶é—´: 2018-02-24 SUN.', desc: ' ä½åœ¨è¿œç¦»å°˜åš£çš„åœŸåœ°ï¼Œä¸€è¾¹å°†æ¯å¤©çš„äº‹æƒ…ç¼–ç»‡æˆåä¸ºå¸Œæ¯”æ¬§çš„å¸ƒï¼Œä¸€è¾¹é™é™ç”Ÿæ´»çš„ä¼Šæ¬§å¤«äººæ°‘ã€‚åœ¨15å²å·¦å³å¤–è¡¨å°±åœæ­¢æˆé•¿ï¼Œæ‹¥æœ‰æ•°ç™¾å¹´å¯¿å‘½çš„ä»–ä»¬ï¼Œè¢«ç§°ä¸ºâ€œç¦»åˆ«çš„ä¸€æ—â€ï¼Œå¹¶è¢«è§†ä¸ºæ´»ç€çš„ä¼ è¯´ã€‚æ²¡æœ‰åŒäº²çš„ä¼Šæ¬§å¤«å°‘å¥³ç›å¥‡äºšï¼Œè¿‡ç€è¢«ä¼™ä¼´åŒ…å›´çš„å¹³ç¨³æ—¥å­ï¼Œå´æ€»æ„Ÿè§‰â€œå­¤èº«ä¸€äººâ€ã€‚ä»–ä»¬çš„è¿™ç§æ—¥å¸¸ï¼Œä¸€ç¬é—´å°±å´©æºƒæ¶ˆå¤±ã€‚è¿½æ±‚ä¼Šæ¬§å¤«çš„é•¿å¯¿ä¹‹è¡€ï¼Œæ¢…è¨è’‚å†›ä¹˜åç€åä¸ºé›·çº³ç‰¹çš„å¤ä»£å…½å‘åŠ¨äº†è¿›æ”»ã€‚åœ¨ç»æœ›ä¸æ··ä¹±ä¹‹ä¸­ï¼Œä¼Šæ¬§å¤«çš„ç¬¬ä¸€ç¾å¥³è•¾è‰äºšè¢«æ¢…è¨è’‚å¸¦èµ°ï¼Œè€Œç›å¥‡äºšæš—æ‹çš„å°‘å¹´å…‹é‡Œå§†ä¹Ÿå¤±è¸ªäº†ã€‚ç›å¥‡äºšè™½ç„¶æ€»ç®—é€ƒè„±äº†ï¼Œå´å¤±å»äº†ä¼™ä¼´å’Œå½’å»ä¹‹åœ°â€¦â€¦ã€‚' }, { img : 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: 'æœèŠ±å¤•èª“â€”â€”äºç¦»åˆ«ä¹‹æœæŸèµ·çº¦å®šä¹‹èŠ±', status: 'å·²è¿½å®Œ', progress: 100, jp: 'ã•ã‚ˆãªã‚‰ã®æœã«ç´„æŸã®èŠ±ã‚’ã‹ã–ã‚ã†', time: '2018-02-24 SUN.', desc: ' ä½åœ¨è¿œç¦»å°˜åš£çš„åœŸåœ°ï¼Œä¸€è¾¹å°†æ¯å¤©çš„äº‹æƒ…ç¼–ç»‡æˆåä¸ºå¸Œæ¯”æ¬§çš„å¸ƒï¼Œä¸€è¾¹é™é™ç”Ÿæ´»çš„ä¼Šæ¬§å¤«äººæ°‘ã€‚åœ¨15å²å·¦å³å¤–è¡¨å°±åœæ­¢æˆé•¿ï¼Œæ‹¥æœ‰æ•°ç™¾å¹´å¯¿å‘½çš„ä»–ä»¬ï¼Œè¢«ç§°ä¸ºâ€œç¦»åˆ«çš„ä¸€æ—â€ï¼Œå¹¶è¢«è§†ä¸ºæ´»ç€çš„ä¼ è¯´ã€‚æ²¡æœ‰åŒäº²çš„ä¼Šæ¬§å¤«å°‘å¥³ç›å¥‡äºšï¼Œè¿‡ç€è¢«ä¼™ä¼´åŒ…å›´çš„å¹³ç¨³æ—¥å­ï¼Œå´æ€»æ„Ÿè§‰â€œå­¤èº«ä¸€äººâ€ã€‚ä»–ä»¬çš„è¿™ç§æ—¥å¸¸ï¼Œä¸€ç¬é—´å°±å´©æºƒæ¶ˆå¤±ã€‚è¿½æ±‚ä¼Šæ¬§å¤«çš„é•¿å¯¿ä¹‹è¡€ï¼Œæ¢…è¨è’‚å†›ä¹˜åç€åä¸ºé›·çº³ç‰¹çš„å¤ä»£å…½å‘åŠ¨äº†è¿›æ”»ã€‚åœ¨ç»æœ›ä¸æ··ä¹±ä¹‹ä¸­ï¼Œä¼Šæ¬§å¤«çš„ç¬¬ä¸€ç¾å¥³è•¾è‰äºšè¢«æ¢…è¨è’‚å¸¦èµ°ï¼Œè€Œç›å¥‡äºšæš—æ‹çš„å°‘å¹´å…‹é‡Œå§†ä¹Ÿå¤±è¸ªäº†ã€‚ç›å¥‡äºšè™½ç„¶æ€»ç®—é€ƒè„±äº†ï¼Œå´å¤±å»äº†ä¼™ä¼´å’Œå½’å»ä¹‹åœ°â€¦â€¦ã€‚' } ] .should-ellipsis{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:95%;}.should-ellipsis-full{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:100%;}.should-ellipsis i{position:absolute;right:24px;}.grey-text{color:#9e9e9e !important}.grey-text.text-darken-4{color:#212121 !important}html{line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}img{border-style:none}progress{display:inline-block;vertical-align:baseline}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{-webkit-box-sizing:border-box;box-sizing:border-box}*,*:before,*:after{-webkit-box-sizing:inherit;box-sizing:inherit}ul:not(.browser-default){padding-left:0;list-style-type:none}ul:not(.browser-default)>li{list-style-type:none}.card{-webkit-box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2);box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2)}.hoverable{-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s}.hoverable:hover{-webkit-box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19);box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19)}i{line-height:inherit}i.right{float:right;margin-left:15px}.bangumi .right{float:right !important}.material-icons{text-rendering:optimizeLegibility;-webkit-font-feature-settings:'liga';-moz-font-feature-settings:'liga';font-feature-settings:'liga'}.row{margin-left:auto;margin-right:auto;margin-bottom:20px}.row:after{content:\"\";display:table;clear:both}.row .col{float:left;-webkit-box-sizing:border-box;box-sizing:border-box;padding:0 .75rem;min-height:1px}.row .col.s12{width:100%;margin-left:auto;left:auto;right:auto}@media only screen and (min-width:601px){.row .col.m6{width:50%;margin-left:auto;left:auto;right:auto}}html{line-height:1.5;font-family:-apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif;font-weight:normal;color:rgba(0,0,0,0.87)}@media only screen and (min-width:0){html{font-size:14px}}@media only screen and (min-width:992px){html{font-size:14.5px}}@media only screen and (min-width:1200px){html{font-size:15px}}.card{position:relative;margin:.5rem 0 1rem 0;background-color:#fff;-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s;border-radius:2px}.card .card-title{font-size:24px;font-weight:300}.card .card-title.activator{cursor:pointer}.card .card-image{position:relative}.card .card-image img{display:block;border-radius:2px 2px 0 0;position:relative;left:0;right:0;top:0;bottom:0;width:100%}.card .card-content{padding:24px;border-radius:0 0 2px 2px}.card .card-content p{margin:0}.card .card-content .card-title{display:block;line-height:32px;margin-bottom:8px}.card .card-content .card-title i{line-height:32px}.card .card-reveal{padding:24px;position:absolute;background-color:#fff;width:100%;overflow-y:auto;left:0;top:100%;height:100%;z-index:3;display:none}.card .card-reveal .card-title{cursor:pointer;display:block}.waves-effect{position:relative;cursor:pointer;display:inline-block;overflow:hidden;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-tap-highlight-color:transparent;vertical-align:middle;z-index:1;-webkit-transition:.3s ease-out;transition:.3s ease-out}.waves-effect img{position:relative;z-index:-1}.waves-block{display:block}::-webkit-input-placeholder{color:#d1d1d1}::-moz-placeholder{color:#d1d1d1}:-ms-input-placeholder{color:#d1d1d1}::-ms-input-placeholder{color:#d1d1d1}[type=\"radio\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"radio\"]:not(:checked)+span{position:relative;padding-left:35px;cursor:pointer;display:inline-block;height:25px;line-height:25px;font-size:1rem;-webkit-transition:.28s ease;transition:.28s ease;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border-radius:50%}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border:2px solid #5a5a5a}[type=\"radio\"]:not(:checked)+span:after{-webkit-transform:scale(0);transform:scale(0)}[type=\"checkbox\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"checkbox\"]:not(:checked):disabled+span:not(.lever):before{border:none;background-color:rgba(0,0,0,0.42)}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):before{width:0;height:0;border:3px solid transparent;left:6px;top:10px;-webkit-transform:rotateZ(37deg);transform:rotateZ(37deg);-webkit-transform-origin:100% 100%;transform-origin:100% 100%}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):after{height:20px;width:20px;background-color:transparent;border:2px solid #5a5a5a;top:0px;z-index:0}input[type=checkbox]:not(:disabled) ~ .lever:active:before,input[type=checkbox]:not(:disabled).tabbed:focus ~ .lever::before{-webkit-transform:scale(2.4);transform:scale(2.4);background-color:rgba(0,0,0,0.08)}input[type=range].focused:focus:not(.active)::-webkit-slider-thumb{-webkit-box-shadow:0 0 0 10px rgba(38,166,154,0.26);box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-moz-range-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-ms-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)} ç•ªç»„è®¡åˆ’ è¿™é‡Œå°†æ˜¯æ°¸è¿œçš„å›å¿† window.onload = function(){ videos.forEach(function(video, i){ $('#rootRow').append(` ${video.title} ${video.jp} ${video.status} ${video.title} ${video.jp} æ”¾é€æ—¶é—´: ${video.time} ${video.desc} ${video.status} `) }) }","keywords":"Bç«™"}],"posts":[{"title":"Fraud Detection | Imbalanced data modeling","slug":"Credit Card Fraud Detection","date":"2020-04-06T13:53:06.000Z","updated":"2020-04-06T16:27:28.272Z","comments":true,"path":"2020/04/06/Credit Card Fraud Detection/","link":"","permalink":"https://littlelittlemoon.github.io/2020/04/06/Credit%20Card%20Fraud%20Detection/","excerpt":"","text":"LDA, QDA and LR for fraud detection | Imbalanced data modeling 123456%matplotlib inline# import warnings filterfrom warnings import simplefilter# ignore all future warningssimplefilter(action='ignore', category=FutureWarning) prepare data 1234567891011import pandas as pd# load datadefault_data = pd.read_csv(\"data/Default.csv\")# prepare datadefault_data.loc[default_data['default'] == 'No', \"default\"] = 0default_data.loc[default_data['default'] == 'Yes', \"default\"] = 1default_data.loc[default_data['student'] == 'No', \"student\"] = 0default_data.loc[default_data['student'] == 'Yes', \"student\"] = 1default_data.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Unnamed: 0 default student balance income count 10000.00000 10000.000000 10000.000000 10000.000000 10000.000000 mean 5000.50000 0.033300 0.294400 835.374886 33516.981876 std 2886.89568 0.179428 0.455795 483.714985 13336.639563 min 1.00000 0.000000 0.000000 0.000000 771.967729 25% 2500.75000 0.000000 0.000000 481.731105 21340.462903 50% 5000.50000 0.000000 0.000000 823.636973 34552.644802 75% 7500.25000 0.000000 1.000000 1166.308386 43807.729272 max 10000.00000 1.000000 1.000000 2654.322576 73554.233495 split training and testing set 123456789from sklearn.model_selection import train_test_split# create features and targetfeatures = [\"balance\", \"income\"]X = default_data[features]y = default_data.default# slipt data set into training and testing settrain_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.7, random_state=1) 1234567import numpy as npimport matplotlib as mplfrom scipy import linalgfrom matplotlib import colorsimport matplotlib.pyplot as pltfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysisfrom sklearn.linear_model import LogisticRegression Plot function 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# set colormapcmap = colors.LinearSegmentedColormap( 'red_blue_classes', &#123;'red': [(0, 1, 1), (1, 0.7, 0.7)], 'green': [(0, 0.7, 0.7), (1, 0.7, 0.7)], 'blue': [(0, 0.7, 0.7), (1, 1, 1)]&#125;)plt.cm.register_cmap(cmap=cmap)# Plot functiondef plot_data(model, X, y, y_pred): plt.ylabel('income') plt.xlabel('balance') tp = (y == y_pred) # True Positive tp0, tp1 = tp[y == 0], tp[y == 1] X0, X1 = X[y == 0], X[y == 1] X0_tp, X0_fp = X0[tp0], X0[~tp0] X1_tp, X1_fp = X1[tp1], X1[~tp1] # true class 0: dots, false class 0: x plt.scatter(X0_tp[\"balance\"], X0_tp[\"income\"], marker='.', color='red') plt.scatter(X0_fp[\"balance\"], X0_fp[\"income\"], marker='x', s=20, color='#990000') # dark red # true class 1: dots, false class 1: x plt.scatter(X1_tp[\"balance\"], X1_tp[\"income\"], marker='.', color='blue') plt.scatter(X1_fp[\"balance\"], X1_fp[\"income\"], marker='x', s=20, color='#000099') # dark blue # class 0 and 1 : all areas for decision boundary nx, ny = 200, 100 x_min, x_max = plt.xlim() y_min, y_max = plt.ylim() xx, yy = np.meshgrid(np.linspace(x_min, x_max, nx), np.linspace(y_min, y_max, ny)) Z = model.predict_proba(np.c_[xx.ravel(), yy.ravel()]) Z = Z[:, 1].reshape(xx.shape) plt.pcolormesh(xx, yy, Z, cmap='red_blue_classes', norm=colors.Normalize(0., 1.), zorder=0) # plot decision boundary plt.contour(xx, yy, Z, [0.5], linewidths=2., colors='white') plt.axis('tight') plt.tight_layout() plt.subplots_adjust(top=0.92) plt.show() Linear Discriminant Analysis 1234567# Linear Discriminant Analysisplt.figure(figsize=(6, 7), facecolor='white')plt.title('Linear Discriminant Analysis', y=1, fontsize=15)lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)y_pred = lda.fit(train_X, train_y).predict(test_X)plot_data(lda, test_X, test_y, y_pred) Quadratic Discriminant Analysis 1234567# Quadratic Discriminant Analysisplt.figure(figsize=(6, 7), facecolor='white')plt.title('Quadratic Discriminant Analysis', y=1, fontsize=15)qda = QuadraticDiscriminantAnalysis(store_covariance=True)y_pred = qda.fit(train_X, train_y).predict(test_X)plot_data(qda, test_X, test_y, y_pred) Use LogisticRegression directly to model the data If I use this data directly to feed the LogisticRegression model, the model will prefer to predict all as 0 for a high accuracy of 0 prediction. 12print(default_data.default.value_counts(dropna = False))print(\"The mean of default: \", default_data.default.mean()) 0 9667 1 333 Name: default, dtype: int64 The mean of default: 0.0333 NOTE: As it showing above: the provided data with very low proportion of positive signals. Conclusion: The provided data is imbalanced ! Solution: usually for imbalanced data, there are some solutions: Collect more data Down-Sampling or Over-Sampling to get balanced samples Change the Thresholds to adjust the prediction Assign class weights for the low rate class 123from sklearn.metrics import confusion_matrix, auc, roc_curve, roc_auc_score, recall_score, precision_recall_curvefrom sklearn.metrics import make_scorer, precision_scorefrom sklearn.model_selection import GridSearchCV 1234567# Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = .33, stratify = y)logitreg_parameters = &#123;'C': np.power(10.0, np.arange(-3, 3))&#125;logitreg = LogisticRegression(verbose = 3, warm_start = True)logitreg_grid = GridSearchCV(logitreg, param_grid = logitreg_parameters, scoring = 'roc_auc', n_jobs = 1)logitreg_grid.fit(train_X, train_y) GridSearchCV(cv=None, error_score=nan, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='auto', n_jobs=None, penalty='l2', random_state=None, solver='lbfgs', tol=0.0001, verbose=3, warm_start=True), iid='deprecated', n_jobs=1, param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])}, pre_dispatch='2*n_jobs', refit=True, return_train_score=False, scoring='roc_auc', verbose=0) 123456# draw decision boundary with LogisticRegression directlyplt.figure(figsize=(6, 7), facecolor='white')plt.title('Logistic Regression directly', y=1, fontsize=15)y_pred = logitreg_grid.predict(test_X)splot = plot_data(logitreg_grid, test_X, test_y, y_pred) 12345678910111213# on OVER-Sampled TRAINing dataprint(\"\\n The recall score on Training data is:\", recall_score(train_y, logitreg_grid.predict(train_X))) # 0.32print(\"\\n The precision score on Training data is:\", precision_score(train_y, logitreg_grid.predict(train_X))) # 0.74# on the separated TEST dataprint(\"\\n Thre recall score on Test data is:\", recall_score(test_y, logitreg_grid.predict(test_X))) # 0.32print(\"\\n Thre precision score on Test data is:\", precision_score(test_y, logitreg_grid.predict(test_X))) # 0.75print(\"\\n Thre Confusion Matrix on Test data is:\", confusion_matrix(test_y, logitreg_grid.predict(test_X))) # [[3178 12][ 74 36]] The recall score on Training data is: 0.32231404958677684 The precision score on Training data is: 0.7222222222222222 Thre recall score on Test data is: 0.3626373626373626 Thre precision score on Test data is: 0.673469387755102 Thre Confusion Matrix on Test data is: [[2893 16] [ 58 33]] Conclusions: From the output above, on the training data, the recall score is 0.32 which means 32 over 100 of the True positive conditions are predicted correctly. And 74 over 100 of the predicted positives are True Positive. On the Test data, the model performance metric evalued by recall or precision are close to the Training data. There is a precision score of 0.81 on the Test data, which means 81 out of 100 predicted positives are True positives. From Confusion Matrix, 36 of 110 True Positives are predicted as positives. And of all 48 predicted as positive, 36 of them are True positives. Change the Thresholds plot roc curve 1234567891011def plot_roc(new_thresholds, logitreg_grid): y_train_pred_probas = logitreg_grid.predict_proba(train_X)[:, 1] # prob of predict as 1 fpr, tpr, thresholds = roc_curve(train_y, y_train_pred_probas) # precision_recall_curve roc = pd.DataFrame(&#123;'FPR':fpr, 'TPR':tpr, 'Thresholds':thresholds&#125;) plt.figure() plt.title('ROC Curve', y = 1, fontsize = 15) plt.plot(roc.FPR, roc.TPR) plt.axvline(new_thresholds, color = '#00C851', linestyle = '--') plt.xlabel(\"FPR\") plt.ylabel(\"TPR\") plt.show() 12new_threshold = 0.1 # 0.5 is the default valueplot_roc(new_threshold, logitreg_grid) By default, the threshold is 0.5. Since the recall score is low, Iâ€™m trying to lower the threshold to get more predicted as Positive. At the same time, more True Negative data will be falsely predicted as Positive. So the Precision score will be lower. 123456789y_test_pred_probas = logitreg_grid.predict_proba(test_X)[:, 1]y_test_pred = (y_test_pred_probas &gt;= new_threshold).astype(int)print(\"After change threshold to 0.1, the recall socre on Test data is:\")print(recall_score(test_y, y_test_pred)) # 0.736print(\"After change threshold to 0.1, the precision socre on Test data is:\")print(precision_score(test_y, y_test_pred)) # 0.301print(\"After change threshold to 0.1, the Confusion Matrix on Test data is:\")print(confusion_matrix(test_y, y_test_pred)) # [[3002 188][ 29 81]] After change threshold to 0.1, the recall socre on Test data is: 0.7142857142857143 After change threshold to 0.1, the precision socre on Test data is: 0.25 After change threshold to 0.1, the Confusion Matrix on Test data is: [[2714 195] [ 26 65]] Create Over-sampling data and Fit the model 1234567891011121314151617oversample_ratio = sum(train_y == 0) / sum(train_y == 1) # size to repeat y == 1# repeat the positive data for X and yy_train_pos_oversample = pd.concat([train_y[train_y==1]] * int(oversample_ratio), axis = 0)X_train_pos_oversample = pd.concat([train_X.loc[train_y==1, :]] * int(oversample_ratio), axis = 0)# concat the repeated data with the original data togethery_train_oversample = pd.concat([train_y, y_train_pos_oversample], axis = 0).reset_index(drop = True)X_train_oversample = pd.concat([train_X, X_train_pos_oversample], axis = 0).reset_index(drop = True)print(y_train_oversample.value_counts(dropna = False, normalize = True))logitreg_parameters = &#123;'C': np.power(10.0, np.arange(-3, 3))&#125;logitreg = LogisticRegression(verbose = 3, warm_start = True)logitreg_grid = GridSearchCV(logitreg, param_grid = logitreg_parameters, scoring = 'roc_auc', n_jobs = 1)logitreg_grid.fit(X_train_oversample, y_train_oversample) 1 0.500665 0 0.499335 Name: default, dtype: float64 GridSearchCV(cv=None, error_score=nan, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='auto', n_jobs=None, penalty='l2', random_state=None, solver='lbfgs', tol=0.0001, verbose=3, warm_start=True), iid='deprecated', n_jobs=1, param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])}, pre_dispatch='2*n_jobs', refit=True, return_train_score=False, scoring='roc_auc', verbose=0) 123456# Logistic Regression with Over-samplingplt.figure(figsize=(6, 7), facecolor='white')plt.title('Logistic Regression with Over-sampling', y=1, fontsize=15)y_pred = logitreg_grid.predict(test_X)plot_data(logitreg_grid, test_X, test_y, y_pred) 12345678910111213# on OVER-Sampled TRAINing dataprint(\"After Over-Sampling, the recall score on Training data is\")print(recall_score(y_train_oversample, logitreg_grid.predict(X_train_oversample))) # 0.865print(\"After Over-Sampling, the precision score on Training data is\")print(precision_score(y_train_oversample, logitreg_grid.predict(X_train_oversample))) # 0.727# on the TESTing dataprint(\"After Over-Sampling, the recall score on Test data is\")print(recall_score(test_y, logitreg_grid.predict(test_X))) # 0.854print(\"After Over-Sampling, the precision score on Test data is\")print(precision_score(test_y, logitreg_grid.predict(test_X))) # 0.080print(\"After Over-Sampling, the Confusion Matrix on Test data is\")print(confusion_matrix(test_y, logitreg_grid.predict(test_X))) # [[2113 1077][ 16 94]] After Over-Sampling, the recall score on Training data is 0.8884297520661157 After Over-Sampling, the precision score on Training data is 0.8717057631045467 After Over-Sampling, the recall score on Test data is 0.8791208791208791 After Over-Sampling, the precision score on Test data is 0.17094017094017094 After Over-Sampling, the Confusion Matrix on Test data is [[2521 388] [ 11 80]] Conclusion: From the output above, on the training data, the recall score is 0.865 which means 86.5 over 100 of the True conditions are predicted correctly. And 85.4 over 100 of the predicted positives are really positive. However, there is only a precision score of 0.080 on the Test data, which means only 8 out of 100 predicted positives are real positives. From Confusion Matrix, 94 of 110 True Positives are predicted as positives. However, the model predicted 1077 Negative data as Positive. That is, this model has pretty strong over-fitting. Change the Thresholds 12new_threshold = 0.2plot_roc(new_threshold, logitreg_grid) 123456789y_test_pred_probas = logitreg_grid.predict_proba(test_X)[:, 1]y_test_pred = (y_test_pred_probas &gt;= new_threshold).astype(int)print(\"After change threshold to 0.2, the recall socre on Test data is:\")print(recall_score(test_y, y_test_pred)) # 0.990print(\"After change threshold to 0.2, the precision socre on Test data is:\")print(precision_score(test_y, y_test_pred)) # 0.047print(\"After change threshold to 0.2, the Confusion Matrix on Test data is:\")print(confusion_matrix(test_y, y_test_pred)) # [[ 1013 2177][ 1 109]] After change threshold to 0.2, the recall socre on Test data is: 0.9340659340659341 After change threshold to 0.2, the precision socre on Test data is: 0.10023584905660378 After change threshold to 0.2, the Confusion Matrix on Test data is: [[2146 763] [ 6 85]] Conclusion: After over-sampling, the model will have higher recall rate. That is, the model will work better on detect the Frauds from True Frauds. The price is the lower precision rate. Logistic Regression with class_weight Rather than over-sampling, we can assign more weights to the lower rate class. we can write out the Likelihood function for Logistic Regression, the Over-Sampling and the assigning more Weights will be equivalent. 1234567positive_weight = sum(train_y == 0) / sum(train_y == 1) # size to repeat y == 1logitreg_parameters = &#123;'C': np.power(10.0, np.arange(-3, 3))&#125;logitreg = LogisticRegression(class_weight = &#123;0 : 1, 1 : positive_weight&#125;, verbose = 3, warm_start = True)logitreg_grid = GridSearchCV(logitreg, param_grid = logitreg_parameters, scoring = 'roc_auc', n_jobs = 1)logitreg_grid.fit(train_X, train_y) GridSearchCV(cv=None, error_score=nan, estimator=LogisticRegression(C=1.0, class_weight={0: 1, 1: 27.925619834710744}, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='auto', n_jobs=None, penalty='l2', random_state=None, solver='lbfgs', tol=0.0001, verbose=3, warm_start=True), iid='deprecated', n_jobs=1, param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])}, pre_dispatch='2*n_jobs', refit=True, return_train_score=False, scoring='roc_auc', verbose=0) 123456# Logistic Regression with class_weightplt.figure(figsize=(6, 7), facecolor='white')plt.title('Logistic Regression', y=1, fontsize=15)y_pred = logitreg_grid.predict(test_X)plot_data(logitreg_grid, test_X, test_y, y_pred) 1234567891011121314print(\"After assign class_weight, the recall score on Training data is\")print(recall_score(y_train_oversample, logitreg_grid.predict(X_train_oversample))) # 0.856print(\"After assign class_weight, the precision score on Training data is\")print(precision_score(y_train_oversample, logitreg_grid.predict(X_train_oversample))) # 0.729# on the separated TEST dataprint(\"After assign class_weight, the recall score on Test data is\")print(recall_score(test_y, logitreg_grid.predict(test_X))) # 0.845print(\"After assign class_weight, the precision score on Test data is\")print(precision_score(test_y, logitreg_grid.predict(test_X))) # 0.081print(\"After assign class_weight, the Confusion Matrix on Test data is\")print(confusion_matrix(test_y, logitreg_grid.predict(test_X))) # [[2135 1055] [ 17 93]]print(\"After assign class_weight, the ROC AUC Score on Test data is\")print(roc_auc_score(test_y, logitreg_grid.predict(test_X))) # 0.757 After assign class_weight, the recall score on Training data is 0.859504132231405 After assign class_weight, the precision score on Training data is 0.7171530599679843 After assign class_weight, the recall score on Test data is 0.8791208791208791 After assign class_weight, the precision score on Test data is 0.075046904315197 After assign class_weight, the Confusion Matrix on Test data is [[1923 986] [ 11 80]] After assign class_weight, the ROC AUC Score on Test data is 0.7700863934965 Conclusion: If I set up the class weight for the positive as the ratio of non-Fault / Fault, I will get the result close to the over-sampling. So, in summary: This specific data is about fraud detection. So the model should focus on to find the frauds to avoid potential loss for the bank. That is, we focus on recall rate. Conclusion If we use the imbalanced data directly, we will get low performance model since the model prefer to predict to the class with dominated frequency class. The recall rate is 0.31. That is, only 31% of the frauds can be detected by this model. To fix that, one way is to do over-sampling or down-sampling. If we use over-sampling, the model performance will be improved a lot. For this specific case, the recall rate on the independent test set will be improved from 0.31 to 0.87 Another way to improve the model performance is to assign more weights to the low frequency class. Generally speaking, for Logistic Regression, assigning weights is similar to over-sampling, from the likelihood function perspective. The final output results are close too as demonstrated above. Reference Credit Card Fraud Detection / Imbalanced data modeling - Part I: Logistic Regression Credit Fraud || Dealing with Imbalanced Datasets","categories":[{"name":"Machine Learning Game","slug":"Machine-Learning-Game","permalink":"https://littlelittlemoon.github.io/categories/Machine-Learning-Game/"},{"name":"Imbalanced Data Modeling","slug":"Machine-Learning-Game/Imbalanced-Data-Modeling","permalink":"https://littlelittlemoon.github.io/categories/Machine-Learning-Game/Imbalanced-Data-Modeling/"}],"tags":[{"name":"LDA","slug":"LDA","permalink":"https://littlelittlemoon.github.io/tags/LDA/"},{"name":"QDA","slug":"QDA","permalink":"https://littlelittlemoon.github.io/tags/QDA/"},{"name":"LR","slug":"LR","permalink":"https://littlelittlemoon.github.io/tags/LR/"},{"name":"Imbalanced Data modeling","slug":"Imbalanced-Data-modeling","permalink":"https://littlelittlemoon.github.io/tags/Imbalanced-Data-modeling/"},{"name":"Machine learning","slug":"Machine-learning","permalink":"https://littlelittlemoon.github.io/tags/Machine-learning/"},{"name":"Classify","slug":"Classify","permalink":"https://littlelittlemoon.github.io/tags/Classify/"}],"keywords":[{"name":"Machine Learning Game","slug":"Machine-Learning-Game","permalink":"https://littlelittlemoon.github.io/categories/Machine-Learning-Game/"},{"name":"Imbalanced Data Modeling","slug":"Machine-Learning-Game/Imbalanced-Data-Modeling","permalink":"https://littlelittlemoon.github.io/categories/Machine-Learning-Game/Imbalanced-Data-Modeling/"}]},{"title":"Leetcode Note in Apri 2020","slug":"Leetcode Note","date":"2020-04-01T01:51:55.000Z","updated":"2020-04-06T16:27:28.273Z","comments":true,"path":"2020/04/01/Leetcode Note/","link":"","permalink":"https://littlelittlemoon.github.io/2020/04/01/Leetcode%20Note/","excerpt":"","text":"python XORï¼ˆå¼‚æˆ–ï¼‰ Finding sigle number in a integer list Given a non-empty array of integers, every element appears twice except for one. Find that single one. Note: Your algorithm should have a linear runtime complexity. Could you implement it without using extra memory? Example: Input: [4,1,2,1,2] Output: 4 my solutions: tuple + list 12345678910111213141516171819202122232425262728293031class Solution: def singleNumber(self, nums: List[int]) -&gt; int: # store the count of positive number p_count = [0] * (max(tuple(nums)) + 1) # store the positive number p_nums = () # store the count of negative number n_count = [0] * (abs(min(tuple(nums))) + 1) # store the negative number n_nums = () # counting for num in nums: if num &gt;= 0: p_nums = p_nums + (num, ) p_count[num] = p_count[num] + 1 else: n_nums = n_nums + (num, ) n_count[abs(num)] = n_count[abs(num)] + 1 # find the sigle number for num in p_nums: if p_count[num] == 1: return num for num in n_nums: if n_count[abs(num)] == 1: return num return None Space complexityï¼š O(n) time complexityï¼š O(n) optimization using XOR The most crucial trick here is to recognize that if you XOR any same number together, you cancel it out (=0). Explanation: nums = [2, 4, 5, 4, 3, 5, 2] XORing everything together = 2 ^ 4 ^ 5 ^ 4 ^ 3 ^ 5 ^ 2 = (2^2) ^ (4^4) ^ (5^5) ^ 3 = 0 ^ 0 ^0 ^ 3 = 3 123class Solution: def singleNumber(self, nums: List[int]) -&gt; int: return reduce(lambda x, y: x^y, nums, 0) Space complexityï¼š O(1) time complexityï¼š O(n) Reduce 12list(map(str, [1, 2, 3, 4, 5, 6, 7, 8, 9]))# output: ['1', '2', '3', '4', '5', '6', '7', '8', '9'] Map reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4) 12345678910# convert string to integerfrom functools import reduceDIGITS = &#123;'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9&#125;def char2num(s): return DIGITS[s]def str2int(s): return reduce(lambda x, y: x * 10 + y, map(char2num, s)) Dictionary &amp; Tuple Group Anagrams Given an array of strings, group anagrams together. Example: Input: [â€œeatâ€, â€œteaâ€, â€œtanâ€, â€œateâ€, â€œnatâ€, â€œbatâ€], Output: [ [â€œateâ€,â€œeatâ€,â€œteaâ€], [â€œnatâ€,â€œtanâ€], [â€œbatâ€] ] My bad answer 12345678910111213141516class Solution: def groupAnagrams(self, strs: List[str]) -&gt; List[List[str]]: group_list = [] group_list.append([strs[0]]) for i in range(1, len(strs)): sorted_str = sorted(strs[i]) for j in range(0, len(group_list)): sorted_comp_str = sorted(group_list[j][0]) if sorted_str == sorted_comp_str: group_list[j].append(strs[i]) break if j == len(group_list) - 1: group_list.append([strs[i]]) break return group_list Result: Time Limit Exceeded Nice answer with dictionary and tuple 123456789101112class Solution: def groupAnagrams(self, strs: List[str]) -&gt; List[List[str]]: # create a null dictionary group_list = &#123;&#125; for s in strs: # sort the string's letters and save as a tuple key = tuple(sorted(s)) # search dictionary with the str's tuple and save the new value group_list[key] = group_list.get(key, []) + [s] return group_list.values() Summary Tuple can be used for the dictionaryâ€™s key. wow~ use dictionary can speed up the search. Algorithm Floydâ€™s cycle detection What we need to do in case we need the starting point of the loop ? Once we know for sure that a loop is present. Move the slowPointer to start of the list,(i.e headNode) and let fastPointer remain there at the meeting point Now move both the pointers one node at a time The point where both pointers will meet, is our required start of the loop. The algorithm uses O(Î» + Î¼) operations of these types, and O(1) storage space. Application Happy number detection A happy number is a number defined by the following process: Starting with any positive integer, replace the number by the sum of the squares of its digits, and repeat the process until the number equals 1 (where it will stay), or it loops endlessly in a cycle which does not include 1. Those numbers for which this process ends in 1 are happy numbers. Short Version utilizing walrus operator := 12345678class Solution: def isHappy(self, n: int) -&gt; bool: def next_num(num): return sum(map(lambda x:int(x)**2, str(num))) slow, fast = n, next_num(n) while (slow:=next_num(slow)) != (fast:=next_num(next_num(fast))) and fast != 1: continue return fast == 1 or not slow == fast Easier to understand version 123456789class Solution: def isHappy(self, n: int) -&gt; bool: def next_num(num): return sum(map(lambda x:int(x)**2, str(num))) slow, fast = n, next_num(n) while slow != fast and fast != 1: slow = next_num(slow) fast = next_num(next_num(fast)) return fast == 1 or not slow == fast Another solution 123456789101112131415161718192021222324252627282930313233class Solution: def isHappy(self, n: int) -&gt; bool: ####################################################################### # let's try different n: # true (1) -&gt; 1 # false (2) -&gt; 4 -&gt; 16 -&gt; 37 -&gt; 58 -&gt; 89 -&gt; 145 -&gt; 42 -&gt; 20 -&gt; 4 # false (3) -&gt; 9 -&gt; 81 -&gt; 65 -&gt; 61 -&gt; 37 (look at 2) # false (4) -&gt; (look at 2) # false (5) -&gt; 25 -&gt; 29 -&gt; 85 -&gt; 89 (look at 2) # false (6) -&gt; 36 -&gt; 45 -&gt; 41 -&gt; 17 -&gt; 50 -&gt; 25 (look at 5) # true (7) -&gt; 49 -&gt; 97 -&gt; 10 # false (8) -&gt; 64 -&gt; 52 -&gt; 29 (look at 5) # false (9) -&gt; 9 -&gt; 81 -&gt; 65 (look at 3) # # All other n &gt;= 10, while computing will become [1-9], # So there are two cases 1 and 7 which are true. # # Notice, that all falses has the same path as 2 (loop). ####################################################################### counting = 0 num = n while True: counting = 0 for str_num in str(num): counting = counting + pow(int(str_num), 2) if counting &gt;= 1 and counting &lt;=9: if counting == 1 or counting == 7: return True else: return False else: num = counting Reference Detecting start of a loop in singly Linked List Floydâ€™s Cycle detection algorithm | Determining the starting point of cycle Updating . . .","categories":[{"name":"Coding Game","slug":"Coding-Game","permalink":"https://littlelittlemoon.github.io/categories/Coding-Game/"},{"name":"Leetcode","slug":"Coding-Game/Leetcode","permalink":"https://littlelittlemoon.github.io/categories/Coding-Game/Leetcode/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://littlelittlemoon.github.io/tags/Leetcode/"},{"name":"Python","slug":"Python","permalink":"https://littlelittlemoon.github.io/tags/Python/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://littlelittlemoon.github.io/tags/Algorithm/"}],"keywords":[{"name":"Coding Game","slug":"Coding-Game","permalink":"https://littlelittlemoon.github.io/categories/Coding-Game/"},{"name":"Leetcode","slug":"Coding-Game/Leetcode","permalink":"https://littlelittlemoon.github.io/categories/Coding-Game/Leetcode/"}]},{"title":"Evalution of hair and scalp condition based on microscopy image analysis ä¹‹å¤´å‘åšåº¦è®¡ç®—é—®é¢˜","slug":"Evalution of hair and scalp condition based on microscopy image analysis ä¹‹å¤´å‘åšåº¦è®¡ç®—é—®é¢˜","date":"2019-12-29T15:51:27.000Z","updated":"2020-04-06T16:27:28.273Z","comments":true,"path":"2019/12/29/Evalution of hair and scalp condition based on microscopy image analysis ä¹‹å¤´å‘åšåº¦è®¡ç®—é—®é¢˜/","link":"","permalink":"https://littlelittlemoon.github.io/2019/12/29/Evalution%20of%20hair%20and%20scalp%20condition%20based%20on%20microscopy%20image%20analysis%20%E4%B9%8B%E5%A4%B4%E5%8F%91%E5%8E%9A%E5%BA%A6%E8%AE%A1%E7%AE%97%E9%97%AE%E9%A2%98/","excerpt":"","text":"Paper: Evalution of hair and scalp condition based on microscopy image analysis æ‘˜è¦ç¿»è¯‘ï¼šç”±äºITæŠ€æœ¯çš„å¿«é€Ÿéƒ¨ç½²ï¼ŒåŒ»ç–—ä¿å¥æœåŠ¡è¿›å…¥äº†ä¸€ä¸ªæ–°æ—¶ä»£ã€‚è¯¸å¦‚å¿ƒè„ç›‘æŠ¤ä¹‹ç±»çš„æŸäº›æœåŠ¡å¯¹äºç”Ÿå‘½è‡³å…³é‡è¦ï¼Œå¹¶æœ‰åŠ©äºæŒ½æ•‘ç”Ÿå‘½ã€‚å¦ä¸€æ–¹é¢ï¼Œç›‘æµ‹è„±å‘æ˜¯å¦ä¸€ç§æœ‰è¶£çš„ä¿å¥æœåŠ¡ã€‚å°½ç®¡è¿™å¯¹ç”Ÿæ´»å¹¶ä¸é‡è¦ï¼Œä½†äººä»¬è¿˜æ˜¯ä¼šéå¸¸æ³¨æ„è‡ªå·±çš„å¤´å‘çŠ¶å†µã€‚è„±å‘æ˜¯ä¸å¤´å‘çŠ¶å†µæœ‰å…³çš„ä¸»è¦é—®é¢˜ä¹‹ä¸€ï¼Œå› ä¸ºè¿‡å¤šå’Œæ— æ„çš„è„±å‘å¯èƒ½å¯¼è‡´ç§ƒå¤´ã€‚å¯ä»¥åœ¨æŠ¤å‘åº—ä¸“ä¸šè¿›è¡ŒæŠ¤å‘ï¼Œä½†æ˜¯è¿™éœ€è¦å¾ˆå¤šæ—¶é—´å’Œæˆæœ¬ã€‚æœ€è¿‘ï¼Œç”±äºå»‰ä»·çš„æ™ºèƒ½è®¾å¤‡ï¼Œå¯¹å¤´å‘çŠ¶å†µçš„è‡ªæˆ‘è¯Šæ–­å·²æˆä¸ºå¯èƒ½ã€‚ä»ç„¶å¾ˆå°‘å¼€å‘ç”¨äºè¯„ä¼°å¤´å‘çŠ¶å†µçš„åº”ç”¨ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°æ–¹æ¡ˆï¼Œé€šè¿‡ä»æ˜¾å¾®é•œå›¾åƒä¸­æå–å„ç§ç‰¹å¾æ¥è¯„ä¼°å¤´å‘å’Œå¤´çš®çš„çŠ¶å†µã€‚å…¶ç‰¹å¾åŒ…æ‹¬å¤´å‘çš„åšåº¦ï¼Œå¤´å‘çš„å¯†åº¦å’Œå¤´çš®çš„æ–‘ç‚¹ã€‚é€šè¿‡å¯¹åŸå‹ç³»ç»Ÿè¿›è¡Œå¹¿æ³›çš„å®éªŒï¼Œæˆ‘ä»¬è¯æ˜äº†è¯¥æ–¹æ¡ˆçš„æœ‰æ•ˆæ€§ã€‚ ä¸ºäº†åˆ†æå¤´çš®å›¾åƒï¼Œåº”è¯¥å°†å¤´å‘å’Œå¤´çš®å½¼æ­¤åˆ†å¼€ã€‚ä¸¤è€…ä¹‹é—´æœ€æ˜æ˜¾çš„åŒºåˆ«æ˜¯å®ƒä»¬çš„é¢œè‰²ã€‚å¤´çš®ç›¸å¯¹æ˜äº®ï¼Œå¤´å‘ç›¸å¯¹æ·±è‰²ã€‚å› æ­¤ï¼Œåœ¨è®¸å¤šç ”ç©¶ä¸­ï¼Œæ ¹æ®é¢œè‰²å¯¹å¤´å‘å’Œå¤´çš®åŒºåŸŸè¿›è¡Œåˆ†ç±»ï¼Œå¹¶æ ¹æ®è¿™ç§åˆ†ç¦»è¿›è¡Œå›¾åƒåˆ†æã€‚ Overall steps for feature extraction Pre-processing è¯¥è®ºæ–‡ä¸­æ‰€æåˆ°çš„å›¾ç‰‡é¢„å¤„ç†æ–¹æ³•å’Œâ€œAn Unsupervised Hair Segmentation and Counting System in Microscopy Imagesâ€ä¸­ç›¸ä¼¼ï¼Œå…·ä½“å¯å‚è€ƒï¼šè®ºæ–‡è§£è¯» - An Unsupervised Hair Segmentation and Counting System in Microscopy Images ä¹‹å¤´å‘è®¡æ•°é—®é¢˜ã€‚ è£åˆ‡å›¾åƒ å›¾åƒå¢å¼º: ä½¿ç”¨Contrast stretchingæ–¹æ³•ï¼Œå¢åŠ å›¾åƒçš„å¯¹æ¯”åº¦ Morphological openingï¼šå»é™¤æ²¹æ€§å’Œæ¹¿æ¶¦çš„å¤´å‘åœ¨å…¶æ˜¾å¾®é•œå›¾åƒä¸­å½¢æˆçš„äº®ç‚¹ äºŒå€¼åŒ–ï¼šç»è¿‡ä¸Šè¿°é¢„å¤„ç†åï¼Œå°†æ‰€å¾—å›¾åƒè½¬æ¢ä¸ºç°åº¦å›¾åƒï¼Œç„¶åæ ¹æ®Otsué˜ˆå€¼è½¬æ¢ä¸ºäºŒè¿›åˆ¶å›¾åƒã€‚ åœ¨äºŒå€¼å›¾åƒä¸­ï¼Œâ€œ 0â€å’Œâ€œ 1â€åˆ†åˆ«è¡¨ç¤ºå¤´å‘åƒç´ å’Œå¤´çš®åƒç´ ã€‚ hair/scalp image analysis å¤´å‘æ£€æµ‹ æŠ€æœ¯ ä½¿ç”¨Cannyè¾¹ç¼˜æ£€æµ‹ç®—æ³•ä»äºŒè¿›åˆ¶å›¾åƒä¸­è·å–æ¯›å‘è½®å»“ã€‚ ç»“æœ å›¾2æ˜¾ç¤ºäº†æ£€æµ‹å’Œå»ºæ¨¡å¤´å‘çš„æ‰€æœ‰æ­¥éª¤ã€‚å¯¹äºå›¾2ï¼ˆaï¼‰ä¸­çš„åŸå§‹æ˜¾å¾®é•œå›¾åƒï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—å‡ºå¤´å‘è½®å»“å’Œéª¨éª¼ã€‚ é€šè¿‡ä½¿ç”¨äºŒè¿›åˆ¶å›¾åƒä¸Šçš„ç¨€ç–è¿ç®—ï¼ˆThinning operationï¼‰ æ¥è®¡ç®—å¤´å‘éª¨æ¶ã€‚Thinningæ˜¯ä¸€ç§å½¢æ€å­¦è¿ç®—ï¼Œå¯å»é™¤æ•´ä¸ªäºŒè¿›åˆ¶å›¾åƒä¸­çš„å‰æ™¯ã€‚ å›¾2ï¼ˆdï¼‰æ˜¾ç¤ºäº†é€šè¿‡å åŠ å¤´å‘è½®å»“å’Œéª¨éª¼å¾—åˆ°çš„æœ€ç»ˆå›¾åƒã€‚ å¤´å‘åšåº¦è®¡ç®— å¤´å‘åšåº¦å¯ä»¥é€šè¿‡ä¸å¤´å‘å‚ç›´çº¿çš„é•¿åº¦æ¥å®šä¹‰ã€‚è¦è·å¾—å‚ç›´çº¿ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦è®¡ç®—å¤´å‘æ–¹å‘. é€šè¿‡è€ƒè™‘ç›¸é‚»åƒç´ å¹¶åº”ç”¨PCAï¼ˆä¸»æˆåˆ†åˆ†æï¼‰ç®—æ³•æ¥è®¡ç®—æ¯ä¸ªåƒç´ çš„æ–¹å‘. å½“è®¡ç®—å¤´å‘éª¨æ¶ä¸Šæ‰€æœ‰ç‚¹çš„æ–¹å‘æ—¶ï¼Œå¯ä»¥è®¡ç®—å‡ºæ¯ä¸ªç‚¹çš„å‚ç›´çº¿ã€‚ç„¶åï¼Œå‚ç›´çº¿ä¸å¤´å‘è¾¹ç•Œçš„äº¤ç‚¹ä¹‹é—´çš„è·ç¦»å°±æ˜¯å¤´å‘çš„åšåº¦ï¼Œå¯ä»¥é€šè¿‡ä½¿ç”¨æ¬§æ°è·ç¦»æ¥è®¡ç®—ï¼š Ï=(x2âˆ’x1)2+(y2âˆ’y1)2\\rho = \\sqrt{\\smash[b]{(x_2-x_1)^2 + (y_2-y_1)^2}} Ï=(x2â€‹âˆ’x1â€‹)2+(y2â€‹âˆ’y1â€‹)2â€‹ æ ¹æ®æ¬§å¼è·ç¦»Ï\\rhoÏå¯è®¡ç®—å‡ºå¤´å‘çš„å¹³å‡åšåº¦ï¼š Thincknessavg=1nâˆ‘i=1n(xi2âˆ’xi1)2+(yi2âˆ’yi1)2Thinckness_{avg} =\\frac{1}{n}\\displaystyle\\sum_{i=1}^n\\sqrt{\\smash[b]{(x_{i2}-x_{i1})^2 + (y_{i2}-y_{i1})^2}} Thincknessavgâ€‹=n1â€‹i=1âˆ‘nâ€‹(xi2â€‹âˆ’xi1â€‹)2+(yi2â€‹âˆ’yi1â€‹)2â€‹ è¿™é‡ŒThincknessavgThinckness_{avg}Thincknessavgâ€‹çš„å•ä½æ˜¯åƒç´ ï¼Œå› æ­¤éœ€è¦ä½¿ç”¨ç­‰å¼å°†å…¶æ›´æ”¹ä¸ºä»ªè¡¨å•ä½: Thincknessactual(um)=Thincknessavg(px)Ã—UL(um/px)mfThinckness_{actual}(um) = \\frac{Thinckness_{avg}(px) Ã—UL(um/px)}{mf} Thincknessactualâ€‹(um)=mfThincknessavgâ€‹(px)Ã—UL(um/px)â€‹ mfmfmf: æ˜¯ç›¸æœºçš„æ”¾å¤§å€ç‡ ULULUL: æ˜¯å•ä½é•¿åº¦ï¼Œè¡¨ç¤ºä¸€ä¸ªåƒç´ çš„å¾®ç±³é•¿åº¦ å®éªŒç»“æœ ä¸ºäº†è¯„ä¼°æˆ‘ä»¬çš„å¤´å‘åšåº¦è¯„ä¼°æ–¹æ³•çš„å‡†ç¡®æ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨ç”µå­æ˜¾å¾®é•œæµ‹é‡äº†å®é™…çš„å¤´å‘åšåº¦ã€‚å¤´å‘åšåº¦æµ‹é‡çš„å‡†ç¡®æ€§å¦‚è¡¨1æ‰€ç¤ºã€‚ æ®æŠ¥é“ï¼ŒéŸ©å›½äººçš„å¹³å‡å¤´å‘åšåº¦ä¸º84.9Î¼mã€‚ä¸æ­¤ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„90.29Î¼mçš„ç»“æœç›¸å½“ä¸é”™ã€‚å®é™…å€¼ï¼ˆé€šè¿‡ç”µå­æ˜¾å¾®é•œè®¡ç®—ï¼‰ä¸ä¼°è®¡å€¼ä¹‹é—´çš„å·®å¼‚å¾ˆå°ã€‚ å¯èƒ½çš„åŸå› ä¹‹ä¸€æ˜¯é˜´å½±æ•ˆæœã€‚å¦ä¸€ä¸ªå¯èƒ½çš„åŸå› æ˜¯ç›¸æœºé•œå¤´å˜å½¢ã€‚ å›¾åƒå°ºå¯¸ä¸º640x480ã€‚ä½†æ˜¯ï¼Œç›¸æœºæ‰€è¦†ç›–åŒºåŸŸçš„çœŸå®å½¢çŠ¶å‡ ä¹æ˜¯æ¤­åœ†å½¢ã€‚å› æ­¤ï¼Œç›¸æœºæ”¾å¤§ç‡åœ¨è¡Œå’Œåˆ—ä¹‹é—´å…·æœ‰å·®å¼‚ã€‚æ ¹æ®æ‹æ‘„è§’åº¦ï¼Œæ”¾å¤§å€ç‡å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒã€‚ æ€»ç»“ é’ˆå¯¹å¤´å‘ç²—ç»†ï¼ˆåšåº¦ï¼‰è®¡ç®—é—®é¢˜ï¼Œä¸Šè¿°è®ºæ–‡æå‡ºäº†åŸºäºå¤´å‘è½®å»“å’Œéª¨éª¼å›¾ï¼Œé€šè¿‡è®¡ç®—æ¯ä¸ªåƒç´ ç‚¹çš„æ–¹å‘å’Œå‚çº¿ï¼Œè¿›ä¸€æ­¥ä½¿ç”¨æ¬§å¼è·ç¦»å…¬å¼æ¥è®¡ç®—å¤´å‘çš„å‚ç›´ç›´å¾„ï¼Œä½†å¯¹ç›¸å…³æŠ€æœ¯çš„åº”ç”¨ç»†èŠ‚æè¿°ä¸å¤šã€‚ å‚è€ƒæ–‡çŒ® Evalution of hair and scalp condition based on microscopy image analysis An Unsupervised Hair Segmentation and Counting System in Microscopy Images Euclidean distance Principal component analysis","categories":[{"name":"Paper Game","slug":"Paper-Game","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/"},{"name":"Smash","slug":"Paper-Game/Smash","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/Smash/"}],"tags":[{"name":"å›¾åƒå¤„ç†","slug":"å›¾åƒå¤„ç†","permalink":"https://littlelittlemoon.github.io/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"çº¿æ£€æµ‹","slug":"çº¿æ£€æµ‹","permalink":"https://littlelittlemoon.github.io/tags/%E7%BA%BF%E6%A3%80%E6%B5%8B/"},{"name":"å¤´å‘åšåº¦è®¡ç®—é—®é¢˜","slug":"å¤´å‘åšåº¦è®¡ç®—é—®é¢˜","permalink":"https://littlelittlemoon.github.io/tags/%E5%A4%B4%E5%8F%91%E5%8E%9A%E5%BA%A6%E8%AE%A1%E7%AE%97%E9%97%AE%E9%A2%98/"}],"keywords":[{"name":"Paper Game","slug":"Paper-Game","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/"},{"name":"Smash","slug":"Paper-Game/Smash","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/Smash/"}]},{"title":"Evalution of hair and scalp condition based on microscopy image analysis ä¹‹å¤´å‘è®¡æ•°é—®é¢˜","slug":"Evalution of hair and scalp condition based on microscopy image analysis ä¹‹å¤´å‘è®¡æ•°é—®é¢˜","date":"2019-12-28T15:58:27.000Z","updated":"2020-04-06T16:27:28.273Z","comments":true,"path":"2019/12/28/Evalution of hair and scalp condition based on microscopy image analysis ä¹‹å¤´å‘è®¡æ•°é—®é¢˜/","link":"","permalink":"https://littlelittlemoon.github.io/2019/12/28/Evalution%20of%20hair%20and%20scalp%20condition%20based%20on%20microscopy%20image%20analysis%20%E4%B9%8B%E5%A4%B4%E5%8F%91%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/","excerpt":"","text":"Paper: Evalution of hair and scalp condition based on microscopy image analysis è®¡æ•°æ–¹æ³• å…¸å‹çš„ä¾¿æºå¼æ˜¾å¾®é•œç›¸æœºé€šå¸¸è¦†ç›–5mm x 5mmçš„çŸ©å½¢ã€‚å› æ­¤ï¼Œå¦‚æœä¸€æ ¹å¤´å‘é•¿äº5æ¯«ç±³ï¼Œåˆ™å®ƒå¿…é¡»è¶…å‡ºçŸ©å½¢ã€‚åŸºäºæ­¤è§‚å¯Ÿï¼Œæˆ‘ä»¬å¯¹æ¯›å‘è®¡æ•°æœ‰ä¸¤ä¸ªå‡è®¾ï¼š æ¯æ ¹å¤´å‘ç”±ä¸€ä¸ªèµ·ç‚¹å’Œä¸€ä¸ªç»ˆç‚¹è¡¨ç¤º; èµ·ç‚¹ä½äºçŸ©å½¢å†…éƒ¨ï¼Œç»ˆç‚¹ä½äºå›¾åƒçš„è¾¹ç•Œä¸Šã€‚ å¤´å‘è®¡æ•°ï¼šä½¿ç”¨é¢„å¤„ç†é˜¶æ®µè·å¾—çš„éª¨æ¶å›¾åƒï¼ŒåŸºäºä¸Šè¿°ä¸¤ç‚¹å‡è®¾ï¼Œå¦‚æœå¤´å‘çš„éª¨æ¶çº¿çš„ä¸€ä¸ªç‚¹åœ¨çŸ©å½¢å†…è€Œå¦ä¸€ç‚¹åœ¨è¾¹ç•Œä¸Šï¼Œåˆ™æˆ‘ä»¬å¯¹å¤´å‘è¿›è¡Œè®¡æ•°ã€‚ å›¾3ç¤ºå‡ºäº†å¤´å‘è®¡æ•°çš„ç¤ºä¾‹ã€‚åœ¨å›¾ä¸­ï¼Œè®¡æ•°çš„åƒç´ ç”¨çº¢è‰²ç‚¹æ ‡è®°ï¼Œå¹¶ä¸”è¿™äº›ç‚¹å åŠ åœ¨åŸå§‹å›¾åƒä¸Šã€‚ç„¶åï¼Œå¯ä»¥é€šè¿‡å°†è®¡æ•°çš„åƒç´ æ•°é™¤ä»¥å›¾åƒå°ºå¯¸æ¥è®¡ç®—å¤´å‘å¯†åº¦ã€‚ å®éªŒç»“æœ ä¸ºäº†è¯„ä¼°å¤´å‘è®¡æ•°ç®—æ³•ï¼Œæˆ‘ä»¬å¯¹200ä¸ªå¤´çš®å›¾åƒçš„æ•°æ®é›†è¿›è¡Œäº†å®éªŒã€‚ è¡¨2åˆ—å‡ºäº†æ ¹æ®æˆ‘ä»¬çš„ç®—æ³•è®¡ç®—å‡ºçš„å®é™…æ¯›å‘æ•°ä¸ä¼°è®¡æ¯›å‘æ•°ä¹‹é—´çš„ç²¾ç¡®åº¦/å¬å›ç‡ã€‚ å¹³å‡å‡†ç¡®åº¦å’Œå¬å›ç‡åˆ†åˆ«ä¸º91.35ï¼…å’Œ92.01ï¼…ã€‚å³ä½¿æ€§èƒ½ç›¸å½“å¥½ï¼Œç²¾åº¦/è°ƒç”¨ç‡ä¹Ÿå¯ä»¥è¿›ä¸€æ­¥æé«˜ã€‚é”™è¯¯çš„ä¸€ä¸ªå…³é”®åŸå› æ˜¯é¢„å¤„ç†å’ŒåŸå§‹å›¾åƒçš„è´¨é‡ã€‚åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œä¸€æ—¦å›¾åƒä¸­å‡ºç°æ¨¡ç³Šç‚¹ï¼Œå°±ä¸å¯èƒ½åœ¨é¢„å¤„ç†æ­¥éª¤ä¸­æ¶ˆé™¤æ‰€æœ‰å™ªéŸ³ã€‚å› æ­¤ï¼Œè€ƒè™‘åˆ°ç›¸æœºå™ªå£°ï¼Œç²¾åº¦éå¸¸å¥½ã€‚ åŒæ ·ï¼Œæˆ‘ä»¬æµ‹è¯•äº†æ¯›å­”è®¡æ•°ç®—æ³•ï¼Œç»“æœæ˜¾ç¤ºå¹³å‡å‡†ç¡®ç‡çº¦ä¸º90ï¼…ã€‚ æ€»ç»“ è®¡æ•°æ€è·¯ å°†å›¾ç‰‡è¾¹ç¼˜çœ‹ä½œä¸€çŸ©å½¢ï¼› å¯¹æ»¡è¶³â€œå¤´å‘ç”±ä¸€ä¸ªèµ·ç‚¹å’Œä¸€ä¸ªç»ˆç‚¹è¡¨ç¤ºï¼Œä¸”èµ·ç‚¹ä½äºçŸ©å½¢å†…éƒ¨ï¼Œç»ˆç‚¹ä½äºå›¾åƒçš„è¾¹ç•Œä¸Šâ€æ¡ä»¶çš„å¤´å‘è¿›è¡Œè®¡æ•°ï¼› ä½¿ç”¨é€šè¿‡ç»†åŒ–æ“ä½œè·å¾—çš„å¤´å‘éª¨æ¶å›¾åƒå¯¹æ»¡è¶³æ¡ä»¶çš„å¤´å‘è¿›è¡Œè®¡æ•°ï¼› é€šè¿‡å°†è®¡æ•°çš„åƒç´ æ•°é™¤ä»¥å›¾åƒå°ºå¯¸æ¥è®¡ç®—å¤´å‘å¯†åº¦ã€‚ å‚è€ƒæ–‡çŒ® Evalution of hair and scalp condition based on microscopy image analysis","categories":[{"name":"Paper Game","slug":"Paper-Game","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/"},{"name":"Smash","slug":"Paper-Game/Smash","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/Smash/"}],"tags":[{"name":"å¤´å‘è®¡æ•°é—®é¢˜","slug":"å¤´å‘è®¡æ•°é—®é¢˜","permalink":"https://littlelittlemoon.github.io/tags/%E5%A4%B4%E5%8F%91%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/"},{"name":"å›¾åƒå¤„ç†","slug":"å›¾åƒå¤„ç†","permalink":"https://littlelittlemoon.github.io/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"çº¿æ£€æµ‹","slug":"çº¿æ£€æµ‹","permalink":"https://littlelittlemoon.github.io/tags/%E7%BA%BF%E6%A3%80%E6%B5%8B/"}],"keywords":[{"name":"Paper Game","slug":"Paper-Game","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/"},{"name":"Smash","slug":"Paper-Game/Smash","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/Smash/"}]},{"title":"An Unsupervised Hair Segmentation and Counting System in Microscopy Images ä¹‹å¤´å‘è®¡æ•°é—®é¢˜","slug":"An Unsupervised Hair Segmentation and Counting System in Microscopy Images ä¹‹å¤´å‘è®¡æ•°é—®é¢˜","date":"2019-12-28T15:51:27.000Z","updated":"2020-04-07T03:09:32.148Z","comments":true,"path":"2019/12/28/An Unsupervised Hair Segmentation and Counting System in Microscopy Images ä¹‹å¤´å‘è®¡æ•°é—®é¢˜/","link":"","permalink":"https://littlelittlemoon.github.io/2019/12/28/An%20Unsupervised%20Hair%20Segmentation%20and%20Counting%20System%20in%20Microscopy%20Images%20%E4%B9%8B%E5%A4%B4%E5%8F%91%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/","excerpt":"","text":"Paper: An Unsupervised Hair Segmentation and Counting System in Microscopy Images æ‘˜è¦ç¿»è¯‘ï¼šæœ¬æ–‡é‡ç‚¹ä»‹ç»ä½¿ç”¨é«˜çº§å›¾åƒå¤„ç†ç®—æ³•å¼€å‘ç”¨äºä¸´åºŠçš„åŒ»å­¦è½¯ä»¶ã€‚æœ¬æ–‡è®¨è®ºäº†å¤´å‘åˆ†å‰²å’Œè®¡æ•°çš„ä¸‰ä¸ªå…³é”®é—®é¢˜: é¦–å…ˆï¼Œå»é™¤ç”±äºæ²¹è„‚æˆ–æ°´åˆ†å¼•èµ·çš„ä»»ä½•äº®ç‚¹ï¼Œè¿™äº›äº®ç‚¹åœ¨å¤´å‘çš„ä¸­éƒ¨å½¢æˆåœ†å½¢å›¾æ¡ˆï¼Œå¹¶æ˜¾ç€å½±å“ç¡®å®šçº¿æ¡çš„å‡†ç¡®æ€§ã€‚ ç¬¬äºŒï¼Œè¯†åˆ«å‡ºä¸¤ä¸ªæ¥è§¦æˆ–é‡å çš„å¤´å‘ï¼Œå¹¶å°†å…¶è§†ä¸ºå•ä¸ªå¤´å‘ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤´å‘æ†ç»‘ç®—æ³•(hair-bundling algorithm)æ¥è®¡ç®—ä»»ä½•éšè—çš„å¤´å‘ã€‚ æœ€åï¼Œå¤´å‘å¯èƒ½å‘ˆæ³¢æµªçŠ¶æˆ–å·æ›²çŠ¶ï¼Œè¿™ä½¿ä¼ ç»Ÿçš„åŸºäºHoughçš„çº¿æ£€æµ‹ç®—æ³•ä¸åˆé€‚ï¼Œå› ä¸ºå®ƒä¼šå—åˆ°å‚æ•°é€‰æ‹©çš„å½±å“ï¼Œä¾‹å¦‚çº¿æ®µçš„æœ€å°é•¿åº¦ä»¥åŠçº¿æ®µä¹‹é—´çš„è·ç¦»ã€‚æˆ‘ä»¬æå‡ºçš„æ¯›å‘è®¡æ•°ç®—æ³•æ¯”åŸºäºHoughçš„æ¯›å‘è®¡æ•°ç®—æ³•è¦å‡†ç¡®å¾—å¤šï¼Œå¹¶ä¸”åœ¨å„ç§ç™½å¹³è¡¡ä¸‹å¯¹å·å‘ï¼Œæ²¹æ€§å¤´çš®ï¼Œå™ªå£°è…èš€å’Œé‡å çš„å¤´å‘éƒ½å…·æœ‰é€‚ç”¨æ€§ã€‚ å…³é”®è¯ï¼šæ¯›å‘è®¡æ•°ï¼Œå¤´çš®è¯Šæ–­ï¼ŒæŠ¤å‘è¯Šæ–­ï¼Œæ¯›å›Šè¯Šæ–­ï¼Œçº¿æ®µæ£€æµ‹ã€‚ System flowchart é¢„å¤„ç†é˜¶æ®µ (Preprocessing Stage) ä½¿ç”¨å¯¹æ¯”åº¦æ‹‰ä¼¸æ–¹æ³•(the contrast-stretching method)æ¥å¢åŠ å¤´çš®å’Œå¤´å‘åƒç´ ä¹‹é—´çš„å¯¹æ¯”åº¦; ä¸ºäº†å‡å°‘äº®ç‚¹çš„å½±å“ï¼Œæå‡ºäº†ä¸€ç§å¥å£®çš„é¢œè‰²å½¢æ€ç®—æ³•(morphological algorithm)ï¼Œä»¥ä½¿é¢œè‰²å¹³æ»‘å¹¶ä¿æŒå¤´å‘çš„ä¿çœŸåº¦; ä¸ºæ¯ä¸ªé¢œè‰²åˆ†é‡åº”ç”¨äº†Karhunen-LoÃ¨veå˜æ¢(KLT)ï¼Œå¹¶ä¿ç•™äº†å…·æœ‰æœ€é«˜èƒ½é‡çš„åˆ†é‡ï¼Œå¹¶ä½¿ç”¨Otsué˜ˆå€¼è·å¾—äº†å¯é çš„äºŒè¿›åˆ¶å›¾åƒã€‚ æ•°æ®é‡‡é›†è§„å®š è¿™é¡¹ç ”ç©¶çš„å”¯ä¸€å‡è®¾: å¤´å‘çš„é¢œè‰²æ¯”çš®è‚¤çš„é¢œè‰²æ·±ã€‚ å¤´å‘å›¾åƒæ˜¯ä»æ•°ç æ˜¾å¾®é•œç›¸æœºï¼ˆDMCï¼‰æ•è·ï¼Œå†…ç½®LEDå¢å¼ºï¼Œå¯è‡ªåŠ¨ä¿æŒäº®åº¦ç¨³å®šã€‚åº”ç”¨85å€çš„å˜ç„¦å€ç‡æ•è·å›¾åƒã€‚é€šå¸¸ï¼Œä½¿ç”¨åˆ†è¾¨ç‡ä¸º1024Ã—768ï¼Œç›¸å½“äºå¤´çš®é¢ç§¯æ˜¯0.25Ã—0.19è‹±å¯¸ã€‚æ­¤å¤–ï¼ŒåŸºäºDMCçš„ç™½å¹³è¡¡å°†æ•è·çš„å›¾åƒåˆ†ä¸ºä¸¤ç»„ï¼š å…·æœ‰æ—¥å…‰çš„å›¾åƒè¢«åˆ†ç±»ä¸ºæ•°æ®é›†ï¼ƒ1ï¼Œ å…·æœ‰è§å…‰çš„å›¾åƒè¢«åˆ†ç±»ä¸ºæ•°æ®é›†ï¼ƒ2ã€‚ ä½¿ç”¨å¯¹æ¯”åº¦æ‹‰ä¼¸(Contrast Stretching)è¿›è¡Œå›¾åƒå¢å¼º ç›®çš„ å¢åŠ å¤´å‘å’Œå¤´çš®ä¹‹é—´çš„å¯¹æ¯”åº¦; å¢åŠ å¤´å‘å’Œå¤´çš®åƒç´ ä¹‹é—´çš„è‰²å·®ã€‚ æŠ€æœ¯ é€šè¿‡åˆ†æ®µçº¿æ€§å¯¹æ¯”åº¦æ‹‰ä¼¸(color transformation by means of piecewise linear contrast stretching)è¿›è¡Œé¢œè‰²å˜æ¢æ¥å¢å¼ºå›¾åƒï¼Œæé«˜å¯¹æ¯”åº¦ï¼› stretched the middle-intensity level, and kept the levels of the low-intensity and high-intensity so as to prevent creating false colors. ç»“æœ è¿›è¡Œå¯¹æ¯”åº¦æ‹‰ä¼¸æ—¶ï¼Œä¸ä¼šæ›´æ”¹åŸå§‹å¤´å‘åƒç´ ï¼Œä¹Ÿä¸ä¼šå¤¸å¤§æ²¹äº®åƒç´ ï¼š é™ä½äº†å¤´çš®åƒç´ çš„å¼ºåº¦; å¢åŠ äº†å¤´çš®å’Œå¤´å‘ä¹‹é—´çš„è‰²å·®; äº®ç‚¹çš„åƒç´ ä¿æŒä¸å˜ã€‚ Bright Spot Removal (BSR) ç›®çš„ é™¤å™ª: å»é™¤æ²¹æ€§å’Œæ¹¿æ¶¦çš„å¤´å‘åœ¨å¤´å‘çš„ä¸­éƒ¨äº§ç”Ÿçš„äº®ç‚¹: æŠ€æœ¯ color morphological processing approach éçº¿æ€§ä¸­å€¼æ»¤æ³¢å™¨(nonlinear median filter)æ¶ˆé™¤ç™½ç‚¹; ç©ºé—´å¹³æ»‘æ»¤æ³¢å™¨(spatial smooth filter)é™ä½ç™½ç‚¹çš„å¼ºåº¦, ç¼ºç‚¹æ˜¯æµ‹è¯•å›¾åƒçš„éæ¯›å‘åŒºåŸŸä¹Ÿå°†å˜å¾—æ¨¡ç³Š; color-based mathematical morphology (MM) method, used it as an ordering process. adopted the MM opening operator to depress the bright spot in the middle of the hairs. ä¾µèš€å›¾åƒ æ”¾å¤§å›¾åƒ opening operation of image f : Î³M,nB(f) = Ï„M,nB(ÎµM,nB(f)), å…¶ä¸­ÎµM,nBå’ŒÏ„M,nBåˆ†åˆ«è¡¨ç¤ºç»“æ„å…ƒç´ Bå¯¹å¤§å°ä¸ºnçš„å›¾åƒfçš„å½¢æ€ä¾µèš€å’Œæ”¾å¤§, å¯¹äºåƒç´ x: ÎµM,nB(f)(x) = {f(y) : f(y) = âˆ§M[f(z)],z âˆˆ n(Bx)} Ï„M,nB(f)(x) = {f(y) : f(y) = âˆ¨M[f(z)],z âˆˆ n(Bx)} âˆ§Må’Œâˆ¨Måˆ†åˆ«è¡¨ç¤ºM-orderingçš„æœ€é«˜å’Œæœ€å°å³° ä½¿ç”¨KLTå°†å½©è‰²å›¾åƒè½¬æ¢ä¸ºç°åº¦å›¾åƒï¼› å›¾åƒäºŒå€¼åŒ–æ­¥éª¤ä¸­ï¼Œä½¿ç”¨äº†Otsué˜ˆå€¼ï¼ˆæŒ‡äº®åº¦çš„èƒ½é‡ï¼‰ä»¥è·å¾—å¯é çš„äºŒå€¼å›¾åƒï¼› ç»“æœ å›¾3ç¤ºå‡ºäº†å»é™¤æ²¹æ€§äº®ç‚¹çš„ç»“æœï¼š å›¾4æ¯”è¾ƒäº†ä½¿ç”¨BSRæ“ä½œæ—¶çš„çº¿è·¯æ£€æµ‹ï¼Œå¹¶æ˜¾ç¤ºäº†å¯¹äºŒå€¼åŒ–å’Œç»†åŒ–æ“ä½œçš„æ˜æ˜¾å½±å“ã€‚å¸¦æœ‰BSRçš„äºŒå€¼åŒ–å›¾åƒå…·æœ‰å‡å°‘çš„äº®ç‚¹åå°„ï¼Œå¹¶ä¸”åœ¨ç»†åŒ–å›¾åƒä¸­ï¼Œäº®ç‚¹è¢«è½¬æ¢ä¸ºå°åœ†åœˆã€‚å›¾4ï¼ˆfï¼‰æ˜¾ç¤ºï¼Œåœ¨çº¿æ£€æµ‹é˜¶æ®µï¼Œä½¿ç”¨BSRç”Ÿæˆçš„å›¾åƒå…·æœ‰è¾ƒå°‘çš„ä¸å¿…è¦çš„çº¿æ®µï¼š Multi-scale Line Detection Stage (MSLD) é‡‡ç”¨æ”¹è¿›çš„éœå¤«å˜æ¢(the Hough transform)ç®—æ³•æ¥æ£€æµ‹ä¸åŒçš„å¤´å‘é•¿åº¦ï¼Œå¹¶å‡å°‘ç”±äºå™ªå£°å¼•èµ·çš„ä»»ä½•é”™è¯¯æ£€æµ‹; å°†å¼¯æ›²çš„å¤´å‘è§†ä¸ºå¤šæ¡ç›´çº¿; ä¸ºäº†é¿å…åœ¨åº”ç”¨ç¨€ç–è¿‡ç¨‹æ—¶ä¸¢å¤±å¤´å‘ï¼Œæˆ‘ä»¬ä½¿ç”¨è¾¹ç¼˜ä¿¡æ¯(edge information)æ¥å‘ç°ä»»ä½•éšè—æˆ–é‡å çš„å¤´å‘ã€‚ æ€»ä½“ç»“æ„åˆ†æ ç›®çš„ æå‡ºå¤šå°ºåº¦æ¡†æ¶æ¥æ˜¯ä¸ºäº†æé«˜å¤´å‘æ£€æµ‹çš„å‡†ç¡®æ€§ï¼› åº”ç”¨å¹³è¡Œçº¿æ†ç»‘ï¼ˆPLBï¼‰ç®—æ³•ï¼ˆparallel line bundling algorithmï¼‰æ¥è¿˜åŸä»»ä½•éšè—æˆ–é‡å çš„å¤´å‘ã€‚ æœ€åï¼Œå°†çŸ¢é‡åŒ–çš„çº¿æ®µç”¨ä½œæ¯›å‘æ ‡è®°å’Œè®¡æ•°æ¨¡å—çš„è¾“å…¥æ•°æ®ã€‚ æŠ€æœ¯ å¯¹HTåº”ç”¨äº†ä¸‰ä¸ªæ¯”ä¾‹çš„å›¾åƒï¼š1024Ã—768ï¼ˆåŸå§‹æ¯”ä¾‹ï¼‰ï¼Œ512Ã—384å’Œ256Ã—192ã€‚å¯¹ç¼©æ”¾æ¯”ä¾‹å›¾åƒåº”ç”¨äº†ä¸¤ç§å¤„ç†æ–¹æ³•ï¼šè¾¹ç¼˜æ£€æµ‹å’Œç»†åŒ–å¤„ç†ã€‚ PLBç®—æ³•åº”ç”¨äºè¾¹ç¼˜å›¾åƒä»¥å‘ç°ç¼ºå¤±çš„çº¿æ®µ HTè¢«åº”ç”¨äºç»†åŒ–å›¾åƒä»¥æå–çº¿æ®µã€‚é€šè¿‡åˆ©ç”¨PLBç®—æ³•ï¼Œå¯ä»¥æ¢å¤éšè—å’Œé‡å çš„å¤´å‘ã€‚ æœ€åï¼Œå°†çŸ¢é‡åŒ–çš„çº¿æ®µé‡æ–°ç¼©æ”¾ä¸ºåŸå§‹å°ºå¯¸1024Ã—768ï¼Œå¹¶ç”±é€»è¾‘æˆ–è¿ç®—ç¬¦è¿›è¡Œæ•´åˆã€‚ ç»“æœ å¦‚å›¾5æ‰€ç¤ºï¼Œç”±äºå¤´å‘çš„é•¿åº¦å’Œå·æ›²åº¦çš„å˜åŒ–ï¼Œä½¿ç”¨å•å°ºåº¦HTä¸èƒ½æ£€æµ‹æ‰€æœ‰çš„å¤´å‘ï¼š å›¾5ï¼ˆaï¼‰æ˜¾ç¤ºï¼Œå½“ä¸€æ ¹å¤´å‘å‡ ä¹å¹³è¡Œå‡ºç°ï¼Œä¸å…¶ä»–å¤´å‘é‡å æ—¶ï¼Œæˆ–è€…å¦‚æœå¤´å‘çš„æ›²ç‡è¶…è¿‡HTçš„å®¹é™ï¼Œé‚£ä¹ˆæœ€ç»ˆä¼šé—æ¼å¤§é‡çš„å¤´å‘ï¼Œè®¸å¤šçº¿æ®µæ ‡ç­¾é”™è¯¯ã€‚ å›¾5ï¼ˆbï¼‰ç¤ºå‡ºäº†ä½¿ç”¨æ¥è‡ªæ‰€æœ‰ç¼©æ”¾å›¾çš„çº¿æ®µçš„ç»“æœï¼Œä»è€Œæ”¹å–„äº†å•ä¸ªåˆ»åº¦çš„ä¸è¶³ã€‚ Parallel Line Bundling (PLB) åŸç† åº”ç”¨Cannyè¾¹ç¼˜æ£€æµ‹å™¨è·å¾—è¾¹ç¼˜å›¾ã€‚åœ¨å›¾6ä¸­ï¼Œå‡è®¾æ£€æµ‹åˆ°ä¸¤æ¡å¹³è¡Œçº¿Aå’ŒBï¼Œç”¨ax+by+ca=0ax + by + c_a = 0ax+by+caâ€‹=0å’Œax+by+cb=0ax + by + c_b = 0ax+by+cbâ€‹=0è¡¨ç¤º, d=âˆ£caâˆ’cbâˆ£a2+b2d=\\frac{|c_a - c_b|} {\\sqrt{a^2 + b^2}}d=a2+b2â€‹âˆ£caâ€‹âˆ’cbâ€‹âˆ£â€‹è¡¨ç¤ºçº¿æ®µA,Bä¹‹é—´çš„è·ç¦»; è®¡ç®—å‡ºå¤¹æœ‰ç»†çº¿çš„å¹³è¡Œçº¿ä¹‹é—´çš„å¹³å‡è·ç¦»davgd_{avg}davgâ€‹ã€‚ å¦‚æœd&gt;davgd &gt; d_{avg}d&gt;davgâ€‹ï¼Œåˆ™å½“(ddavg)&gt;wth(dd_{avg})&gt;w_{th}(ddavgâ€‹)&gt;wthâ€‹æ—¶ï¼Œå°†å‘ç°éšè—çš„å¤´å‘ï¼Œå…¶ä¸­wthw_{th}wthâ€‹è¡¨ç¤ºè¾¹ç•Œå› å­ï¼Œå°†é€šè¿‡å¤´çš®å›¾åƒçš„åˆ†è¾¨ç‡æ ¹æ®ç»éªŒè¿›è¡Œä¿®æ”¹ã€‚ ç»“æœ åœ¨å›¾7ï¼ˆaï¼‰ä¸­ï¼Œåœ†åœˆè¡¨ç¤ºéšè—çš„å¤´å‘ï¼Œå¦‚å›¾7ï¼ˆbï¼‰æ‰€ç¤ºï¼š Hair Labling and Counting ä½¿ç”¨MSLDæ¨¡å—ï¼Œå¾—å‡ºäº†ä¸€ç»„çº¿æ®µã€‚æ ¹æ®å¤´å‘çš„æ›²ç‡å’Œæ–¹å‘ï¼Œå°†å¤´å‘å®ç°ä¸ºå…·æœ‰ä¸åŒé•¿åº¦çš„åˆ†æ®µçº¿å‘é‡ç°‡ã€‚è¿™é¡¹ç ”ç©¶çš„ç›®çš„æ˜¯å‡†ç¡®è®¡ç®—å¤´çš®ä¸Šçš„æ¯›å‘æ•°é‡ã€‚è¿™å¯ä»¥çœ‹ä½œæ˜¯èšç±»å’Œæ ‡è®°é—®é¢˜ã€‚ç›®æ ‡æ˜¯å°†ä¸€ç»„çº¿æ®µç»„åˆæˆè¯­ä¹‰â€œå¤´å‘â€å¹¶åˆ†é…å”¯ä¸€çš„æ ‡ç­¾ã€‚ç”±äºæ¯æ ¹å¤´å‘éƒ½ç”±ç›¸äº’å…³è”çš„çº¿æ®µç»„æˆï¼Œå› æ­¤æˆ‘ä»¬ä¸ºæ¯ä¸ªç°‡åˆ†é…äº†å”¯ä¸€çš„æ ‡ç­¾ã€‚ æˆ‘ä»¬é‡‡ç”¨äº†æ¾å¼›æ ‡è®°ç®—æ³•(Relaxation labeling algorithm)æ¥è¯†åˆ«æ¯ä¸ªå•ç‹¬çš„çº¿æ®µï¼Œä»¥ç¡®å®šä¸å“ªä¸ªçº¿æ®µç›¸å…³è”ã€‚ å›¾8ï¼ˆaï¼‰æ˜¾ç¤ºäº†10ä¸ªå•ç‹¬çš„çº¿æ®µçš„ç¤ºä¾‹ï¼Œè¿™äº›çº¿æ®µè¢«æ ‡è®°ä¸ºæ¥è‡ªåŒä¸€æ ¹å¤´å‘ï¼Œç„¶åç»˜åˆ¶åˆ°ï¼ˆÏï¼ŒÎ¸ï¼‰ï¼ˆÏï¼ŒÎ¸ï¼‰ï¼ˆÏï¼ŒÎ¸ï¼‰åæ ‡ç³»ä¸Šï¼Œå¦‚å›¾8ï¼ˆbï¼‰æ‰€ç¤ºã€‚ äº¤å‰ç‚¹å¤„ç´¯ç§¯å›¾çš„ç»“æœå³°å€¼ä¸º10ã€‚ Relaxation Labeling (RL) æ¾å¼›æ ‡æ³¨ï¼ˆRLï¼‰æ˜¯ä¸€ç§ç›¸äº’å…³è”çš„å›å½’æ–¹æ³•ï¼Œå®ƒä½¿ç”¨ç¬¦å·æ¥æè¿°æ¨¡å‹çš„å½¢çŠ¶ã€‚ å®ƒæ—¨åœ¨å°†ç›®æ ‡å¯¹è±¡ï¼ˆå³æœ¬æ–‡ä¸­çš„çº¿æ®µï¼‰ä¸ç¬¦å·æˆ–æ‰€è°“çš„æ ‡è®°ï¼ˆå³å¤´å‘æ ‡ç­¾ï¼‰è¿›è¡ŒåŒ¹é…ã€‚RLç®—æ³•é¦–å…ˆåˆ†é…ä¸€ç»„éšæœºæ ‡è®°ã€‚ç„¶åï¼Œé€šè¿‡è¿­ä»£è®¡ç®—ï¼Œå¯ä»¥è·å¾—æ›´å‡†ç¡®ï¼Œæ›´ç²¾ç¡®çš„æ ‡è®°é›†ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼ŒRLç®—æ³•è¢«è§†ä¸ºç”¨äºæ ‡è®°æ¯ä¸ªçº¿æ®µçš„èšç±»æ–¹æ³•ã€‚ åŸç† ä»¤C(iï¼ŒÎ»ï¼Œjï¼ŒÎ»â€²)C(iï¼ŒÎ»ï¼Œjï¼ŒÎ»&#x27;)C(iï¼ŒÎ»ï¼Œjï¼ŒÎ»â€²)è¡¨ç¤ºçº¦æŸä¸ºÎ»çš„çº¿æ®µä¸çº¦æŸä¸ºÎ»â€™çš„çº¿æ®µjçš„å…¼å®¹æ€§ï¼Œå…¶çº¦æŸä¸º: âˆ‘Î»C(iï¼ŒÎ»ï¼Œjï¼ŒÎ»â€²)=1\\displaystyle\\sum_{Î»}C(iï¼ŒÎ»ï¼Œjï¼ŒÎ»&#x27;) = 1Î»âˆ‘â€‹C(iï¼ŒÎ»ï¼Œjï¼ŒÎ»â€²)=1 for âˆ€i,j,Î»,Î»'ã€‚ å…¼å®¹æ€§Cè¡¨ç¤ºæ ‡è®°ä¸ºÎ»â€™çš„çº¿æ®µjå’Œæ ‡è®°ä¸ºÎ»çš„çº¿æ®µiä¹‹é—´çš„ç›¸äº’ä¾èµ–æ€§ã€‚ å¦‚æœå…¼å®¹æ€§ä»…ç”±åˆ°åŸç‚¹çš„è·ç¦»å†³å®šï¼Œåˆ™å¯èƒ½ä¼šå‡ºç°é”™è¯¯çš„è§£é‡Šã€‚ å› æ­¤å°†å…¼å®¹æ€§å®šä¹‰å¦‚ä¸‹ï¼š C(iï¼ŒÎ»ï¼Œjï¼ŒÎ»â€²)={âˆ’1if iâˆ‰SjÎµâˆ£cosâ¡[Î¸i(Î»)âˆ’Î¸j(Î»â€²)]âˆ£+(1âˆ’Îµ)Ïi(Î»)Ïj(Î»â€²)if iâˆˆSjâˆ©Î»=/ Î»â€²0otherwise C(iï¼ŒÎ»ï¼Œjï¼ŒÎ»&#x27;) = \\begin{cases} -1 &amp;\\text{if } i \\notin S_j \\\\ \\varepsilon |\\cos[\\theta_i(\\lambda) - \\theta_j(Î»&#x27;)]| + (1-\\varepsilon) \\frac{\\rho_i(\\lambda)}{\\rho_j(Î»&#x27;)} &amp;\\text{if } iâˆˆS_jâˆ©Î»{=}\\mathllap{/\\,}Î»&#x27; \\\\ 0 &amp;\\text{otherwise } \\end{cases} C(iï¼ŒÎ»ï¼Œjï¼ŒÎ»â€²)=â©âªâ¨âªâ§â€‹âˆ’1Îµâˆ£cos[Î¸iâ€‹(Î»)âˆ’Î¸jâ€‹(Î»â€²)]âˆ£+(1âˆ’Îµ)Ïjâ€‹(Î»â€²)Ïiâ€‹(Î»)â€‹0â€‹if iâˆˆ/â€‹Sjâ€‹if iâˆˆSjâ€‹âˆ©Î»=/â€‹Î»â€²otherwise â€‹ ä¸Šå¼ä¸­ï¼š Îµè¡¨ç¤ºè·ç¦»å’Œæ–¹å‘ç½®ä¿¡åº¦ä¹‹é—´çš„åŠ æƒå› å­ SjS_jSjâ€‹è¡¨ç¤ºçº¿æ®µjçš„ç›¸é‚»å‡è®¾ Î¸i(Î»)Î¸_i(Î»)Î¸iâ€‹(Î»)è¡¨ç¤ºä»çº¿æ®µiåˆ°æ ‡è®°ä¸ºÎ»çš„çº¿æ®µjçš„æ–¹å‘ Ïi(Î»)Ï_i(Î»)Ïiâ€‹(Î»)è¡¨ç¤ºåŸç‚¹åˆ°çº¿æ®µiå’Œæ ‡è®°ä¸ºÎ»çš„çº¿æ®µjä¹‹é—´çš„è·ç¦» å¦‚æœÏj(Î»)Ï_j(Î»)Ïjâ€‹(Î»)é«˜, ä¸”C(iï¼ŒÎ»ï¼Œjï¼ŒÎ»â€²)C(iï¼ŒÎ»ï¼Œjï¼ŒÎ»&#x27;)C(iï¼ŒÎ»ï¼Œjï¼ŒÎ»â€²)ä¸ºæ­£ï¼Œåˆ™Ïi(Î»)Ï_i(Î»)Ïiâ€‹(Î»)å¢åŠ ã€‚ æ­¤æ ‡è®°ç®—æ³•æ˜¯ä¸€ä¸ªè¿­ä»£å¹¶è¡Œè¿‡ç¨‹ï¼Œç±»ä¼¼äºæ¦‚ç‡æ¾å¼›ä¸­ä½¿ç”¨çš„æ ‡è®°ä¸¢å¼ƒè§„åˆ™ï¼Œæ“ä½œå‘˜æ ¹æ®å…¶ä»–é‡é‡å’Œå…¼å®¹æ€§åå¤è°ƒæ•´æ ‡ç­¾é‡é‡ã€‚ å¯¹äºæ¯ä¸ªçº¿æ®µå’Œæ¯ä¸ªæ ‡ç­¾ï¼Œæ–°æƒé‡qi(r)(Î»)q_i^{(r)}(\\lambda)qi(r)â€‹(Î»)çš„è®¡ç®—å¦‚ä¸‹ï¼š qi(r)(Î»)=âˆ‘j,j=/ iâˆ‘Î»â€²C(iï¼ŒÎ»ï¼Œjï¼ŒÎ»â€²)pj(r)(Î»â€²)q_i^{(r)}(\\lambda) = \\sum_{\\mathclap{j, j{=}\\mathllap{/\\,}i}} \\sum_{\\mathclap{Î»&#x27;}}C(iï¼ŒÎ»ï¼Œjï¼ŒÎ»&#x27;)p_j^{(r)}(Î»&#x27;) qi(r)â€‹(Î»)=j,j=/â€‹iâ€‹âˆ‘â€‹Î»â€²âˆ‘â€‹C(iï¼ŒÎ»ï¼Œjï¼ŒÎ»â€²)pj(r)â€‹(Î»â€²) å…¶ä¸­: rè¡¨ç¤ºç¬¬ræ¬¡è¿­ä»£ åœ¨ç­‰å¼ä¸­ï¼Œä¹˜ç§¯å’Œæ˜¯è¢«æ ‡è®°ä¸ºÎ»çš„ç»™å®šçº¿æ®µiçš„æœŸæœ› qi(r)(Î»)q_i^{(r)}(\\lambda)qi(r)â€‹(Î»)æ˜¯å½“å‰èµ‹å€¼pj(r)(Î»â€²)p_j^{(r)}(Î»&#x27;)pj(r)â€‹(Î»â€²)çš„åŠ æƒå’Œã€‚ æ–°ä»»åŠ¡å¯ä»¥ç”¨å·²ä¸‹å…¬å¼æ›´æ–°ï¼š pi(r+1)(Î»)=pi(r)(Î»)[1+qi(r)(Î»)]âˆ‘j=1mpi(r)(Î»â€²)[1+qi(r)(Î»â€²)]p_i^{(r+1)}(\\lambda) = \\frac{p_i^{(r)}(Î»)[1+q_i^{(r)}(Î»)]}{\\displaystyle\\sum_{j=1}^mp_i^{(r)}(Î»&#x27;)[1+q_i^{(r)}(Î»&#x27;)]} pi(r+1)â€‹(Î»)=j=1âˆ‘mâ€‹pi(r)â€‹(Î»â€²)[1+qi(r)â€‹(Î»â€²)]pi(r)â€‹(Î»)[1+qi(r)â€‹(Î»)]â€‹ åœ¨è¿™é‡Œï¼Œåªé€‰æ‹©pi(r)(Î»)p_i^{(r)}(\\lambda)pi(r)â€‹(Î»)å’ŒC(iï¼ŒÎ»ï¼Œjï¼ŒÎ»â€²)C(iï¼ŒÎ»ï¼Œjï¼ŒÎ»&#x27;)C(iï¼ŒÎ»ï¼Œjï¼ŒÎ»â€²)å¹¶åº”ç”¨è¯¥ç­‰å¼é€’å½’æ›´æ–°pi(r)(Î»)p_i^{(r)}(\\lambda)pi(r)â€‹(Î»)ï¼Œç›´åˆ°å®ƒä»¬åœæ­¢å˜åŒ–æˆ–æ”¶æ•›åˆ°1ã€‚å¯¹æ¯ä¸ªçº¿æ®µè¿›è¡Œè¿­ä»£éªŒè¯ï¼Œç›´åˆ°å°†å…¶åˆ†é…ç»™æ­£ç¡®çš„è¯­ä¹‰æ ‡ç­¾â€œ hairâ€ä¸ºæ­¢ã€‚ å®éªŒç»“æœ ä¸ºäº†è¯„ä¼°è¯¥ç³»ç»Ÿï¼Œæˆ‘ä»¬ä»UPMOSTï¼ˆUPG622ï¼‰DMCæ•è·äº†40ä¸ªåˆ†è¾¨ç‡ä¸º1024Ã—768çš„æ¯”ä¾‹å°ºå›¾åƒä½œä¸ºæµ‹è¯•æ•°æ®é›†ã€‚æ ¹æ®DMCçš„ç™½å¹³è¡¡ï¼Œæˆ‘ä»¬å°†æµ‹è¯•å›¾åƒåˆ†ä¸ºä¸¤ç»„ï¼Œåˆ†åˆ«æ˜¯æ•°æ®é›†1å’Œæ•°æ®é›†2ã€‚ Experiment 1: Cross-Validation of the Line Detection å›¾10ï¼ˆbï¼‰-ï¼ˆdï¼‰æ˜¾ç¤ºäº†é¢„å¤„ç†æ¨¡å—çš„ç»“æœï¼ŒåŒ…æ‹¬äº®ç‚¹å»é™¤ï¼ˆBSRï¼‰ï¼ŒäºŒå€¼åŒ–å’Œç¨€åŒ–è¿‡ç¨‹ã€‚ ä¸ºäº†è¯„ä¼°å¤šå°ºåº¦çº¿æ£€æµ‹ç®—æ³•çš„æ€§èƒ½ï¼Œæµ‹è¯•å›¾åƒæˆ‘ä»¬å°†HTåº”ç”¨äºä¸‰ç§ä¸åŒå°ºåº¦ï¼Œä»¥æå–çº¿æ®µã€‚ ç„¶åä½¿ç”¨å¤´å‘æ ‡ç­¾æœºåˆ¶ç¡®å®šå¤´å‘çš„æ•°é‡ã€‚ å¦‚å›¾10ï¼ˆeï¼‰-ï¼ˆfï¼‰æ‰€ç¤ºï¼Œå½©è‰²çº¿ä»£è¡¨å¤´å‘çš„æ ‡ç­¾ã€‚ æ¢å¥è¯è¯´ï¼Œå³ä½¿å¤´å‘äº¤å‰æˆ–é‡å ï¼Œä¹Ÿå¯ä»¥å‡†ç¡®åœ°æ ‡è®°å¤´å‘ã€‚ ä»¥ä¸‹éƒ¨åˆ†æ¼”ç¤ºäº†æœ‰å…³ç²¾ç¡®åº¦å’Œå¬å›ç‡çš„æ¯›å‘è®¡æ•°çš„å®¢è§‚æµ‹é‡ã€‚ æˆ‘ä»¬æ¯”è¾ƒäº†ä½¿ç”¨BSRå’ŒMSLDæ¨¡å—ç»„åˆçš„å››ç§æƒ…å†µï¼ŒåŒ…æ‹¬BSR + MSLDï¼Œè€Œæ²¡æœ‰åŒæ—¶ä½¿ç”¨BSRå’ŒMSLDï¼Œä»…BSRå’Œä»…MSLDã€‚ è¡¨Iæ¯”è¾ƒäº†åŸºäºæ¨¡å—ä½¿ç”¨æƒ…å†µçš„ç³»ç»Ÿæ•æ„Ÿæ€§ã€‚åŸºäºå½¢æ€å­¦çš„BSRå’ŒMSLDæœºåˆ¶ï¼Œä»¥æé«˜å¤´å‘æ£€æµ‹çš„æ€§èƒ½ï¼Œå…¶å‡†ç¡®ç‡åˆ†åˆ«ä¸º94.98ï¼…å’Œ98.05ï¼…ã€‚ä¸ä¼ ç»Ÿçš„HTçº¿æ£€æµ‹æ–¹æ³•ç›¸æ¯”ï¼Œæ•°æ®é›†1å’Œæ•°æ®é›†2åˆ†åˆ«æé«˜äº†2ï¼…å’Œ1.5ï¼…ã€‚ä»å¬å›ç‡çš„è§’åº¦æ¥çœ‹ï¼Œå®ƒä¹Ÿé«˜äºå…¶ä»–æ¨¡å—ç»„åˆã€‚ å¹³å‡è€Œè¨€ï¼Œæˆ‘ä»¬çš„å¬å›ç‡åˆ†åˆ«ä¸º9ï¼…å’Œ10ï¼…ã€‚æ ¹æ®æˆ‘ä»¬çš„è§‚å¯Ÿï¼Œåº”ç”¨BSRåï¼Œå‡†ç¡®ç‡å¾—åˆ°äº†æé«˜ã€‚ ä½†æ˜¯ï¼Œå°†MSLDåº”ç”¨äºæ•°æ®é›†ï¼ƒ2æ—¶ï¼Œå‡†ç¡®ç‡ä¸‹é™ï¼Œå› ä¸ºå®ƒåœ¨æ²¹æ€§å¤´çš®åŒºåŸŸä¸­äº§ç”Ÿäº†å¤§é‡çš„å…‰åå°„ã€‚åŒæ ·ï¼Œå¤´å‘ä¸­éƒ¨çš„äº®ç‚¹ä¹Ÿè¢«å¤§å¤§å¢å¼ºï¼Œå¯¼è‡´ç²¾ç¡®åº¦é™ä½ã€‚ Experiment 2: System Refinement Using the PLB Algorithm è¡¨IIæ˜¾ç¤ºäº†PLBç®—æ³•çš„æ•ˆç‡ã€‚PLBæ–¹æ³•ä½¿ç³»ç»Ÿèƒ½å¤Ÿæå–ç¼ºå¤±çš„æ¯›å‘ï¼Œç²¾ç¡®ç‡æé«˜äº†0.5ï¼…ï¼Œå¬å›ç‡æé«˜äº†5ï¼…ã€‚ PLBç®—æ³•å¯ä»¥ç”¨ä½œç³»ç»Ÿå¾®è°ƒè¿‡ç¨‹ï¼Œå°†ç³»ç»Ÿæ€§èƒ½å¹³å‡æé«˜åˆ°96.89ï¼…ã€‚è¿™æ˜¯åˆç†çš„ï¼Œå› ä¸ºéšè—çš„å¤´å‘ä¸ç»å¸¸å‡ºç°ã€‚ æ­¤å¤–ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æ˜¾å¾®é•œæ§åˆ¶å¤´å‘å›¾åƒçš„åˆ†è¾¨ç‡å’Œè§’åº¦ï¼Œä»¥é¿å…è¿™ç§æƒ…å†µã€‚ Experiment 3: Complexity Analysis å½“æ¶‰åŠåˆ°ç³»ç»Ÿå¤æ‚æ€§åˆ†ææ—¶ï¼Œæˆ‘ä»¬çŸ¥é“æ‹Ÿè®®çš„å¤´å‘è®¡æ•°ç³»ç»Ÿä¼šèŠ±è´¹æ›´å¤šæ—¶é—´ã€‚å¹³å‡è€Œè¨€ï¼Œé«˜åˆ†è¾¨ç‡æµ‹è¯•å›¾åƒéœ€è¦ä¸åˆ°4ç§’çš„æ—¶é—´å³å¯å¾—å‡ºæ¯›å‘è®¡æ•°ä¿¡æ¯ã€‚ è¡¨IIIåˆ—å‡ºäº†æ¯ä¸ªæ¨¡å—æ‰€éœ€çš„æ—¶é—´ä¸æ€»æ‰§è¡Œæ—¶é—´çš„æ¯”è¾ƒã€‚ MSLDä½¿ç”¨ä¸‰ä¸ªæ¯”ä¾‹å°ºæ¥è·å–ä¸€ç»„çº¿æ®µï¼Œè¿™éœ€è¦å¤§éƒ¨åˆ†æ‰§è¡Œæ—¶é—´ã€‚ HTå°†è¾¹ç¼˜æŠ•å½±åˆ°ï¼ˆÏï¼ŒÎ¸ï¼‰ç©ºé—´ä»¥æå–å±€éƒ¨æœ€å¤§å€¼çš„è¿‡ç¨‹éå¸¸è€—æ—¶ã€‚ ä¸ºäº†å…‹æœè¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬åœ¨MSLDä¸­ä»…ä½¿ç”¨äº†ä¸¤ä¸ªæ ‡åº¦ã€‚ä½†æ˜¯ï¼Œæ­¤å°è¯•å¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚ æ­¤å¤–ï¼Œç»†åŒ–è¿‡ç¨‹å ç”¨äº†æ€»å¤„ç†æ—¶é—´çš„å››åˆ†ä¹‹ä¸€ä»¥ä¸Šã€‚è¿™æ˜¯æ‰§è¡Œæ—¶é—´å’Œç³»ç»Ÿç²¾åº¦ä¹‹é—´çš„æƒè¡¡ã€‚ æ€»ç»“ è¿™é¡¹ç ”ç©¶æå‡ºäº†ä¸€ç§è‡ªåŠ¨çš„å¤´å‘åˆ†å‰²å’Œè®¡æ•°ç³»ç»Ÿï¼Œä»¥å‡å°‘äººå·¥è¯„ä¼°è€…è¿›è¡Œè¯¦ç»†å¤´çš®è¯„ä¼°æ‰€éœ€çš„æ—¶é—´ã€‚ é¦–å…ˆï¼Œæ²¹æ€§å’Œæ¹¿æ¶¦çš„å¤´å‘ä¼šåœ¨å¤´å‘ä¸­é—´äº§ç”Ÿäº®ç‚¹ã€‚åœ¨è®¡ç®—å¤´å‘æ•°ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦æ¶ˆé™¤å¤´å‘ä¸Šçš„äº®ç‚¹ï¼Œä»¥é¿å…é‡å¤è®¡ç®—ä¸€äº›å¤´å‘çš„é—®é¢˜ã€‚ ç¬¬äºŒï¼Œæ³¢æµªçŠ¶å’Œå·å‘å®¹æ˜“å¯¼è‡´çº¿æ£€æµ‹æ•…éšœã€‚å½“å¤´å‘ä¸ç›´æ—¶ï¼Œå¸¸è§„çš„çº¿æ£€æµ‹ç®—æ³•æ— æ•ˆã€‚ ç¬¬ä¸‰ï¼Œå½“å¤´å‘ç›¸äº’äº¤å‰å¹¶äº’ç›¸å’¬åˆæ—¶ï¼Œä¼šå‡ºç°å¯¹å¤´å‘æ•°é‡çš„ä½ä¼°ï¼Œè¿™ä½¿å¾—ç²¾ç¡®å®šä½æ‰€æœ‰å¤´å‘éå¸¸å›°éš¾ã€‚ æœ€åï¼Œç”±äºå¤´çš®ç›¸å¯¹æœªæ›å…‰ï¼Œå› æ­¤å¤´çš®çš„å›¾åƒé€šå¸¸æ¨¡ç³Šæˆ–éš¾ä»¥çœ‹è§ã€‚å¦å¤–ï¼Œå¤´çš®é€šå¸¸ç…§æ˜ä¸è¶³æˆ–æ›å…‰è¿‡åº¦ã€‚ è®¡æ•°æ€è·¯ é€šè¿‡å¯¹ä¸åŒç¼©ç•¥å›¾ä¸­çš„å¤´å‘åšHTçº¿æ®µæ£€æµ‹ï¼Œç„¶åå°†æ‰€æœ‰æ£€æµ‹ç»“æœè¿›è¡Œâ€œé€»è¾‘æˆ–â€æ•´åˆï¼Œä»¥å‡å°‘ç¼ºå¤±å¤´å‘çš„è®¡æ•°ï¼Œè§£å†³é‡å å¤´å‘çš„æ¼è®¡æ•°çš„é—®é¢˜ã€‚ æœ¬æ–‡çš„æ¡†æ¶å¯ä»¥è¢«è§†ä¸ºè¿ˆå‘åŒ–å¦†å“å’Œå¤´çš®æ²»ç–—åº”ç”¨çš„æ™ºèƒ½è®¡ç®—æœºè¾…åŠ©åŒ»å­¦å›¾åƒå¤„ç†çš„ç¬¬ä¸€æ­¥ã€‚ æŠ€æœ¯æ€»ç»“ é¢„å¤„ç†é˜¶æ®µ å¯¹è¾“å…¥æ•°æ®ï¼ˆå¤´çš®å›¾ç‰‡ï¼‰è¿›è¡Œé¢„å¤„ç†ï¼Œä¸ºä¸‹ä¸€é˜¶æ®µå¯¹å›¾ç‰‡ä¸­å¤´å‘è¿›è¡Œç²¾å‡†è®¡æ•°ç­‰åŠŸèƒ½æ€§æ“ä½œåšå¥½é“ºå«ã€‚ä¸»è¦ç”¨åˆ°ä»¥ä¸‹æŠ€æœ¯ï¼š Contrast Stretching (Normalization): å¯¹æ¯”åº¦æ‹‰ä¼¸ï¼ˆé€šå¸¸ç§°ä¸ºå½’ä¸€åŒ–ï¼‰æ˜¯ä¸€ç§ç®€å•çš„å›¾åƒå¢å¼ºæŠ€æœ¯,æ—¨åœ¨é€šè¿‡â€œæ‹‰ä¼¸â€å›¾åƒæ‰€åŒ…å«çš„å¼ºåº¦å€¼èŒƒå›´ä»¥è¦†ç›–æ‰€éœ€çš„å€¼èŒƒå›´æ¥æ”¹å–„å›¾åƒçš„å¯¹æ¯”åº¦ã€‚ æŠ€æœ¯åº”ç”¨ï¼šå¢åŠ å¤´çš®ä¸å¤´å‘ä¹‹é—´çš„å¯¹æ¯”åº¦ï¼Œæ–¹ä¾¿ä¸‹é˜¶æ®µå¯¹å¤´å‘è¿›è¡Œè¯­ä¹‰åˆ†å‰²ã€‚ Color Morphology EXTENDING MATHEMATICAL MORPHOLOGY TO COLOR IMAGE PROCESSING æŠ€æœ¯åº”ç”¨ï¼š é™¤å™ªï¼Œå»é™¤æ²¹æ€§å’Œæ¹¿æ¶¦çš„å¤´å‘åœ¨å¤´å‘çš„ä¸­éƒ¨äº§ç”Ÿçš„äº®ç‚¹ Karhunen-Loeve Transform (KLT) Karhunen-Loeveå˜æ¢ï¼ˆKLTï¼‰ï¼ˆä¹Ÿç§°ä¸ºHotellingå˜æ¢å’Œç‰¹å¾å‘é‡å˜æ¢ï¼‰ï¼Œå®ƒä¸ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰å¯†åˆ‡ç›¸å…³ï¼Œå¹¶å¹¿æ³›ç”¨äºè®¸å¤šé¢†åŸŸçš„æ•°æ®åˆ†æä¸­, KLå˜æ¢åŸºäºå›¾åƒçš„ç»Ÿè®¡å±æ€§ï¼Œå¹¶å…·æœ‰ä¸€äº›é‡è¦çš„å±æ€§ï¼Œä½¿å…¶å¯ç”¨äºå›¾åƒå¤„ç†ï¼Œç‰¹åˆ«æ˜¯å›¾åƒå‹ç¼©ã€‚ æŠ€æœ¯åº”ç”¨ï¼š å°†å½©è‰²å›¾åƒè½¬æ¢ä¸ºç°åº¦å›¾åƒã€‚ Otsu thresholding Otsu thresholdingï¼šç®€å•è¯´æ¥è¯¥æ–¹æ³•å¯å°†ç°åº¦å›¾åƒè¿˜åŸä¸ºäºŒè¿›åˆ¶å›¾åƒã€‚åœ¨å›¾åƒå¤„ç†å’Œåˆ†æä¸­ï¼Œæœ‰æ—¶éœ€è¦ä¸€ç§æ–¹æ³•æ¥åˆ†ç¦»ä¸¤ä¸ªç›¸å…³æ•°æ®ï¼Œä¾‹å¦‚èƒŒæ™¯å’Œå‰æ™¯ã€‚Otsué˜ˆå€¼æ˜¯ä¸€ç§æ•°æ®é©±åŠ¨çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥è‡ªé€‚åº”åœ°æ‰¾åˆ°æœ€ä½³é˜ˆå€¼ä»¥åŒºåˆ†ä¸¤ç±»æ•°æ®ã€‚ æŠ€æœ¯åº”ç”¨ï¼š å›¾åƒåˆ†å‰²å’Œå›¾åƒäºŒå€¼åŒ–ã€‚ å¤šå°ºåº¦çº¿æ£€æµ‹é˜¶æ®µï¼ˆMSLDï¼‰ è¯¥é˜¶æ®µä¸»è¦æ˜¯é€šè¿‡å„ç§æŠ€æœ¯ï¼Œå…‹æœé‡å å¤´å‘æ— æ³•è®¡æ•°ï¼Œä»¥åŠç›¸é‚»å¤´å‘ä¹‹é—´çš„å¤´çš®è¢«è¯†åˆ«ä¸ºå¤´å‘ç­‰å½±å“å¤´å‘è®¡æ•°çš„ç›¸å…³é—®é¢˜ã€‚ä¸ºä¸‹é˜¶æ®µå¯¹å¤´å‘è¿›è¡Œç²¾å‡†è®¡æ•°çš„åšå¥½é“ºå«ã€‚ä¸»è¦ç”¨åˆ°ä»¥ä¸‹æŠ€æœ¯ï¼š éœå¤«å˜æ¢ï¼ˆHT) éœå¤«å˜æ¢ï¼ˆHTï¼‰ éœå¤«å˜æ¢æ˜¯ä¸€ç§å¯ç”¨äºéš”ç¦»å›¾åƒä¸­ç‰¹å®šå½¢çŠ¶çš„ç‰¹å¾çš„æŠ€æœ¯ã€‚å› ä¸ºå®ƒè¦æ±‚ä»¥æŸç§å‚æ•°å½¢å¼æŒ‡å®šæ‰€éœ€çš„ç‰¹å¾ï¼Œæ‰€ä»¥ç»å…¸çš„Houghå˜æ¢æœ€å¸¸ç”¨äºæ£€æµ‹è§„åˆ™æ›²çº¿ï¼ˆä¾‹å¦‚ç›´çº¿ï¼Œåœ†ï¼Œæ¤­åœ†ç­‰ï¼‰ã€‚ æŠ€æœ¯åº”ç”¨ï¼š HTæ˜¯æœ€å¸¸ç”¨çš„çº¿æ£€æµ‹æ¡†æ¶ä¹‹ä¸€ã€‚ä½†æ˜¯å½“ä½¿ç”¨å¸¸è§„çš„å•å°ºåº¦HTæ—¶ï¼Œå¯èƒ½ä¼šä¸¢å¤±å¤§é‡çš„å¤´å‘æ®µã€‚æ•…æå‡ºå°†HTåº”ç”¨äºä¸‰ä¸ªæ¯”ä¾‹çš„å›¾åƒï¼ŒåŒ…æ‹¬1024Ã—768ï¼ˆåŸå§‹æ¯”ä¾‹ï¼‰ï¼Œ512Ã—384å’Œ256Ã—192ï¼Œæœ€åé€šè¿‡é€»è¾‘æˆ–å°†ä¸‰ä¸ªæ¯”ä¾‹å›¾åƒä¸­çš„è¢«æ£€æµ‹å‡ºçš„å¤´å‘è¿›è¡Œæ•´åˆï¼Œä»¥æé«˜å¤´å‘è®¡æ•°å‡†ç¡®åº¦ã€‚ Canny Edge Detection Cannyè¾¹ç¼˜æ£€æµ‹æ˜¯ä¸€ç§å¤šæ­¥éª¤ç®—æ³•ï¼Œå¯ä»¥åŒæ—¶æ£€æµ‹åˆ°å™ªå£°è¢«æŠ‘åˆ¶çš„è¾¹ç¼˜ã€‚åœ¨å›¾åƒäºŒå€¼åŒ–æ­¥éª¤ä¸­ï¼Œç”±äºé”™è¯¯åœ°å‡å®šäº†ä¸¤æ ¹å•ç‹¬çš„å¤´å‘çš„è¿æ¥ï¼Œä½äºä¸¤æ ¹å¤´å‘ä¹‹é—´çš„å¤´çš®åƒç´ è¢«æ ‡è®°ä¸ºå¤´å‘çš„ä¸€éƒ¨åˆ†ã€‚è€Œä¸”ï¼Œå½“ä¸¤æ ¹å¤´å‘å¤ªé è¿‘æˆ–å½¼æ­¤é‡å æ—¶ï¼Œå¦‚æœç›´æ¥åº”ç”¨ç¨€ç–ç®—æ³•ï¼Œåˆ™ä¼šé”™è¿‡ä¸€æ ¹æˆ–ä¸¤æ ¹å¤´å‘ã€‚ æŠ€æœ¯åº”ç”¨ï¼š ä½¿ç”¨è¾¹ç¼˜ä¿¡æ¯æ¥æ‰¾å‡ºéšè—æˆ–é‡å çš„å¤´å‘ã€‚å¯ä»¥ä»éšè—çš„å¤´å‘æˆ–é‡å çš„å¤šæ ¹å¤´å‘ä¸­æå–ä¸¤ä¸ªå¹³è¡Œçš„è¾¹ç¼˜ã€‚ Thinning Parallel Line Bundling (PLB) å¤´å‘æ ‡è®°å’Œè®¡æ•°é˜¶æ®µï¼ˆHair Labling and Countingï¼‰ è¯¥é˜¶æ®µçš„ç›®çš„æ˜¯å‡†ç¡®è®¡ç®—å¤´çš®ä¸Šçš„æ¯›å‘æ•°é‡ã€‚è¿™å¯ä»¥çœ‹ä½œæ˜¯èšç±»å’Œæ ‡è®°é—®é¢˜ã€‚ç›®æ ‡æ˜¯å°†ä¸€ç»„çº¿æ®µç»„åˆæˆè¯­ä¹‰â€œå¤´å‘â€å¹¶åˆ†é…å”¯ä¸€çš„æ ‡ç­¾ã€‚ ä¸»è¦ç”¨åˆ°ä»¥ä¸‹æŠ€æœ¯ï¼š Relaxation Labeling æ¾å¼›æ ‡è®°æ˜¯ä¸€ç§å›¾åƒå¤„ç†æ–¹æ³•ã€‚å…¶ç›®æ ‡æ˜¯å°†æ ‡ç­¾ä¸ç»™å®šå›¾åƒçš„åƒç´ æˆ–ç»™å®šå›¾çš„èŠ‚ç‚¹ç›¸å…³è”ã€‚ æŠ€æœ¯åº”ç”¨ï¼š åœ¨æœ¬ç ”ç©¶ä¸­ï¼ŒRLç®—æ³•è¢«è§†ä¸ºç”¨äºæ ‡è®°æ¯ä¸ªçº¿æ®µçš„èšç±»æ–¹æ³•ã€‚ å‚è€ƒæ–‡çŒ® An Unsupervised Hair Segmentation and Counting System in Microscopy Images Contrast Stretching (Normalization) Color Morphology EXTENDING MATHEMATICAL MORPHOLOGY TO COLOR IMAGE PROCESSING Karhunen-Loeve Transform (KLT) Otsu thresholding Hough Transformï¼ˆHT) Canny Edge Detection Thinning Evaluation of a Bundling Technique for Parallel Coordinates Relaxation Labeling","categories":[{"name":"Paper Game","slug":"Paper-Game","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/"},{"name":"Smash","slug":"Paper-Game/Smash","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/Smash/"}],"tags":[{"name":"å¤´å‘è®¡æ•°é—®é¢˜","slug":"å¤´å‘è®¡æ•°é—®é¢˜","permalink":"https://littlelittlemoon.github.io/tags/%E5%A4%B4%E5%8F%91%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/"},{"name":"å›¾åƒå¤„ç†","slug":"å›¾åƒå¤„ç†","permalink":"https://littlelittlemoon.github.io/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"çº¿æ£€æµ‹","slug":"çº¿æ£€æµ‹","permalink":"https://littlelittlemoon.github.io/tags/%E7%BA%BF%E6%A3%80%E6%B5%8B/"}],"keywords":[{"name":"Paper Game","slug":"Paper-Game","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/"},{"name":"Smash","slug":"Paper-Game/Smash","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/Smash/"}]},{"title":"Kayleen's Space","slug":"Hexo-Theme-Sakura","date":"2019-12-12T14:16:01.000Z","updated":"2020-04-07T03:09:33.416Z","comments":true,"path":"2019/12/12/Hexo-Theme-Sakura/","link":"","permalink":"https://littlelittlemoon.github.io/2019/12/12/Hexo-Theme-Sakura/","excerpt":"","text":"hexo-theme-sakuraä¸»é¢˜ English document åŸºäºWordPressä¸»é¢˜Sakuraä¿®æ”¹æˆHexoçš„ä¸»é¢˜ã€‚ demoé¢„è§ˆ æ­£åœ¨å¼€å‘ä¸­â€¦ äº¤æµç¾¤ è‹¥ä½ æ˜¯ä½¿ç”¨è€…ï¼ŒåŠ ç¾¤QQ: 801511924 è‹¥ä½ æ˜¯åˆ›ä½œè€…ï¼ŒåŠ ç¾¤QQ: 194472590 ä¸»é¢˜ç‰¹æ€§ é¦–é¡µå¤§å±è§†é¢‘ é¦–é¡µéšæœºå°é¢ å›¾ç‰‡æ‡’åŠ è½½ valineè¯„è®º fancy-boxç›¸å†Œ pjaxæ”¯æŒï¼ŒéŸ³ä¹ä¸é—´æ–­ aplayeréŸ³ä¹æ’­æ”¾å™¨ å¤šçº§å¯¼èˆªèœå•ï¼ˆæŒ‰ç°åœ¨å¤§éƒ¨åˆ†hexoä¸»é¢˜æ¥è¯´ï¼Œè¿™ä¹Ÿç®—æ˜¯ä¸ªç‰¹æ€§äº†ï¼‰ èµèµä½œè€… å¦‚æœå–œæ¬¢hexo-theme-sakuraä¸»é¢˜ï¼Œå¯ä»¥è€ƒè™‘èµ„åŠ©ä¸€ä¸‹å“¦~éå¸¸æ„Ÿæ¿€ï¼ paypal | Alipay æ”¯ä»˜å® | WeChat Pay å¾®ä¿¡æ”¯ä»˜ æœªå®Œå–„çš„ä½¿ç”¨æ•™ç¨‹ é‚£å•¥ï¼Ÿè€å®è¯´æˆ‘ç›®å‰ä¹Ÿä¸æ˜¯å¾ˆæœ‰æ¡ç†233333333~ 1ã€ä¸»é¢˜ä¸‹è½½å®‰è£… hexo-theme-sakuraå»ºè®®ä¸‹è½½å‹ç¼©åŒ…æ ¼å¼ï¼Œå› ä¸ºé™¤äº†ä¸»é¢˜å†…å®¹è¿˜æœ‰äº›sourceçš„é…ç½®å¯¹æ–°æ‰‹æ¥è¯´æ¯”è¾ƒå¤ªéº»çƒ¦ï¼Œç›´æ¥ä¸‹è½½è§£å‹å°±çœå»è¿™äº›éº»çƒ¦å’¯ã€‚ ä¸‹è½½å¥½åè§£å‹åˆ°åšå®¢æ ¹ç›®å½•ï¼ˆä¸æ˜¯ä¸»é¢˜ç›®å½•å“¦ï¼Œé‡å¤çš„é€‰æ‹©æ›¿æ¢ï¼‰ã€‚æ¥ç€åœ¨å‘½ä»¤è¡Œï¼ˆcmdã€bashï¼‰è¿è¡Œnpm iå®‰è£…ä¾èµ–ã€‚ 2ã€ä¸»é¢˜é…ç½® åšå®¢æ ¹ç›®å½•ä¸‹çš„_configé…ç½® ç«™ç‚¹ 12345678# Sitetitle: ä½ çš„ç«™ç‚¹åsubtitle:description: ç«™ç‚¹ç®€ä»‹keywords:author: ä½œè€…ålanguage: zh-cntimezone: éƒ¨ç½² 123456deploy: type: git repo: github: ä½ çš„githubä»“åº“åœ°å€ # coding: ä½ çš„codingä»“åº“åœ°å€ branch: master å¤‡ä»½ ï¼ˆä½¿ç”¨hexo bå‘å¸ƒå¤‡ä»½åˆ°è¿œç¨‹ä»“åº“ï¼‰ 1234567backup: type: git message: backup my blog of https://honjun.github.io/ repository: # ä½ çš„githubä»“åº“åœ°å€,å¤‡ä»½åˆ†æ”¯å ï¼ˆå»ºè®®æ–°å»ºbackupåˆ†æ”¯ï¼‰ github: https://github.com/honjun/honjun.github.io.git,backup # coding: https://git.coding.net/hojun/hojun.git,backup ä¸»é¢˜ç›®å½•ä¸‹çš„_configé…ç½® å…¶ä¸­æ ‡æ˜ã€æ”¹ã€‘çš„æ˜¯éœ€è¦ä¿®æ”¹éƒ¨é—¨ï¼Œæ ‡æ˜ã€é€‰ã€‘æ˜¯å¯æ”¹å¯ä¸æ”¹ï¼Œæ ‡æ˜ã€éã€‘æ˜¯ä¸ç”¨æ”¹çš„éƒ¨åˆ† 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121# site name# ç«™ç‚¹å ã€æ”¹ã€‘prefixName: ã•ãã‚‰è˜ãã®siteName: hojun# favicon and site master avatar# ç«™ç‚¹çš„faviconå’Œå¤´åƒ è¾“å…¥å›¾ç‰‡è·¯å¾„ï¼ˆä¸‹é¢çš„é…ç½®æ˜¯éƒ½æ˜¯cdnçš„ç›¸å¯¹è·¯å¾„ï¼Œæ²¡æœ‰cdnè¯·å¡«å†™å®Œæ•´è·¯å¾„ï¼Œå»ºè®®ä½¿ç”¨jsdeliveræ­å»ºä¸€ä¸ªcdnå•¦ï¼Œå…ˆå»ä¸‹è½½æˆ‘çš„cdnæ›¿æ¢ä¸‹å›¾ç‰‡å°±è¡Œäº†ï¼Œç®€å•æ–¹ä¾¿~ï¼‰ã€æ”¹ã€‘favicon: /images/favicon.icoavatar: /img/custom/avatar.jpg# ç«™ç‚¹url ã€æ”¹ã€‘url: https://sakura.hojun.cn# ç«™ç‚¹ä»‹ç»ï¼ˆæˆ–è€…è¯´æ˜¯ä¸ªäººç­¾åï¼‰ã€æ”¹ã€‘description: Live your life with passion! With some drive!# ç«™ç‚¹cdnï¼Œæ²¡æœ‰å°±ä¸ºç©º ã€æ”¹ã€‘ è‹¥æ˜¯cdnä¸ºç©ºï¼Œä¸€äº›å›¾ç‰‡åœ°å€å°±è¦å¡«å®Œæ•´åœ°å€äº†ï¼Œæ¯”å¦‚ä¹‹å‰avatarå°±è¦å¡«https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/custom/avatar.jpgcdn: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6# å¼€å¯pjax ã€é€‰ã€‘pjax: 1# ç«™ç‚¹é¦–é¡µçš„å…¬å‘Šä¿¡æ¯ ã€æ”¹ã€‘notice: hexo-Sakuraä¸»é¢˜å·²ç»å¼€æºï¼Œç›®å‰æ­£åœ¨å¼€å‘ä¸­...# æ‡’åŠ è½½çš„åŠ è½½ä¸­å›¾ç‰‡ ã€é€‰ã€‘lazyloadImg: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/loader/orange.progress-bar-stripe-loader.svg# ç«™ç‚¹èœå•é…ç½® ã€é€‰ã€‘menus: é¦–é¡µ: &#123; path: /, fa: fa-fort-awesome faa-shake &#125; å½’æ¡£: &#123; path: /archives, fa: fa-archive faa-shake, submenus: &#123; æŠ€æœ¯: &#123;path: /categories/æŠ€æœ¯/, fa: fa-code &#125;, ç”Ÿæ´»: &#123;path: /categories/ç”Ÿæ´»/, fa: fa-file-text-o &#125;, èµ„æº: &#123;path: /categories/èµ„æº/, fa: fa-cloud-download &#125;, éšæƒ³: &#123;path: /categories/éšæƒ³/, fa: fa-commenting-o &#125;, è½¬è½½: &#123;path: /categories/è½¬è½½/, fa: fa-book &#125; &#125; &#125; æ¸…å•: &#123; path: javascript:;, fa: fa-list-ul faa-vertical, submenus: &#123; ä¹¦å•: &#123;path: /tags/æ‚¦è¯»/, fa: fa-th-list faa-bounce &#125;, ç•ªç»„: &#123;path: /bangumi/, fa: fa-film faa-vertical &#125;, æ­Œå•: &#123;path: /music/, fa: fa-headphones &#125;, å›¾é›†: &#123;path: /tags/å›¾é›†/, fa: fa-photo &#125; &#125; &#125; ç•™è¨€æ¿: &#123; path: /comment/, fa: fa-pencil-square-o faa-tada &#125; å‹äººå¸: &#123; path: /links/, fa: fa-link faa-shake &#125; èµèµ: &#123; path: /donate/, fa: fa-heart faa-pulse &#125; å…³äº: &#123; path: /, fa: fa-leaf faa-wrench , submenus: &#123; æˆ‘ï¼Ÿ: &#123;path: /about/, fa: fa-meetup&#125;, ä¸»é¢˜: &#123;path: /theme-sakura/, fa: iconfont icon-sakura &#125;, Lab: &#123;path: /lab/, fa: fa-cogs &#125;, &#125; &#125; å®¢æˆ·ç«¯: &#123; path: /client/, fa: fa-android faa-vertical &#125; RSS: &#123; path: /atom.xml, fa: fa-rss faa-pulse &#125;# Home page sort type: -1: newer firstï¼Œ1: older first. ã€éã€‘homePageSortType: -1# Home page article shown number) ã€éã€‘homeArticleShown: 10# èƒŒæ™¯å›¾ç‰‡ ã€é€‰ã€‘bgn: 8# startdashé¢æ¿ url, title, desc img ã€æ”¹ã€‘startdash: - &#123;url: /theme-sakura/, title: Sakura, desc: æœ¬ç«™ hexo ä¸»é¢˜, img: /img/startdash/sakura.md.png&#125; - &#123;url: http://space.bilibili.com/271849279, title: Bilibili, desc: åšä¸»çš„bç«™è§†é¢‘, img: /img/startdash/bilibili.jpg&#125; - &#123;url: /, title: hojunçš„ä¸‡äº‹å±‹, desc: æŠ€æœ¯æœåŠ¡, img: /img/startdash/wangshiwu.jpg&#125;# your site build time or founded date# ä½ çš„ç«™ç‚¹å»ºç«‹æ—¥æœŸ ã€æ”¹ã€‘siteBuildingTime: 07/17/2018# ç¤¾äº¤æŒ‰é’®(social) url, img PCç«¯é…ç½® ã€æ”¹ã€‘social: github: &#123;url: http://github.com/honjun, img: /img/social/github.png&#125; sina: &#123;url: http://weibo.com/mashirozx?is_all=1, img: /img/social/sina.png&#125; wangyiyun: &#123;url: http://weibo.com/mashirozx?is_all=1, img: /img/social/wangyiyun.png&#125; zhihu: &#123;url: http://weibo.com/mashirozx?is_all=1, img: /img/social/zhihu.png&#125; email: &#123;url: http://weibo.com/mashirozx?is_all=1, img: /img/social/email.svg&#125; wechat: &#123;url: /#, qrcode: /img/custom/wechat.jpg, img: /img/social/wechat.png&#125;# ç¤¾äº¤æŒ‰é’®(msocial) url, img ç§»åŠ¨ç«¯é…ç½® ã€æ”¹ã€‘msocial: github: &#123;url: http://github.com/honjun, fa: fa-github, color: 333&#125; weibo: &#123;url: http://weibo.com/mashirozx?is_all=1, fa: fa-weibo, color: dd4b39&#125; qq: &#123;url: https://wpa.qq.com/msgrd?v=3&amp;uin=954655431&amp;site=qq&amp;menu=yes, fa: fa-qq, color: 25c6fe&#125;# èµèµäºŒç»´ç ï¼ˆå…¶ä¸­wechatSQæ˜¯èµèµå•é¡µé¢çš„èµèµç å›¾ç‰‡ï¼‰ã€æ”¹ã€‘donate: alipay: /img/custom/donate/AliPayQR.jpg wechat: /img/custom/donate/WeChanQR.jpg wechatSQ: /img/custom/donate/WeChanSQ.jpg# é¦–é¡µè§†é¢‘åœ°å€ä¸ºhttps://cdn.jsdelivr.net/gh/honjun/hojun@1.2/Unbroken.mp4ï¼Œé…ç½®å¦‚ä¸‹ ã€æ”¹ã€‘movies: url: https://cdn.jsdelivr.net/gh/honjun/hojun@1.2 # å¤šä¸ªè§†é¢‘ç”¨é€—å·éš”å¼€ï¼Œéšæœºè·å–ã€‚æ”¯æŒçš„æ ¼å¼ç›®å‰å·²çŸ¥MP4,Flvã€‚å…¶ä»–çš„å¯ä»¥è¯•ä¸‹ï¼Œä¸ä¿è¯æœ‰ç”¨ name: Unbroken.mp4# å·¦ä¸‹è§’aplayeræ’­æ”¾å™¨é…ç½® ä¸»è¦æ”¹idå’Œserverè¿™ä¸¤é¡¹ï¼Œä¿®æ”¹è¯¦è§[aplayeræ–‡æ¡£] ã€æ”¹ã€‘aplayer: id: 2660651585 server: netease type: playlist fixed: true mini: false autoplay: false loop: all order: random preload: auto volume: 0.7 mutex: true# Valineè¯„è®ºé…ç½®ã€æ”¹ã€‘valine: truev_appId: GyC3NzMvd0hT9Yyd2hYIC0MN-gzGzoHszv_appKey: mgOpfzbkHYqU92CV4IDlAUHQ åˆ†ç±»é¡µå’Œæ ‡ç­¾é¡µé…ç½® åˆ†ç±»é¡µ æ ‡ç­¾é¡µ é…ç½®é¡¹åœ¨\\themes\\Sakura\\languages\\zh-cn.ymlé‡Œã€‚æ–°å¢ä¸€ä¸ªåˆ†ç±»æˆ–æ ‡ç­¾æœ€å¥½åŠ ä¸‹å“¦ï¼Œå½“ç„¶å«Œéº»çƒ¦å¯ä»¥ç›´æ¥ä½¿ç”¨ä¸€å¼ é»˜è®¤å›¾ç‰‡ï¼ˆå¯ä»¥æ”¹ä¸»é¢˜æˆ–è€…ç›´æ¥æŠŠ404å›¾ç‰‡æ›¿æ¢ä¸‹ï¼Œå¾æ±‚ä¸‹æ„è§è¦ä¸è¦ç»™è¿™ä¸ªåœ¨é…ç½®æ–‡ä»¶ä¸­åŠ ä¸ªå¼€å…³ï¼Œå¯ä»¥issueæˆ–ç¾¤é‡Œæå‡ºæ¥ï¼‰ï¼Œç°åœ¨æ˜¯æ²¡è®¾ç½®çš„è¯ä¼šä½¿ç”¨é‚£ç§å€’ç«‹å°ç‹—404å“¦ã€‚ 12345678910111213141516171819#category# æŒ‰åˆ†ç±»ååˆ›å»ºæŠ€æœ¯: #ä¸­æ–‡æ ‡é¢˜ zh: é‡ç”ŸæŠ€æœ¯åä¼š # è‹±æ–‡æ ‡é¢˜ en: Geek â€“ Only for Love # å°é¢å›¾ç‰‡ img: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/banner/coding.jpgç”Ÿæ´»: zh: ç”Ÿæ´» en: live img: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/banner/writing.jpg#tag# æ ‡ç­¾åå³æ˜¯æ ‡é¢˜æ‚¦è¯»: # å°é¢å›¾ç‰‡ img: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/banner/reading.jpg å•é¡µé¢å°é¢é…ç½® å¦‚ç•™è¨€æ¿é¡µé¢é¡µé¢ï¼Œä½äºsourceä¸‹çš„commentä¸‹ï¼Œæ‰“å¼€index.mdå¦‚ä¸‹ï¼š 123456789---title: commentdate: 2018-12-20 23:13:48keywords: ç•™è¨€æ¿description: comments: true# åœ¨è¿™é‡Œé…ç½®å•é¡µé¢å¤´éƒ¨å›¾ç‰‡ï¼Œè‡ªå®šä¹‰æ›¿æ¢å“¦~photos: https://cdn.jsdelivr.net/gh/honjun/cdn@1.4/img/banner/comment.jpg--- å•é¡µé¢é…ç½® ç•ªç»„è®¡åˆ’é¡µ ï¼ˆè¯·ç›´æ¥åœ¨ä¸‹è½½åçš„æ–‡ä»¶ä¸­æ”¹ï¼Œä¸‹é¢çš„æ·»åŠ äº†æ³¨é‡Šå¯èƒ½ä¼šæœ‰äº›å½±å“ï¼‰ 123456789101112131415161718192021222324252627282930---layout: bangumititle: bangumicomments: falsedate: 2019-02-10 21:32:48keywords:description:bangumis: # ç•ªç»„å›¾ç‰‡ - img: https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg # ç•ªç»„å title: æœèŠ±å¤•èª“â€”â€”äºç¦»åˆ«ä¹‹æœæŸèµ·çº¦å®šä¹‹èŠ± # è¿½ç•ªçŠ¶æ€ ï¼ˆè¿½ç•ªing/å·²è¿½å®Œï¼‰ status: å·²è¿½å®Œ # è¿½ç•ªè¿›åº¦ progress: 100 # ç•ªå‰§æ—¥æ–‡åç§° jp: ã•ã‚ˆãªã‚‰ã®æœã«ç´„æŸã®èŠ±ã‚’ã‹ã–ã‚ã† # æ”¾é€æ—¶é—´ time: æ”¾é€æ—¶é—´: 2018-02-24 SUN. # ç•ªå‰§ä»‹ç» desc: ä½åœ¨è¿œç¦»å°˜åš£çš„åœŸåœ°ï¼Œä¸€è¾¹å°†æ¯å¤©çš„äº‹æƒ…ç¼–ç»‡æˆåä¸ºå¸Œæ¯”æ¬§çš„å¸ƒï¼Œä¸€è¾¹é™é™ç”Ÿæ´»çš„ä¼Šæ¬§å¤«äººæ°‘ã€‚åœ¨15å²å·¦å³å¤–è¡¨å°±åœæ­¢æˆé•¿ï¼Œæ‹¥æœ‰æ•°ç™¾å¹´å¯¿å‘½çš„ä»–ä»¬ï¼Œè¢«ç§°ä¸ºâ€œç¦»åˆ«çš„ä¸€æ—â€ï¼Œå¹¶è¢«è§†ä¸ºæ´»ç€çš„ä¼ è¯´ã€‚æ²¡æœ‰åŒäº²çš„ä¼Šæ¬§å¤«å°‘å¥³ç›å¥‡äºšï¼Œè¿‡ç€è¢«ä¼™ä¼´åŒ…å›´çš„å¹³ç¨³æ—¥å­ï¼Œå´æ€»æ„Ÿè§‰â€œå­¤èº«ä¸€äººâ€ã€‚ä»–ä»¬çš„è¿™ç§æ—¥å¸¸ï¼Œä¸€ç¬é—´å°±å´©æºƒæ¶ˆå¤±ã€‚è¿½æ±‚ä¼Šæ¬§å¤«çš„é•¿å¯¿ä¹‹è¡€ï¼Œæ¢…è¨è’‚å†›ä¹˜åç€åä¸ºé›·çº³ç‰¹çš„å¤ä»£å…½å‘åŠ¨äº†è¿›æ”»ã€‚åœ¨ç»æœ›ä¸æ··ä¹±ä¹‹ä¸­ï¼Œä¼Šæ¬§å¤«çš„ç¬¬ä¸€ç¾å¥³è•¾è‰äºšè¢«æ¢…è¨è’‚å¸¦èµ°ï¼Œè€Œç›å¥‡äºšæš—æ‹çš„å°‘å¹´å…‹é‡Œå§†ä¹Ÿå¤±è¸ªäº†ã€‚ç›å¥‡äºšè™½ç„¶æ€»ç®—é€ƒè„±äº†ï¼Œå´å¤±å»äº†ä¼™ä¼´å’Œå½’å»ä¹‹åœ°â€¦â€¦ã€‚ - img: https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg title: æœèŠ±å¤•èª“â€”â€”äºç¦»åˆ«ä¹‹æœæŸèµ·çº¦å®šä¹‹èŠ± status: å·²è¿½å®Œ progress: 50 jp: ã•ã‚ˆãªã‚‰ã®æœã«ç´„æŸã®èŠ±ã‚’ã‹ã–ã‚ã† time: æ”¾é€æ—¶é—´: 2018-02-24 SUN. desc: ä½åœ¨è¿œç¦»å°˜åš£çš„åœŸåœ°ï¼Œä¸€è¾¹å°†æ¯å¤©çš„äº‹æƒ…ç¼–ç»‡æˆåä¸ºå¸Œæ¯”æ¬§çš„å¸ƒï¼Œä¸€è¾¹é™é™ç”Ÿæ´»çš„ä¼Šæ¬§å¤«äººæ°‘ã€‚åœ¨15å²å·¦å³å¤–è¡¨å°±åœæ­¢æˆé•¿ï¼Œæ‹¥æœ‰æ•°ç™¾å¹´å¯¿å‘½çš„ä»–ä»¬ï¼Œè¢«ç§°ä¸ºâ€œç¦»åˆ«çš„ä¸€æ—â€ï¼Œå¹¶è¢«è§†ä¸ºæ´»ç€çš„ä¼ è¯´ã€‚æ²¡æœ‰åŒäº²çš„ä¼Šæ¬§å¤«å°‘å¥³ç›å¥‡äºšï¼Œè¿‡ç€è¢«ä¼™ä¼´åŒ…å›´çš„å¹³ç¨³æ—¥å­ï¼Œå´æ€»æ„Ÿè§‰â€œå­¤èº«ä¸€äººâ€ã€‚ä»–ä»¬çš„è¿™ç§æ—¥å¸¸ï¼Œä¸€ç¬é—´å°±å´©æºƒæ¶ˆå¤±ã€‚è¿½æ±‚ä¼Šæ¬§å¤«çš„é•¿å¯¿ä¹‹è¡€ï¼Œæ¢…è¨è’‚å†›ä¹˜åç€åä¸ºé›·çº³ç‰¹çš„å¤ä»£å…½å‘åŠ¨äº†è¿›æ”»ã€‚åœ¨ç»æœ›ä¸æ··ä¹±ä¹‹ä¸­ï¼Œä¼Šæ¬§å¤«çš„ç¬¬ä¸€ç¾å¥³è•¾è‰äºšè¢«æ¢…è¨è’‚å¸¦èµ°ï¼Œè€Œç›å¥‡äºšæš—æ‹çš„å°‘å¹´å…‹é‡Œå§†ä¹Ÿå¤±è¸ªäº†ã€‚ç›å¥‡äºšè™½ç„¶æ€»ç®—é€ƒè„±äº†ï¼Œå´å¤±å»äº†ä¼™ä¼´å’Œå½’å»ä¹‹åœ°â€¦â€¦ã€‚--- å‹é“¾é¡µ ï¼ˆè¯·ç›´æ¥åœ¨ä¸‹è½½åçš„æ–‡ä»¶ä¸­æ”¹ï¼Œä¸‹é¢çš„æ·»åŠ äº†æ³¨é‡Šå¯èƒ½ä¼šæœ‰äº›å½±å“ï¼‰ 1234567891011121314151617181920212223242526272829303132333435363738394041424344---layout: linkstitle: links# åˆ›å»ºæ—¥æœŸï¼Œå¯ä»¥æ”¹ä¸‹date: 2018-12-19 23:11:06 # å›¾ç‰‡ä¸Šçš„æ ‡é¢˜ï¼Œè‡ªå®šä¹‰ä¿®æ”¹keywords: å‹äººå¸ description: # true/false å¼€å¯/å…³é—­è¯„è®ºcomments: true # é¡µé¢å¤´éƒ¨å›¾ç‰‡ï¼Œè‡ªå®šä¹‰ä¿®æ”¹photos: https://cdn.jsdelivr.net/gh/honjun/cdn@1.4/img/banner/links.jpg # å‹é“¾é…ç½®links: # ç±»å‹åˆ†ç»„ - group: ä¸ªäººé¡¹ç›® # ç±»å‹ç®€ä»‹ desc: å……åˆ†è¯´æ˜è¿™å®¶ä¼™æ˜¯æ¡å’¸é±¼ &lt; (ï¿£ï¸¶ï¿£)&gt; items: # å‹é“¾é“¾æ¥ - url: https://shino.cc/fgvf # å‹é“¾å¤´åƒ img: https://cloud.moezx.cc/Picture/svg/landscape/fields.svg # å‹é“¾ç«™ç‚¹å name: Google # å‹é“¾ä»‹ç» ä¸‹é¢é›·åŒ desc: Google é•œåƒ - url: https://shino.cc/fgvf img: https://cloud.moezx.cc/Picture/svg/landscape/fields.svg name: Google desc: Google é•œåƒ # ç±»å‹åˆ†ç»„... - group: å°ä¼™ä¼´ä»¬ desc: æ¬¢è¿äº¤æ¢å‹é“¾ ê‰‚(ËŠá—œË‹) items: - url: https://shino.cc/fgvf img: https://cloud.moezx.cc/Picture/svg/landscape/fields.svg name: Google desc: Google é•œåƒ - url: https://shino.cc/fgvf img: https://cloud.moezx.cc/Picture/svg/landscape/fields.svg name: Google desc: Google é•œåƒ--- å†™æ–‡ç« é…ç½® ä¸»é¢˜é›†æˆäº†ä¸ªäººæ’ä»¶hexo-tag-biliå’Œhexo-tag-fancybox_imgã€‚å…¶ä¸­hexo-tag-biliç”¨æ¥åœ¨æ–‡ç« æˆ–å•é¡µé¢ä¸­æ’å…¥Bç«™å¤–é“¾è§†é¢‘ï¼Œä½¿ç”¨è¯­æ³•å¦‚ä¸‹ï¼š 1&#123;% bili video_id [page] %&#125; è¯¦ç»†ä½¿ç”¨æ•™ç¨‹è¯¦è§hexo-tag-biliã€‚ hexo-tag-fancybox_imgç”¨æ¥åœ¨æ–‡ç« æˆ–å•é¡µé¢ä¸­å›¾ç‰‡ï¼Œä½¿ç”¨è¯­æ³•å¦‚ä¸‹ï¼š 1&#123;% fb_img src [caption] %&#125; è¯¦ç»†ä½¿ç”¨æ•™ç¨‹è¯¦è§hexo-tag-fancybox_img è¿˜æœ‰å•¥ï¼Œä¸€æ—¶æƒ³ä¸èµ·æ¥â€¦ To be continuedâ€¦","categories":[{"name":"æŠ€æœ¯","slug":"æŠ€æœ¯","permalink":"https://littlelittlemoon.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"web","slug":"web","permalink":"https://littlelittlemoon.github.io/tags/web/"},{"name":"æ‚¦è¯»","slug":"æ‚¦è¯»","permalink":"https://littlelittlemoon.github.io/tags/%E6%82%A6%E8%AF%BB/"}],"keywords":[{"name":"æŠ€æœ¯","slug":"æŠ€æœ¯","permalink":"https://littlelittlemoon.github.io/categories/%E6%8A%80%E6%9C%AF/"}]}]}