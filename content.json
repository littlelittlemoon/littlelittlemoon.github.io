{"meta":{"title":"LITTLEMEEMOON","subtitle":"Every day with dreams is wonderful.","description":"This is my place where I can share my things about life, academic or just for fun, enjoy. :)","author":"Kayleen","url":"https://littlelittlemoon.github.io"},"pages":[{"title":"about","date":"2019-12-12T14:14:36.000Z","updated":"2020-04-07T11:13:12.948Z","comments":false,"path":"about/index.html","permalink":"https://littlelittlemoon.github.io/about/index.html","excerpt":"","text":"[さくら荘のhojun] 与&nbsp; Mashiro&nbsp; （ 真（ま）白（しろ） ） 对话中... bot_ui_ini()","keywords":"关于"},{"title":"bangumi","date":"2019-02-10T13:32:48.000Z","updated":"2020-04-06T16:05:44.917Z","comments":false,"path":"bangumi/index.html","permalink":"https://littlelittlemoon.github.io/bangumi/index.html","excerpt":"","text":"","keywords":null},{"title":"client","date":"2018-12-20T15:13:35.000Z","updated":"2020-04-06T16:22:30.837Z","comments":false,"path":"client/index.html","permalink":"https://littlelittlemoon.github.io/client/index.html","excerpt":"","text":"直接下载 or 扫码下载：","keywords":"Android客户端"},{"title":"donate","date":"2019-12-20T15:13:05.000Z","updated":"2020-04-07T11:12:31.758Z","comments":false,"path":"donate/index.html","permalink":"https://littlelittlemoon.github.io/donate/index.html","excerpt":"","text":"","keywords":"谢谢饲主了喵~"},{"title":"comment","date":"2019-12-20T15:13:48.000Z","updated":"2020-04-07T11:12:26.682Z","comments":true,"path":"comment/index.html","permalink":"https://littlelittlemoon.github.io/comment/index.html","excerpt":"","text":"念两句诗 人闲桂花落，夜静春山空。 月出惊山鸟，时鸣春涧中。 王维 ·《鸟鸣涧》","keywords":"留言板"},{"title":"categories","date":"2019-12-20T15:13:48.000Z","updated":"2020-04-07T05:10:27.765Z","comments":true,"path":"categories/index.html","permalink":"https://littlelittlemoon.github.io/categories/index.html","excerpt":"","text":"念两句诗 叙别梦、扬州一觉。 【宋代】吴文英《夜游宫·人去西楼雁杳》","keywords":"文章分类"},{"title":"links","date":"2018-12-19T15:11:06.000Z","updated":"2020-04-07T11:12:52.882Z","comments":true,"path":"links/index.html","permalink":"https://littlelittlemoon.github.io/links/index.html","excerpt":"","text":"","keywords":"友人帐"},{"title":"music","date":"2018-12-20T15:14:28.000Z","updated":"2020-04-07T11:12:59.292Z","comments":false,"path":"music/index.html","permalink":"https://littlelittlemoon.github.io/music/index.html","excerpt":"","text":"","keywords":"喜欢的音乐"},{"title":"lab","date":"2019-01-05T13:47:59.000Z","updated":"2020-04-07T11:12:44.050Z","comments":false,"path":"lab/index.html","permalink":"https://littlelittlemoon.github.io/lab/index.html","excerpt":"","text":"sakura主题 balabala","keywords":"Lab实验室"},{"title":"rss","date":"2018-12-20T15:09:03.000Z","updated":"2020-04-06T16:05:44.919Z","comments":true,"path":"rss/index.html","permalink":"https://littlelittlemoon.github.io/rss/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-12-12T14:14:16.000Z","updated":"2020-04-07T11:13:06.637Z","comments":true,"path":"tags/index.html","permalink":"https://littlelittlemoon.github.io/tags/index.html","excerpt":"","text":"","keywords":"标签"},{"title":"theme-sakura","date":"2019-01-04T14:53:25.000Z","updated":"2020-04-06T16:05:44.919Z","comments":false,"path":"theme-sakura/index.html","permalink":"https://littlelittlemoon.github.io/theme-sakura/index.html","excerpt":"","text":"Hexo主题Sakura修改自WordPress主题Sakura，感谢原作者Mashiro","keywords":"Hexo 主题 Sakura 🌸"},{"title":"video","date":"2018-12-20T15:14:38.000Z","updated":"2020-04-06T16:05:44.919Z","comments":false,"path":"video/index.html","permalink":"https://littlelittlemoon.github.io/video/index.html","excerpt":"","text":"var videos = [ { img: 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: '朝花夕誓——于离别之朝束起约定之花', status: '已追完', progress: 100, jp: 'さよならの朝に約束の花をかざろう', time: '放送时间: 2018-02-24 SUN.', desc: ' 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。' }, { img : 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: '朝花夕誓——于离别之朝束起约定之花', status: '已追完', progress: 100, jp: 'さよならの朝に約束の花をかざろう', time: '2018-02-24 SUN.', desc: ' 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。' } ] .should-ellipsis{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:95%;}.should-ellipsis-full{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:100%;}.should-ellipsis i{position:absolute;right:24px;}.grey-text{color:#9e9e9e !important}.grey-text.text-darken-4{color:#212121 !important}html{line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}img{border-style:none}progress{display:inline-block;vertical-align:baseline}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{-webkit-box-sizing:border-box;box-sizing:border-box}*,*:before,*:after{-webkit-box-sizing:inherit;box-sizing:inherit}ul:not(.browser-default){padding-left:0;list-style-type:none}ul:not(.browser-default)>li{list-style-type:none}.card{-webkit-box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2);box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2)}.hoverable{-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s}.hoverable:hover{-webkit-box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19);box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19)}i{line-height:inherit}i.right{float:right;margin-left:15px}.bangumi .right{float:right !important}.material-icons{text-rendering:optimizeLegibility;-webkit-font-feature-settings:'liga';-moz-font-feature-settings:'liga';font-feature-settings:'liga'}.row{margin-left:auto;margin-right:auto;margin-bottom:20px}.row:after{content:\"\";display:table;clear:both}.row .col{float:left;-webkit-box-sizing:border-box;box-sizing:border-box;padding:0 .75rem;min-height:1px}.row .col.s12{width:100%;margin-left:auto;left:auto;right:auto}@media only screen and (min-width:601px){.row .col.m6{width:50%;margin-left:auto;left:auto;right:auto}}html{line-height:1.5;font-family:-apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif;font-weight:normal;color:rgba(0,0,0,0.87)}@media only screen and (min-width:0){html{font-size:14px}}@media only screen and (min-width:992px){html{font-size:14.5px}}@media only screen and (min-width:1200px){html{font-size:15px}}.card{position:relative;margin:.5rem 0 1rem 0;background-color:#fff;-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s;border-radius:2px}.card .card-title{font-size:24px;font-weight:300}.card .card-title.activator{cursor:pointer}.card .card-image{position:relative}.card .card-image img{display:block;border-radius:2px 2px 0 0;position:relative;left:0;right:0;top:0;bottom:0;width:100%}.card .card-content{padding:24px;border-radius:0 0 2px 2px}.card .card-content p{margin:0}.card .card-content .card-title{display:block;line-height:32px;margin-bottom:8px}.card .card-content .card-title i{line-height:32px}.card .card-reveal{padding:24px;position:absolute;background-color:#fff;width:100%;overflow-y:auto;left:0;top:100%;height:100%;z-index:3;display:none}.card .card-reveal .card-title{cursor:pointer;display:block}.waves-effect{position:relative;cursor:pointer;display:inline-block;overflow:hidden;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-tap-highlight-color:transparent;vertical-align:middle;z-index:1;-webkit-transition:.3s ease-out;transition:.3s ease-out}.waves-effect img{position:relative;z-index:-1}.waves-block{display:block}::-webkit-input-placeholder{color:#d1d1d1}::-moz-placeholder{color:#d1d1d1}:-ms-input-placeholder{color:#d1d1d1}::-ms-input-placeholder{color:#d1d1d1}[type=\"radio\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"radio\"]:not(:checked)+span{position:relative;padding-left:35px;cursor:pointer;display:inline-block;height:25px;line-height:25px;font-size:1rem;-webkit-transition:.28s ease;transition:.28s ease;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border-radius:50%}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border:2px solid #5a5a5a}[type=\"radio\"]:not(:checked)+span:after{-webkit-transform:scale(0);transform:scale(0)}[type=\"checkbox\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"checkbox\"]:not(:checked):disabled+span:not(.lever):before{border:none;background-color:rgba(0,0,0,0.42)}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):before{width:0;height:0;border:3px solid transparent;left:6px;top:10px;-webkit-transform:rotateZ(37deg);transform:rotateZ(37deg);-webkit-transform-origin:100% 100%;transform-origin:100% 100%}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):after{height:20px;width:20px;background-color:transparent;border:2px solid #5a5a5a;top:0px;z-index:0}input[type=checkbox]:not(:disabled) ~ .lever:active:before,input[type=checkbox]:not(:disabled).tabbed:focus ~ .lever::before{-webkit-transform:scale(2.4);transform:scale(2.4);background-color:rgba(0,0,0,0.08)}input[type=range].focused:focus:not(.active)::-webkit-slider-thumb{-webkit-box-shadow:0 0 0 10px rgba(38,166,154,0.26);box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-moz-range-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-ms-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)} 番组计划 这里将是永远的回忆 window.onload = function(){ videos.forEach(function(video, i){ $('#rootRow').append(` ${video.title} ${video.jp} ${video.status} ${video.title} ${video.jp} 放送时间: ${video.time} ${video.desc} ${video.status} `) }) }","keywords":"B站"}],"posts":[{"title":"Fraud Detection | Imbalanced data modeling","slug":"Credit Card Fraud Detection","date":"2020-04-06T13:53:06.000Z","updated":"2020-04-06T16:27:28.272Z","comments":true,"path":"2020/04/06/Credit Card Fraud Detection/","link":"","permalink":"https://littlelittlemoon.github.io/2020/04/06/Credit%20Card%20Fraud%20Detection/","excerpt":"","text":"LDA, QDA and LR for fraud detection | Imbalanced data modeling 123456%matplotlib inline# import warnings filterfrom warnings import simplefilter# ignore all future warningssimplefilter(action='ignore', category=FutureWarning) prepare data 1234567891011import pandas as pd# load datadefault_data = pd.read_csv(\"data/Default.csv\")# prepare datadefault_data.loc[default_data['default'] == 'No', \"default\"] = 0default_data.loc[default_data['default'] == 'Yes', \"default\"] = 1default_data.loc[default_data['student'] == 'No', \"student\"] = 0default_data.loc[default_data['student'] == 'Yes', \"student\"] = 1default_data.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Unnamed: 0 default student balance income count 10000.00000 10000.000000 10000.000000 10000.000000 10000.000000 mean 5000.50000 0.033300 0.294400 835.374886 33516.981876 std 2886.89568 0.179428 0.455795 483.714985 13336.639563 min 1.00000 0.000000 0.000000 0.000000 771.967729 25% 2500.75000 0.000000 0.000000 481.731105 21340.462903 50% 5000.50000 0.000000 0.000000 823.636973 34552.644802 75% 7500.25000 0.000000 1.000000 1166.308386 43807.729272 max 10000.00000 1.000000 1.000000 2654.322576 73554.233495 split training and testing set 123456789from sklearn.model_selection import train_test_split# create features and targetfeatures = [\"balance\", \"income\"]X = default_data[features]y = default_data.default# slipt data set into training and testing settrain_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.7, random_state=1) 1234567import numpy as npimport matplotlib as mplfrom scipy import linalgfrom matplotlib import colorsimport matplotlib.pyplot as pltfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysisfrom sklearn.linear_model import LogisticRegression Plot function 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# set colormapcmap = colors.LinearSegmentedColormap( 'red_blue_classes', &#123;'red': [(0, 1, 1), (1, 0.7, 0.7)], 'green': [(0, 0.7, 0.7), (1, 0.7, 0.7)], 'blue': [(0, 0.7, 0.7), (1, 1, 1)]&#125;)plt.cm.register_cmap(cmap=cmap)# Plot functiondef plot_data(model, X, y, y_pred): plt.ylabel('income') plt.xlabel('balance') tp = (y == y_pred) # True Positive tp0, tp1 = tp[y == 0], tp[y == 1] X0, X1 = X[y == 0], X[y == 1] X0_tp, X0_fp = X0[tp0], X0[~tp0] X1_tp, X1_fp = X1[tp1], X1[~tp1] # true class 0: dots, false class 0: x plt.scatter(X0_tp[\"balance\"], X0_tp[\"income\"], marker='.', color='red') plt.scatter(X0_fp[\"balance\"], X0_fp[\"income\"], marker='x', s=20, color='#990000') # dark red # true class 1: dots, false class 1: x plt.scatter(X1_tp[\"balance\"], X1_tp[\"income\"], marker='.', color='blue') plt.scatter(X1_fp[\"balance\"], X1_fp[\"income\"], marker='x', s=20, color='#000099') # dark blue # class 0 and 1 : all areas for decision boundary nx, ny = 200, 100 x_min, x_max = plt.xlim() y_min, y_max = plt.ylim() xx, yy = np.meshgrid(np.linspace(x_min, x_max, nx), np.linspace(y_min, y_max, ny)) Z = model.predict_proba(np.c_[xx.ravel(), yy.ravel()]) Z = Z[:, 1].reshape(xx.shape) plt.pcolormesh(xx, yy, Z, cmap='red_blue_classes', norm=colors.Normalize(0., 1.), zorder=0) # plot decision boundary plt.contour(xx, yy, Z, [0.5], linewidths=2., colors='white') plt.axis('tight') plt.tight_layout() plt.subplots_adjust(top=0.92) plt.show() Linear Discriminant Analysis 1234567# Linear Discriminant Analysisplt.figure(figsize=(6, 7), facecolor='white')plt.title('Linear Discriminant Analysis', y=1, fontsize=15)lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)y_pred = lda.fit(train_X, train_y).predict(test_X)plot_data(lda, test_X, test_y, y_pred) Quadratic Discriminant Analysis 1234567# Quadratic Discriminant Analysisplt.figure(figsize=(6, 7), facecolor='white')plt.title('Quadratic Discriminant Analysis', y=1, fontsize=15)qda = QuadraticDiscriminantAnalysis(store_covariance=True)y_pred = qda.fit(train_X, train_y).predict(test_X)plot_data(qda, test_X, test_y, y_pred) Use LogisticRegression directly to model the data If I use this data directly to feed the LogisticRegression model, the model will prefer to predict all as 0 for a high accuracy of 0 prediction. 12print(default_data.default.value_counts(dropna = False))print(\"The mean of default: \", default_data.default.mean()) 0 9667 1 333 Name: default, dtype: int64 The mean of default: 0.0333 NOTE: As it showing above: the provided data with very low proportion of positive signals. Conclusion: The provided data is imbalanced ! Solution: usually for imbalanced data, there are some solutions: Collect more data Down-Sampling or Over-Sampling to get balanced samples Change the Thresholds to adjust the prediction Assign class weights for the low rate class 123from sklearn.metrics import confusion_matrix, auc, roc_curve, roc_auc_score, recall_score, precision_recall_curvefrom sklearn.metrics import make_scorer, precision_scorefrom sklearn.model_selection import GridSearchCV 1234567# Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = .33, stratify = y)logitreg_parameters = &#123;'C': np.power(10.0, np.arange(-3, 3))&#125;logitreg = LogisticRegression(verbose = 3, warm_start = True)logitreg_grid = GridSearchCV(logitreg, param_grid = logitreg_parameters, scoring = 'roc_auc', n_jobs = 1)logitreg_grid.fit(train_X, train_y) GridSearchCV(cv=None, error_score=nan, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='auto', n_jobs=None, penalty='l2', random_state=None, solver='lbfgs', tol=0.0001, verbose=3, warm_start=True), iid='deprecated', n_jobs=1, param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])}, pre_dispatch='2*n_jobs', refit=True, return_train_score=False, scoring='roc_auc', verbose=0) 123456# draw decision boundary with LogisticRegression directlyplt.figure(figsize=(6, 7), facecolor='white')plt.title('Logistic Regression directly', y=1, fontsize=15)y_pred = logitreg_grid.predict(test_X)splot = plot_data(logitreg_grid, test_X, test_y, y_pred) 12345678910111213# on OVER-Sampled TRAINing dataprint(\"\\n The recall score on Training data is:\", recall_score(train_y, logitreg_grid.predict(train_X))) # 0.32print(\"\\n The precision score on Training data is:\", precision_score(train_y, logitreg_grid.predict(train_X))) # 0.74# on the separated TEST dataprint(\"\\n Thre recall score on Test data is:\", recall_score(test_y, logitreg_grid.predict(test_X))) # 0.32print(\"\\n Thre precision score on Test data is:\", precision_score(test_y, logitreg_grid.predict(test_X))) # 0.75print(\"\\n Thre Confusion Matrix on Test data is:\", confusion_matrix(test_y, logitreg_grid.predict(test_X))) # [[3178 12][ 74 36]] The recall score on Training data is: 0.32231404958677684 The precision score on Training data is: 0.7222222222222222 Thre recall score on Test data is: 0.3626373626373626 Thre precision score on Test data is: 0.673469387755102 Thre Confusion Matrix on Test data is: [[2893 16] [ 58 33]] Conclusions: From the output above, on the training data, the recall score is 0.32 which means 32 over 100 of the True positive conditions are predicted correctly. And 74 over 100 of the predicted positives are True Positive. On the Test data, the model performance metric evalued by recall or precision are close to the Training data. There is a precision score of 0.81 on the Test data, which means 81 out of 100 predicted positives are True positives. From Confusion Matrix, 36 of 110 True Positives are predicted as positives. And of all 48 predicted as positive, 36 of them are True positives. Change the Thresholds plot roc curve 1234567891011def plot_roc(new_thresholds, logitreg_grid): y_train_pred_probas = logitreg_grid.predict_proba(train_X)[:, 1] # prob of predict as 1 fpr, tpr, thresholds = roc_curve(train_y, y_train_pred_probas) # precision_recall_curve roc = pd.DataFrame(&#123;'FPR':fpr, 'TPR':tpr, 'Thresholds':thresholds&#125;) plt.figure() plt.title('ROC Curve', y = 1, fontsize = 15) plt.plot(roc.FPR, roc.TPR) plt.axvline(new_thresholds, color = '#00C851', linestyle = '--') plt.xlabel(\"FPR\") plt.ylabel(\"TPR\") plt.show() 12new_threshold = 0.1 # 0.5 is the default valueplot_roc(new_threshold, logitreg_grid) By default, the threshold is 0.5. Since the recall score is low, I’m trying to lower the threshold to get more predicted as Positive. At the same time, more True Negative data will be falsely predicted as Positive. So the Precision score will be lower. 123456789y_test_pred_probas = logitreg_grid.predict_proba(test_X)[:, 1]y_test_pred = (y_test_pred_probas &gt;= new_threshold).astype(int)print(\"After change threshold to 0.1, the recall socre on Test data is:\")print(recall_score(test_y, y_test_pred)) # 0.736print(\"After change threshold to 0.1, the precision socre on Test data is:\")print(precision_score(test_y, y_test_pred)) # 0.301print(\"After change threshold to 0.1, the Confusion Matrix on Test data is:\")print(confusion_matrix(test_y, y_test_pred)) # [[3002 188][ 29 81]] After change threshold to 0.1, the recall socre on Test data is: 0.7142857142857143 After change threshold to 0.1, the precision socre on Test data is: 0.25 After change threshold to 0.1, the Confusion Matrix on Test data is: [[2714 195] [ 26 65]] Create Over-sampling data and Fit the model 1234567891011121314151617oversample_ratio = sum(train_y == 0) / sum(train_y == 1) # size to repeat y == 1# repeat the positive data for X and yy_train_pos_oversample = pd.concat([train_y[train_y==1]] * int(oversample_ratio), axis = 0)X_train_pos_oversample = pd.concat([train_X.loc[train_y==1, :]] * int(oversample_ratio), axis = 0)# concat the repeated data with the original data togethery_train_oversample = pd.concat([train_y, y_train_pos_oversample], axis = 0).reset_index(drop = True)X_train_oversample = pd.concat([train_X, X_train_pos_oversample], axis = 0).reset_index(drop = True)print(y_train_oversample.value_counts(dropna = False, normalize = True))logitreg_parameters = &#123;'C': np.power(10.0, np.arange(-3, 3))&#125;logitreg = LogisticRegression(verbose = 3, warm_start = True)logitreg_grid = GridSearchCV(logitreg, param_grid = logitreg_parameters, scoring = 'roc_auc', n_jobs = 1)logitreg_grid.fit(X_train_oversample, y_train_oversample) 1 0.500665 0 0.499335 Name: default, dtype: float64 GridSearchCV(cv=None, error_score=nan, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='auto', n_jobs=None, penalty='l2', random_state=None, solver='lbfgs', tol=0.0001, verbose=3, warm_start=True), iid='deprecated', n_jobs=1, param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])}, pre_dispatch='2*n_jobs', refit=True, return_train_score=False, scoring='roc_auc', verbose=0) 123456# Logistic Regression with Over-samplingplt.figure(figsize=(6, 7), facecolor='white')plt.title('Logistic Regression with Over-sampling', y=1, fontsize=15)y_pred = logitreg_grid.predict(test_X)plot_data(logitreg_grid, test_X, test_y, y_pred) 12345678910111213# on OVER-Sampled TRAINing dataprint(\"After Over-Sampling, the recall score on Training data is\")print(recall_score(y_train_oversample, logitreg_grid.predict(X_train_oversample))) # 0.865print(\"After Over-Sampling, the precision score on Training data is\")print(precision_score(y_train_oversample, logitreg_grid.predict(X_train_oversample))) # 0.727# on the TESTing dataprint(\"After Over-Sampling, the recall score on Test data is\")print(recall_score(test_y, logitreg_grid.predict(test_X))) # 0.854print(\"After Over-Sampling, the precision score on Test data is\")print(precision_score(test_y, logitreg_grid.predict(test_X))) # 0.080print(\"After Over-Sampling, the Confusion Matrix on Test data is\")print(confusion_matrix(test_y, logitreg_grid.predict(test_X))) # [[2113 1077][ 16 94]] After Over-Sampling, the recall score on Training data is 0.8884297520661157 After Over-Sampling, the precision score on Training data is 0.8717057631045467 After Over-Sampling, the recall score on Test data is 0.8791208791208791 After Over-Sampling, the precision score on Test data is 0.17094017094017094 After Over-Sampling, the Confusion Matrix on Test data is [[2521 388] [ 11 80]] Conclusion: From the output above, on the training data, the recall score is 0.865 which means 86.5 over 100 of the True conditions are predicted correctly. And 85.4 over 100 of the predicted positives are really positive. However, there is only a precision score of 0.080 on the Test data, which means only 8 out of 100 predicted positives are real positives. From Confusion Matrix, 94 of 110 True Positives are predicted as positives. However, the model predicted 1077 Negative data as Positive. That is, this model has pretty strong over-fitting. Change the Thresholds 12new_threshold = 0.2plot_roc(new_threshold, logitreg_grid) 123456789y_test_pred_probas = logitreg_grid.predict_proba(test_X)[:, 1]y_test_pred = (y_test_pred_probas &gt;= new_threshold).astype(int)print(\"After change threshold to 0.2, the recall socre on Test data is:\")print(recall_score(test_y, y_test_pred)) # 0.990print(\"After change threshold to 0.2, the precision socre on Test data is:\")print(precision_score(test_y, y_test_pred)) # 0.047print(\"After change threshold to 0.2, the Confusion Matrix on Test data is:\")print(confusion_matrix(test_y, y_test_pred)) # [[ 1013 2177][ 1 109]] After change threshold to 0.2, the recall socre on Test data is: 0.9340659340659341 After change threshold to 0.2, the precision socre on Test data is: 0.10023584905660378 After change threshold to 0.2, the Confusion Matrix on Test data is: [[2146 763] [ 6 85]] Conclusion: After over-sampling, the model will have higher recall rate. That is, the model will work better on detect the Frauds from True Frauds. The price is the lower precision rate. Logistic Regression with class_weight Rather than over-sampling, we can assign more weights to the lower rate class. we can write out the Likelihood function for Logistic Regression, the Over-Sampling and the assigning more Weights will be equivalent. 1234567positive_weight = sum(train_y == 0) / sum(train_y == 1) # size to repeat y == 1logitreg_parameters = &#123;'C': np.power(10.0, np.arange(-3, 3))&#125;logitreg = LogisticRegression(class_weight = &#123;0 : 1, 1 : positive_weight&#125;, verbose = 3, warm_start = True)logitreg_grid = GridSearchCV(logitreg, param_grid = logitreg_parameters, scoring = 'roc_auc', n_jobs = 1)logitreg_grid.fit(train_X, train_y) GridSearchCV(cv=None, error_score=nan, estimator=LogisticRegression(C=1.0, class_weight={0: 1, 1: 27.925619834710744}, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='auto', n_jobs=None, penalty='l2', random_state=None, solver='lbfgs', tol=0.0001, verbose=3, warm_start=True), iid='deprecated', n_jobs=1, param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])}, pre_dispatch='2*n_jobs', refit=True, return_train_score=False, scoring='roc_auc', verbose=0) 123456# Logistic Regression with class_weightplt.figure(figsize=(6, 7), facecolor='white')plt.title('Logistic Regression', y=1, fontsize=15)y_pred = logitreg_grid.predict(test_X)plot_data(logitreg_grid, test_X, test_y, y_pred) 1234567891011121314print(\"After assign class_weight, the recall score on Training data is\")print(recall_score(y_train_oversample, logitreg_grid.predict(X_train_oversample))) # 0.856print(\"After assign class_weight, the precision score on Training data is\")print(precision_score(y_train_oversample, logitreg_grid.predict(X_train_oversample))) # 0.729# on the separated TEST dataprint(\"After assign class_weight, the recall score on Test data is\")print(recall_score(test_y, logitreg_grid.predict(test_X))) # 0.845print(\"After assign class_weight, the precision score on Test data is\")print(precision_score(test_y, logitreg_grid.predict(test_X))) # 0.081print(\"After assign class_weight, the Confusion Matrix on Test data is\")print(confusion_matrix(test_y, logitreg_grid.predict(test_X))) # [[2135 1055] [ 17 93]]print(\"After assign class_weight, the ROC AUC Score on Test data is\")print(roc_auc_score(test_y, logitreg_grid.predict(test_X))) # 0.757 After assign class_weight, the recall score on Training data is 0.859504132231405 After assign class_weight, the precision score on Training data is 0.7171530599679843 After assign class_weight, the recall score on Test data is 0.8791208791208791 After assign class_weight, the precision score on Test data is 0.075046904315197 After assign class_weight, the Confusion Matrix on Test data is [[1923 986] [ 11 80]] After assign class_weight, the ROC AUC Score on Test data is 0.7700863934965 Conclusion: If I set up the class weight for the positive as the ratio of non-Fault / Fault, I will get the result close to the over-sampling. So, in summary: This specific data is about fraud detection. So the model should focus on to find the frauds to avoid potential loss for the bank. That is, we focus on recall rate. Conclusion If we use the imbalanced data directly, we will get low performance model since the model prefer to predict to the class with dominated frequency class. The recall rate is 0.31. That is, only 31% of the frauds can be detected by this model. To fix that, one way is to do over-sampling or down-sampling. If we use over-sampling, the model performance will be improved a lot. For this specific case, the recall rate on the independent test set will be improved from 0.31 to 0.87 Another way to improve the model performance is to assign more weights to the low frequency class. Generally speaking, for Logistic Regression, assigning weights is similar to over-sampling, from the likelihood function perspective. The final output results are close too as demonstrated above. Reference Credit Card Fraud Detection / Imbalanced data modeling - Part I: Logistic Regression Credit Fraud || Dealing with Imbalanced Datasets","categories":[{"name":"Machine Learning Game","slug":"Machine-Learning-Game","permalink":"https://littlelittlemoon.github.io/categories/Machine-Learning-Game/"},{"name":"Imbalanced Data Modeling","slug":"Machine-Learning-Game/Imbalanced-Data-Modeling","permalink":"https://littlelittlemoon.github.io/categories/Machine-Learning-Game/Imbalanced-Data-Modeling/"}],"tags":[{"name":"LDA","slug":"LDA","permalink":"https://littlelittlemoon.github.io/tags/LDA/"},{"name":"QDA","slug":"QDA","permalink":"https://littlelittlemoon.github.io/tags/QDA/"},{"name":"LR","slug":"LR","permalink":"https://littlelittlemoon.github.io/tags/LR/"},{"name":"Imbalanced Data modeling","slug":"Imbalanced-Data-modeling","permalink":"https://littlelittlemoon.github.io/tags/Imbalanced-Data-modeling/"},{"name":"Machine learning","slug":"Machine-learning","permalink":"https://littlelittlemoon.github.io/tags/Machine-learning/"},{"name":"Classify","slug":"Classify","permalink":"https://littlelittlemoon.github.io/tags/Classify/"}],"keywords":[{"name":"Machine Learning Game","slug":"Machine-Learning-Game","permalink":"https://littlelittlemoon.github.io/categories/Machine-Learning-Game/"},{"name":"Imbalanced Data Modeling","slug":"Machine-Learning-Game/Imbalanced-Data-Modeling","permalink":"https://littlelittlemoon.github.io/categories/Machine-Learning-Game/Imbalanced-Data-Modeling/"}]},{"title":"Leetcode Note in Apri 2020","slug":"Leetcode Note","date":"2020-04-01T01:51:55.000Z","updated":"2020-04-06T16:27:28.273Z","comments":true,"path":"2020/04/01/Leetcode Note/","link":"","permalink":"https://littlelittlemoon.github.io/2020/04/01/Leetcode%20Note/","excerpt":"","text":"python XOR（异或） Finding sigle number in a integer list Given a non-empty array of integers, every element appears twice except for one. Find that single one. Note: Your algorithm should have a linear runtime complexity. Could you implement it without using extra memory? Example: Input: [4,1,2,1,2] Output: 4 my solutions: tuple + list 12345678910111213141516171819202122232425262728293031class Solution: def singleNumber(self, nums: List[int]) -&gt; int: # store the count of positive number p_count = [0] * (max(tuple(nums)) + 1) # store the positive number p_nums = () # store the count of negative number n_count = [0] * (abs(min(tuple(nums))) + 1) # store the negative number n_nums = () # counting for num in nums: if num &gt;= 0: p_nums = p_nums + (num, ) p_count[num] = p_count[num] + 1 else: n_nums = n_nums + (num, ) n_count[abs(num)] = n_count[abs(num)] + 1 # find the sigle number for num in p_nums: if p_count[num] == 1: return num for num in n_nums: if n_count[abs(num)] == 1: return num return None Space complexity： O(n) time complexity： O(n) optimization using XOR The most crucial trick here is to recognize that if you XOR any same number together, you cancel it out (=0). Explanation: nums = [2, 4, 5, 4, 3, 5, 2] XORing everything together = 2 ^ 4 ^ 5 ^ 4 ^ 3 ^ 5 ^ 2 = (2^2) ^ (4^4) ^ (5^5) ^ 3 = 0 ^ 0 ^0 ^ 3 = 3 123class Solution: def singleNumber(self, nums: List[int]) -&gt; int: return reduce(lambda x, y: x^y, nums, 0) Space complexity： O(1) time complexity： O(n) Reduce 12list(map(str, [1, 2, 3, 4, 5, 6, 7, 8, 9]))# output: ['1', '2', '3', '4', '5', '6', '7', '8', '9'] Map reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4) 12345678910# convert string to integerfrom functools import reduceDIGITS = &#123;'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9&#125;def char2num(s): return DIGITS[s]def str2int(s): return reduce(lambda x, y: x * 10 + y, map(char2num, s)) Dictionary &amp; Tuple Group Anagrams Given an array of strings, group anagrams together. Example: Input: [“eat”, “tea”, “tan”, “ate”, “nat”, “bat”], Output: [ [“ate”,“eat”,“tea”], [“nat”,“tan”], [“bat”] ] My bad answer 12345678910111213141516class Solution: def groupAnagrams(self, strs: List[str]) -&gt; List[List[str]]: group_list = [] group_list.append([strs[0]]) for i in range(1, len(strs)): sorted_str = sorted(strs[i]) for j in range(0, len(group_list)): sorted_comp_str = sorted(group_list[j][0]) if sorted_str == sorted_comp_str: group_list[j].append(strs[i]) break if j == len(group_list) - 1: group_list.append([strs[i]]) break return group_list Result: Time Limit Exceeded Nice answer with dictionary and tuple 123456789101112class Solution: def groupAnagrams(self, strs: List[str]) -&gt; List[List[str]]: # create a null dictionary group_list = &#123;&#125; for s in strs: # sort the string's letters and save as a tuple key = tuple(sorted(s)) # search dictionary with the str's tuple and save the new value group_list[key] = group_list.get(key, []) + [s] return group_list.values() Summary Tuple can be used for the dictionary’s key. wow~ use dictionary can speed up the search. Algorithm Floyd’s cycle detection What we need to do in case we need the starting point of the loop ? Once we know for sure that a loop is present. Move the slowPointer to start of the list,(i.e headNode) and let fastPointer remain there at the meeting point Now move both the pointers one node at a time The point where both pointers will meet, is our required start of the loop. The algorithm uses O(λ + μ) operations of these types, and O(1) storage space. Application Happy number detection A happy number is a number defined by the following process: Starting with any positive integer, replace the number by the sum of the squares of its digits, and repeat the process until the number equals 1 (where it will stay), or it loops endlessly in a cycle which does not include 1. Those numbers for which this process ends in 1 are happy numbers. Short Version utilizing walrus operator := 12345678class Solution: def isHappy(self, n: int) -&gt; bool: def next_num(num): return sum(map(lambda x:int(x)**2, str(num))) slow, fast = n, next_num(n) while (slow:=next_num(slow)) != (fast:=next_num(next_num(fast))) and fast != 1: continue return fast == 1 or not slow == fast Easier to understand version 123456789class Solution: def isHappy(self, n: int) -&gt; bool: def next_num(num): return sum(map(lambda x:int(x)**2, str(num))) slow, fast = n, next_num(n) while slow != fast and fast != 1: slow = next_num(slow) fast = next_num(next_num(fast)) return fast == 1 or not slow == fast Another solution 123456789101112131415161718192021222324252627282930313233class Solution: def isHappy(self, n: int) -&gt; bool: ####################################################################### # let's try different n: # true (1) -&gt; 1 # false (2) -&gt; 4 -&gt; 16 -&gt; 37 -&gt; 58 -&gt; 89 -&gt; 145 -&gt; 42 -&gt; 20 -&gt; 4 # false (3) -&gt; 9 -&gt; 81 -&gt; 65 -&gt; 61 -&gt; 37 (look at 2) # false (4) -&gt; (look at 2) # false (5) -&gt; 25 -&gt; 29 -&gt; 85 -&gt; 89 (look at 2) # false (6) -&gt; 36 -&gt; 45 -&gt; 41 -&gt; 17 -&gt; 50 -&gt; 25 (look at 5) # true (7) -&gt; 49 -&gt; 97 -&gt; 10 # false (8) -&gt; 64 -&gt; 52 -&gt; 29 (look at 5) # false (9) -&gt; 9 -&gt; 81 -&gt; 65 (look at 3) # # All other n &gt;= 10, while computing will become [1-9], # So there are two cases 1 and 7 which are true. # # Notice, that all falses has the same path as 2 (loop). ####################################################################### counting = 0 num = n while True: counting = 0 for str_num in str(num): counting = counting + pow(int(str_num), 2) if counting &gt;= 1 and counting &lt;=9: if counting == 1 or counting == 7: return True else: return False else: num = counting Reference Detecting start of a loop in singly Linked List Floyd’s Cycle detection algorithm | Determining the starting point of cycle Updating . . .","categories":[{"name":"Coding Game","slug":"Coding-Game","permalink":"https://littlelittlemoon.github.io/categories/Coding-Game/"},{"name":"Leetcode","slug":"Coding-Game/Leetcode","permalink":"https://littlelittlemoon.github.io/categories/Coding-Game/Leetcode/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://littlelittlemoon.github.io/tags/Leetcode/"},{"name":"Python","slug":"Python","permalink":"https://littlelittlemoon.github.io/tags/Python/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://littlelittlemoon.github.io/tags/Algorithm/"}],"keywords":[{"name":"Coding Game","slug":"Coding-Game","permalink":"https://littlelittlemoon.github.io/categories/Coding-Game/"},{"name":"Leetcode","slug":"Coding-Game/Leetcode","permalink":"https://littlelittlemoon.github.io/categories/Coding-Game/Leetcode/"}]},{"title":"Evalution of hair and scalp condition based on microscopy image analysis 之头发厚度计算问题","slug":"Evalution of hair and scalp condition based on microscopy image analysis 之头发厚度计算问题","date":"2019-12-29T15:51:27.000Z","updated":"2020-04-06T16:27:28.273Z","comments":true,"path":"2019/12/29/Evalution of hair and scalp condition based on microscopy image analysis 之头发厚度计算问题/","link":"","permalink":"https://littlelittlemoon.github.io/2019/12/29/Evalution%20of%20hair%20and%20scalp%20condition%20based%20on%20microscopy%20image%20analysis%20%E4%B9%8B%E5%A4%B4%E5%8F%91%E5%8E%9A%E5%BA%A6%E8%AE%A1%E7%AE%97%E9%97%AE%E9%A2%98/","excerpt":"","text":"Paper: Evalution of hair and scalp condition based on microscopy image analysis 摘要翻译：由于IT技术的快速部署，医疗保健服务进入了一个新时代。诸如心脏监护之类的某些服务对于生命至关重要，并有助于挽救生命。另一方面，监测脱发是另一种有趣的保健服务。尽管这对生活并不重要，但人们还是会非常注意自己的头发状况。脱发是与头发状况有关的主要问题之一，因为过多和无意的脱发可能导致秃头。可以在护发店专业进行护发，但是这需要很多时间和成本。最近，由于廉价的智能设备，对头发状况的自我诊断已成为可能。仍然很少开发用于评估头发状况的应用。在本文中，我们提出了一种新方案，通过从显微镜图像中提取各种特征来评估头发和头皮的状况。其特征包括头发的厚度，头发的密度和头皮的斑点。通过对原型系统进行广泛的实验，我们证明了该方案的有效性。 为了分析头皮图像，应该将头发和头皮彼此分开。两者之间最明显的区别是它们的颜色。头皮相对明亮，头发相对深色。因此，在许多研究中，根据颜色对头发和头皮区域进行分类，并根据这种分离进行图像分析。 Overall steps for feature extraction Pre-processing 该论文中所提到的图片预处理方法和“An Unsupervised Hair Segmentation and Counting System in Microscopy Images”中相似，具体可参考：论文解读 - An Unsupervised Hair Segmentation and Counting System in Microscopy Images 之头发计数问题。 裁切图像 图像增强: 使用Contrast stretching方法，增加图像的对比度 Morphological opening：去除油性和湿润的头发在其显微镜图像中形成的亮点 二值化：经过上述预处理后，将所得图像转换为灰度图像，然后根据Otsu阈值转换为二进制图像。 在二值图像中，“ 0”和“ 1”分别表示头发像素和头皮像素。 hair/scalp image analysis 头发检测 技术 使用Canny边缘检测算法从二进制图像中获取毛发轮廓。 结果 图2显示了检测和建模头发的所有步骤。对于图2（a）中的原始显微镜图像，我们可以计算出头发轮廓和骨骼。 通过使用二进制图像上的稀疏运算（Thinning operation） 来计算头发骨架。Thinning是一种形态学运算，可去除整个二进制图像中的前景。 图2（d）显示了通过叠加头发轮廓和骨骼得到的最终图像。 头发厚度计算 头发厚度可以通过与头发垂直线的长度来定义。要获得垂直线，我们首先需要计算头发方向. 通过考虑相邻像素并应用PCA（主成分分析）算法来计算每个像素的方向. 当计算头发骨架上所有点的方向时，可以计算出每个点的垂直线。然后，垂直线与头发边界的交点之间的距离就是头发的厚度，可以通过使用欧氏距离来计算： ρ=(x2−x1)2+(y2−y1)2\\rho = \\sqrt{\\smash[b]{(x_2-x_1)^2 + (y_2-y_1)^2}} ρ=(x2​−x1​)2+(y2​−y1​)2​ 根据欧式距离ρ\\rhoρ可计算出头发的平均厚度： Thincknessavg=1n∑i=1n(xi2−xi1)2+(yi2−yi1)2Thinckness_{avg} =\\frac{1}{n}\\displaystyle\\sum_{i=1}^n\\sqrt{\\smash[b]{(x_{i2}-x_{i1})^2 + (y_{i2}-y_{i1})^2}} Thincknessavg​=n1​i=1∑n​(xi2​−xi1​)2+(yi2​−yi1​)2​ 这里ThincknessavgThinckness_{avg}Thincknessavg​的单位是像素，因此需要使用等式将其更改为仪表单位: Thincknessactual(um)=Thincknessavg(px)×UL(um/px)mfThinckness_{actual}(um) = \\frac{Thinckness_{avg}(px) ×UL(um/px)}{mf} Thincknessactual​(um)=mfThincknessavg​(px)×UL(um/px)​ mfmfmf: 是相机的放大倍率 ULULUL: 是单位长度，表示一个像素的微米长度 实验结果 为了评估我们的头发厚度评估方法的准确性，我们使用电子显微镜测量了实际的头发厚度。头发厚度测量的准确性如表1所示。 据报道，韩国人的平均头发厚度为84.9μm。与此相比，我们的90.29μm的结果相当不错。实际值（通过电子显微镜计算）与估计值之间的差异很小。 可能的原因之一是阴影效果。另一个可能的原因是相机镜头变形。 图像尺寸为640x480。但是，相机所覆盖区域的真实形状几乎是椭圆形。因此，相机放大率在行和列之间具有差异。根据拍摄角度，放大倍率可能会有所不同。 总结 针对头发粗细（厚度）计算问题，上述论文提出了基于头发轮廓和骨骼图，通过计算每个像素点的方向和垂线，进一步使用欧式距离公式来计算头发的垂直直径，但对相关技术的应用细节描述不多。 参考文献 Evalution of hair and scalp condition based on microscopy image analysis An Unsupervised Hair Segmentation and Counting System in Microscopy Images Euclidean distance Principal component analysis","categories":[{"name":"Paper Game","slug":"Paper-Game","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/"},{"name":"Smash","slug":"Paper-Game/Smash","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/Smash/"}],"tags":[{"name":"图像处理","slug":"图像处理","permalink":"https://littlelittlemoon.github.io/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"线检测","slug":"线检测","permalink":"https://littlelittlemoon.github.io/tags/%E7%BA%BF%E6%A3%80%E6%B5%8B/"},{"name":"头发厚度计算问题","slug":"头发厚度计算问题","permalink":"https://littlelittlemoon.github.io/tags/%E5%A4%B4%E5%8F%91%E5%8E%9A%E5%BA%A6%E8%AE%A1%E7%AE%97%E9%97%AE%E9%A2%98/"}],"keywords":[{"name":"Paper Game","slug":"Paper-Game","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/"},{"name":"Smash","slug":"Paper-Game/Smash","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/Smash/"}]},{"title":"Evalution of hair and scalp condition based on microscopy image analysis 之头发计数问题","slug":"Evalution of hair and scalp condition based on microscopy image analysis 之头发计数问题","date":"2019-12-28T15:58:27.000Z","updated":"2020-04-06T16:27:28.273Z","comments":true,"path":"2019/12/28/Evalution of hair and scalp condition based on microscopy image analysis 之头发计数问题/","link":"","permalink":"https://littlelittlemoon.github.io/2019/12/28/Evalution%20of%20hair%20and%20scalp%20condition%20based%20on%20microscopy%20image%20analysis%20%E4%B9%8B%E5%A4%B4%E5%8F%91%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/","excerpt":"","text":"Paper: Evalution of hair and scalp condition based on microscopy image analysis 计数方法 典型的便携式显微镜相机通常覆盖5mm x 5mm的矩形。因此，如果一根头发长于5毫米，则它必须超出矩形。基于此观察，我们对毛发计数有两个假设： 每根头发由一个起点和一个终点表示; 起点位于矩形内部，终点位于图像的边界上。 头发计数：使用预处理阶段获得的骨架图像，基于上述两点假设，如果头发的骨架线的一个点在矩形内而另一点在边界上，则我们对头发进行计数。 图3示出了头发计数的示例。在图中，计数的像素用红色点标记，并且这些点叠加在原始图像上。然后，可以通过将计数的像素数除以图像尺寸来计算头发密度。 实验结果 为了评估头发计数算法，我们对200个头皮图像的数据集进行了实验。 表2列出了根据我们的算法计算出的实际毛发数与估计毛发数之间的精确度/召回率。 平均准确度和召回率分别为91.35％和92.01％。即使性能相当好，精度/调用率也可以进一步提高。错误的一个关键原因是预处理和原始图像的质量。在我们的实验中，一旦图像中出现模糊点，就不可能在预处理步骤中消除所有噪音。因此，考虑到相机噪声，精度非常好。 同样，我们测试了毛孔计数算法，结果显示平均准确率约为90％。 总结 计数思路 将图片边缘看作一矩形； 对满足“头发由一个起点和一个终点表示，且起点位于矩形内部，终点位于图像的边界上”条件的头发进行计数； 使用通过细化操作获得的头发骨架图像对满足条件的头发进行计数； 通过将计数的像素数除以图像尺寸来计算头发密度。 参考文献 Evalution of hair and scalp condition based on microscopy image analysis","categories":[{"name":"Paper Game","slug":"Paper-Game","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/"},{"name":"Smash","slug":"Paper-Game/Smash","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/Smash/"}],"tags":[{"name":"头发计数问题","slug":"头发计数问题","permalink":"https://littlelittlemoon.github.io/tags/%E5%A4%B4%E5%8F%91%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/"},{"name":"图像处理","slug":"图像处理","permalink":"https://littlelittlemoon.github.io/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"线检测","slug":"线检测","permalink":"https://littlelittlemoon.github.io/tags/%E7%BA%BF%E6%A3%80%E6%B5%8B/"}],"keywords":[{"name":"Paper Game","slug":"Paper-Game","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/"},{"name":"Smash","slug":"Paper-Game/Smash","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/Smash/"}]},{"title":"An Unsupervised Hair Segmentation and Counting System in Microscopy Images 之头发计数问题","slug":"An Unsupervised Hair Segmentation and Counting System in Microscopy Images 之头发计数问题","date":"2019-12-28T15:51:27.000Z","updated":"2020-04-07T03:09:32.148Z","comments":true,"path":"2019/12/28/An Unsupervised Hair Segmentation and Counting System in Microscopy Images 之头发计数问题/","link":"","permalink":"https://littlelittlemoon.github.io/2019/12/28/An%20Unsupervised%20Hair%20Segmentation%20and%20Counting%20System%20in%20Microscopy%20Images%20%E4%B9%8B%E5%A4%B4%E5%8F%91%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/","excerpt":"","text":"Paper: An Unsupervised Hair Segmentation and Counting System in Microscopy Images 摘要翻译：本文重点介绍使用高级图像处理算法开发用于临床的医学软件。本文讨论了头发分割和计数的三个关键问题: 首先，去除由于油脂或水分引起的任何亮点，这些亮点在头发的中部形成圆形图案，并显着影响确定线条的准确性。 第二，识别出两个接触或重叠的头发，并将其视为单个头发。为了解决这个问题，我们提出了一种头发捆绑算法(hair-bundling algorithm)来计算任何隐藏的头发。 最后，头发可能呈波浪状或卷曲状，这使传统的基于Hough的线检测算法不合适，因为它会受到参数选择的影响，例如线段的最小长度以及线段之间的距离。我们提出的毛发计数算法比基于Hough的毛发计数算法要准确得多，并且在各种白平衡下对卷发，油性头皮，噪声腐蚀和重叠的头发都具有适用性。 关键词：毛发计数，头皮诊断，护发诊断，毛囊诊断，线段检测。 System flowchart 预处理阶段 (Preprocessing Stage) 使用对比度拉伸方法(the contrast-stretching method)来增加头皮和头发像素之间的对比度; 为了减少亮点的影响，提出了一种健壮的颜色形态算法(morphological algorithm)，以使颜色平滑并保持头发的保真度; 为每个颜色分量应用了Karhunen-Loève变换(KLT)，并保留了具有最高能量的分量，并使用Otsu阈值获得了可靠的二进制图像。 数据采集规定 这项研究的唯一假设: 头发的颜色比皮肤的颜色深。 头发图像是从数码显微镜相机（DMC）捕获，内置LED增强，可自动保持亮度稳定。应用85倍的变焦倍率捕获图像。通常，使用分辨率为1024×768，相当于头皮面积是0.25×0.19英寸。此外，基于DMC的白平衡将捕获的图像分为两组： 具有日光的图像被分类为数据集＃1， 具有荧光的图像被分类为数据集＃2。 使用对比度拉伸(Contrast Stretching)进行图像增强 目的 增加头发和头皮之间的对比度; 增加头发和头皮像素之间的色差。 技术 通过分段线性对比度拉伸(color transformation by means of piecewise linear contrast stretching)进行颜色变换来增强图像，提高对比度； stretched the middle-intensity level, and kept the levels of the low-intensity and high-intensity so as to prevent creating false colors. 结果 进行对比度拉伸时，不会更改原始头发像素，也不会夸大油亮像素： 降低了头皮像素的强度; 增加了头皮和头发之间的色差; 亮点的像素保持不变。 Bright Spot Removal (BSR) 目的 除噪: 去除油性和湿润的头发在头发的中部产生的亮点: 技术 color morphological processing approach 非线性中值滤波器(nonlinear median filter)消除白点; 空间平滑滤波器(spatial smooth filter)降低白点的强度, 缺点是测试图像的非毛发区域也将变得模糊; color-based mathematical morphology (MM) method, used it as an ordering process. adopted the MM opening operator to depress the bright spot in the middle of the hairs. 侵蚀图像 放大图像 opening operation of image f : γM,nB(f) = τM,nB(εM,nB(f)), 其中εM,nB和τM,nB分别表示结构元素B对大小为n的图像f的形态侵蚀和放大, 对于像素x: εM,nB(f)(x) = {f(y) : f(y) = ∧M[f(z)],z ∈ n(Bx)} τM,nB(f)(x) = {f(y) : f(y) = ∨M[f(z)],z ∈ n(Bx)} ∧M和∨M分别表示M-ordering的最高和最小峰 使用KLT将彩色图像转换为灰度图像； 图像二值化步骤中，使用了Otsu阈值（指亮度的能量）以获得可靠的二值图像； 结果 图3示出了去除油性亮点的结果： 图4比较了使用BSR操作时的线路检测，并显示了对二值化和细化操作的明显影响。带有BSR的二值化图像具有减少的亮点反射，并且在细化图像中，亮点被转换为小圆圈。图4（f）显示，在线检测阶段，使用BSR生成的图像具有较少的不必要的线段： Multi-scale Line Detection Stage (MSLD) 采用改进的霍夫变换(the Hough transform)算法来检测不同的头发长度，并减少由于噪声引起的任何错误检测; 将弯曲的头发视为多条直线; 为了避免在应用稀疏过程时丢失头发，我们使用边缘信息(edge information)来发现任何隐藏或重叠的头发。 总体结构分析 目的 提出多尺度框架来是为了提高头发检测的准确性； 应用平行线捆绑（PLB）算法（parallel line bundling algorithm）来还原任何隐藏或重叠的头发。 最后，将矢量化的线段用作毛发标记和计数模块的输入数据。 技术 对HT应用了三个比例的图像：1024×768（原始比例），512×384和256×192。对缩放比例图像应用了两种处理方法：边缘检测和细化处理。 PLB算法应用于边缘图像以发现缺失的线段 HT被应用于细化图像以提取线段。通过利用PLB算法，可以恢复隐藏和重叠的头发。 最后，将矢量化的线段重新缩放为原始尺寸1024×768，并由逻辑或运算符进行整合。 结果 如图5所示，由于头发的长度和卷曲度的变化，使用单尺度HT不能检测所有的头发： 图5（a）显示，当一根头发几乎平行出现，与其他头发重叠时，或者如果头发的曲率超过HT的容限，那么最终会遗漏大量的头发，许多线段标签错误。 图5（b）示出了使用来自所有缩放图的线段的结果，从而改善了单个刻度的不足。 Parallel Line Bundling (PLB) 原理 应用Canny边缘检测器获得边缘图。在图6中，假设检测到两条平行线A和B，用ax+by+ca=0ax + by + c_a = 0ax+by+ca​=0和ax+by+cb=0ax + by + c_b = 0ax+by+cb​=0表示, d=∣ca−cb∣a2+b2d=\\frac{|c_a - c_b|} {\\sqrt{a^2 + b^2}}d=a2+b2​∣ca​−cb​∣​表示线段A,B之间的距离; 计算出夹有细线的平行线之间的平均距离davgd_{avg}davg​。 如果d&gt;davgd &gt; d_{avg}d&gt;davg​，则当(ddavg)&gt;wth(dd_{avg})&gt;w_{th}(ddavg​)&gt;wth​时，将发现隐藏的头发，其中wthw_{th}wth​表示边界因子，将通过头皮图像的分辨率根据经验进行修改。 结果 在图7（a）中，圆圈表示隐藏的头发，如图7（b）所示： Hair Labling and Counting 使用MSLD模块，得出了一组线段。根据头发的曲率和方向，将头发实现为具有不同长度的分段线向量簇。这项研究的目的是准确计算头皮上的毛发数量。这可以看作是聚类和标记问题。目标是将一组线段组合成语义“头发”并分配唯一的标签。由于每根头发都由相互关联的线段组成，因此我们为每个簇分配了唯一的标签。 我们采用了松弛标记算法(Relaxation labeling algorithm)来识别每个单独的线段，以确定与哪个线段相关联。 图8（a）显示了10个单独的线段的示例，这些线段被标记为来自同一根头发，然后绘制到（ρ，θ）（ρ，θ）（ρ，θ）坐标系上，如图8（b）所示。 交叉点处累积图的结果峰值为10。 Relaxation Labeling (RL) 松弛标注（RL）是一种相互关联的回归方法，它使用符号来描述模型的形状。 它旨在将目标对象（即本文中的线段）与符号或所谓的标记（即头发标签）进行匹配。RL算法首先分配一组随机标记。然后，通过迭代计算，可以获得更准确，更精确的标记集。在本研究中，RL算法被视为用于标记每个线段的聚类方法。 原理 令C(i，λ，j，λ′)C(i，λ，j，λ&#x27;)C(i，λ，j，λ′)表示约束为λ的线段与约束为λ’的线段j的兼容性，其约束为: ∑λC(i，λ，j，λ′)=1\\displaystyle\\sum_{λ}C(i，λ，j，λ&#x27;) = 1λ∑​C(i，λ，j，λ′)=1 for ∀i,j,λ,λ'。 兼容性C表示标记为λ’的线段j和标记为λ的线段i之间的相互依赖性。 如果兼容性仅由到原点的距离决定，则可能会出现错误的解释。 因此将兼容性定义如下： C(i，λ，j，λ′)={−1if i∉Sjε∣cos⁡[θi(λ)−θj(λ′)]∣+(1−ε)ρi(λ)ρj(λ′)if i∈Sj∩λ=/ λ′0otherwise C(i，λ，j，λ&#x27;) = \\begin{cases} -1 &amp;\\text{if } i \\notin S_j \\\\ \\varepsilon |\\cos[\\theta_i(\\lambda) - \\theta_j(λ&#x27;)]| + (1-\\varepsilon) \\frac{\\rho_i(\\lambda)}{\\rho_j(λ&#x27;)} &amp;\\text{if } i∈S_j∩λ{=}\\mathllap{/\\,}λ&#x27; \\\\ 0 &amp;\\text{otherwise } \\end{cases} C(i，λ，j，λ′)=⎩⎪⎨⎪⎧​−1ε∣cos[θi​(λ)−θj​(λ′)]∣+(1−ε)ρj​(λ′)ρi​(λ)​0​if i∈/​Sj​if i∈Sj​∩λ=/​λ′otherwise ​ 上式中： ε表示距离和方向置信度之间的加权因子 SjS_jSj​表示线段j的相邻假设 θi(λ)θ_i(λ)θi​(λ)表示从线段i到标记为λ的线段j的方向 ρi(λ)ρ_i(λ)ρi​(λ)表示原点到线段i和标记为λ的线段j之间的距离 如果ρj(λ)ρ_j(λ)ρj​(λ)高, 且C(i，λ，j，λ′)C(i，λ，j，λ&#x27;)C(i，λ，j，λ′)为正，则ρi(λ)ρ_i(λ)ρi​(λ)增加。 此标记算法是一个迭代并行过程，类似于概率松弛中使用的标记丢弃规则，操作员根据其他重量和兼容性反复调整标签重量。 对于每个线段和每个标签，新权重qi(r)(λ)q_i^{(r)}(\\lambda)qi(r)​(λ)的计算如下： qi(r)(λ)=∑j,j=/ i∑λ′C(i，λ，j，λ′)pj(r)(λ′)q_i^{(r)}(\\lambda) = \\sum_{\\mathclap{j, j{=}\\mathllap{/\\,}i}} \\sum_{\\mathclap{λ&#x27;}}C(i，λ，j，λ&#x27;)p_j^{(r)}(λ&#x27;) qi(r)​(λ)=j,j=/​i​∑​λ′∑​C(i，λ，j，λ′)pj(r)​(λ′) 其中: r表示第r次迭代 在等式中，乘积和是被标记为λ的给定线段i的期望 qi(r)(λ)q_i^{(r)}(\\lambda)qi(r)​(λ)是当前赋值pj(r)(λ′)p_j^{(r)}(λ&#x27;)pj(r)​(λ′)的加权和。 新任务可以用已下公式更新： pi(r+1)(λ)=pi(r)(λ)[1+qi(r)(λ)]∑j=1mpi(r)(λ′)[1+qi(r)(λ′)]p_i^{(r+1)}(\\lambda) = \\frac{p_i^{(r)}(λ)[1+q_i^{(r)}(λ)]}{\\displaystyle\\sum_{j=1}^mp_i^{(r)}(λ&#x27;)[1+q_i^{(r)}(λ&#x27;)]} pi(r+1)​(λ)=j=1∑m​pi(r)​(λ′)[1+qi(r)​(λ′)]pi(r)​(λ)[1+qi(r)​(λ)]​ 在这里，只选择pi(r)(λ)p_i^{(r)}(\\lambda)pi(r)​(λ)和C(i，λ，j，λ′)C(i，λ，j，λ&#x27;)C(i，λ，j，λ′)并应用该等式递归更新pi(r)(λ)p_i^{(r)}(\\lambda)pi(r)​(λ)，直到它们停止变化或收敛到1。对每个线段进行迭代验证，直到将其分配给正确的语义标签“ hair”为止。 实验结果 为了评估该系统，我们从UPMOST（UPG622）DMC捕获了40个分辨率为1024×768的比例尺图像作为测试数据集。根据DMC的白平衡，我们将测试图像分为两组，分别是数据集1和数据集2。 Experiment 1: Cross-Validation of the Line Detection 图10（b）-（d）显示了预处理模块的结果，包括亮点去除（BSR），二值化和稀化过程。 为了评估多尺度线检测算法的性能，测试图像我们将HT应用于三种不同尺度，以提取线段。 然后使用头发标签机制确定头发的数量。 如图10（e）-（f）所示，彩色线代表头发的标签。 换句话说，即使头发交叉或重叠，也可以准确地标记头发。 以下部分演示了有关精确度和召回率的毛发计数的客观测量。 我们比较了使用BSR和MSLD模块组合的四种情况，包括BSR + MSLD，而没有同时使用BSR和MSLD，仅BSR和仅MSLD。 表I比较了基于模块使用情况的系统敏感性。基于形态学的BSR和MSLD机制，以提高头发检测的性能，其准确率分别为94.98％和98.05％。与传统的HT线检测方法相比，数据集1和数据集2分别提高了2％和1.5％。从召回率的角度来看，它也高于其他模块组合。 平均而言，我们的召回率分别为9％和10％。根据我们的观察，应用BSR后，准确率得到了提高。 但是，将MSLD应用于数据集＃2时，准确率下降，因为它在油性头皮区域中产生了大量的光反射。同样，头发中部的亮点也被大大增强，导致精确度降低。 Experiment 2: System Refinement Using the PLB Algorithm 表II显示了PLB算法的效率。PLB方法使系统能够提取缺失的毛发，精确率提高了0.5％，召回率提高了5％。 PLB算法可以用作系统微调过程，将系统性能平均提高到96.89％。这是合理的，因为隐藏的头发不经常出现。 此外，我们可以通过显微镜控制头发图像的分辨率和角度，以避免这种情况。 Experiment 3: Complexity Analysis 当涉及到系统复杂性分析时，我们知道拟议的头发计数系统会花费更多时间。平均而言，高分辨率测试图像需要不到4秒的时间即可得出毛发计数信息。 表III列出了每个模块所需的时间与总执行时间的比较。 MSLD使用三个比例尺来获取一组线段，这需要大部分执行时间。 HT将边缘投影到（ρ，θ）空间以提取局部最大值的过程非常耗时。 为了克服这个问题，我们在MSLD中仅使用了两个标度。但是，此尝试导致性能下降。 此外，细化过程占用了总处理时间的四分之一以上。这是执行时间和系统精度之间的权衡。 总结 这项研究提出了一种自动的头发分割和计数系统，以减少人工评估者进行详细头皮评估所需的时间。 首先，油性和湿润的头发会在头发中间产生亮点。在计算头发数之前，我们需要消除头发上的亮点，以避免重复计算一些头发的问题。 第二，波浪状和卷发容易导致线检测故障。当头发不直时，常规的线检测算法无效。 第三，当头发相互交叉并互相咬合时，会出现对头发数量的低估，这使得精确定位所有头发非常困难。 最后，由于头皮相对未曝光，因此头皮的图像通常模糊或难以看见。另外，头皮通常照明不足或曝光过度。 计数思路 通过对不同缩略图中的头发做HT线段检测，然后将所有检测结果进行“逻辑或”整合，以减少缺失头发的计数，解决重叠头发的漏计数的问题。 本文的框架可以被视为迈向化妆品和头皮治疗应用的智能计算机辅助医学图像处理的第一步。 技术总结 预处理阶段 对输入数据（头皮图片）进行预处理，为下一阶段对图片中头发进行精准计数等功能性操作做好铺垫。主要用到以下技术： Contrast Stretching (Normalization): 对比度拉伸（通常称为归一化）是一种简单的图像增强技术,旨在通过“拉伸”图像所包含的强度值范围以覆盖所需的值范围来改善图像的对比度。 技术应用：增加头皮与头发之间的对比度，方便下阶段对头发进行语义分割。 Color Morphology EXTENDING MATHEMATICAL MORPHOLOGY TO COLOR IMAGE PROCESSING 技术应用： 除噪，去除油性和湿润的头发在头发的中部产生的亮点 Karhunen-Loeve Transform (KLT) Karhunen-Loeve变换（KLT）（也称为Hotelling变换和特征向量变换），它与主成分分析（PCA）密切相关，并广泛用于许多领域的数据分析中, KL变换基于图像的统计属性，并具有一些重要的属性，使其可用于图像处理，特别是图像压缩。 技术应用： 将彩色图像转换为灰度图像。 Otsu thresholding Otsu thresholding：简单说来该方法可将灰度图像还原为二进制图像。在图像处理和分析中，有时需要一种方法来分离两个相关数据，例如背景和前景。Otsu阈值是一种数据驱动的方法，该方法可以自适应地找到最佳阈值以区分两类数据。 技术应用： 图像分割和图像二值化。 多尺度线检测阶段（MSLD） 该阶段主要是通过各种技术，克服重叠头发无法计数，以及相邻头发之间的头皮被识别为头发等影响头发计数的相关问题。为下阶段对头发进行精准计数的做好铺垫。主要用到以下技术： 霍夫变换（HT) 霍夫变换（HT） 霍夫变换是一种可用于隔离图像中特定形状的特征的技术。因为它要求以某种参数形式指定所需的特征，所以经典的Hough变换最常用于检测规则曲线（例如直线，圆，椭圆等）。 技术应用： HT是最常用的线检测框架之一。但是当使用常规的单尺度HT时，可能会丢失大量的头发段。故提出将HT应用于三个比例的图像，包括1024×768（原始比例），512×384和256×192，最后通过逻辑或将三个比例图像中的被检测出的头发进行整合，以提高头发计数准确度。 Canny Edge Detection Canny边缘检测是一种多步骤算法，可以同时检测到噪声被抑制的边缘。在图像二值化步骤中，由于错误地假定了两根单独的头发的连接，位于两根头发之间的头皮像素被标记为头发的一部分。而且，当两根头发太靠近或彼此重叠时，如果直接应用稀疏算法，则会错过一根或两根头发。 技术应用： 使用边缘信息来找出隐藏或重叠的头发。可以从隐藏的头发或重叠的多根头发中提取两个平行的边缘。 Thinning Parallel Line Bundling (PLB) 头发标记和计数阶段（Hair Labling and Counting） 该阶段的目的是准确计算头皮上的毛发数量。这可以看作是聚类和标记问题。目标是将一组线段组合成语义“头发”并分配唯一的标签。 主要用到以下技术： Relaxation Labeling 松弛标记是一种图像处理方法。其目标是将标签与给定图像的像素或给定图的节点相关联。 技术应用： 在本研究中，RL算法被视为用于标记每个线段的聚类方法。 参考文献 An Unsupervised Hair Segmentation and Counting System in Microscopy Images Contrast Stretching (Normalization) Color Morphology EXTENDING MATHEMATICAL MORPHOLOGY TO COLOR IMAGE PROCESSING Karhunen-Loeve Transform (KLT) Otsu thresholding Hough Transform（HT) Canny Edge Detection Thinning Evaluation of a Bundling Technique for Parallel Coordinates Relaxation Labeling","categories":[{"name":"Paper Game","slug":"Paper-Game","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/"},{"name":"Smash","slug":"Paper-Game/Smash","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/Smash/"}],"tags":[{"name":"头发计数问题","slug":"头发计数问题","permalink":"https://littlelittlemoon.github.io/tags/%E5%A4%B4%E5%8F%91%E8%AE%A1%E6%95%B0%E9%97%AE%E9%A2%98/"},{"name":"图像处理","slug":"图像处理","permalink":"https://littlelittlemoon.github.io/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"线检测","slug":"线检测","permalink":"https://littlelittlemoon.github.io/tags/%E7%BA%BF%E6%A3%80%E6%B5%8B/"}],"keywords":[{"name":"Paper Game","slug":"Paper-Game","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/"},{"name":"Smash","slug":"Paper-Game/Smash","permalink":"https://littlelittlemoon.github.io/categories/Paper-Game/Smash/"}]},{"title":"Kayleen's Space","slug":"Hexo-Theme-Sakura","date":"2019-12-12T14:16:01.000Z","updated":"2020-04-07T03:09:33.416Z","comments":true,"path":"2019/12/12/Hexo-Theme-Sakura/","link":"","permalink":"https://littlelittlemoon.github.io/2019/12/12/Hexo-Theme-Sakura/","excerpt":"","text":"hexo-theme-sakura主题 English document 基于WordPress主题Sakura修改成Hexo的主题。 demo预览 正在开发中… 交流群 若你是使用者，加群QQ: 801511924 若你是创作者，加群QQ: 194472590 主题特性 首页大屏视频 首页随机封面 图片懒加载 valine评论 fancy-box相册 pjax支持，音乐不间断 aplayer音乐播放器 多级导航菜单（按现在大部分hexo主题来说，这也算是个特性了） 赞赏作者 如果喜欢hexo-theme-sakura主题，可以考虑资助一下哦~非常感激！ paypal | Alipay 支付宝 | WeChat Pay 微信支付 未完善的使用教程 那啥？老实说我目前也不是很有条理233333333~ 1、主题下载安装 hexo-theme-sakura建议下载压缩包格式，因为除了主题内容还有些source的配置对新手来说比较太麻烦，直接下载解压就省去这些麻烦咯。 下载好后解压到博客根目录（不是主题目录哦，重复的选择替换）。接着在命令行（cmd、bash）运行npm i安装依赖。 2、主题配置 博客根目录下的_config配置 站点 12345678# Sitetitle: 你的站点名subtitle:description: 站点简介keywords:author: 作者名language: zh-cntimezone: 部署 123456deploy: type: git repo: github: 你的github仓库地址 # coding: 你的coding仓库地址 branch: master 备份 （使用hexo b发布备份到远程仓库） 1234567backup: type: git message: backup my blog of https://honjun.github.io/ repository: # 你的github仓库地址,备份分支名 （建议新建backup分支） github: https://github.com/honjun/honjun.github.io.git,backup # coding: https://git.coding.net/hojun/hojun.git,backup 主题目录下的_config配置 其中标明【改】的是需要修改部门，标明【选】是可改可不改，标明【非】是不用改的部分 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121# site name# 站点名 【改】prefixName: さくら荘そのsiteName: hojun# favicon and site master avatar# 站点的favicon和头像 输入图片路径（下面的配置是都是cdn的相对路径，没有cdn请填写完整路径，建议使用jsdeliver搭建一个cdn啦，先去下载我的cdn替换下图片就行了，简单方便~）【改】favicon: /images/favicon.icoavatar: /img/custom/avatar.jpg# 站点url 【改】url: https://sakura.hojun.cn# 站点介绍（或者说是个人签名）【改】description: Live your life with passion! With some drive!# 站点cdn，没有就为空 【改】 若是cdn为空，一些图片地址就要填完整地址了，比如之前avatar就要填https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/custom/avatar.jpgcdn: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6# 开启pjax 【选】pjax: 1# 站点首页的公告信息 【改】notice: hexo-Sakura主题已经开源，目前正在开发中...# 懒加载的加载中图片 【选】lazyloadImg: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/loader/orange.progress-bar-stripe-loader.svg# 站点菜单配置 【选】menus: 首页: &#123; path: /, fa: fa-fort-awesome faa-shake &#125; 归档: &#123; path: /archives, fa: fa-archive faa-shake, submenus: &#123; 技术: &#123;path: /categories/技术/, fa: fa-code &#125;, 生活: &#123;path: /categories/生活/, fa: fa-file-text-o &#125;, 资源: &#123;path: /categories/资源/, fa: fa-cloud-download &#125;, 随想: &#123;path: /categories/随想/, fa: fa-commenting-o &#125;, 转载: &#123;path: /categories/转载/, fa: fa-book &#125; &#125; &#125; 清单: &#123; path: javascript:;, fa: fa-list-ul faa-vertical, submenus: &#123; 书单: &#123;path: /tags/悦读/, fa: fa-th-list faa-bounce &#125;, 番组: &#123;path: /bangumi/, fa: fa-film faa-vertical &#125;, 歌单: &#123;path: /music/, fa: fa-headphones &#125;, 图集: &#123;path: /tags/图集/, fa: fa-photo &#125; &#125; &#125; 留言板: &#123; path: /comment/, fa: fa-pencil-square-o faa-tada &#125; 友人帐: &#123; path: /links/, fa: fa-link faa-shake &#125; 赞赏: &#123; path: /donate/, fa: fa-heart faa-pulse &#125; 关于: &#123; path: /, fa: fa-leaf faa-wrench , submenus: &#123; 我？: &#123;path: /about/, fa: fa-meetup&#125;, 主题: &#123;path: /theme-sakura/, fa: iconfont icon-sakura &#125;, Lab: &#123;path: /lab/, fa: fa-cogs &#125;, &#125; &#125; 客户端: &#123; path: /client/, fa: fa-android faa-vertical &#125; RSS: &#123; path: /atom.xml, fa: fa-rss faa-pulse &#125;# Home page sort type: -1: newer first，1: older first. 【非】homePageSortType: -1# Home page article shown number) 【非】homeArticleShown: 10# 背景图片 【选】bgn: 8# startdash面板 url, title, desc img 【改】startdash: - &#123;url: /theme-sakura/, title: Sakura, desc: 本站 hexo 主题, img: /img/startdash/sakura.md.png&#125; - &#123;url: http://space.bilibili.com/271849279, title: Bilibili, desc: 博主的b站视频, img: /img/startdash/bilibili.jpg&#125; - &#123;url: /, title: hojun的万事屋, desc: 技术服务, img: /img/startdash/wangshiwu.jpg&#125;# your site build time or founded date# 你的站点建立日期 【改】siteBuildingTime: 07/17/2018# 社交按钮(social) url, img PC端配置 【改】social: github: &#123;url: http://github.com/honjun, img: /img/social/github.png&#125; sina: &#123;url: http://weibo.com/mashirozx?is_all=1, img: /img/social/sina.png&#125; wangyiyun: &#123;url: http://weibo.com/mashirozx?is_all=1, img: /img/social/wangyiyun.png&#125; zhihu: &#123;url: http://weibo.com/mashirozx?is_all=1, img: /img/social/zhihu.png&#125; email: &#123;url: http://weibo.com/mashirozx?is_all=1, img: /img/social/email.svg&#125; wechat: &#123;url: /#, qrcode: /img/custom/wechat.jpg, img: /img/social/wechat.png&#125;# 社交按钮(msocial) url, img 移动端配置 【改】msocial: github: &#123;url: http://github.com/honjun, fa: fa-github, color: 333&#125; weibo: &#123;url: http://weibo.com/mashirozx?is_all=1, fa: fa-weibo, color: dd4b39&#125; qq: &#123;url: https://wpa.qq.com/msgrd?v=3&amp;uin=954655431&amp;site=qq&amp;menu=yes, fa: fa-qq, color: 25c6fe&#125;# 赞赏二维码（其中wechatSQ是赞赏单页面的赞赏码图片）【改】donate: alipay: /img/custom/donate/AliPayQR.jpg wechat: /img/custom/donate/WeChanQR.jpg wechatSQ: /img/custom/donate/WeChanSQ.jpg# 首页视频地址为https://cdn.jsdelivr.net/gh/honjun/hojun@1.2/Unbroken.mp4，配置如下 【改】movies: url: https://cdn.jsdelivr.net/gh/honjun/hojun@1.2 # 多个视频用逗号隔开，随机获取。支持的格式目前已知MP4,Flv。其他的可以试下，不保证有用 name: Unbroken.mp4# 左下角aplayer播放器配置 主要改id和server这两项，修改详见[aplayer文档] 【改】aplayer: id: 2660651585 server: netease type: playlist fixed: true mini: false autoplay: false loop: all order: random preload: auto volume: 0.7 mutex: true# Valine评论配置【改】valine: truev_appId: GyC3NzMvd0hT9Yyd2hYIC0MN-gzGzoHszv_appKey: mgOpfzbkHYqU92CV4IDlAUHQ 分类页和标签页配置 分类页 标签页 配置项在\\themes\\Sakura\\languages\\zh-cn.yml里。新增一个分类或标签最好加下哦，当然嫌麻烦可以直接使用一张默认图片（可以改主题或者直接把404图片替换下，征求下意见要不要给这个在配置文件中加个开关，可以issue或群里提出来），现在是没设置的话会使用那种倒立小狗404哦。 12345678910111213141516171819#category# 按分类名创建技术: #中文标题 zh: 野生技术协会 # 英文标题 en: Geek – Only for Love # 封面图片 img: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/banner/coding.jpg生活: zh: 生活 en: live img: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/banner/writing.jpg#tag# 标签名即是标题悦读: # 封面图片 img: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/banner/reading.jpg 单页面封面配置 如留言板页面页面，位于source下的comment下，打开index.md如下： 123456789---title: commentdate: 2018-12-20 23:13:48keywords: 留言板description: comments: true# 在这里配置单页面头部图片，自定义替换哦~photos: https://cdn.jsdelivr.net/gh/honjun/cdn@1.4/img/banner/comment.jpg--- 单页面配置 番组计划页 （请直接在下载后的文件中改，下面的添加了注释可能会有些影响） 123456789101112131415161718192021222324252627282930---layout: bangumititle: bangumicomments: falsedate: 2019-02-10 21:32:48keywords:description:bangumis: # 番组图片 - img: https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg # 番组名 title: 朝花夕誓——于离别之朝束起约定之花 # 追番状态 （追番ing/已追完） status: 已追完 # 追番进度 progress: 100 # 番剧日文名称 jp: さよならの朝に約束の花をかざろう # 放送时间 time: 放送时间: 2018-02-24 SUN. # 番剧介绍 desc: 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。 - img: https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg title: 朝花夕誓——于离别之朝束起约定之花 status: 已追完 progress: 50 jp: さよならの朝に約束の花をかざろう time: 放送时间: 2018-02-24 SUN. desc: 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。--- 友链页 （请直接在下载后的文件中改，下面的添加了注释可能会有些影响） 1234567891011121314151617181920212223242526272829303132333435363738394041424344---layout: linkstitle: links# 创建日期，可以改下date: 2018-12-19 23:11:06 # 图片上的标题，自定义修改keywords: 友人帐 description: # true/false 开启/关闭评论comments: true # 页面头部图片，自定义修改photos: https://cdn.jsdelivr.net/gh/honjun/cdn@1.4/img/banner/links.jpg # 友链配置links: # 类型分组 - group: 个人项目 # 类型简介 desc: 充分说明这家伙是条咸鱼 &lt; (￣︶￣)&gt; items: # 友链链接 - url: https://shino.cc/fgvf # 友链头像 img: https://cloud.moezx.cc/Picture/svg/landscape/fields.svg # 友链站点名 name: Google # 友链介绍 下面雷同 desc: Google 镜像 - url: https://shino.cc/fgvf img: https://cloud.moezx.cc/Picture/svg/landscape/fields.svg name: Google desc: Google 镜像 # 类型分组... - group: 小伙伴们 desc: 欢迎交换友链 ꉂ(ˊᗜˋ) items: - url: https://shino.cc/fgvf img: https://cloud.moezx.cc/Picture/svg/landscape/fields.svg name: Google desc: Google 镜像 - url: https://shino.cc/fgvf img: https://cloud.moezx.cc/Picture/svg/landscape/fields.svg name: Google desc: Google 镜像--- 写文章配置 主题集成了个人插件hexo-tag-bili和hexo-tag-fancybox_img。其中hexo-tag-bili用来在文章或单页面中插入B站外链视频，使用语法如下： 1&#123;% bili video_id [page] %&#125; 详细使用教程详见hexo-tag-bili。 hexo-tag-fancybox_img用来在文章或单页面中图片，使用语法如下： 1&#123;% fb_img src [caption] %&#125; 详细使用教程详见hexo-tag-fancybox_img 还有啥，一时想不起来… To be continued…","categories":[{"name":"技术","slug":"技术","permalink":"https://littlelittlemoon.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"web","slug":"web","permalink":"https://littlelittlemoon.github.io/tags/web/"},{"name":"悦读","slug":"悦读","permalink":"https://littlelittlemoon.github.io/tags/%E6%82%A6%E8%AF%BB/"}],"keywords":[{"name":"技术","slug":"技术","permalink":"https://littlelittlemoon.github.io/categories/%E6%8A%80%E6%9C%AF/"}]}]}