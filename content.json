{"meta":{"title":"LITTLEMEEMOON","subtitle":"Every day with dreams is wonderful.","description":"This is my place where I can share my things about life, academic or just for fun, enjoy. :)","author":"Kayleen","url":"https://littlelittlemoon.github.io"},"pages":[{"title":"about","date":"2019-12-12T14:14:36.000Z","updated":"2020-04-08T13:08:47.938Z","comments":false,"path":"about/index.html","permalink":"https://littlelittlemoon.github.io/about/index.html","excerpt":"","text":"[Bear Cave - Kayleen]] 与&nbsp; Kayleen&nbsp; （ 真（ま）白（しろ） ） 对话中... bot_ui_ini()","keywords":"关于"},{"title":"bangumi","date":"2019-02-10T13:32:48.000Z","updated":"2020-04-06T16:05:44.917Z","comments":false,"path":"bangumi/index.html","permalink":"https://littlelittlemoon.github.io/bangumi/index.html","excerpt":"","text":"","keywords":null},{"title":"categories","date":"2019-12-20T15:13:48.000Z","updated":"2020-04-12T13:55:28.953Z","comments":true,"path":"categories/index.html","permalink":"https://littlelittlemoon.github.io/categories/index.html","excerpt":"","text":"In maintenance Hi, 此页面还在维护中哦，谢谢你的期待，可以留言给我哦~ [ Bear Cave ] Kayleen","keywords":"文章分类"},{"title":"comment","date":"2019-12-20T15:13:48.000Z","updated":"2020-04-07T11:26:02.901Z","comments":true,"path":"comment/index.html","permalink":"https://littlelittlemoon.github.io/comment/index.html","excerpt":"","text":"念两句诗 人闲桂花落，夜静春山空。 月出惊山鸟，时鸣春涧中。 王维 ·《鸟鸣涧》","keywords":"留言板"},{"title":"client","date":"2018-12-20T15:13:35.000Z","updated":"2020-04-06T16:22:30.837Z","comments":false,"path":"client/index.html","permalink":"https://littlelittlemoon.github.io/client/index.html","excerpt":"","text":"直接下载 or 扫码下载：","keywords":"Android客户端"},{"title":"donate","date":"2019-12-20T15:13:05.000Z","updated":"2020-04-07T11:26:06.240Z","comments":false,"path":"donate/index.html","permalink":"https://littlelittlemoon.github.io/donate/index.html","excerpt":"","text":"","keywords":"谢谢饲主了喵~"},{"title":"lab","date":"2019-01-05T13:47:59.000Z","updated":"2020-04-12T13:55:36.478Z","comments":false,"path":"lab/index.html","permalink":"https://littlelittlemoon.github.io/lab/index.html","excerpt":"","text":"In maintenance Hi, 此页面还在维护中哦，谢谢你的期待，可以留言给我哦~ [ Bear Cave ] Kayleen","keywords":"Lab实验室"},{"title":"rss","date":"2018-12-20T15:09:03.000Z","updated":"2020-04-06T16:05:44.919Z","comments":true,"path":"rss/index.html","permalink":"https://littlelittlemoon.github.io/rss/index.html","excerpt":"","text":""},{"title":"music","date":"2018-12-20T15:14:28.000Z","updated":"2020-04-09T08:55:04.838Z","comments":false,"path":"music/index.html","permalink":"https://littlelittlemoon.github.io/music/index.html","excerpt":"","text":"","keywords":"小悦邀你停下来听会歌😊"},{"title":"tags","date":"2018-12-12T14:14:16.000Z","updated":"2020-04-12T13:56:00.798Z","comments":true,"path":"tags/index.html","permalink":"https://littlelittlemoon.github.io/tags/index.html","excerpt":"","text":"In maintenance Hi, 此页面还在维护中哦，谢谢你的期待，可以留言给我哦~ [ Bear Cave ] Kayleen","keywords":"标签"},{"title":"theme-sakura","date":"2019-01-04T14:53:25.000Z","updated":"2020-04-06T16:05:44.919Z","comments":false,"path":"theme-sakura/index.html","permalink":"https://littlelittlemoon.github.io/theme-sakura/index.html","excerpt":"","text":"Hexo主题Sakura修改自WordPress主题Sakura，感谢原作者Mashiro","keywords":"Hexo 主题 Sakura 🌸"},{"title":"video","date":"2018-12-20T15:14:38.000Z","updated":"2020-04-06T16:05:44.919Z","comments":false,"path":"video/index.html","permalink":"https://littlelittlemoon.github.io/video/index.html","excerpt":"","text":"var videos = [ { img: 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: '朝花夕誓——于离别之朝束起约定之花', status: '已追完', progress: 100, jp: 'さよならの朝に約束の花をかざろう', time: '放送时间: 2018-02-24 SUN.', desc: ' 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。' }, { img : 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: '朝花夕誓——于离别之朝束起约定之花', status: '已追完', progress: 100, jp: 'さよならの朝に約束の花をかざろう', time: '2018-02-24 SUN.', desc: ' 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。' } ] .should-ellipsis{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:95%;}.should-ellipsis-full{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:100%;}.should-ellipsis i{position:absolute;right:24px;}.grey-text{color:#9e9e9e !important}.grey-text.text-darken-4{color:#212121 !important}html{line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}img{border-style:none}progress{display:inline-block;vertical-align:baseline}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{-webkit-box-sizing:border-box;box-sizing:border-box}*,*:before,*:after{-webkit-box-sizing:inherit;box-sizing:inherit}ul:not(.browser-default){padding-left:0;list-style-type:none}ul:not(.browser-default)>li{list-style-type:none}.card{-webkit-box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2);box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2)}.hoverable{-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s}.hoverable:hover{-webkit-box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19);box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19)}i{line-height:inherit}i.right{float:right;margin-left:15px}.bangumi .right{float:right !important}.material-icons{text-rendering:optimizeLegibility;-webkit-font-feature-settings:'liga';-moz-font-feature-settings:'liga';font-feature-settings:'liga'}.row{margin-left:auto;margin-right:auto;margin-bottom:20px}.row:after{content:\"\";display:table;clear:both}.row .col{float:left;-webkit-box-sizing:border-box;box-sizing:border-box;padding:0 .75rem;min-height:1px}.row .col.s12{width:100%;margin-left:auto;left:auto;right:auto}@media only screen and (min-width:601px){.row .col.m6{width:50%;margin-left:auto;left:auto;right:auto}}html{line-height:1.5;font-family:-apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif;font-weight:normal;color:rgba(0,0,0,0.87)}@media only screen and (min-width:0){html{font-size:14px}}@media only screen and (min-width:992px){html{font-size:14.5px}}@media only screen and (min-width:1200px){html{font-size:15px}}.card{position:relative;margin:.5rem 0 1rem 0;background-color:#fff;-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s;border-radius:2px}.card .card-title{font-size:24px;font-weight:300}.card .card-title.activator{cursor:pointer}.card .card-image{position:relative}.card .card-image img{display:block;border-radius:2px 2px 0 0;position:relative;left:0;right:0;top:0;bottom:0;width:100%}.card .card-content{padding:24px;border-radius:0 0 2px 2px}.card .card-content p{margin:0}.card .card-content .card-title{display:block;line-height:32px;margin-bottom:8px}.card .card-content .card-title i{line-height:32px}.card .card-reveal{padding:24px;position:absolute;background-color:#fff;width:100%;overflow-y:auto;left:0;top:100%;height:100%;z-index:3;display:none}.card .card-reveal .card-title{cursor:pointer;display:block}.waves-effect{position:relative;cursor:pointer;display:inline-block;overflow:hidden;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-tap-highlight-color:transparent;vertical-align:middle;z-index:1;-webkit-transition:.3s ease-out;transition:.3s ease-out}.waves-effect img{position:relative;z-index:-1}.waves-block{display:block}::-webkit-input-placeholder{color:#d1d1d1}::-moz-placeholder{color:#d1d1d1}:-ms-input-placeholder{color:#d1d1d1}::-ms-input-placeholder{color:#d1d1d1}[type=\"radio\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"radio\"]:not(:checked)+span{position:relative;padding-left:35px;cursor:pointer;display:inline-block;height:25px;line-height:25px;font-size:1rem;-webkit-transition:.28s ease;transition:.28s ease;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border-radius:50%}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border:2px solid #5a5a5a}[type=\"radio\"]:not(:checked)+span:after{-webkit-transform:scale(0);transform:scale(0)}[type=\"checkbox\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"checkbox\"]:not(:checked):disabled+span:not(.lever):before{border:none;background-color:rgba(0,0,0,0.42)}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):before{width:0;height:0;border:3px solid transparent;left:6px;top:10px;-webkit-transform:rotateZ(37deg);transform:rotateZ(37deg);-webkit-transform-origin:100% 100%;transform-origin:100% 100%}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):after{height:20px;width:20px;background-color:transparent;border:2px solid #5a5a5a;top:0px;z-index:0}input[type=checkbox]:not(:disabled) ~ .lever:active:before,input[type=checkbox]:not(:disabled).tabbed:focus ~ .lever::before{-webkit-transform:scale(2.4);transform:scale(2.4);background-color:rgba(0,0,0,0.08)}input[type=range].focused:focus:not(.active)::-webkit-slider-thumb{-webkit-box-shadow:0 0 0 10px rgba(38,166,154,0.26);box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-moz-range-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-ms-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)} 番组计划 这里将是永远的回忆 window.onload = function(){ videos.forEach(function(video, i){ $('#rootRow').append(` ${video.title} ${video.jp} ${video.status} ${video.title} ${video.jp} 放送时间: ${video.time} ${video.desc} ${video.status} `) }) }","keywords":"B站"},{"title":"links","date":"2018-12-19T15:11:06.000Z","updated":"2020-04-12T14:21:27.604Z","comments":true,"path":"links/index.html","permalink":"https://littlelittlemoon.github.io/links/index.html","excerpt":"","text":"","keywords":"友人帐"},{"title":"Life","date":"2020-04-12T12:50:45.000Z","updated":"2020-04-12T14:06:41.057Z","comments":true,"path":"categories/Life/index.html","permalink":"https://littlelittlemoon.github.io/categories/Life/index.html","excerpt":"","text":"In maintenance Hi, 此页面还在维护中哦，谢谢你的期待，可以留言给我哦~ [ Bear Cave ] Kayleen","keywords":null},{"title":"Repost","date":"2020-04-12T12:51:48.000Z","updated":"2020-04-12T14:06:35.642Z","comments":true,"path":"categories/Repost/index.html","permalink":"https://littlelittlemoon.github.io/categories/Repost/index.html","excerpt":"","text":"In maintenance Hi, 此页面还在维护中哦，谢谢你的期待，可以留言给我哦~ [ Bear Cave ] Kayleen","keywords":null},{"title":"Thoughts","date":"2020-04-12T12:51:27.000Z","updated":"2020-04-12T13:55:23.553Z","comments":true,"path":"categories/Thoughts/index.html","permalink":"https://littlelittlemoon.github.io/categories/Thoughts/index.html","excerpt":"","text":"In maintenance Hi, 此页面还在维护中哦，谢谢你的期待，可以留言给我哦~ [ Bear Cave ] Kayleen","keywords":null},{"title":"initial page","date":"2020-04-12T12:53:20.000Z","updated":"2020-04-12T13:55:45.127Z","comments":true,"path":"tags/Cave/index.html","permalink":"https://littlelittlemoon.github.io/tags/Cave/index.html","excerpt":"","text":"In maintenance Hi, 此页面还在维护中哦，谢谢你的期待，可以留言给我哦~ [ Bear Cave ] Kayleen","keywords":null},{"title":"initial page","date":"2020-04-12T12:53:20.000Z","updated":"2020-04-16T08:36:05.588Z","comments":true,"path":"tags/Reading/index.html","permalink":"https://littlelittlemoon.github.io/tags/Reading/index.html","excerpt":"","text":"In maintenance Hi, 此页面还在维护中哦，谢谢你的期待，可以留言给我哦~ [ Bear Cave ] Kayleen","keywords":null},{"title":"initial page","date":"2020-04-12T12:53:20.000Z","updated":"2020-04-12T14:05:59.298Z","comments":true,"path":"tags/Pictures/index.html","permalink":"https://littlelittlemoon.github.io/tags/Pictures/index.html","excerpt":"","text":"In maintenance Hi, 此页面还在维护中哦，谢谢你的期待，可以留言给我哦~ [ Bear Cave ] Kayleen","keywords":null},{"title":"Updating...","date":"2020-04-12T12:53:20.000Z","updated":"2020-04-16T08:33:49.463Z","comments":false,"path":"tags/Updating/index.html","permalink":"https://littlelittlemoon.github.io/tags/Updating/index.html","excerpt":"","text":"暂时没有正在更新的内容哦~","keywords":null}],"posts":[{"title":"Blockchain | Consensus Mechanisms","slug":"Repost/Consensus_Mechanisms","date":"2020-04-18T16:42:36.000Z","updated":"2020-04-18T16:45:26.067Z","comments":true,"path":"2020/04/19/Repost/Consensus_Mechanisms/","link":"","permalink":"https://littlelittlemoon.github.io/2020/04/19/Repost/Consensus_Mechanisms/","excerpt":"","text":"Consensus Mechanisms (&#x5171;&#x8BC6;&#x673A;&#x5236;) &#x5728;&#x5BC6;&#x7801;&#x5B66;&#x4E2D;&#xFF0C;&#x6709;&#x4E00;&#x79CD;&#x7406;&#x8BBA;&#x6307;&#x51FA;&#xFF0C;&#x4EFB;&#x4F55;&#x53EF;&#x4EE5;&#x7531;&#x4E2D;&#x592E;&#x653F;&#x515A;&#x5B8C;&#x6210;&#x7684;&#x4E8B;&#x60C5;&#xFF0C;&#x4E5F;&#x53EF;&#x4EE5;&#x5728;&#x6CA1;&#x6709;&#x4E2D;&#x592E;&#x653F;&#x515A;&#x7684;&#x60C5;&#x51B5;&#x4E0B;&#x5B8C;&#x6210;&#x3002;&#x8FD9;&#x6307;&#x7684;&#x662F;&#x6295;&#x7968;&#xFF0C;&#x62CD;&#x5356;&#xFF0C;&#x94F6;&#x884C;&#x4E1A;&#x52A1;&#x7B49;&#x3002;&#x4F8B;&#x5982;&#xFF0C;OpenBazaar&#x662F;eBay&#x7684;&#x53BB;&#x4E2D;&#x5FC3;&#x5316;&#x7248;&#x672C;&#xFF0C;Bisq&#x662F;Coinbase&#x7684;&#x53BB;&#x4E2D;&#x5FC3;&#x5316;&#x7248;&#x672C;&#xFF0C;&#x800C;&#x6BD4;&#x7279;&#x5E01;&#x672C;&#x8EAB;&#x662F;&#x6CD5;&#x5B9A;&#x8D27;&#x5E01;&#x7684;&#x53BB;&#x4E2D;&#x5FC3;&#x5316;&#x7248;&#x672C;&#x3002; &#x5728;&#x5206;&#x6563;&#x7F51;&#x7EDC;&#x4E2D;&#xFF0C;&#x6CA1;&#x6709;&#x6807;&#x5C3A;&#x53EF;&#x4EE5;&#x786E;&#x4FDD;&#x6BCF;&#x4E2A;&#x4EBA;&#x90FD;&#x9075;&#x5B88;&#x89C4;&#x5219;&#x3002;&#x76F8;&#x53CD;&#xFF0C;&#x5206;&#x6563;&#x7F51;&#x7EDC;&#x4F9D;&#x8D56;&#x5171;&#x8BC6;&#x673A;&#x5236;&#x3002; &#x5171;&#x8BC6;&#x673A;&#x5236;&#x662F;&#x4E00;&#x7FA4;&#x4EBA;&#x505A;&#x51FA;&#x51B3;&#x5B9A;&#x7684;&#x65B9;&#x5F0F;&#x3002;&#x4F8B;&#x5982;&#xFF0C;&#x6BD4;&#x7279;&#x5E01;&#x7528;&#x6237;&#x9700;&#x8981;&#x4E0D;&#x65AD;&#x66F4;&#x65B0;&#x5176;&#x4EA4;&#x6613;&#x5386;&#x53F2;&#xFF0C;&#x4EE5;&#x53CD;&#x6620;&#x65B0;&#x7684;&#x4EA4;&#x6613;&#x548C;&#x94B1;&#x5305;(wallets)&#x4F59;&#x989D;&#x3002;&#x5171;&#x8BC6;&#x673A;&#x5236;&#x4F7F;&#x964C;&#x751F;&#x4EBA;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x7ED9;&#x4E88;&#x7ECF;&#x6D4E;&#x5956;&#x52B1;&#x6216;&#x7ECF;&#x6D4E;&#x60E9;&#x7F5A;&#x6765;&#x8FBE;&#x6210;&#x534F;&#x8BAE;&#x3002;&#x5171;&#x8BC6;&#x673A;&#x5236;&#x7684;&#x4E3B;&#x8981;&#x76EE;&#x6807;&#x662F;&#x963B;&#x6B62;&#x7528;&#x6237;&#x91CD;&#x590D;&#x82B1;&#x8D39;(double-spending)&#x76F8;&#x540C;&#x7684;&#x786C;&#x5E01;&#x3002;&#x5982;&#x679C;&#x7528;&#x6237;&#x53EF;&#x4EE5;&#x5C06;&#x540C;&#x4E00;&#x6BD4;&#x7279;&#x5E01;&#x53D1;&#x9001;&#x5230;&#x4E24;&#x4E2A;&#x4E0D;&#x540C;&#x7684;&#x94B1;&#x5305;&#xFF0C;&#x90A3;&#x4E48;&#x6BD4;&#x7279;&#x5E01;&#x7684;&#x4F9B;&#x5E94;&#x53EF;&#x80FD;&#x4F1A;&#x65E0;&#x9650;&#x81A8;&#x80C0;&#xFF0C;&#x8FD9;&#x5C06;&#x5BFC;&#x81F4;&#x8BE5;&#x8D27;&#x5E01;&#x7684;&#x8D2D;&#x4E70;&#x529B;&#x4E0B;&#x964D;&#x3002;&#x4E3A;&#x4E86;&#x963B;&#x6B62;&#x53CC;&#x91CD;&#x652F;&#x51FA;&#xFF0C;&#x7EF4;&#x62A4;&#x6BD4;&#x7279;&#x5E01;&#x533A;&#x5757;&#x94FE;&#x7684;&#x6BCF;&#x53F0;&#x8BA1;&#x7B97;&#x673A;&#x90FD;&#x5FC5;&#x987B;&#x5177;&#x6709;&#x5173;&#x4E8E;&#x54EA;&#x4E9B;&#x94B1;&#x5305;&#x62E5;&#x6709;&#x591A;&#x5C11;&#x4EF7;&#x503C;&#x7684;&#x76F8;&#x540C;&#x4FE1;&#x606F;&#x3002; &#x6392;&#x540D;&#x524D;100&#x4F4D;&#x7684;&#x52A0;&#x5BC6;&#x8D27;&#x5E01;&#x5171;&#x8BC6;&#x673A;&#x5236; &#x5982;&#x8868;1&#x6240;&#x793A;&#xFF0C;&#x5927;&#x7EA6;&#x6709;17&#x79CD;&#x4E0D;&#x540C;&#x7684;&#x5171;&#x8BC6;&#x673A;&#x5236;&#x3002;&#x4F46;&#x662F;&#xFF0C;&#x5B83;&#x4EEC;&#x90FD;&#x4E0D;&#x662F;&#x5B8C;&#x7F8E;&#x7684;&#x3002;&#x5230;&#x76EE;&#x524D;&#x4E3A;&#x6B62;&#xFF0C;&#x6700;&#x5B89;&#x5168;&#x7684;&#x5171;&#x8BC6;&#x673A;&#x5236;&#x4ECD;&#x7136;&#x662F;&#x6BD4;&#x7279;&#x5E01;&#x4F7F;&#x7528;&#x7684;&#x539F;&#x59CB;&#x673A;&#x5236;&#xFF1A;&#x5DE5;&#x4F5C;&#x8BC1;&#x660E;(proof of work)&#x3002; &#x4F46;&#x662F;&#xFF0C;&#x5DE5;&#x4F5C;&#x8BC1;&#x660E;(proof of work)&#x4F9D;&#x8D56;&#x4E8E;&#x77FF;&#x5DE5;&#xFF0C;&#x8FD9;&#x53EF;&#x80FD;&#x5BFC;&#x81F4;&#x96C6;&#x4E2D;&#x5316;&#x3002;&#x5F00;&#x53D1;&#x4EBA;&#x5458;&#x4E00;&#x76F4;&#x5728;&#x52AA;&#x529B;&#x6253;&#x8D25;&#x5DE5;&#x4F5C;&#x91CF;&#x8BC1;&#x660E;&#xFF0C;&#x56E0;&#x4E3A;&#x6D88;&#x9664;&#x77FF;&#x5DE5;&#x548C;&#x4ED6;&#x4EEC;&#x7684;&#x7535;&#x529B;&#x6D88;&#x8017;&#x7684;&#x786C;&#x5E01;&#x4F1A;&#x5728;ICO&#x5E02;&#x573A;&#x4E0A;&#x5927;&#x6D6A;&#x3002; &#x8868;1 Visa&#x548C;PayPal&#x7B49;&#x516C;&#x53F8;&#x65E0;&#x9700;&#x91C7;&#x7528;&#x5171;&#x8BC6;&#x673A;&#x5236;&#xFF0C;&#x56E0;&#x4E3A;&#x5B83;&#x4EEC;&#x53EF;&#x4EE5;&#x63A7;&#x5236;&#x6574;&#x4E2A;&#x7F51;&#x7EDC;&#x3002;&#x5982;&#x679C;&#x6709;&#x4EBA;&#x4F7F;&#x7528;&#x4ED6;&#x4EEC;&#x7684;Visa&#x4FE1;&#x7528;&#x5361;&#xFF0C;&#x5219;&#x4FE1;&#x606F;&#x5C06;&#x53D1;&#x9001;&#x5230;Visa&#x7EF4;&#x62A4;&#x7684;&#x96C6;&#x4E2D;&#x5F0F;&#x6570;&#x636E;&#x5E93;&#x3002;&#x6211;&#x4EEC;&#x4FE1;&#x4EFB;&#x8FD9;&#x4E9B;&#x516C;&#x53F8;&#x6765;&#x4FDD;&#x62A4;&#x6211;&#x4EEC;&#x7684;&#x654F;&#x611F;&#x4FE1;&#x606F;&#x5E76;&#x7ED3;&#x7B97;&#x6211;&#x4EEC;&#x7684;&#x4EA4;&#x6613;&#x3002;&#x7531;&#x4E8E;Visa&#x63A7;&#x5236;&#x7740;&#x7F51;&#x7EDC;&#xFF0C;&#x56E0;&#x6B64;&#x4ED6;&#x4EEC;&#x53EF;&#x4EE5;&#x64A4;&#x6D88;&#x548C;&#x5BA1;&#x67E5;&#x4EA4;&#x6613;&#x3002;&#x5728;1970&#x5E74;&#x4EE3;&#xFF0C;&#x8BA1;&#x7B97;&#x673A;&#x4E13;&#x5BB6;&#x5F00;&#x59CB;&#x63A2;&#x7D22;&#x5176;&#x4ED6;&#x65B9;&#x6CD5;&#x6765;&#x89E3;&#x51B3;&#x6B64;&#x95EE;&#x9898;&#xFF0C;&#x56E0;&#x4E3A;&#x4ED6;&#x4EEC;&#x610F;&#x8BC6;&#x5230;&#xFF0C;&#x5373;&#x4F7F;&#x662F;&#x4E2D;&#x592E;&#x6743;&#x5A01;&#x4E5F;&#x53EF;&#x80FD;&#x906D;&#x5230;&#x5BF9;&#x624B;&#x7684;&#x653B;&#x51FB;&#x6216;&#x4ECE;&#x5185;&#x90E8;&#x88AB;&#x7834;&#x574F;&#x3002;&#x5728;&#x52A0;&#x5BC6;&#x8D27;&#x5E01;&#x7F51;&#x7EDC;&#x4E2D;&#x8FDB;&#x884C;&#x5206;&#x6563;&#x51B3;&#x7B56;&#x7684;&#x4E24;&#x79CD;&#x6700;&#x6D41;&#x884C;&#x7684;&#x65B9;&#x6CD5;&#x79F0;&#x4E3A;&#x201C;&#x5DE5;&#x4F5C;&#x91CF;&#x8BC1;&#x660E;(proof of work)&#x201D;&#x548C;&#x201C;&#x6743;&#x76CA;&#x8BC1;&#x660E;(proof of stake)&#x201D;&#x3002; &#x4F46;&#x662F;&#xFF0C;&#x5B58;&#x5728;&#x8BB8;&#x591A;&#x5171;&#x8BC6;&#x673A;&#x5236;&#xFF0C;&#x5305;&#x62EC;&#x6743;&#x9650;&#x8BC1;&#x660E;&#xFF0C;&#x7A7A;&#x95F4;&#x8BC1;&#x660E;&#x548C;&#x91CD;&#x8981;&#x6027;&#x8BC1;&#x660E;&#x3002;&#x6240;&#x6709;&#x8FD9;&#x4E9B;&#x4E0D;&#x540C;&#x7684;&#x65B9;&#x6CD5;&#x90FD;&#x662F;&#x9488;&#x5BF9;Byzantine Generals&#x2019; Problem&#x7684;&#x63D0;&#x8BAE;&#x89E3;&#x51B3;&#x65B9;&#x6848;&#x3002; &#x56FE;1 Byzantine Generals&#x2019; Problem&#x2019; Problem &#x60F3;&#x8C61;&#x4E00;&#x4E0B;&#xFF0C;&#x57CE;&#x5821;&#x4E2D;&#x6709;&#x4E00;&#x4F4D;&#x56FD;&#x738B;&#xFF0C;&#x7531;300&#x540D;&#x58EB;&#x5175;&#x634D;&#x536B;&#x3002;&#x57CE;&#x5821;&#x5468;&#x56F4;&#x6709;&#x4E94;&#x652F;&#x519B;&#x961F;&#xFF0C;&#x6BCF;&#x652F;100&#x4EBA;&#x3002;&#x6BCF;&#x652F;&#x519B;&#x961F;&#x5728;&#x5468;&#x56F4;&#x7684;&#x5C71;&#x4E18;&#x90FD;&#x6709;&#x81EA;&#x5DF1;&#x7684;&#x8425;&#x5730;&#xFF0C;&#x8FD8;&#x6709;&#x81EA;&#x5DF1;&#x7684;&#x5C06;&#x519B;&#x3002;&#x5C06;&#x519B;&#x4EEC;&#x9700;&#x8981;&#x76F8;&#x4E92;&#x4EA4;&#x6D41;&#xFF0C;&#x4EE5;&#x4FBF;&#x5C31;&#x653B;&#x51FB;&#x7B56;&#x7565;&#x8FBE;&#x6210;&#x5171;&#x8BC6;&#x3002;&#x4F46;&#x662F;&#xFF0C;&#x5C06;&#x519B;&#x4EEC;&#x4E0D;&#x5BB9;&#x6613;&#x5F7C;&#x6B64;&#x4FE1;&#x4EFB;&#xFF0C;&#x56E0;&#x4E3A;&#x4ED6;&#x4EEC;&#x6000;&#x7591;&#x5176;&#x4E2D;&#x4E00;&#x4E9B;&#x5C06;&#x519B;&#x662F;&#x53DB;&#x5F92;&#x3002;&#x5982;&#x679C;&#x4ED6;&#x4EEC;&#x5728;&#x8FDB;&#x653B;&#x548C;&#x91C7;&#x53D6;&#x7B56;&#x7565;&#x7684;&#x65F6;&#x5019;&#x4ECE;&#x4E00;&#x4E2A;&#x8425;&#x5730;&#x5411;&#x53E6;&#x4E00;&#x4E2A;&#x8425;&#x5730;&#x53D1;&#x9001;&#x6D88;&#x606F;&#xFF0C;&#x90A3;&#x4E48;&#x4E0D;&#x5FE0;&#x7684;&#x5C06;&#x9886;&#x4EEC;&#x53EF;&#x4EE5;&#x8F7B;&#x677E;&#x5730;&#x66F4;&#x6539;&#x6B64;&#x6D88;&#x606F;&#x5E76;&#x5C06;&#x865A;&#x5047;&#x4FE1;&#x606F;&#x4F20;&#x9012;&#x7ED9;&#x4E0B;&#x4E00;&#x4E2A;&#x8425;&#x5730;&#x3002;&#x53D1;&#x9001;&#x7B80;&#x5355;&#x7684;&#x6D88;&#x606F;&#x5E76;&#x4E0D;&#x5B89;&#x5168;&#xFF0C;&#x56E0;&#x4E3A;&#x4E66;&#x9762;&#x6587;&#x672C;&#x5F88;&#x5BB9;&#x6613;&#x66F4;&#x6539;&#x3002;&#x9519;&#x8BEF;&#x7684;&#x4FE1;&#x606F;&#x53EF;&#x80FD;&#x4F1A;&#x5BFC;&#x81F4;&#x53DB;&#x5F92;&#x8D62;&#x5F97;&#x8FD9;&#x573A;&#x6218;&#x6597;&#xFF0C;&#x56E0;&#x4E3A;&#x4E0D;&#x540C;&#x7684;&#x9635;&#x8425;&#x4F1A;&#x5728;&#x9519;&#x8BEF;&#x7684;&#x65F6;&#x95F4;&#x53D1;&#x52A8;&#x8FDB;&#x653B;&#xFF0C;&#x751A;&#x81F3;&#x6839;&#x672C;&#x4E0D;&#x4F1A;&#x53D1;&#x52A8;&#x8FDB;&#x653B;&#x3002; &#x5982;&#x4ECA;&#xFF0C;&#x7535;&#x8BDD;&#x4F1A;&#x8BAE;&#x53EF;&#x4EE5;&#x4EE3;&#x66FF;&#x9A6C;&#x80CC;&#x4E0A;&#x7684;&#x4FE1;&#x4F7F;&#xFF0C;&#x4F46;&#x95EE;&#x9898;&#x4ECD;&#x7136;&#x5B58;&#x5728;&#x3002;&#x60A8;&#x5982;&#x4F55;&#x786E;&#x5B9A;&#x90AE;&#x4EF6;&#x662F;&#x771F;&#x5B9E;&#x7684;&#x800C;&#x4E0D;&#x88AB;&#x7BE1;&#x6539;&#xFF1F;&#x771F;&#x5B9E;&#x6027;&#x662F;&#x6307;&#x5BF9;&#x624B;&#x4F2A;&#x88C5;&#x6210;&#x522B;&#x4EBA;&#x53EF;&#x4EE5;&#x4F2A;&#x9020;&#x7535;&#x8BDD;&#x6216;&#x7535;&#x5B50;&#x90AE;&#x4EF6;&#x7684;&#x95EE;&#x9898;&#x3002;&#x7BE1;&#x6539;&#x662F;&#x6307;&#x653B;&#x51FB;&#x8005;&#x66F4;&#x6539;&#xFF0C;&#x5220;&#x9664;&#x6216;&#x9605;&#x8BFB;&#x6D88;&#x606F;&#x7684;&#x5185;&#x5BB9;&#x3002; &#x4E3A;&#x4E86;&#x89E3;&#x51B3;&#x62DC;&#x5360;&#x5EAD;&#x5C06;&#x519B;(Byzantine Generals&#x2019; Problem)&#x7684;&#x95EE;&#x9898;&#xFF0C;&#x5171;&#x8BC6;&#x7B97;&#x6CD5;&#x4F9D;&#x8D56;&#x4E24;&#x4E2A;&#x6982;&#x5FF5;: 1. &#x9996;&#x5148;&#xFF0C;&#x6BCF;&#x4E2A;&#x5C06;&#x519B;&#x90FD;&#x9700;&#x8981;&#x5728;&#x7F51;&#x7EDC;&#x4E0A;&#x6295;&#x5165;&#x8D44;&#x6E90;&#xFF0C;&#x5373;&#x4ED6;&#x4EEC;&#x9700;&#x8981;&#x62E5;&#x6709;&#x201C;&#x6E38;&#x620F;&#x4E2D;&#x7684;&#x76AE;&#x80A4;&#x201D;&#x3002;&#x4F8B;&#x5982;&#xFF0C;&#x5047;&#x8BBE;&#x6709;&#x4E24;&#x4E2A;&#x5546;&#x4EBA;&#x51B3;&#x5B9A;&#x5171;&#x540C;&#x521B;&#x5EFA;&#x4E00;&#x5BB6;&#x5408;&#x8D44;&#x4F01;&#x4E1A;&#xFF0C;&#x800C;&#x4E00;&#x4E2A;&#x5546;&#x4EBA;&#x62D2;&#x7EDD;&#x5411;&#x8BE5;&#x5408;&#x8D44;&#x4F01;&#x4E1A;&#x6295;&#x5165;&#x4EFB;&#x4F55;&#x65F6;&#x95F4;&#x6216;&#x8D44;&#x91D1;&#x3002;&#x88AB;&#x6295;&#x8D44;&#x7684;&#x5408;&#x4F19;&#x4EBA;&#x4F1A;&#x5BF9;&#x5408;&#x4F19;&#x4EBA;&#x5BF9;&#x9879;&#x76EE;&#x7684;&#x5FE0;&#x8BDA;&#x5EA6;&#x611F;&#x5230;&#x6000;&#x7591;&#x3002;&#x5206;&#x6563;&#x7F51;&#x7EDC;&#x4E2D;&#x4E5F;&#x5B58;&#x5728;&#x76F8;&#x540C;&#x7684;&#x60F3;&#x6CD5;&#x3002; 2. &#x7B2C;&#x4E8C;&#x4E2A;&#x6982;&#x5FF5;&#x662F;&#x5FC5;&#x987B;&#x5B58;&#x5728;&#x6240;&#x6709;&#x4EE5;&#x524D;&#x7684;&#x201C;&#x9632;&#x7BE1;&#x6539;&#x201D;&#x901A;&#x4FE1;&#x7684;&#x5206;&#x7C7B;&#x5E10;&#x3002;&#x9632;&#x7BE1;&#x6539;&#x662F;&#x6307;&#x8BA1;&#x7B97;&#x673A;&#x80FD;&#x591F;&#x7ACB;&#x5373;&#x68C0;&#x6D4B;&#x5230;&#x901A;&#x4FE1;&#x5386;&#x53F2;&#x8BB0;&#x5F55;&#x5DF2;&#x88AB;&#x66F4;&#x6539;&#x6216;&#x5220;&#x9664;&#x7684;&#x80FD;&#x529B;&#x3002;&#x5206;&#x7C7B;&#x8D26;&#x7684;&#x6570;&#x5B57;&#x7248;&#x672C;&#x662F;&#x4E00;&#x4E2A;&#x533A;&#x5757;&#x94FE;&#xFF0C;&#x53EF;&#x8DDF;&#x8E2A;&#x6BCF;&#x4E2A;&#x7528;&#x6237;&#x7684;&#x4EA4;&#x6613;&#xFF0C;&#x5E76;&#x4F7F;&#x7528;&#x6563;&#x5217;&#x51FD;&#x6570;&#x5C06;&#x5176;&#x94FE;&#x63A5;&#xFF0C;&#x4EE5;&#x786E;&#x4FDD;&#x6570;&#x636E;&#x7684;&#x771F;&#x5B9E;&#x6027;. &#x56DE;&#x5230;&#x62DC;&#x5360;&#x5EAD;&#x5C06;&#x519B;(Byzantine Generals&#x2019; Problem)&#x7684;&#x95EE;&#x9898;&#x4E0A;&#xFF0C;&#x4ED6;&#x4EEC;&#x53EF;&#x4EE5;&#x786E;&#x4FDD;&#x540C;&#x5FD7;&#x5FE0;&#x8BDA;&#x7684;&#x4E00;&#x79CD;&#x65B9;&#x6CD5;&#x662F;&#xFF0C;&#x4F7F;&#x6BCF;&#x4E2A;&#x5C06;&#x519B;&#x5C06;&#x5927;&#x91CF;&#x8D44;&#x91D1;&#x6295;&#x5165;&#x65E0;&#x6CD5;&#x6E17;&#x900F;&#x7684;&#x4EE3;&#x7BA1;&#x8D26;&#x6237;&#x3002;&#x5728;&#x5C06;&#x519B;&#x53D1;&#x9001;&#x4FE1;&#x606F;&#x4E4B;&#x524D;&#xFF0C;&#x4ED6;&#x5FC5;&#x987B;&#x4F7F;&#x7528;&#x80FD;&#x8BC1;&#x660E;&#x81EA;&#x5DF1;&#x8EAB;&#x4EFD;&#x7684;&#x52A0;&#x5BC6;&#x5B89;&#x5168;&#x7B7E;&#x540D;&#x6765;&#x7B7E;&#x540D;&#x81EA;&#x5DF1;&#x7684;&#x540D;&#x5B57;&#x3002;&#x5982;&#x679C;&#x5C06;&#x519B;&#x6709;&#x4EFB;&#x4F55;&#x4E0D;&#x5F53;&#x884C;&#x4E3A;&#xFF0C;&#x5219;&#x519B;&#x961F;&#x5C06;&#x67E5;&#x770B;&#x901A;&#x8BAF;&#x7C3F;&#x5E76;&#x67E5;&#x770B;&#x53DB;&#x5F92;&#x7684;&#x7B7E;&#x540D;&#x3002;&#x53DB;&#x5F92;&#x4ECD;&#x7136;&#x53EF;&#x4EE5;&#x4E3E;&#x6B62;&#x5F97;&#x4F53;&#xFF0C;&#x4F46;&#x662F;&#x73B0;&#x5728;&#x4ED6;&#x5C06;&#x906D;&#x53D7;&#x7ECF;&#x6D4E;&#x635F;&#x5931;&#xFF0C;&#x56E0;&#x4E3A;&#x519B;&#x961F;&#x4E0D;&#x4F1A;&#x5C06;&#x4ED6;&#x7684;&#x62BC;&#x91D1;&#x8FD8;&#x7ED9;&#x4ED6;&#x3002;&#x8FD9;&#x79CD;&#x8FBE;&#x6210;&#x5206;&#x6563;&#x5F0F;&#x5171;&#x8BC6;&#x7684;&#x65B9;&#x6CD5;&#x79F0;&#x4E3A;&#x201C;&#x6743;&#x76CA;&#x8BC1;&#x660E;&#x201D;&#xFF0C;&#x56E0;&#x4E3A;&#x6BCF;&#x4E2A;&#x666E;&#x901A;&#x4EBA;&#x6216;&#x73B0;&#x4EE3;&#x8BA1;&#x7B97;&#x673A;&#x7528;&#x6237;&#x90FD;&#x5BF9;&#x7F51;&#x7EDC;&#x7684;&#x6210;&#x529F;&#x8FDB;&#x884C;&#x4E86;&#x6295;&#x8D44;&#x3002;&#x7F51;&#x7EDC;&#x7684;&#x53E6;&#x4E00;&#x79CD;&#x9009;&#x62E9;&#x662F;&#x8BA9;&#x7F51;&#x7EDC;&#x8FEB;&#x4F7F;&#x6BCF;&#x4E2A;&#x5C06;&#x519B;&#x5728;&#x4ED6;&#x4EEC;&#x6210;&#x529F;&#x7B7E;&#x540D;&#x5E76;&#x53D1;&#x9001;&#x6D88;&#x606F;&#x4E4B;&#x524D;&#x89E3;&#x51B3;&#x4E00;&#x4E2A;&#x6781;&#x5176;&#x590D;&#x6742;&#x7684;&#x6570;&#x5B66;&#x95EE;&#x9898;&#x3002;&#x4E3A;&#x4E86;&#x5FEB;&#x901F;&#x89E3;&#x51B3;&#x6570;&#x5B66;&#x95EE;&#x9898;&#xFF0C;&#x4E00;&#x822C;&#x5C06;&#x9700;&#x8981;&#x5411;&#x6602;&#x8D35;&#x7684;&#x6570;&#x5B66;&#x5BB6;&#x6295;&#x5165;&#x5927;&#x91CF;&#x8D44;&#x91D1;&#x3002;&#x8FD9;&#x79CD;&#x5171;&#x8BC6;&#x65B9;&#x6CD5;&#x88AB;&#x79F0;&#x4E3A;&#x201C;&#x5DE5;&#x4F5C;&#x91CF;&#x8BC1;&#x660E;&#x201D;&#xFF0C;&#x56E0;&#x4E3A;&#x5C06;&#x519B;&#x8BC1;&#x660E;&#x4ED6;&#x6295;&#x5165;&#x4E86;&#x8BF8;&#x5982;&#x65F6;&#x95F4;&#x548C;&#x8D44;&#x672C;&#x4E4B;&#x7C7B;&#x7684;&#x7A00;&#x7F3A;&#x8D44;&#x6E90;&#x6765;&#x89E3;&#x51B3;&#x6570;&#x5B66;&#x95EE;&#x9898;&#x3002; &#x5171;&#x8BC6;&#x673A;&#x5236;&#x6982;&#x8FF0; &#x5982;&#x56FE;2&#x6240;&#x793A;&#xFF0C;&#x5171;&#x8BC6;&#x673A;&#x5236;&#x6CBF;&#x7740;&#x4E24;&#x4E2A;&#x4E3B;&#x8F74;&#x5B58;&#x5728;&#xFF0C;&#x5373;&#x96C6;&#x4E2D;&#x7A0B;&#x5EA6;&#x548C;&#x5916;&#x90E8;&#x951A;&#x70B9;&#x7A0B;&#x5EA6;&#x3002;&#x5782;&#x76F4;&#x8F74;&#x7684;&#x8303;&#x56F4;&#x4ECE;&#x96C6;&#x4E2D;&#x5F0F;(&#x9700;&#x8981;&#x4FE1;&#x4EFB;&#x4E00;&#x4E2A;&#x4EBA;&#x6216;&#x7EC4;&#x7EC7;&#x624D;&#x80FD;&#x6B63;&#x786E;&#x5730;&#x8FDB;&#x884C;&#x4EA4;&#x6613;)&#x5230;&#x5206;&#x6563;&#x5F0F;(&#x964C;&#x751F;&#x4EBA;&#x7ED3;&#x7B97;&#x4EA4;&#x6613;&#x7684;&#x5730;&#x65B9;). &#x4F8B;&#x5982;&#xFF0C;&#x6BD4;&#x7279;&#x5E01;&#x7684;&#x5DE5;&#x4F5C;&#x91CF;&#x8BC1;&#x660E;&#x5171;&#x8BC6;&#x673A;&#x5236;&#x5C31;&#x662F;&#x4E00;&#x4E2A;&#x672A;&#x7ECF;&#x8BB8;&#x53EF;&#x7684;&#x516C;&#x5171;&#x533A;&#x5757;&#x94FE;&#x7684;&#x4F8B;&#x5B50;&#xFF0C;&#x56E0;&#x4E3A;&#x4E0D;&#x53D7;&#x4FE1;&#x4EFB;&#x7684;&#x964C;&#x751F;&#x4EBA;&#x53EF;&#x4EE5;&#x6210;&#x4E3A;&#x4EA4;&#x6613;&#x9A8C;&#x8BC1;&#x8005;&#xFF0C;&#x5E76;&#x4E14;&#x65E0;&#x9700;&#x900F;&#x9732;&#x5176;&#x8EAB;&#x4EFD;&#x3002;&#x53E6;&#x4E00;&#x4E2A;&#x4F8B;&#x5B50;&#x662F;&#x95E8;&#x7F57;&#x5E01;(Monero)&#x3002; &#x56FE;2 &#x6A2A;&#x8F74;&#x662F;&#x6307;&#x7528;&#x6237;&#x9700;&#x8981;&#x8FDB;&#x884C;&#x54EA;&#x79CD;&#x6295;&#x8D44;&#x624D;&#x80FD;&#x5728;&#x7CFB;&#x7EDF;&#x4E2D;&#x83B7;&#x5F97;&#x80FD;&#x91CF;&#x3002;&#x4F8B;&#x5982;&#xFF0C;&#x6BD4;&#x7279;&#x5E01;&#x8981;&#x6C42;&#x7528;&#x6237;&#x5728;&#x73B0;&#x5B9E;&#x4E16;&#x754C;&#x4E2D;&#x627F;&#x8BFA;&#x7A00;&#x7F3A;&#x8D44;&#x6E90;&#xFF0C;&#x4EE5;&#x4FBF;&#x5728;&#x6BD4;&#x7279;&#x5E01;&#x7F51;&#x7EDC;&#x4E2D;&#x505A;&#x51FA;&#x51B3;&#x5B9A;, &#x8FD9;&#x79F0;&#x4E3A;&#x5916;&#x90E8;&#x951A;&#x3002;&#x76F8;&#x53CD;&#xFF0C;&#x843D;&#x5165;&#x53F3;&#x4E0A;&#x8C61;&#x9650;&#x7684;&#x5171;&#x8BC6;&#x673A;&#x5236;&#xFF08;&#x4F8B;&#x5982;&#xFF0C;&#x80A1;&#x6743;&#x8BC1;&#x660E;&#xFF09;&#x4E0D;&#x9700;&#x8981;&#x5916;&#x90E8;&#x8D44;&#x6E90;&#x5373;&#x53EF;&#x5728;&#x7F51;&#x7EDC;&#x5185;&#x505A;&#x51FA;&#x51B3;&#x7B56;&#x3002;&#x8BE5;&#x8C61;&#x9650;&#x5305;&#x62EC;NXT&#x548C;Peercoin&#x7B49;&#x786C;&#x5E01;&#x3002;&#x4EE5;&#x592A;&#x574A;&#x8BA1;&#x5212;&#x5728;19&#x5E74;&#x4ECE;&#x5DE6;&#x4E0A;&#x8C61;&#x9650;&#x5207;&#x6362;&#x5230;&#x53F3;&#x4E0A;&#x8C61;&#x9650;&#x3002; &#x5728;&#x53F3;&#x4E0B;&#x8C61;&#x9650;&#x7684;&#x9891;&#x8C31;&#x7684;&#x53E6;&#x4E00;&#x4FA7;&#xFF0C;&#x5141;&#x8BB8;&#x4F7F;&#x7528;&#x79C1;&#x6709;&#x534F;&#x5546;&#x673A;&#x5236;&#xFF0C;&#x4F8B;&#x5982;&#x62DC;&#x5360;&#x5EAD;&#x5F0F;&#x5BB9;&#x9519;(byzantine fault tolerance)&#x3002;IBM&#x7684;Hyperledger&#x662F;&#x6570;&#x636E;&#x7ED3;&#x6784;&#x7684;&#x793A;&#x4F8B;&#xFF0C;&#x5141;&#x8BB8;&#x521B;&#x5EFA;&#x8005;&#x6307;&#x5B9A;&#x8C01;&#x6765;&#x7ED3;&#x7B97;&#x4EA4;&#x6613;&#x3002;&#x4F7F;&#x7528;Hyperledger&#x6216;Microsoft&#x7684;Blockchain&#x4F5C;&#x4E3A;&#x670D;&#x52A1;&#x7684;&#x516C;&#x53F8;&#x5C06;&#x77E5;&#x9053;&#x4ED6;&#x4EEC;&#x9009;&#x62E9;&#x63A7;&#x5236;&#x7F51;&#x7EDC;&#x7684;&#x4EBA;&#x5458;&#x7684;&#x8EAB;&#x4EFD;&#xFF0C;&#x5E76;&#x4E14;&#x7F51;&#x7EDC;&#x7528;&#x6237;&#x5C06;&#x9700;&#x8981;&#x4FE1;&#x4EFB;&#x8FD9;&#x4E9B;&#x4EBA;&#x5458;&#x3002;&#x8FD9;&#x4E9B;&#x7CFB;&#x7EDF;&#x662F;&#x96C6;&#x4E2D;&#x5F0F;&#x7684;&#xFF0C;&#x6CA1;&#x6709;&#x5916;&#x90E8;&#x951A;&#x70B9;&#x3002;&#x5DE6;&#x4E0B;&#x8C61;&#x9650;&#x4E2D;&#x7684;&#x786C;&#x5E01;&#x662F;IOTA&#xFF0C;Byteball&#x548C;Hashgraph&#x4E4B;&#x7C7B;&#x7684;&#x3002;&#x8FD9;&#x4E9B;&#x786C;&#x5E01;&#x6709;&#x89C1;&#x8BC1;&#x8005;&#x548C;&#x534F;&#x8C03;&#x8005;&#x6765;&#x96C6;&#x4E2D;&#x7CFB;&#x7EDF;&#x3002;&#x4F46;&#x662F;&#xFF0C;&#x4ED6;&#x4EEC;&#x4ECD;&#x7136;&#x8981;&#x6C42;&#x9A8C;&#x8BC1;&#x8005;&#x63D0;&#x4F9B;&#x5916;&#x90E8;&#x8D44;&#x6E90;&#xFF0C;&#x4EE5;&#x4FBF;&#x5728;&#x7F51;&#x7EDC;&#x4E2D;&#x83B7;&#x5F97;&#x80FD;&#x91CF;&#x3002;&#x6700;&#x5E38;&#x89C1;&#x7684;&#x5171;&#x8BC6;&#x673A;&#x5236;&#x662F;&#x6709;&#x5411;&#x65E0;&#x73AF;&#x56FE;&#x7ED3;&#x6784;&#x4E0E;&#x9632;&#x6B62;Sybil&#x653B;&#x51FB;&#x7684;&#x5DE5;&#x4F5C;&#x8BC1;&#x660E;&#x76F8;&#x7ED3;&#x5408;&#x3002; Proof of Work (PoW) &#x5BF9;&#x4E8E;&#x6BD4;&#x7279;&#x5E01;&#xFF0C;&#x60A8;&#x53EF;&#x4EE5;&#x5C06;&#x62DC;&#x5360;&#x5EAD;&#x5C06;&#x519B;&#x89C6;&#x4E3A;&#x4E0D;&#x540C;&#x7684;&#x6BD4;&#x7279;&#x5E01;&#x94B1;&#x5305;&#x3002;&#x8FD0;&#x884C;&#x6BD4;&#x7279;&#x5E01;&#x8F6F;&#x4EF6;&#x7684;&#x8BA1;&#x7B97;&#x673A;&#x4F7F;&#x7528;&#x5DE5;&#x4F5C;&#x91CF;&#x8BC1;&#x660E;&#x5171;&#x8BC6;&#x7B97;&#x6CD5;&#x6765;&#x8FBE;&#x6210;&#x5173;&#x4E8E;&#x6709;&#x6548;&#x4ED8;&#x6B3E;&#x7684;&#x534F;&#x8BAE;&#x3002; &#x6839;&#x636E;&#x5728;&#x9ED1;&#x6D77;&#x94FE;&#x4F1A;&#x8BAE;&#x4E0A;&#x7684;&#x514B;&#x91CC;&#x65AF;&#x8482;&#x5B89;&#xB7;&#x8D6B;&#x91CC;&#x65AF;&#x6258;&#x592B;&#xFF08;Hristian Hristov&#xFF09;&#x7684;&#x8BF4;&#x6CD5;&#xFF0C;&#x5DE5;&#x4F5C;&#x8BC1;&#x660E;&#x662F;: &gt; &quot;&#x96BE;&#x4EE5;&#xFF08;&#x6602;&#x8D35;&#xFF0C;&#x8D39;&#x65F6;&#xFF09;&#x751F;&#x6210;&#x4F46;&#x6613;&#x4E8E;&#x5176;&#x4ED6;&#x4EBA;&#x9A8C;&#x8BC1;&#x4E14;&#x6EE1;&#x8DB3;&#x67D0;&#x4E9B;&#x8981;&#x6C42;&#x7684;&#x4E00;&#x6761;&#x6570;&#x636E;&#x3002;&#x4EA7;&#x751F;&#x5DE5;&#x4F5C;&#x8BC1;&#x660E;&#x53EF;&#x80FD;&#x662F;&#x4E00;&#x4E2A;&#x968F;&#x673A;&#x8FC7;&#x7A0B;&#xFF0C;&#x53EF;&#x80FD;&#x6027;&#x5F88;&#x5C0F;&#xFF0C;&#x56E0;&#x6B64;&#x5728;&#x751F;&#x6210;&#x6709;&#x6548;&#x7684;&#x5DE5;&#x4F5C;&#x8BC1;&#x660E;&#x4E4B;&#x524D;&#xFF0C;&#x5E73;&#x5747;&#x9700;&#x8981;&#x8FDB;&#x884C;&#x591A;&#x6B21;&#x5C1D;&#x8BD5;&#x548C;&#x9519;&#x8BEF;&#x3002;&quot; &#x5982;&#x679C;Mark&#x5E0C;&#x671B;&#x5411;Demelza&#x53D1;&#x9001;5&#x6BD4;&#x7279;&#x5E01;&#xFF0C;&#x5219;&#x6574;&#x4E2A;&#x7F51;&#x7EDC;&#x5FC5;&#x987B;&#x786E;&#x4FDD;Mark&#x62E5;&#x6709;5&#x6BD4;&#x7279;&#x5E01;&#xFF0C;&#x5E76;&#x4E14;&#x4EA4;&#x6613;&#x5FC5;&#x987B;&#x4F7F;&#x7528;Mark&#x7684;&#x6570;&#x5B57;&#x7B7E;&#x540D;&#x8FDB;&#x884C;&#x7B7E;&#x540D;&#x3002;&#x6BD4;&#x7279;&#x5E01;&#x8282;&#x70B9;&#x6BCF;&#x5341;&#x5206;&#x949F;&#x5C31;&#x4E00;&#x9879;&#x4EA4;&#x6613;&#x5728;&#x6709;&#x6548;&#x7684;&#x201C;&#x6316;&#x77FF;&#x201D;&#x8FC7;&#x7A0B;&#x4E2D;&#x8FBE;&#x6210;&#x534F;&#x8BAE;&#x3002;&#x5728;&#x786E;&#x8BA4;&#x65B0;&#x7684;&#x4EA4;&#x6613;&#x5757;&#x4E4B;&#x524D;&#xFF0C;&#x77FF;&#x5DE5;&#x5148;&#x8BA1;&#x7B97;&#x6563;&#x5217;&#x503C;&#xFF0C;&#x76F4;&#x5230;&#x627E;&#x5230;&#x6240;&#x9700;&#x6570;&#x91CF;&#xFF0C;&#x8BE5;&#x6570;&#x91CF;&#x5C0F;&#x4E8E;&#x7531;&#x79F0;&#x4E3A;&#x96BE;&#x5EA6;&#x76EE;&#x6807;&#x7684;&#x8F6F;&#x4EF6;&#x534F;&#x8BAE;&#x8BBE;&#x7F6E;&#x7684;&#x7279;&#x5B9A;&#x6570;&#x91CF;&#x3002;&#x4F8B;&#x5982;&#xFF0C;&#x5728;&#x6BD4;&#x7279;&#x5E01;&#x534F;&#x8BAE;&#x4E2D;&#xFF0C;&#x77FF;&#x5DE5;&#x5FC5;&#x987B;&#x627E;&#x5230;&#x6B63;&#x786E;&#x7684;&#x201C;&#x968F;&#x673A;&#x6570;&#x201D;&#x6216;&#x4EFB;&#x610F;&#x6570;&#x5B57;&#xFF0C;&#x5176;&#x4EA7;&#x751F;&#x7684;&#x6563;&#x5217;&#x503C;&#x4F4E;&#x4E8E;&#x8F6F;&#x4EF6;&#x8BBE;&#x7F6E;&#x7684;&#x96BE;&#x5EA6;&#x76EE;&#x6807;&#x3002;&#x8FD9;&#x88AB;&#x79F0;&#x4E3A;&#x54C8;&#x5E0C;&#x96BE;&#x9898;&#xFF0C;&#x56E0;&#x4E3A;&#x77FF;&#x5DE5;&#x5FC5;&#x987B;&#x5C06;&#x968F;&#x673A;&#x6570;&#x6DFB;&#x52A0;&#x5230;&#x533A;&#x5757;&#x94FE;&#x4E2D;&#x524D;&#x4E00;&#x4E2A;&#x533A;&#x5757;&#x7684;&#x54C8;&#x5E0C;&#x4E2D;&#x3002;&#x8BA1;&#x7B97;&#x8F93;&#x51FA;&#x662F;&#x4E00;&#x4E2A;&#x57FA;&#x672C;&#x4E0A;&#x843D;&#x5165;&#x76EE;&#x6807;&#x7A7A;&#x95F4;&#x7684;&#x6570;&#x5B57;&#xFF0C;&#x8BE5;&#x76EE;&#x6807;&#x7A7A;&#x95F4;&#x76F8;&#x5BF9;&#x4E8E;&#x6574;&#x4E2A;&#x54C8;&#x5E0C;&#x51FD;&#x6570;&#x7684;&#x8F83;&#x5927;&#x8F93;&#x51FA;&#x7A7A;&#x95F4;&#x800C;&#x8A00;&#x76F8;&#x5BF9;&#x8F83;&#x5C0F;&#x3002;&#x8BE5;&#x7F16;&#x53F7;&#x6210;&#x4E3A;&#x8BE5;&#x533A;&#x5757;&#x7684;&#x6807;&#x8BC6;&#x53F7;&#xFF0C;&#x7528;&#x4F5C;&#x4E0B;&#x4E00;&#x4E2A;&#x533A;&#x5757;&#x7684;&#x54C8;&#x5E0C;&#x96BE;&#x9898;&#x7684;&#x8F93;&#x5165;&#x3002; Proof of Work Computation &#x56FE;3 &#x5DE5;&#x4F5C;&#x91CF;&#x8BC1;&#x660E;&#x4F7F;&#x7528;&#x4E24;&#x79CD;&#x4E3B;&#x8981;&#x7684;&#x8D22;&#x52A1;&#x5956;&#x52B1;&#x65B9;&#x5F0F;&#x6765;&#x6FC0;&#x52B1;&#x7528;&#x6237;&#x7EF4;&#x62A4;&#x7F51;&#x7EDC;&#xFF1A;&#x5956;&#x52B1;&#x548C;&#x4EA4;&#x6613;&#x8D39;&#x7528;&#x3002; 1. &#x7B2C;&#x4E00;&#x4E2A;&#x53D1;&#x73B0;&#x54C8;&#x5E0C;&#x503C;&#x4F4E;&#x4E8E;&#x7ED9;&#x5B9A;&#x96BE;&#x5EA6;&#x76EE;&#x6807;&#x7684;&#x77FF;&#x5DE5;&#x5C06;&#x6709;&#x6743;&#x201C;&#x6253;&#x5370;&#x201D;&#x65B0;&#x7684;&#x6BD4;&#x7279;&#x5E01;&#xFF0C;&#x5E76;&#x63A5;&#x6536;&#x53D1;&#x9001;&#x65B9;&#x5728;&#x5E7F;&#x64AD;&#x4ED8;&#x6B3E;&#x65F6;&#x5411;&#x7F51;&#x7EDC;&#x652F;&#x4ED8;&#x7684;&#x4EA4;&#x6613;&#x8D39;&#x3002;&#x6BCF;&#x4E2A;&#x533A;&#x5757;&#x7684;&#x7B2C;&#x4E00;&#x7B14;&#x4EA4;&#x6613;&#x90FD;&#x662F;&#x201C;&#x786C;&#x5E01;&#x521B;&#x9020;&#x4EA4;&#x6613;&#x201D;&#x3002;&#x786C;&#x5E01;&#x521B;&#x9020;&#x4EA4;&#x6613;&#x5141;&#x8BB8;&#x533A;&#x5757;&#x7684;&#x77FF;&#x5DE5;&#x94F8;&#x9020;&#x65B0;&#x7684;&#x6BD4;&#x7279;&#x5E01;&#x5E76;&#x5C06;&#x8FD9;&#x4E9B;&#x65B0;&#x7684;&#x6BD4;&#x7279;&#x5E01;&#x53D1;&#x9001;&#x5230;&#x4ED6;&#x6216;&#x5979;&#x7684;&#x94B1;&#x5305;&#x3002;2016&#x5E74;&#xFF0C;&#x96C6;&#x4F53;&#x5956;&#x52B1;&#x7684;&#x4EF7;&#x503C;&#x7EA6;&#x4E3A;25&#x4E2A;&#x6BD4;&#x7279;&#x5E01;&#x3002;&#x4F46;&#x662F;&#xFF0C;&#x6B64;&#x901F;&#x7387;&#x5927;&#x7EA6;&#x6BCF;&#x56DB;&#x5E74;&#x4E0B;&#x964D;&#x4E00;&#x6B21;&#xFF0C;&#x76EE;&#x524D;(18&#x5E74;)&#x4E3A;12.5&#x6BD4;&#x7279;&#x5E01;&#x3002;&#x96C6;&#x4F53;&#x5956;&#x52B1;&#x6FC0;&#x52B1;&#x8BDA;&#x5B9E;&#x7684;&#x884C;&#x4E3A;&#xFF0C;&#x56E0;&#x4E3A;&#x53EA;&#x6709;&#x5728;&#x7EF4;&#x62A4;&#x7F51;&#x7EDC;&#x7684;&#x5176;&#x4ED6;&#x7528;&#x6237;&#x63A5;&#x53D7;&#x786C;&#x5E01;&#x521B;&#x9020;&#x4EA4;&#x6613;&#x7684;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;&#x786C;&#x5E01;&#x521B;&#x9020;&#x4EA4;&#x6613;&#x624D;&#x6709;&#x4EF7;&#x503C;&#x3002; 2. &#x7B2C;&#x4E8C;&#x4E2A;&#x5956;&#x52B1;&#x662F;&#x4EA4;&#x6613;&#x8D39;&#x7528;&#x3002;&#x7528;&#x6237;&#x53D1;&#x9001;&#x6BD4;&#x7279;&#x5E01;&#x4EA4;&#x6613;&#x65F6;&#xFF0C;&#x4ED6;&#x4EEC;&#x4F1A;&#x6536;&#x53D6;&#x8D39;&#x7528;&#x3002;&#x8D39;&#x7528;&#x8D8A;&#x9AD8;&#xFF0C;&#x77FF;&#x5DE5;&#x5C06;&#x4EA4;&#x6613;&#x5305;&#x542B;&#x5728;&#x5176;&#x5019;&#x9009;&#x533A;&#x5757;&#x4E2D;&#x7684;&#x53EF;&#x80FD;&#x6027;&#x5C31;&#x8D8A;&#x5927;&#xFF0C;&#x8FD9;&#x610F;&#x5473;&#x7740;&#x4EA4;&#x6613;&#x7684;&#x786E;&#x8BA4;&#x65F6;&#x95F4;&#x5C06;&#x66F4;&#x5FEB;&#x3002; Bitcoin Minig and Transaction Revenues &#x56FE;4 &#x4F46;&#x662F;&#xFF0C;&#x6BD4;&#x7279;&#x5E01;&#x7684;&#x5DE5;&#x4F5C;&#x91CF;&#x8BC1;&#x660E;&#x7B97;&#x6CD5;&#x6709;&#x7F3A;&#x70B9;&#x3002; &#x9996;&#x5148;&#xFF0C;&#x653B;&#x51FB;&#x8005;&#x53EF;&#x4EE5;&#x5229;&#x7528;&#x51E0;&#x79CD;&#x653B;&#x51FB;&#x5A92;&#x4ECB;&#xFF0C;&#x5305;&#x62EC;&#xFF1A; 1. race attack 2. Finney attack 3. vector 76 attack 4. alternative history attack 5. majority attack 6. denial-of-service attack 7. Sybil attack 8. selfish mining &#x7B2C;&#x4E8C;&#xFF0C;&#x8BE5;&#x7F51;&#x7EDC;&#x4F7F;&#x7528;&#x5927;&#x91CF;&#x80FD;&#x6E90;&#x548C;&#x786C;&#x4EF6;&#x8BBE;&#x5907;&#xFF0C;&#x636E;&#x4F30;&#x8BA1;&#x6BCF;&#x5E74;&#x82B1;&#x8D39;&#x5927;&#x7EA6;4&#x4EBF;&#x7F8E;&#x5143;&#x3002;&#x7531;&#x4E8E;&#x8D8A;&#x6765;&#x8D8A;&#x591A;&#x7684;&#x4F01;&#x4E1A;&#x5BB6;&#x52A0;&#x5165;&#x91C7;&#x77FF;&#x4E1A;&#xFF0C;&#x5BFB;&#x627E;&#x6BD4;&#x7279;&#x5E01;&#x533A;&#x5757;&#x7684;&#x96BE;&#x5EA6;&#x4E0D;&#x65AD;&#x589E;&#x52A0;&#x3002;&#x56E0;&#x6B64;&#xFF0C;&#x77FF;&#x5DE5;&#x4E3A;&#x627E;&#x5230;&#x533A;&#x5757;&#x6240;&#x5FC5;&#x987B;&#x8D2D;&#x4E70;&#x7684;&#x7535;&#x529B;&#x5728;&#x4E0D;&#x65AD;&#x589E;&#x52A0;&#x3002;&#x8FD9;&#x5C31;&#x662F;&#x4E3A;&#x4EC0;&#x4E48;&#x91C7;&#x77FF;&#x81EA;&#x7136;&#x4F1A;&#x96C6;&#x4E2D;&#x5728;&#x7535;&#x4EF7;&#x4FBF;&#x5B9C;&#x7684;&#x56FD;&#x5BB6;/&#x5730;&#x533A;&#x7684;&#x539F;&#x56E0;&#x3002; &#x50CF;&#x9EC4;&#x91D1;&#x4E00;&#x6837;&#xFF0C;&#x6BD4;&#x7279;&#x5E01;&#x4E5F;&#x4F7F;&#x7528;&#x7535;&#x529B;&#x548C;&#x8D44;&#x672C;&#x8BBE;&#x5907;&#x6765;&#x5F00;&#x91C7;&#x65B0;&#x786C;&#x5E01;&#x3002;&#x968F;&#x673A;&#x9009;&#x62E9;&#x521B;&#x5EFA;&#x4E00;&#x4E2A;&#x533A;&#x5757;&#x5E76;&#x83B7;&#x5F97;&#x5956;&#x52B1;&#x7684;&#x6982;&#x7387;&#x7B49;&#x4E8E;&#x6BCF;&#x4E2A;&#x77FF;&#x5DE5;&#x7684;&#x91C7;&#x77FF;&#x80FD;&#x529B;&#x9664;&#x4EE5;&#x7F51;&#x7EDC;&#x4E0A;&#x91C7;&#x77FF;&#x80FD;&#x529B;&#x7684;&#x603B;&#x548C;&#x3002;&#x6316;&#x6398;&#x786C;&#x4EF6;&#x6D88;&#x8017;&#x7684;&#x529F;&#x7387;&#x8D8A;&#x591A;&#xFF0C;&#x54C8;&#x5E0C;&#x7387;&#x5C31;&#x8D8A;&#x9AD8;&#x3002;&#x8FD9;&#x6837;&#x53EF;&#x4EE5;&#x4ECE;&#x91C7;&#x77FF;&#x4E2D;&#x83B7;&#x5F97;&#x66F4;&#x9AD8;&#x7684;&#x5229;&#x6DA6;&#x3002;&#x7528;&#x4E8E;&#x8BA1;&#x7B97;&#x7684;&#x53C2;&#x6570;&#x5305;&#x62EC;&#xFF1A;&#x96BE;&#x5EA6;&#x7CFB;&#x6570;&#xFF0C;&#x54C8;&#x5E0C;&#x7387;(TH/s)&#xFF0C;BTC/USD&#x6C47;&#x7387;&#xFF0C;&#x4EE5;&#x767E;&#x5206;&#x6BD4;&#x8868;&#x793A;&#x7684;&#x6C60;&#x8D39;&#x7528;&#xFF0C;&#x786C;&#x4EF6;&#x6210;&#x672C;(USD)&#xFF0C;&#x529F;&#x7387;(watt)&#xFF0C;&#x529F;&#x7387;&#x6210;&#x672C;(USD/kWh) Proof of Stake (PoS) &#x4E0E;&#x6BD4;&#x7279;&#x5E01;&#x6216;&#x9EC4;&#x91D1;&#x4E0D;&#x540C;&#xFF0C;&#x80A1;&#x6743;&#x8BC1;&#x660E;&#x5141;&#x8BB8;&#x62E5;&#x6709;&#x6700;&#x591A;&#x8D44;&#x4EA7;&#x7684;&#x7528;&#x6237;&#x51ED;&#x7A7A;&#x521B;&#x9020;&#x786C;&#x5E01;&#x3002;&#x5728;&#x80A1;&#x6743;&#x8BC1;&#x660E;&#x7CFB;&#x7EDF;&#x4E2D;&#xFF0C;&#x83B7;&#x5F97;&#x5956;&#x52B1;&#x7684;&#x6982;&#x7387;&#x7B49;&#x4E8E;&#x7528;&#x6237;&#x6301;&#x6709;&#x7684;&#x786C;&#x5E01;&#x6BD4;&#x4F8B;&#x9664;&#x4EE5;&#x6D41;&#x901A;&#x786C;&#x5E01;&#x603B;&#x6570;&#x3002;&#x5B58;&#x5728;&#x591A;&#x79CD;&#x80A1;&#x6743;&#x8BC1;&#x660E;&#xFF0C;&#x5305;&#x62EC;&#x79DF;&#x8D41;&#x80A1;&#x6743;&#x8BC1;&#x660E;&#x548C;&#x59D4;&#x6258;&#x80A1;&#x6743;&#x8BC1;&#x660E;&#x3002;&#x4E24;&#x79CD;&#x7CFB;&#x7EDF;&#x90FD;&#x8FBE;&#x5230;&#x76F8;&#x4F3C;&#x7684;&#x7ED3;&#x679C;&#x3002;&#x4F46;&#x662F;&#xFF0C;&#x5DE5;&#x4F5C;&#x8BC1;&#x660E;&#x4F1A;&#x7ED9;&#x73AF;&#x5883;&#x5E26;&#x6765;&#x8D1F;&#x9762;&#x7684;&#x5916;&#x90E8;&#x5F71;&#x54CD;&#x3002;&#x90A3;&#x4E3A;&#x4EC0;&#x4E48;&#x4EBA;&#x4EEC;&#x4ECD;&#x5728;&#x4F7F;&#x7528;&#x5DE5;&#x4F5C;&#x8BC1;&#x660E;&#xFF1F;&#x5E02;&#x503C;&#x6700;&#x9AD8;&#x7684;&#x4EE3;&#x5E01;&#x90FD;&#x4F9D;&#x8D56;&#x4E8E;&#x5DE5;&#x4F5C;&#x91CF;&#x8BC1;&#x660E;&#xFF0C;&#x4F46;&#x80A1;&#x6743;&#x8BC1;&#x660E;&#x8D8A;&#x6765;&#x8D8A;&#x53D7;&#x6B22;&#x8FCE;&#xFF1A;&#x4EE5;&#x592A;&#x574A;&#xFF0C;&#x7B2C;&#x4E8C;&#x5927;&#x5E02;&#x503C;&#x4EE3;&#x5E01;&#xFF0C;&#x6709;&#x671B;&#x5728;19&#x5E74;&#x4ECE;&#x5DE5;&#x4F5C;&#x91CF;&#x8BC1;&#x660E;&#x8F6C;&#x53D8;&#x4E3A;&#x59D4;&#x6258;&#x7684;&#x80A1;&#x6743;&#x8BC1;&#x660E;&#x3002; Proof of Stake attack vectors noting-at-stake attack short-and-long-range attacks precomputing attack denial-of-service attack Sybil attack bribe attack &#x9664;&#x4E86;&#x653B;&#x51FB;&#x5A92;&#x4ECB;&#x4E4B;&#x5916;&#xFF0C;&#x80A1;&#x6743;&#x8BC1;&#x660E;&#x8FD8;&#x6CA1;&#x6709;&#x5728;&#x5E02;&#x573A;&#x4E0A;&#x5F97;&#x5230;&#x5F88;&#x597D;&#x7684;&#x6D4B;&#x8BD5;&#x3002;&#x5C3D;&#x7BA1;&#x8BB8;&#x591A;&#x80A1;&#x6743;&#x8BC1;&#x660E;&#x7684;&#x652F;&#x6301;&#x8005;&#x58F0;&#x79F0;&#x5B83;&#x6CA1;&#x6709;&#x5DE5;&#x4F5C;&#x8BC1;&#x660E;&#x90A3;&#x4E48;&#x96C6;&#x4E2D;&#xFF0C;&#x4F46;&#x8FD9;&#x4E0D;&#x4E00;&#x5B9A;&#x662F;&#x6B63;&#x786E;&#x7684;&#x3002;&#x7531;&#x4E8E;&#x6295;&#x8D44;&#x8005;&#x5BF9;&#x4ED6;&#x4EEC;&#x7684;long positions&#x6536;&#x53D6;&#x5229;&#x606F;&#xFF0C;&#x80A1;&#x6743;&#x8BC1;&#x660E;&#x9F13;&#x52B1;&#x56E4;&#x79EF;&#x800C;&#x975E;&#x5DE5;&#x4F5C;&#x8BC1;&#x660E;&#x3002; &#x6B63;&#x5982;&#x5B89;&#x5FB7;&#x70C8;&#x4E9A;&#x65AF;&#xB7;&#x5B89;&#x4E1C;&#x8BFA;&#x666E;&#x6D1B;&#x65AF;&#xFF08;Andreas Antonopoulos&#xFF09;&#x5728;&#x9A6C;&#x6765;&#x897F;&#x4E9A;&#x5409;&#x9686;&#x5761;&#x7684;&#x7EF4;&#x65AF;&#x739B;&#xB7;&#x6BD4;&#x6602;&#x96C6;&#x56E2;&#xFF08;Wisma BeeOn Group&#xFF09;&#x4E0A;&#x89E3;&#x91CA;&#x7684;&#x90A3;&#x6837;&#xFF0C;&#x80A1;&#x6743;&#x8BC1;&#x660E;&#x53EF;&#x4EE5;&#x4F7F;&#x5BCC;&#x4EBA;&#x53D8;&#x5F97;&#x66F4;&#x5BCC;&#x88D5;&#x3002;&#x8FD9;&#x5BF9;&#x52A0;&#x5BC6;&#x8D27;&#x5E01;&#x7684;&#x6301;&#x6709;&#x8005;&#x4EA7;&#x751F;&#x4E86;&#x96C6;&#x4E2D;&#x5F71;&#x54CD;&#x3002;&#x76F8;&#x53CD;&#xFF0C;&#x5DE5;&#x4F5C;&#x91CF;&#x8BC1;&#x660E;&#x77FF;&#x5DE5;&#x88AB;&#x8FEB;&#x5411;&#x5E02;&#x573A;&#x53D1;&#x5E03;&#x4E00;&#x5B9A;&#x6570;&#x91CF;&#x7684;&#x786C;&#x5E01;&#xFF0C;&#x4EE5;&#x4FBF;&#x6295;&#x8D44;&#x4E8E;&#x65B0;&#x7684;&#x91C7;&#x77FF;&#x786C;&#x4EF6;&#x5E76;&#x652F;&#x4ED8;&#x7535;&#x8D39;&#x3002;&#x8FD9;&#x4F7F;&#x5F97;&#x6BCF;&#x5929;&#x90FD;&#x6709;&#x76F8;&#x5BF9;&#x6052;&#x5B9A;&#x6570;&#x91CF;&#x7684;&#x65B0;&#x94F8;&#x9020;&#x6BD4;&#x7279;&#x5E01;&#x8FDB;&#x5165;&#x5E02;&#x573A;&#x3002; &#x603B;&#x7ED3; &#x52A0;&#x5BC6;&#x8D27;&#x5E01;&#x9762;&#x4E34;&#x7684;&#x4E3B;&#x8981;&#x6298;&#x8877;&#x662F;&#x96C6;&#x4E2D;&#x5316;&#x548C;&#x6548;&#x7387;&#x4E4B;&#x95F4;&#x3002;&#x51B3;&#x7B56;&#x8FC7;&#x7A0B;&#x8D8A;&#x96C6;&#x4E2D;&#xFF0C;&#x51B3;&#x7B56;&#x901F;&#x5EA6;&#x8D8A;&#x5FEB;&#xFF0C;&#x7F51;&#x7EDC;&#x53EF;&#x6269;&#x5C55;&#x6027;&#x8D8A;&#x5F3A;&#x3002;&#x53E6;&#x4E00;&#x65B9;&#x9762;&#xFF0C;&#x7F51;&#x7EDC;&#x8D8A;&#x4E0D;&#x96C6;&#x4E2D;&#xFF0C;&#x8FBE;&#x6210;&#x5171;&#x8BC6;&#x6240;&#x82B1;&#x8D39;&#x7684;&#x65F6;&#x95F4;&#x5C31;&#x8D8A;&#x957F;&#x3002;&#x8FD9;&#x4E0E;&#x72EC;&#x88C1;&#x653F;&#x6743;&#x548C;&#x76F4;&#x63A5;&#x6C11;&#x4E3B;&#x653F;&#x4F53;&#x4E4B;&#x95F4;&#x7684;&#x4E8C;&#x5206;&#x6CD5;&#x4E0D;&#x540C;&#x3002;&#x5F53;&#x80A1;&#x4E1C;&#x4E4B;&#x95F4;&#x7684;&#x7B49;&#x7EA7;&#x5236;&#x5EA6;&#x7EDF;&#x4E00;&#x65F6;&#xFF0C;&#x5F88;&#x96BE;&#x8FBE;&#x6210;&#x4E00;&#x81F4;&#x7684;&#x51B3;&#x7B56;&#x3002;&#x5C3D;&#x7BA1;&#x5F15;&#x5165;&#x4EA4;&#x6613;&#x5BF9;&#x624B;&#x5E76;&#x4E0D;&#x662F;&#x5728;&#x6BCF;&#x79CD;&#x60C5;&#x51B5;&#x4E0B;&#x90FD;&#x5B58;&#x5728;&#x95EE;&#x9898;&#xFF0C;&#x4F46;&#x533A;&#x5757;&#x94FE;&#x6280;&#x672F;&#x7684;&#x6700;&#x521D;&#x76EE;&#x6807;&#x662F;&#x5728;&#x6CA1;&#x6709;&#x4E2D;&#x4ECB;&#x673A;&#x6784;&#x7684;&#x60C5;&#x51B5;&#x4E0B;&#x8FBE;&#x6210;&#x5171;&#x8BC6;&#x3002;&#x77FF;&#x5DE5;&#xFF0C;&#x7532;&#x9AA8;&#x6587;&#xFF0C;&#x89C1;&#x8BC1;&#x4EBA;&#xFF0C;&#x4EE3;&#x8868;&#x6216;&#x5229;&#x76CA;&#x76F8;&#x5173;&#x8005;&#x90FD;&#x5728;&#x4E00;&#x5B9A;&#x7A0B;&#x5EA6;&#x4E0A;&#x96C6;&#x4E2D;&#x4E86;&#x7CFB;&#x7EDF;&#x3002; &#x65E0;&#x9700;&#x5F15;&#x5165;&#x6709;&#x5411;&#x65E0;&#x73AF;&#x56FE;&#x534F;&#x8C03;&#x5668;&#x5C31;&#x53EF;&#x4EE5;&#x6D88;&#x9664;&#x5DE5;&#x4F5C;&#x7528;&#x7535;&#x91CF;&#x8BC1;&#x660E;&#x7684;&#x5171;&#x8BC6;&#x673A;&#x5236;&#x5C06;&#x5728;&#x52A0;&#x5BC6;&#x7A7A;&#x95F4;&#x4E2D;&#x6210;&#x4E3A;&#x5934;&#x6761;&#x65B0;&#x95FB;&#x3002;&#x9EBB;&#x7701;&#x7406;&#x5DE5;&#x5B66;&#x9662;&#x7684;&#x5BC6;&#x7801;&#x5B66;&#x5BB6;&#x897F;&#x5C14;&#x7EF4;&#x5965;&#xB7;&#x7C73;&#x5361;&#x5229;&#xFF08;Silvio Micali&#xFF09;&#x62A5;&#x544A;&#x8BF4;&#xFF0C;&#x4ED6;&#x7684;&#x5171;&#x8BC6;&#x673A;&#x5236;Algorand&#x540C;&#x65F6;&#x5B9E;&#x73B0;&#x4E86;&#x53BB;&#x4E2D;&#x5FC3;&#x5316;&#x548C;&#x5B89;&#x5168;&#x6027;&#x3002;&#x6211;&#x4EEC;&#x8BA1;&#x5212;&#x5C06;&#x8FD9;&#x79CD;&#x7B97;&#x6CD5;&#x548C;&#x91C7;&#x7528;&#x8BE5;&#x7B97;&#x6CD5;&#x7684;&#x786C;&#x5E01;&#x4FDD;&#x7559;&#x5728;&#x6211;&#x4EEC;&#x7684;&#x96F7;&#x8FBE;&#x4E0A;&#x3002;&#x6B64;&#x5916;&#xFF0C;&#x8BF8;&#x5982;Tezos&#x548C;Dfinity&#x4E4B;&#x7C7B;&#x7684;&#x4EE3;&#x5E01;&#x6709;&#x671B;&#x5C06;&#x6CBB;&#x7406;&#x5D4C;&#x5165;&#x534F;&#x8BAE;&#x7EA7;&#x522B;&#xFF0C;&#x8FD9;&#x53EF;&#x80FD;&#x4F7F;&#x5206;&#x6563;&#x80A1;&#x4E1C;&#x80FD;&#x591F;&#x66F4;&#x5FEB;&#x5730;&#x8FBE;&#x6210;&#x5171;&#x8BC6;&#x3002;&#x5C3D;&#x7BA1;&#x6211;&#x4EEC;&#x5BF9;&#x5F00;&#x53D1;&#x4EBA;&#x5458;&#x957F;&#x671F;&#x89E3;&#x51B3;&#x6269;&#x5C55;&#x95EE;&#x9898;&#x7684;&#x80FD;&#x529B;&#x6301;&#x4E50;&#x89C2;&#x6001;&#x5EA6;&#xFF0C;&#x4F46;&#x6211;&#x4EEC;&#x8BA4;&#x8BC6;&#x5230;&#xFF0C;&#x5DE5;&#x4F5C;&#x8BC1;&#x660E;&#x81F3;&#x5C11;&#x5DF2;&#x6709;&#x5341;&#x5E74;&#x7684;&#x826F;&#x597D;&#x8BB0;&#x5F55;&#x4F7F;&#x5176;&#x6210;&#x4E3A;&#x5171;&#x8BC6;&#x673A;&#x5236;&#x7684;&#x4E0D;&#x8D25;&#x652F;&#x6301;&#x8005;&#x3002;&#x4F46;&#x662F;&#xFF0C;&#x653F;&#x5E9C;&#x53EF;&#x80FD;&#x4F1A;&#x6253;&#x51FB;&#x7528;&#x7535;&#x6765;&#x5F00;&#x91C7;&#x52A0;&#x5BC6;&#x8D27;&#x5E01;&#xFF0C;&#x56E0;&#x6B64;&#xFF0C;&#x6211;&#x4EEC;&#x5EFA;&#x8BAE;&#x6301;&#x6709;&#x4E00;&#x7CFB;&#x5217;&#x5177;&#x6709;&#x4E0D;&#x540C;&#x5171;&#x8BC6;&#x673A;&#x5236;&#x7684;&#x52A0;&#x5BC6;&#x8D44;&#x4EA7;&#x3002; &#x540D;&#x8BCD;&#x89E3;&#x91CA; wallets &#x6BD4;&#x7279;&#x5E01;&#x94B1;&#x5305;&#x7528;&#x4E8E;&#x7BA1;&#x7406;&#x6BCF;&#x4E2A;&#x7528;&#x6237;&#x7684;&#x516C;&#x79C1;&#x94A5;&#x5BF9;&#x3002;&#x8FD9;&#x4E9B;&#x94B1;&#x5305;&#x53EF;&#x4EE5;&#x662F;&#x5728;&#x7EBF;&#xFF0C;&#x53F0;&#x5F0F;&#x673A;&#xFF0C;&#x624B;&#x673A;&#xFF0C;&#x7EB8;&#x5F20;&#x6216;&#x786C;&#x4EF6;&#x3002;&#x800C;&#x4E14;&#xFF0C;&#x8FD9;&#x4E9B;&#x94B1;&#x5305;&#x5206;&#x4E3A;&#x4E24;&#x4E2A;&#x4E0D;&#x540C;&#x7684;&#x7EC4;&#xFF1A;&#x70ED;&#x94B1;&#x5305;&#x548C;&#x51B7;&#x94B1;&#x5305;&#x3002;&#x533A;&#x522B;&#x5728;&#x4E8E;&#x4ED6;&#x4EEC;&#x5982;&#x4F55;&#x7BA1;&#x7406;&#x7528;&#x6237;&#x7684;&#x516C;&#x94A5;-&#x79C1;&#x94A5;&#x5BF9;&#x7684;&#x79C1;&#x94A5;: 1. &#x5982;&#x679C;&#x79C1;&#x94A5;&#x5DF2;&#x751F;&#x6210;&#x5E76;&#x8131;&#x673A;&#x5B58;&#x50A8;&#xFF0C;&#x5219;&#x5B83;&#x4F4D;&#x4E8E;&#x51B7;&#x94B1;&#x5305;(cold wallet)&#x4E2D;; 2. &#x5982;&#x679C;&#x79C1;&#x94A5;&#x662F;&#x5728;&#x7EBF;&#x751F;&#x6210;&#x548C;&#x5B58;&#x50A8;&#x7684;&#xFF0C;&#x5219;&#x5B83;&#x4F4D;&#x4E8E;&#x70ED;&#x94B1;&#x5305;(hot wallet)&#x4E2D;&#x3002; double-spending double-spending&#x662F;&#x4F2A;&#x9020;&#x6CD5;&#x5B9A;&#x8D27;&#x5E01;&#x6216;&#x8D2C;&#x4F4E;&#x8BF8;&#x5982;&#x9EC4;&#x91D1;&#x4E4B;&#x7C7B;&#x7684;&#x5B9E;&#x7269;&#x5546;&#x54C1;&#x8D27;&#x5E01;&#x7684;&#x6570;&#x5B57;&#x7248;&#x672C;&#x3002;double-spending&#x662F;&#x5C06;&#x76F8;&#x540C;&#x7684;&#x52A0;&#x5BC6;&#x8D27;&#x5E01;&#x5355;&#x4F4D;&#x53D1;&#x9001;&#x5230;&#x4E24;&#x4E2A;&#x94B1;&#x5305;&#x5730;&#x5740;&#x4EE5;&#x8FDB;&#x884C;&#x6B3A;&#x8BC8;&#x7684;&#x8FC7;&#x7A0B;&#x3002; proof of work &#x6709;&#x4E24;&#x79CD;&#x7C7B;&#x578B;&#x7684;&#x5DE5;&#x4F5C;&#x91CF;&#x8BC1;&#x660E;&#x534F;&#x8BAE;&#x3002;&#x4E00;&#x79CD;&#x534F;&#x8BAE;&#x662F;&#x6311;&#x6218;&#x54CD;&#x5E94;&#x534F;&#x8BAE;(challenge-response)&#x3002;&#x53E6;&#x4E00;&#x4E2A;&#x662F;&#x89E3;&#x51B3;&#x65B9;&#x6848;&#x9A8C;&#x8BC1;&#x534F;&#x8BAE;(solution-verification protocol)&#x3002; transaction fee &#x4EA4;&#x6613;&#x8D39;&#x662F;&#x7531;&#x6BD4;&#x7279;&#x5E01;&#x7528;&#x6237;&#x63D0;&#x4F9B;&#x7684;&#x4E00;&#x79CD;&#x6FC0;&#x52B1;&#x63AA;&#x65BD;&#xFF0C;&#x4EE5;&#x786E;&#x4FDD;&#x4ED6;&#x6216;&#x5979;&#x7684;&#x4EA4;&#x6613;&#x5C06;&#x88AB;&#x5305;&#x62EC;&#x5728;&#x7F51;&#x7EDC;&#x4E0A;&#x7ED3;&#x7B97;&#x7684;&#x4E0B;&#x4E00;&#x4E2A;&#x4EA4;&#x6613;&#x5757;&#x4E2D;&#x3002;&#x4EA4;&#x6613;&#x8D39;&#x7528;&#x7531;&#x6210;&#x529F;&#x5C06;&#x533A;&#x5757;&#x6DFB;&#x52A0;&#x5230;&#x533A;&#x5757;&#x94FE;&#x7684;&#x6BD4;&#x7279;&#x5E01;&#x77FF;&#x5DE5;&#x6216;&#x91C7;&#x77FF;&#x6C60;&#x5904;&#x7406;&#x548C;&#x63A5;&#x6536;&#x3002; &#x6BD4;&#x7279;&#x5E01;&#x5F53;&#x524D;&#x7684;&#x5757;&#x5927;&#x5C0F;&#x9650;&#x5236;&#x4E3A;1&#x5146;&#x5B57;&#x8282;&#xFF0C;&#x6BCF;&#x4E2A;&#x5757;&#x90FD;&#x5DF2;&#x586B;&#x5145;&#x5230;&#x5176;&#x6700;&#x5927;&#x6570;&#x636E;&#x5BB9;&#x91CF;&#x3002;&#x7531;&#x4E8E;&#x4F7F;&#x7528;&#x7F51;&#x7EDC;&#x7684;&#x9700;&#x6C42;&#x6EE1;&#x8DB3;&#x4E86;&#x7F51;&#x7EDC;&#x7684;&#x56FA;&#x5B9A;&#x5BB9;&#x91CF;&#xFF0C;&#x56E0;&#x6B64;&#x4EA7;&#x751F;&#x4E86;&#x201C;&#x4EA4;&#x6613;&#x7A00;&#x7F3A;&#x6027;&#x201D;&#x3002;&#x4EA4;&#x6613;&#x7A00;&#x7F3A;&#x6027;&#x662F;&#x7531;&#x4E8E;&#x6BCF;10&#x5206;&#x949F;&#x6700;&#x591A;&#x63D0;&#x4F9B;&#x4EF7;&#x503C;1,000,000&#x5B57;&#x8282;&#x7684;&#x4EA4;&#x6613;&#x6570;&#x636E;&#xFF0C;&#x800C;&#x4E0D;&#x662F;&#x7F51;&#x7EDC;&#x7528;&#x6237;&#x53D1;&#x9001;&#x6BD4;&#x7279;&#x5E01;&#x4EA4;&#x6613;&#x7684;&#x53EF;&#x53D8;&#x9700;&#x6C42;&#x3002;&#x968F;&#x540E;&#xFF0C;&#x51FA;&#x73B0;&#x4E86;&#x6536;&#x8D39;&#x5E02;&#x573A;&#x3002;&#x5728;&#x8FD9;&#x4E2A;&#x5E02;&#x573A;&#x4E2D;&#xFF0C;&#x786E;&#x8BA4;&#x4EA4;&#x6613;&#x9700;&#x8981;&#x6BCF;&#x5343;&#x5B57;&#x8282;&#x6700;&#x4F4E;&#x8D39;&#x7528;&#x3002;&#x8D85;&#x51FA;&#x8BE5;&#x6700;&#x5C0F;&#x503C;&#x7684;&#x4EFB;&#x4F55;&#x5185;&#x5BB9;&#x90FD;&#x5C06;&#x5728;&#x4E0B;&#x4E00;&#x4E2A;&#x533A;&#x5757;&#x4E2D;&#x5F97;&#x5230;&#x786E;&#x8BA4;&#xFF0C;&#x800C;&#x4F4E;&#x4E8E;&#x6B64;&#x6700;&#x5C0F;&#x503C;&#x7684;&#x4EFB;&#x4F55;&#x5185;&#x5BB9;&#x90FD;&#x5FC5;&#x987B;&#x7B49;&#x5230;&#x7ADE;&#x4E89;&#x4E0D;&#x662F;&#x90A3;&#x4E48;&#x6FC0;&#x70C8;&#x4E3A;&#x6B62;&#x3002;&#x8FD9;&#x662F;&#x7531;&#x4E8E;&#x77FF;&#x5DE5;&#x666E;&#x904D;&#x5E0C;&#x671B;&#x83B7;&#x5F97;&#x6700;&#x5927;&#x5229;&#x6DA6;&#x5E76;&#x5E0C;&#x671B;&#x4E3A;&#x5176;&#x7F51;&#x7EDC;&#x670D;&#x52A1;&#x4ED8;&#x8D39;&#x3002; &#x539F;&#x6587;&#x94FE;&#x63A5;","categories":[{"name":"Repost","slug":"Repost","permalink":"https://littlelittlemoon.github.io/categories/Repost/"},{"name":"Blockchain","slug":"Repost/Blockchain","permalink":"https://littlelittlemoon.github.io/categories/Repost/Blockchain/"},{"name":"Consensus Mechanisms","slug":"Repost/Blockchain/Consensus-Mechanisms","permalink":"https://littlelittlemoon.github.io/categories/Repost/Blockchain/Consensus-Mechanisms/"}],"tags":[{"name":"Blockchain","slug":"Blockchain","permalink":"https://littlelittlemoon.github.io/tags/Blockchain/"},{"name":"Consensus Mechanisms","slug":"Consensus-Mechanisms","permalink":"https://littlelittlemoon.github.io/tags/Consensus-Mechanisms/"},{"name":"Bitcoin","slug":"Bitcoin","permalink":"https://littlelittlemoon.github.io/tags/Bitcoin/"},{"name":"PoW","slug":"PoW","permalink":"https://littlelittlemoon.github.io/tags/PoW/"},{"name":"PoS","slug":"PoS","permalink":"https://littlelittlemoon.github.io/tags/PoS/"}],"keywords":[{"name":"Repost","slug":"Repost","permalink":"https://littlelittlemoon.github.io/categories/Repost/"},{"name":"Blockchain","slug":"Repost/Blockchain","permalink":"https://littlelittlemoon.github.io/categories/Repost/Blockchain/"},{"name":"Consensus Mechanisms","slug":"Repost/Blockchain/Consensus-Mechanisms","permalink":"https://littlelittlemoon.github.io/categories/Repost/Blockchain/Consensus-Mechanisms/"}]},{"title":"Leetcode Note in Apri 2020 | part 3 | day 15-21 | (二).","slug":"Technology/Leetcode-Note-in-Apri-2020-part-3-day-15-21-(二)","date":"2020-04-18T06:35:52.000Z","updated":"2020-04-18T09:47:23.535Z","comments":true,"path":"2020/04/18/Technology/Leetcode-Note-in-Apri-2020-part-3-day-15-21-(二)/","link":"","permalink":"https://littlelittlemoon.github.io/2020/04/18/Technology/Leetcode-Note-in-Apri-2020-part-3-day-15-21-(%E4%BA%8C)/","excerpt":"","text":"写在前面的话 这篇文章只会更新一道题，这道题是我目前做LeetCode以来第一次做到的和图论相关的题，所以想单独拿出来做一个总结，借该题巩固以前学过的相关算法以及在该题中的应用。 相关算法与数据结构 算法 深度优先搜索算法（Depth-First-Search，DFS） 深度优先搜索算法（英语：Depth-First-Search，DFS）是一种用于遍历或搜索树或图的算法。这个算法会尽可能深的搜索树的分支。当节点v的所在边都己被探寻过，搜索将回溯到发现节点v的那条边的起始节点。这一过程一直进行到已发现从源节点可达的所有节点为止。如果还存在未被发现的节点，则选择其中一个作为源节点并重复以上过程，整个进程反复进行直到所有节点都被访问为止。这种算法不会根据图的结构等信息调整执行策略。 深度优先搜索是图论中的经典算法，利用深度优先搜索算法可以产生目标图的拓扑排序表，利用拓扑排序表可以方便的解决很多相关的图论问题，如无权最长路径问题等等。 维基百科 动画演示 dfs 实现方法 首先将根节点放入stack中。 从stack中取出第一个节点，并检验它是否为目标。 2.1 如果找到目标，则结束搜寻并回传结果。 2.2 否则将它某一个尚未检验过的直接子节点加入stack中。 重复步骤2。 如果不存在未检测过的直接子节点。 4.1 将上一级节点加入stack中。 4.2 重复步骤2。 重复步骤4。 若stack为空，表示整张图都检查过了——亦即图中没有欲搜寻的目标。结束搜寻并回传“找不到目标”。 伪代码 bool visited[MAX_VERTEX_NUM]; void DFSTraverse(Graph G){ for(v = 0; v &lt; G.vexnum; ++i) visited[v] = false; for(v = 0; v &lt; G.vexnum; ++v) if(!visited[v]) DFS(G,v); } void DFS(Graph G,int v) { visit（v）; visited[v] = true; for(w = FirstNeighbor(G,v); w &gt;= 0; w = NextNeighbor(G,v,w)) if(!visited[w]) DFS(G,w); } 广度优先搜索算法（Breadth-First Search，BFS） 广度优先搜索算法（英语：Breadth-First Search，缩写为BFS），又译作宽度优先搜索，或横向优先搜索，是一种图形搜索算法。简单的说，BFS是从根节点开始，沿着树的宽度遍历树的节点。如果所有节点均被访问，则算法中止。广度优先搜索的实现一般采用open-closed表。 维基百科 动画演示 bfs 实现方法 首先将根节点放入队列中; 从队列中取出第一个节点，并检验它是否为目标; 2.1 如果找到目标，则结束搜索并回传结果; 2.2 否则将它所有尚未检验过的直接子节点加入队列中。 若队列为空，表示整张图都检查过了——亦即图中没有欲搜索的目标。结束搜索并回传“找不到目标”; 重复步骤2。 伪代码 bfs_code Flood fill算法 Flood fill算法是从一个区域中提取若干个连通的点与其他相邻区域区分开（或分别染成不同颜色）的经典算法。因为其思路类似洪水从一个区域扩散到所有能到达的区域而得名。在GNU Go和扫雷中，Flood Fill算法被用来计算需要被清除的区域。维基百科。该算法可用深度优先遍历算法或广度优先遍历算法实现。 算法实现 Flood fill算法接受三个参数：起始节点，目标颜色和替换颜色。 算法遍历所有的节点以寻找和起始节点相连的节点（通过一条目标颜色的路径相连），然后 改变他们的颜色为替换颜色。目前有许多flood-fill算法的构建方式，但是他们都显示或隐式的使用队列或者栈 根据我们是否考虑当前节点对角线方向的节点，算法分为四路算法（不考虑对角线方向的节点）和八路算法（考虑对角线方向的节点）。 伪代码 /*假设MAX_X与MAX_Y是图的宽和高*/ void flood_fill(int x,int y,int color) { area[x][y] = color; if(x &gt; 0 &amp;&amp; area[x-1][y] == 0) flood_fill(x-1, y, color); if(y &gt; 0 &amp;&amp; area[x][y-1] == 0) flood_fill(x, y-1, color); if(x &lt; MAX_X &amp;&amp; area[x+1][y] == 0) flood_fill(x+1, y, color); if(y &lt; MAX_Y &amp;&amp; area[x][y+1] == 0) flood_fill(x, y+1, color); } 动画演示 四个方向上的Flood Fill flood_fill_4 八个方向上的Flood Fill flood_fill_8 数据结构 并查集 在计算机科学中，并查集是一种树型的数据结构，用于处理一些不交集（Disjoint Sets）的合并及查询问题。有一个联合-查找算法（union-find algorithm）定义了两个用于此数据结构的操作： - Find：确定元素属于哪一个子集。它可以被用来确定两个元素是否属于同一子集。 - Union：将两个子集合并成同一个集合。 由于支持这两种操作，一个不相交集也常被称为联合-查找数据结构（union-find data structure）或合并-查找集合（merge-find set）。其他的重要方法，MakeSet，用于创建单元素集合。有了这些方法，许多经典的划分问题可以被解决。 为了更加精确的定义这些方法，需要定义如何表示集合。一种常用的策略是为每个集合选定一个固定的元素，称为代表，以表示整个集合。接着，Find(x) 返回x所属集合的代表，而Union使用两个集合的代表作为参数。维基百科 伪代码 在并查集森林中，每个集合的代表即是集合的根节点。“查找”根据其父节点的引用向根行进直到到底树根。“联合”将两棵树合并到一起，这通过将一棵树的根连接到另一棵树的根。实现这样操作的一种方法是： function MakeSet(x) x.parent := x x.rank := 0 function Union(x, y) xRoot := Find(x) yRoot := Find(y) if xRoot == yRoot return // x和y不在同一个集合，合并它们。 if xRoot.rank &lt; yRoot.rank xRoot.parent := yRoot else if xRoot.rank &gt; yRoot.rank yRoot.parent := xRoot else yRoot.parent := xRoot xRoot.rank := xRoot.rank + 1 function Find(x) if x.parent != x x.parent := Find(x.parent) return x.parent 应用 Number of Islands Given a 2d grid map of '1's (land) and '0's (water), count the number of islands. An island is surrounded by water and is formed by connecting adjacent lands horizontally or vertically. You may assume all four edges of the grid are all surrounded by water. Example 1: Input: 11110 11010 11000 00000 Output: 1 Example 2: Input: 11000 11000 00100 00011 Output: 3 Solutions 该题的解题思路有两个，一个是使用Flood fill算法，一个是采用并查集的方法。 基于Flood Fill算法 根据算法特点，我们可以从一个点出发，然后找到与其连通的点（可通过深度优先或者广度优先算法实现）。而这一片连着的区域就是我们要找的岛屿。根据题意，该题应采用四个方向的flood fill算法。具体看代码实现。 采用深度优先遍历实现 class Solution: def __dfs(self, grid, i, j, m, n, marked): marked[i][j] = True for direction in self.directions: new_i = i + direction[0] new_j = j + direction[1] if 0 &lt;= new_i &lt; m and 0 &lt;= new_j &lt; n and not(marked[new_i][new_j]) and grid[new_i][new_j] == &#39;1&#39;: self.__dfs(grid, new_i, new_j, m, n, marked) # x-1,y # x,y-1 x,y x,y+1 # x+1,y # 方向数组，它表示了相对于当前位置的 4 个方向的横、纵坐标的偏移量，这是一个常见的技巧 directions = [(-1, 0), (0, -1), (1, 0), (0, 1)] def numIslands(self, grid: List[List[str]]) -&gt; int: m = len(grid) # 特判 if m == 0: return 0 n = len(grid[0]) marked = [[False for _ in range(n)] for _ in range(m)] count = 0 # 从第 1 行、第 1 格开始，对每一格尝试进行一次 DFS 操作 for i in range(m): for j in range(n): # 只要是陆地，且没有被访问过的，就可以使用 DFS 发现与之相连的陆地，并进行标记 if not(marked[i][j]) and grid[i][j] == &#39;1&#39;: # count 可以理解为连通分量 count += 1 self.__dfs(grid, i, j, m, n, marked) return count 采用广度优先遍历实现 使用广度优先遍历不用回溯，但需要一个辅助队列。 class Solution: def __bfs(self, grid, queue, cur_x, cur_y, m, n, marked): # 得到 4 个方向的坐标 for direction in self.directions: new_i = cur_x + direction[0] new_j = cur_y + direction[1] # 如果不越界、没有被访问过并且是陆地，继续放入队列，放入队列的同时标记已经访问过 if 0 &lt;= new_i &lt; m and 0 &lt;= new_j &lt; n and not(marked[new_i][new_j]) and grid[new_i][new_j] == &#39;1&#39;: queue.append((new_i, new_j)) # 在放入队列以后，马上标记成已经访问过，因为只要进入了队列，迟早都会遍历到它 # 如果是出队列的时候再标记，会造成很多重复的结点进入队列，造成重复的操作 marked[new_i][new_j] = True directions = [(-1, 0), (0, -1), (1, 0), (0, 1)] def numIslands(self, grid: List[List[str]]) -&gt; int: m = len(grid) if m == 0: return 0 n = len(grid[0]) marked = [[False for _ in range(n)] for _ in range(m)] count = 0 # 从第 1 行、第 1 格开始，对每一格尝试进行一次 DFS 操作 for i in range(m): for j in range(n): # 只要是陆地，且没有被访问过的，就可以使用 BFS 发现与之相连的陆地，并进行标记 if not(marked[i][j]) and grid[i][j] == &#39;1&#39;: # count 可以理解为连通分量 count += 1 queue = deque() queue.append((i, j)) # 标记上已经访问过 marked[i][j] = True while queue: cur_x, cur_y = queue.popleft() self.__bfs(grid, queue, cur_x, cur_y, m, n, marked) return count 基于并查集 使用并查集解决本问题的基本思想： 1. 如果当前是“陆地”，尝试与周围合并； 2. 如果当前是“水域”，就把所有的“水域”合并在一起，为此，可设置了一个虚拟的结点，表示“所有的水域都和这个虚拟结点是连接的”。 class Solution: def numIslands(self, grid: List[List[str]]) -&gt; int: class UnionFind: def __init__(self, n): self.count = n self.parent = [i for i in range(n)] self.rank = [1 for _ in range(n)] def get_count(self): return self.count def find(self, p): while p != self.parent[p]: self.parent[p] = self.parent[self.parent[p]] p = self.parent[p] return p def is_connected(self, p, q): return self.find(p) == self.find(q) def union(self, p, q): p_root = self.find(p) q_root = self.find(q) if p_root == q_root: return if self.rank[p_root] &gt; self.rank[q_root]: self.parent[q_root] = p_root elif self.rank[p_root] &lt; self.rank[q_root]: self.parent[p_root] = q_root else: self.parent[q_root] = p_root self.rank[p_root] += 1 self.count -= 1 row = len(grid) # 特判 if row == 0: return 0 col = len(grid[0]) def get_index(x, y): return x * col + y # 注意：我们不用像 DFS 和 BFS 一样，4 个方向都要尝试，只要看一看右边和下面就可以了 directions = [(1, 0), (0, 1)] # 多开一个空间，把水域 &quot;0&quot; 都归到这个虚拟空间 dummy_node = row * col uf = UnionFind(dummy_node + 1) for i in range(row): for j in range(col): # 如果是水域，都连到那个虚拟的空间去 if grid[i][j] == &#39;0&#39;: uf.union(get_index(i, j), dummy_node) if grid[i][j] == &#39;1&#39;: # 向下向右如果都是陆地，就合并 for direction in directions: new_x = i + direction[0] new_y = j + direction[1] if new_x &lt; row and new_y &lt; col and grid[new_x][new_y] == &#39;1&#39;: uf.union(get_index(i, j), get_index(new_x, new_y)) # 减去虚拟结点 return uf.get_count() - 1 参考资料 Flood fill 深度优先算法 广度优先算法 并查集 https://leetcode-cn.com/problems/number-of-islands/solution/dfs-bfs-bing-cha-ji-python-dai-ma-java-dai-ma-by-l/","categories":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Coding","slug":"Technology/Coding","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/"},{"name":"Leetcode","slug":"Technology/Coding/Leetcode","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/Leetcode/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://littlelittlemoon.github.io/tags/Leetcode/"},{"name":"Python","slug":"Python","permalink":"https://littlelittlemoon.github.io/tags/Python/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://littlelittlemoon.github.io/tags/Algorithm/"},{"name":"DFS","slug":"DFS","permalink":"https://littlelittlemoon.github.io/tags/DFS/"},{"name":"BFS","slug":"BFS","permalink":"https://littlelittlemoon.github.io/tags/BFS/"},{"name":"并查集","slug":"并查集","permalink":"https://littlelittlemoon.github.io/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/"}],"keywords":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Coding","slug":"Technology/Coding","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/"},{"name":"Leetcode","slug":"Technology/Coding/Leetcode","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/Leetcode/"}]},{"title":"Paper Smash|Blockchain Technology for Healthcare-Facilitating the Transition to Patient-Driven Interoperability","slug":"Technology/BlockChain-Patient-Driven-Interoperability","date":"2020-04-16T07:47:09.000Z","updated":"2020-04-16T10:00:40.315Z","comments":true,"path":"2020/04/16/Technology/BlockChain-Patient-Driven-Interoperability/","link":"","permalink":"https://littlelittlemoon.github.io/2020/04/16/Technology/BlockChain-Patient-Driven-Interoperability/","excerpt":"","text":"摘要 【背景】传统上，基于机构驱动的医疗保健的互操作性集中于业务实体（例如，不同的医院系统）之间的数据交换。最近有一种推动以患者为主导的互操作性的方法，其中，健康数据交换是由患者主导并由患者驱动的。 【问题】以患者为中心的互操作性带来了围绕安全性和隐私，技术，激励措施和治理的新挑战和新要求，而这类挑战必须满足此类数据共享才能成功获得成功。并且其中许多挑战在传统的互操作性中也还没有得以解决 【本文提出的解决方法】 3.1 研究了区块链技术如何通过五种机制促进这种转变： （1）数字访问规则 （2）数据聚合 （3）数据流动性 （4）患者身份 （5）数据不变性 3.2 研究了阻碍区块链的患者驱动的互操作性的障碍，特别是临床数据交易量，隐私和安全性，患者参与度和激励措施。 【结论】尽管以患者为主导的互操作性方法是医疗保健中令人兴奋的趋势，但鉴于这些挑战，区块链能否促进从以机构为中心的数据共享向以患者为中心的数据共享过渡尚待观察。 研究内容 why区块链 从摘要和介绍部分可以得知，本文就医疗保健的互操作性，用户医疗数据交换提出了一些目前面临的挑战。在以患者为主导的互操作性的方法的趋势以及传统方式依旧面临许多挑战尚未解决的前提下，作者提出了采用区块链这样一种新颖的技术，使其在提高互操作性方面发挥作用。这是因为区块链对共享，分发和加密的重视，对健康数据特别有吸引力。尤其是，更新的区块链工作（智能合约，第二层系统，许可的区块链）进一步提供了潜在的医疗用例，并且在医疗保健领域不乏对技术潜力的大肆宣传。故可以利用区块链技术促进从机构驱动的互操作性到以患者为中心的互操作性的转变。 主要工作 健康数据的互操作性问题 互操作性(Interoperability)的定义与作用 卫生信息与管理系统学会将Interoperability定义为：不同信息技术系统和软件应用程序进行通信，交换数据和使用已交换信息的能力。 对于医疗保健而言，互操作性具有多个潜在优势： 1. 通讯良好的系统可以提高运营效率，减少诸如手动输入从传真接收的数据之类的行政任务所花费的时间； 2. 减少重复的临床干预，例如图像研究或实验室订单； 3. 降低总体卫生系统成本，减少浪费； 4. 通过减少暴露于辐射或侵入性程序来提高患者安全性； 5. 通过促进在现场即时访问相关的纵向临床数据的途径来改善临床护理。 互操作性的转变 传统互操作性（机构驱动的互操作性） 传统医疗保健互操作性格局通常以业务实体为中心，例如医院，私人诊所和药房，并且通常在创建数据的信息系统中创建和隔离数据（例如：医院的电子健康记录）。如图1A所示： 图1AB 面临的挑战 单个患者的健康数据分散在众多系统中，并且没有机构能够提供完整的信息； 即使不同的系统具有高度的互操作性，患者仍然会丢失数据； 不同机构之间的交流可能会在运营上带来挑战，并且需要所涉实体之间进行大量合作； 数据共享协议，复杂的患者匹配算法，程序和管理规则； 许多技术障碍。例如，事务和实体认证必须是健壮的（并且对于每个实体对实体的关系都必须重复进行）。还应该进行活动和阈值监视以及一些异常检测； 数据交换的安全性至关重要，数据交换的标准（例如FHIR或CDA）也必须达成共识； 患者能够访问其健康数据的需求； 转变趋势 以患者为主导的互操作性的方法，健康数据交换是由患者介导并由患者驱动。 区块链如何促进转变 降低验证和联网成本 区块链技术可以允许多个利益相关者定期就共享数据的真实状态达成一致，这样的共享数据可以代表有关个人，实体的信息交易的凭证和属性等。根据技术的设计和实施方式，它还可以利用激励手段来推动建设，管理更新和协调记录。而“智能合约”是以太坊等平台的重要组成部分，它可以使各方之间的协议可以由存储在区块链中的计算机代码来控制和执行。 区块链可以提供不同程度的隐私和记录匿名性，透明性和不变性。例如，虽然“比特币”是公开的，但“许可的”区块链网络可能会通过限制成员资格和读写控制，围绕共识机制或智能合约创建而具有更严格的访问控制。 对两个成本的考究 第一成本是指区块链验证交易属性的能力（例如，交易是否发生，牵涉到谁，牵涉到的个人的凭证是什么等），并以比传统系统更低的成本确保数据完整性。 第二成本是指无需依靠传统的中介机构（例如金融机构，或者就医疗数据而言的医院信息管理办公室）就能够引导和运营市场的能力。 了解如何通过区块链技术可以增强患者驱动的互操作性方面，这两种成本都起着关键作用。 结论 降低验证和联网成本都很重要，因为它们可以提高不同实体进行互操作的能力以及临床数据交换的可能性和影响。 竞争能力较弱的市场将减少共享数据的实体的数量，从而导致临床数据交换的全面性降低。 同样，高昂的验证费用可能会导致不良的临床事件，例如由于患者匹配不当而导致实验室结果遗漏。 区块链可以提供重要的催化剂，以改善数据交换，尤其是患者驱动的互操作性。 区块链在患者驱动的互操作性中的作用 从高层次上讲，可以将区块链技术视为数字交换的平台，该平台无需传统的中介就可以运行。 健康数据可以存在于多个系统中，并且共享数据需要实体之间的许多协作点。 随着互操作性变得更加以患者为中心，就有机会利用区块链技术来促进这种交换，并让患者对其数据有更大的控制权。 可以实现患者驱动的互操作性的区块链特性 区块链功能 患者驱动的互操作性中的应用示例 数字访问规则 临床数据（链下或链上存储）与患者的公钥链接。患者可以使用诸如智能合约之类的区块链属性来为数据分配访问规则。例如，授权在固定的时间段内释放给研究患者注册表。 数据汇整 患者使用特定于机构的登录名连接到不同的机构界面，向该机构提供其区块链公钥以及将数据安全传输到区块链的权限。因此，跨多个机构完成的临床数据可以使用该技术进行汇总。 数据流动性 高度敏感的临床数据（例如，高级护理计划的“代码状态”或药物过敏）可以在公共区块链上发布，以确保适当地，即时地访问此信息。 患者身份 患者可以通过多签名钱包或移动设备管理公共密钥，并使用公共密钥基础结构（PKI）来建立自己的身份，以从区块链中检索临床数据，以及添加新信息（例如家庭监控设备）。PKI确保提供者和机构可以相信患者正在生成数据。 数据不变性 临床数据安全地分布在多个实体中，从而确保完整性，降低丢失风险并提供审计跟踪（以防恶意行为者）。区块链的Append-only模型可确保所有可访问信息的提供商都具有完整的临床图景。 区块链改善方法 数字访问规则的管理 授予临床数据发布权限是一项具有挑战性的功能，通常由数据孤岛所有者控制。区块链为集中管理共享数据的身份验证和授权规则提供了一种集中和共享的机制。 例如，一个区块链可能具有“智能财产”（一个通过区块链管理所有权的实体），以允许某种形式的数字财产拥有明确的所有权。数据的保管人清晰地显示在区块链上，并且可以随后为其数据分配访问规则和权限，从而使共享更加容易。 数据聚合 随着患者逐渐拥有更多的健康数据所有权，他们的首要任务之一就是将所有临床数据收集在一起，例如，通过建立与每个要使用数据的系统的API连接。一旦患者建立了这些联系，他们就可以适当地收集和汇总其健康数据。区块链平台可以促进这一点-尤其是与支持区块链的数字访问规则结合使用。例如，例如，临床会诊可以安全地广播到网络并连接到患者的匿名数字身份。如果所有机构的所有临床经验都遵循这一范例，则患者只需与一个平台进行交互，因为所有健康数据都可以通过相同的协议和标准获得。此外，患者可以将自己的患者生成的健康数据（PGHD）发布到区块链网络。如果患者授权书发布，此类PGHD可以提供活动监测或在正式医疗保健场所之外捕获的其他个人健康数据。 数据流动性 -&gt; 快速访问临床信息 区块链提高了数据流动性和数据可用性，并使患者更容易与其他实体共享数据 围绕患者身份 没有美国国民的患者识别码，临床信息系统经常有一个人的多个记录。这些记录的实体解析是运营和研究兴趣的活跃领域，并且在规模上可能具有很大挑战性。 区块链对公钥基础设施（PKI）的使用提供了一种集中式识别方法（个人的公钥），可用于在机构之间链接该患者的记录。如果每个机构都知道患者的公共密钥，并且该密钥已链接到其自己的内部标识符（例如，患者在注册时将其公共密钥链接到其患者门户帐户），则随后的临床事件会广播到区块链网络可以将该公钥作为患者参考，以方便患者匹配。 数据不变性（稳定性） 由于区块链通常是不可变的，因此添加到链中的数据将持续存在。这降低了丢失的风险，提供了审计跟踪（例如，在恶意行为者的情况下），并确保所有方都可以获得完整的数字历史记录（提供适当的访问控制）。 图1C描述了一种方法，其中两个没有正式业务关系（但具有标准数据接口）的组织可以利用区块链层进行数据访问和授权规则。 区块链支持的基于患者驱动的互操作性的张力和障碍 障碍 大批量，高频交易是临床数据的挑战 大批量，高频交易是临床数据的基石，并且随着现代技术的进步，临床数据的规模呈指数增长。例如，单个心脏磁共振图像可能需要200兆字节的存储空间。考虑到区块链的分布式性质，使用当前技术将数据存储在链上是不可行的。此外，基于工作量证明（例如比特币），验证新交易可能需要花费大量时间在区块链上。这些限制有利于小规模，相对少见的交易。 有很多方法可以解决这个问题，例如比特币的闪电网络，基于共识的替代方法（例如，股权证明）或许可的区块链的区块链，但是需要进一步的工作来了解这些解决方案是否可以避免规模扩张挑战。 涉及隐私和安全性的挑战 区块链技术的某些实现是匿名的—身份通常在公钥后被掩盖，但是交易的其他属性是公开共享的。这对于健康数据是有问题的。 首先，基本的人口统计信息可以识别人，并且如果一个人的公钥与他们的身份匹配，则与该公钥相关的所有交易都将被链接到个人。然而对公共区块链造成灾难性影响的同时，私有区块链也存在问题，因为个人可能不希望私有区块链的所有成员都可以访问同一数据，或者他们可能希望在之后的某个时间点撤消对其数据的授权，但是用户一旦将其身份链接到其公钥，则两者均无法实现。保健行业将需要区块链的实现允许选择性地公开私人信息（例如Zcash），并依靠零知识密码学来提供对底层数据具有高度隐私性的交易验证。 患者参与的挑战 以患者为主导的互操作性框架与机构驱动的架构相比，必然需要更多的患者参与。 如果患者要成为自主的数字管理员，他们将需要某种方式来管理其数字资产（例如钥匙或密码）。 需要考虑用于管理丢失的数字资产的机制（例如忘记密码，丢失密钥等）。 这可能需要额外的中介，而且尚不清楚谁将扮演这个角色—也许是一个新的商业市场的机会，类似于加密货币交易所。 激励措施的挑战 尽管法律现在要求EHR必须具有面向患者的API，但并非所有医疗数据都一样，并且激励机构在没有经济动机的情况下建立面向患者的数据连接将具有挑战性–合规性与真实性之间的区别。 例如，虽然药物清单可能是医院面向患者的EHR API的必填数据输出，但尚不清楚制药收益管理者是否需要在没有明确业务价值的情况下构造和公开所有药物批准或交易。围绕数据共享的进一步激励措施将进一步加强API经济性，并导致更多的患者数据自主权。 表2描述了这些挑战以及潜在的缓解措施： 挑战 缓解措施 临床数据交易量 1. 将数据交换集中在汇总的临床数据上；2. 本地地理区域的许可区块链可处理大量交易而无需时间密集验证；3. 区块链扩展方法学的新技术和研究 隐私与安全 1.授权的仅限会员的区块链圈，以最大程度地减少公众曝光；2. 链下数据存储，链上侧重于权限或其他元数据 患者参与 中介人“APP”生态系统，用于管理公共密钥和权限 激励措施 1. 联邦政府继续鼓励扩大API覆盖范围；2. 开放数据与报销价值的关联；3.支持API的系统的竞争压力，鼓励不支持API的系统投资API基础设施 总结 这篇文章好像只是提出了概念，但是并没有对具体方案实施进行解说。","categories":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Paper Smash","slug":"Technology/Paper-Smash","permalink":"https://littlelittlemoon.github.io/categories/Technology/Paper-Smash/"}],"tags":[{"name":"Paper","slug":"Paper","permalink":"https://littlelittlemoon.github.io/tags/Paper/"},{"name":"Patient-Driven Interoperability","slug":"Patient-Driven-Interoperability","permalink":"https://littlelittlemoon.github.io/tags/Patient-Driven-Interoperability/"},{"name":"Blockchain","slug":"Blockchain","permalink":"https://littlelittlemoon.github.io/tags/Blockchain/"}],"keywords":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Paper Smash","slug":"Technology/Paper-Smash","permalink":"https://littlelittlemoon.github.io/categories/Technology/Paper-Smash/"}]},{"title":"Leetcode Note in Apri 2020 | part 3 | day 15-21 | (一).","slug":"Technology/Leetcode-Note-in-Apri-2020-part-3-day-15-21-(一)","date":"2020-04-15T12:33:23.000Z","updated":"2020-04-18T06:30:33.176Z","comments":true,"path":"2020/04/15/Technology/Leetcode-Note-in-Apri-2020-part-3-day-15-21-(一)/","link":"","permalink":"https://littlelittlemoon.github.io/2020/04/15/Technology/Leetcode-Note-in-Apri-2020-part-3-day-15-21-(%E4%B8%80)/","excerpt":"","text":"写在前面的话 第三次更新，这次更新可能会把一周的内容分为两篇文章，因为放一篇文章的话内容有点太长了。新的挑战！继续前进~ Product of Array Except Self Given an array nums of n integers where n &gt; 1, return an array output such that output[i] is equal to the product of all the elements of nums except nums[i]. Example: Input: [1,2,3,4] Output: [24,12,8,6] Constraint: It's guaranteed that the product of the elements of any prefix or suffix of the array (including the whole array) fits in a 32 bit integer. Note: Please solve it without division and in O(n). Follow up: Could you solve it with constant space complexity? (The output array does not count as extra space for the purpose of space complexity analysis.) Solution 具体思路在代码注释中已经说的很清楚了，我这里简单概括一下： 这个题有个限制：不能使用除法，这个限制让这道题变得有点难度。本来我们可以把数组里面所有元素相乘，然后通过除以相应index的数就可以得到每个数对应的除自己以外的数的积。 有了限制条件之后，我想了很久也没有想到很好的方法，之后看到其他小伙伴的解题思路，就突然来了灵感。我们可以将数组根据当前元素分为两部分（左边和右边）。然后分别计算元素两边的所有元素的积，再将两边所得的积相乘，就得到了当前元素应该对应的积。具体看代码实现和注释。 class Solution: def productExceptSelf(self, nums: List[int]) -&gt; List[int]: # The length of the input array n_len = len(nums) # The product array to be returned product = [0] * n_len # product[i] contains the product of all the elements to the left # Note: for the element at index &#39;0&#39;, there are no elements to the left, # so the product[0] would be 1 product[0] = 1 for i in range(1, n_len): # product[i - 1] already contains the product of elements to the left of &#39;i - 1&#39; # Simply multiplying it with nums[i - 1] would give the product of all # elements to the left of index &#39;i&#39; product[i] = nums[i - 1] * product[i - 1] # R contains the product of all the elements to the right # Note: for the element at index &#39;length - 1&#39;, there are no elements to the right, # so the R would be 1 R = 1; for i in reversed(range(n_len)): # For the index &#39;i&#39;, R would contain the # product of all elements to the right. We update R accordingly product[i] = product[i] * R R *= nums[i] return product Valid Parenthesis String Given a string containing only three types of characters: '(', ')' and '', write a function to check whether this string is valid. We define the validity of a string by these rules: 1. Any left parenthesis '(' must have a corresponding right parenthesis ')'. 2. Any right parenthesis ')' must have a corresponding left parenthesis '('. 3. Left parenthesis '(' must go before the corresponding right parenthesis ')'. 4. '' could be treated as a single right parenthesis ')' or a single left parenthesis '(' or an empty string. 5. An empty string is also valid. Example 1: Input: \"()\" Output: True Example 2: Input: \"()\" Output: True Example 3: Input: \"())\" Output: True Solution 这个题的思路也是比较常规，可以通过判断开括号的个数来判断当前字符串是否有效（=0：有效，其他无效）。但是由于*可以代替左括号(，也可以代替右括号)，所以针对这道题，我们不能简单的用一个变量来计算开括号的个数。但思路是一致的，我们可以通过必须要必配的开括号个数（最小开括号个数）和最大需要匹配的开括号个数来判断字符串是否有效，故我们需要两个变量：nrp_min(记录需要被匹配的最小开括号个数)，nrp_max（记录最大需要被匹配的开括号个数）。具体实现说明见代码及注释。 class Solution: def checkValidString(self, s: str) -&gt; bool: # nrp_min: counts the minimum open parenthesis # nrp_max: counts the maximum open parenthesis, nrp_min = nrp_max = 0 for i in s: # when we meet a &#39;(&#39;, we need a &#39;)&#39; to match if i == &#39;(&#39;: nrp_max += 1 nrp_min += 1 # when we meet a &#39;)&#39;, we can match a &#39;(&#39; if i == &#39;)&#39;: nrp_max -= 1 nrp_min = max(nrp_min - 1, 0) # when we meet &#39;*&#39;, we can match a &#39;(&#39; and also may need a &#39;)&#39; to match # so the max number of &#39;)&#39; we need should +1, and the min number of &#39;)&#39; # we need should -1 if i == &#39;*&#39;: nrp_max += 1 nrp_min = max(nrp_min - 1, 0) # if at the end of the loop, the max number of &#39;)&#39; we need is &lt; 0, it means the # number of &#39;(&#39; is bigger than the number of &#39;)&#39;,this string is invalid. if nrp_max &lt; 0: return False # if the min number of &#39;)&#39; we need is 0, it means all of the &#39;(&#39; have one &#39;)&#39; be paired return nrp_min == 0 总结 这周的题比之前的要难一点，今天做了一道题让我懵圈了，因为我已经把之前学的关于图的相关算法忘完了，其实也不算是忘了相关算法，而是不能将学过的算法和实际问题联系起来，下一篇文章我会详细写一篇关于这道题的解法，也算是巩固和应用以前学过的知识吧！再接再厉！","categories":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Coding","slug":"Technology/Coding","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/"},{"name":"Leetcode","slug":"Technology/Coding/Leetcode","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/Leetcode/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://littlelittlemoon.github.io/tags/Leetcode/"},{"name":"Python","slug":"Python","permalink":"https://littlelittlemoon.github.io/tags/Python/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://littlelittlemoon.github.io/tags/Algorithm/"}],"keywords":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Coding","slug":"Technology/Coding","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/"},{"name":"Leetcode","slug":"Technology/Coding/Leetcode","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/Leetcode/"}]},{"title":"僵尸企业分类|模型训练|LightGBM","slug":"Technology/僵尸企业分类-模型训练-LightGBM","date":"2020-04-11T11:25:37.000Z","updated":"2020-04-12T13:06:54.541Z","comments":true,"path":"2020/04/11/Technology/僵尸企业分类-模型训练-LightGBM/","link":"","permalink":"https://littlelittlemoon.github.io/2020/04/11/Technology/%E5%83%B5%E5%B0%B8%E4%BC%81%E4%B8%9A%E5%88%86%E7%B1%BB-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83-LightGBM/","excerpt":"","text":"写到前面的话 在上一篇文章中，我对僵尸企业分类问题的数据预处理做了介绍，这篇文章主要介绍模型训练部分，采用的算法框架是LightGBM(Light Gradient Boosting Machine)，是一个实现 GBDT 算法的框架。而GBDT(Gradient Boosting Decision Tree)的主要思想是利用弱分类器（决策树）迭代训练以得到最优模型，该模型具有训练效果好、不易过拟合等优点。 LightGBM有各种很好的特性，类比很多boosting tools优化速度和内存的使用上采用基于预排序的算法进行决策树学习，LightGBM使用基于直方图的算法，支持高效率的并行训练，并且具有以下优点： 1. 更快的训练速度 2. 更低的内存消耗 3. 更好的准确率 4. 分布式支持，可以快速处理海量数据 具体算法原理我也没搞太明白，哈哈。我准备后面好好学习一番，然后再写一篇关于LightGBM的文章，主要是记录自己的学习过程，写一些自己的理解。这里大家如果感兴趣可以去看看官方文档. 模型训练 定义模型训练函数 import lightgbm as lgb from sklearn import metrics def train_model(X_train, y_train, X_valid, y_valid, test=None, feature_cols=None, is_base=True): if feature_cols is None: feature_cols = X_train.columns.drop([&quot;行业&quot;, &quot;区域&quot;, &quot;企业类型&quot;, &quot;控制人类型&quot;]) dtrain = lgb.Dataset(X_train[feature_cols], label=y_train) dvalid = lgb.Dataset(X_valid[feature_cols], label=y_valid) param = {&#39;num_leaves&#39;: 64, &#39;objective&#39;: &#39;binary&#39;, &#39;metric&#39;: &#39;auc&#39;, &#39;seed&#39;: 7} num_round = 1000 print(&quot;Training model!&quot;) bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], early_stopping_rounds=20, verbose_eval=False) # 预测结果是概率值，将其转换为binary value valid_pred = bst.predict(X_valid[feature_cols]) valid_pred = valid_pred &gt; 0.5 valid_pred = valid_pred.astype(int) valid_score = metrics.roc_auc_score(y_valid, valid_pred) print(&quot;precision recall fscore support:&quot;) print(metrics.precision_recall_fscore_support(y_valid, valid_pred, average=&#39;micro&#39;)) print(f&quot;Validation AUC score: {valid_score}&quot;) if test is not None: test_pred = bst.predict(test[feature_cols]) test_pred = test_pred &gt; 0.5 test_pred = test_pred.astype(int) test_pred = test[[&#39;ID&#39;]].join(pd.DataFrame({&#39;flag&#39;: test_pred})) if is_base: test_pred.to_csv(&#39;test_base.txt&#39;, sep=&#39;,&#39;, index=False) else: test_pred.to_csv(&#39;test_.txt&#39;, sep=&#39;,&#39;, index=False) return bst, valid_score else: return bst, valid_score 加载处理好的数据集 import pandas as pd # load training data all_data = pd.read_csv(&quot;data/train/train.csv&quot;) # load testing data test = pd.read_csv(&quot;data/test/test.csv&quot;) test_base = pd.read_csv(&quot;data/test/base-test.csv&quot;) 将训练数据集拆分为训练集与验证集 from sklearn.preprocessing import OneHotEncoder, LabelEncoder from sklearn.model_selection import train_test_split import category_encoders as ce from sklearn.utils import shuffle all_data_X = all_data[all_data.columns.drop([&quot;flag&quot;])] all_data_y = all_data[&quot;flag&quot;] # shuffle data（optional） all_data_X, all_data_y = shuffle(all_data_X, all_data_y) # test = shuffle(test) train_X, valid_X, train_y, valid_y = train_test_split(all_data_X, all_data_y, random_state=66) 类型变量处理 通常，本质上是分类的任何数据属性都是离散值，这些离散值属于类别或类的特定有限集合。在属性或由模型预测的变量的上下文中，通常也称为类或标签。 这些离散值本质上可以是文本或数字。这次base data里面的行业，区域，企业类型，控制人类型等就是属于这一类属性，我刚开始的想法是把这类属性值做一个encoding，具体什么类型的encoding可以根据属性对模型的影响程度和模型训练效果来确定。这里只给出了count encoding的例子，如果后面有时间我会专门写一篇处理这类属性的常用方法，做一个详细的总结，这里就不展开了。 Count Encoding for categorical variables cat_features = [&quot;行业&quot;, &quot;区域&quot;, &quot;企业类型&quot;, &quot;控制人类型&quot;] count_enc = ce.CountEncoder(cols=cat_features) # Learn encoding from the training set count_enc.fit(train_X[cat_features]) train_encoded_X = train_X.join(count_enc.transform(train_X[cat_features]) .add_suffix(&quot;_count&quot;)) valid_encoded_X = valid_X.join(count_enc.transform(valid_X[cat_features]) .add_suffix(&quot;_count&quot;)) test_encoded = test.join(count_enc.transform(test[cat_features]) .add_suffix(&quot;_count&quot;)) 模型训练 原始数据 为了看分类数据处理对模型性能的影响，下面的训练没有用编码后的类别数据，训练的时候会把类别属性列删掉。 print(&quot;Baseline model&quot;) _ = train_model(train_X, train_y, valid_X, valid_y, test, is_base=True) Baseline model Training model! precision recall fscore support: (1.0, 1.0, 1.0, None) Validation AUC score: 1.0 结果超出意料，就是最粗糙的数据，没有做任何特征选择和优化，就可以得到这么搞得精度，说实话我当时是怀疑自己的，反复确认了好几遍代码，发现没啥问题。🤣再次证明数据预处理的重要性，数据处理好了，最简单的模型也可以达到很好的效果。 Count Encoding类别属性后的数据 print(&quot;Count Encoding model&quot;) _ = train_model(train_encoded_X, train_y, valid_encoded_X, valid_y, test_encoded, is_base=False) Count Encoding model Training model! precision recall fscore support: (1.0, 1.0, 1.0, None) Validation AUC score: 1.0 两次的训练结果没有任何差别，也失去了特征优化的动力😃","categories":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Machine Learning","slug":"Technology/Machine-Learning","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/"},{"name":"Modeling","slug":"Technology/Machine-Learning/Modeling","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/Modeling/"}],"tags":[{"name":"LightGBM","slug":"LightGBM","permalink":"https://littlelittlemoon.github.io/tags/LightGBM/"},{"name":"Count Encoding","slug":"Count-Encoding","permalink":"https://littlelittlemoon.github.io/tags/Count-Encoding/"}],"keywords":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Machine Learning","slug":"Technology/Machine-Learning","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/"},{"name":"Modeling","slug":"Technology/Machine-Learning/Modeling","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/Modeling/"}]},{"title":"僵尸企业分类|数据预处理","slug":"Technology/僵尸企业分类-数据预处理","date":"2020-04-10T12:02:34.000Z","updated":"2020-04-18T10:31:56.322Z","comments":true,"path":"2020/04/10/Technology/僵尸企业分类-数据预处理/","link":"","permalink":"https://littlelittlemoon.github.io/2020/04/10/Technology/%E5%83%B5%E5%B0%B8%E4%BC%81%E4%B8%9A%E5%88%86%E7%B1%BB-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/","excerpt":"","text":"问题描述 僵尸企业是指缺乏盈利能力却能够以低于市场最优利率成本获得信贷资源，依靠外界输血而缺乏自生能力的企业。僵尸企业的存在破坏了市场机制，加剧了信贷资源的错配，带来了严重的产能过剩问题，还对其他非僵尸企业产生了投资挤出效应。 因此需要对正常企业和僵尸企业进行分类，现给出一批有标签的企业数据作为训练集，标签为0表示正常企业，标签为1表示僵尸企业；同时给出无标签数据作为测试集，请对无标签数据进行分类。 数据集说明 数据集包括训练集和测试集两部分，每个部分又包括: 1. 企业基本数据: 包含企业的一些基本属性以及企业的标签（即flag--0：正常企业，1：僵尸企业）; 2. 企业知识产权数据: 包含企业的知识产权相关信息，根据id可与基本数据一一对应; 3. 企业金融数据: 包含企业2015~2017三年的金融相关信息，根据id可与基本数据相对应; 4. 企业年报数据: 包含企业2015~2017三年的年报数据，根据id可与基本数据相对应。 数据预处理 工具函数定义 combined_base_knowledge_data 函数说明 该函数用于根据ID合并base data和knowledge data数据集。 函数实现 def combined_base_knowledge_data(base_data, knowledge_data): combined_base_knowledge_data = base_data .set_index(&#39;ID&#39;) .join(knowledge_data .set_index(&#39;ID&#39;)) combined_base_knowledge_data = combined_base_knowledge_data .fillna(combined_base_knowledge_data .median()) return combined_base_knowledge_data fill_na 函数说明 该函数用于填充数据集中缺失的数据： 1. 年份数据：根据ID和年份查找出对应ID缺失的年份，然后补全缺失的年份； 2. 其他缺失数据统一用中位数补齐。 函数实现 # fill null year def fill(oragin_data, years = [2015, 2016, 2017]): # pick null year data null_years = oragin_data.loc[oragin_data.year.isna()] # fill year for year in years: IDs = oragin_data[[&quot;ID&quot;]].loc[oragin_data.year == year] for null_year_id in null_years[&quot;ID&quot;].unique(): tmp = IDs.loc[IDs.ID == null_year_id] if tmp.empty: index = oragin_data.loc[( oragin_data.ID == null_year_id) &amp; (oragin_data.year.isna() )].index.tolist() if len(index) != 0: oragin_data.loc[index[0]:index[0], &quot;year&quot;] = year # fill other missing value with median value new_data = oragin_data.fillna(oragin_data.median()) return new_data; combined_new_year_money_data 函数说明 该方法用于根据ID和year合并year data和money data。 函数实现 def combined_new_year_money_data(new_year_data, new_money_data): return pd.merge(new_year_data, new_money_data, on=[&#39;ID&#39;, &#39;year&#39;]) split_data 函数说明 该函数用于根据ID和year拆分新特征，将原数据集三年的数据按年份拆分成新的特征，使拆分后的数据集可与base data数据集用ID一一对应。主要用于year data数据集和money data数据集的拆分。 函数实现 def split_data(combined_new_year_money_data): # split data with year combined_new_year_data_2015 = combined_new_year_money_data.loc[ combined_new_year_money_data.year == 2015] .set_index(&#39;ID&#39;) .add_suffix(&quot;_2015&quot;).drop(columns=[&#39;year_2015&#39;]) combined_new_year_data_2016 = combined_new_year_money_data.loc[ combined_new_year_money_data.year == 2016] .set_index(&#39;ID&#39;) .add_suffix(&quot;_2016&quot;).drop(columns=[&#39;year_2016&#39;]) combined_new_year_data_2017 = combined_new_year_money_data.loc[ combined_new_year_money_data.year == 2017] .set_index(&#39;ID&#39;) .add_suffix(&quot;_2017&quot;).drop(columns=[&#39;year_2017&#39;]) # marge data with ID combined_new_splited_year_money_data = pd.merge( combined_new_year_data_2015, combined_new_year_data_2016, on=[&#39;ID&#39;]) combined_new_splited_year_money_data = pd.merge( combined_new_splited_year_money_data, combined_new_year_data_2017, on=[&#39;ID&#39;]) return combined_new_splited_year_money_data 训练数据集处理 加载原始数据 import pandas as pd # load training data base_train_data = pd.read_csv(&quot;data/train/base-train.csv&quot;) year_train_data = pd.read_csv(&quot;data/train/year-train.csv&quot;) knowledge_train_data = pd.read_csv(&quot;data/train/knowledge-train.csv&quot;) money_train_data = pd.read_csv(&quot;data/train/money-train.csv&quot;) 查看原始数据集信息：base data and knowledge data base_train_data base_train_data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID 注册时间 注册资本 行业 区域 企业类型 控制人类型 控制人持股比例 flag 0 5986361 2014.0 7090.0 服务业 湖北 有限责任公司 自然人 0.93 0 1 5991749 2007.0 5940.0 零售业 湖南 合伙企业 企业法人 0.57 0 2 5998154 2002.0 9720.0 工业 福建 合伙企业 自然人 0.74 0 3 5984390 2000.0 4800.0 商业服务业 山东 股份有限公司 NaN 0.90 0 4 5980535 2004.0 4530.0 零售业 广东 农民专业合作社 自然人 0.95 0 base_train_data.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID 注册时间 注册资本 控制人持股比例 flag count 2.851900e+04 28230.000000 28220.000000 28223.000000 28519.000000 mean 4.332423e+06 2007.010627 5024.659816 0.754786 0.392721 std 2.161092e+06 4.326800 2860.157458 0.145008 0.488364 min 2.800000e+01 2000.000000 100.000000 0.510000 0.000000 25% 2.324856e+06 2003.000000 2530.000000 0.630000 0.000000 50% 5.981915e+06 2007.000000 5010.000000 0.750000 0.000000 75% 5.990992e+06 2011.000000 7490.000000 0.880000 1.000000 max 6.000000e+06 2014.000000 10000.000000 1.000000 1.000000 knowledge_train_data knowledge_train_data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID 专利 商标 著作权 0 28 0.0 1.0 1.0 1 230 0.0 0.0 0.0 2 693 0.0 0.0 0.0 3 990 0.0 0.0 0.0 4 1274 0.0 0.0 0.0 knowledge_train_data.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID 专利 商标 著作权 count 2.851900e+04 28233.000000 28216.00000 28237.000000 mean 4.332423e+06 0.342507 0.36334 0.371428 std 2.161092e+06 0.474557 0.48097 0.483195 min 2.800000e+01 0.000000 0.00000 0.000000 25% 2.324856e+06 0.000000 0.00000 0.000000 50% 5.981915e+06 0.000000 0.00000 0.000000 75% 5.990992e+06 1.000000 1.00000 1.000000 max 6.000000e+06 1.000000 1.00000 1.000000 合并 base data 和 knowledge data combined_base_knowledge_train_data = combined_base_knowledge_data( base_train_data, knowledge_train_data ) combined_base_knowledge_train_data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 注册时间 注册资本 行业 区域 企业类型 控制人类型 控制人持股比例 flag 专利 商标 著作权 ID 5986361 2014.0 7090.0 服务业 湖北 有限责任公司 自然人 0.93 0 0.0 0.0 0.0 5991749 2007.0 5940.0 零售业 湖南 合伙企业 企业法人 0.57 0 1.0 1.0 0.0 5998154 2002.0 9720.0 工业 福建 合伙企业 自然人 0.74 0 1.0 1.0 0.0 5984390 2000.0 4800.0 商业服务业 山东 股份有限公司 NaN 0.90 0 0.0 0.0 0.0 5980535 2004.0 4530.0 零售业 广东 农民专业合作社 自然人 0.95 0 0.0 1.0 1.0 查看 year data 和 money data数据集信息 year_train_data year_train_data.head(10) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID year 从业人数 资产总额 负债总额 营业总收入 主营业务收入 利润总额 纳税总额 所有者权益合计 0 28 2015.0 794.0 16400.0 28700.0 72160.0 28864.0 7216.0 0.0 -12300.0 1 230 2015.0 485.0 23520.0 10080.0 115248.0 57624.0 57624.0 0.0 13440.0 2 693 2015.0 534.0 133760.0 125400.0 655424.0 262169.6 196627.2 0.0 8360.0 3 990 2015.0 863.0 33760.0 25320.0 145168.0 58067.2 14516.8 0.0 8440.0 4 1274 2015.0 254.0 74900.0 104325.0 277130.0 110852.0 55426.0 0.0 -29425.0 5 1560 2015.0 491.0 105000.0 98000.0 147000.0 73500.0 29400.0 0.0 7000.0 6 3261 2015.0 799.0 417000.0 822880.0 1751400.0 1401120.0 350280.0 0.0 -405880.0 7 3313 2015.0 784.0 501600.0 986480.0 2156880.0 1294128.0 431376.0 0.0 -484880.0 8 3537 2015.0 647.0 17800.0 13350.0 8900.0 4450.0 2670.0 0.0 4450.0 9 3719 2015.0 369.0 317000.0 465990.0 380400.0 228240.0 152160.0 0.0 -148990.0 year_train_data.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID year 从业人数 ... 利润总额 纳税总额 所有者权益合计 count 8.554800e+04 84692.000000 84743.000000 ... 8.469900e+04 8.473100e+04 84673.000000 mean 4.332626e+06 2015.999870 510.808421 ... 1.027939e+05 7.079659e+04 -27390.880033 std 2.160933e+06 0.816398 283.129690 ... 1.536672e+05 1.588261e+05 108355.730296 min 2.800000e+01 2015.000000 20.000000 ... 7.800000e+00 0.000000e+00 -828340.000000 25% 2.325192e+06 2015.000000 266.000000 ... 1.396755e+04 0.000000e+00 -53130.000000 50% 5.981916e+06 2016.000000 512.000000 ... 4.514400e+04 1.240200e+03 250.000000 75% 5.990992e+06 2017.000000 756.000000 ... 1.238400e+05 6.668040e+04 8900.000000 max 5.999999e+06 2017.000000 1000.000000 ... 1.807398e+06 2.089620e+06 429570.000000 year_train_data money_train_data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID year 债权融资额度 债权融资成本 股权融资额度 股权融资成本 内部融资和贸易融资额度 内部融资和贸易融资成本 项目融资和政策融资额度 项目融资和政策融资成本 0 28 2015.0 0.0 0.0 0.0 0.000 21648.0 1298.88 0.0 0.000 1 230 2015.0 0.0 0.0 0.0 0.000 0.0 0.00 470.4 28.224 2 693 2015.0 0.0 0.0 0.0 0.000 0.0 0.00 5350.4 321.024 3 990 NaN 0.0 0.0 0.0 0.000 0.0 0.00 675.2 40.512 4 1274 2015.0 0.0 0.0 11085.2 443.408 0.0 0.00 NaN 0.000 money_train_data.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID year 债权融资额度 ... 内部融资和贸易融资成本 项目融资和政策融资额度 项目融资和政策融资成本 count 8.554800e+04 84703.000000 84739.000000 ... 84720.000000 84686.000000 84695.000000 mean 4.332626e+06 2016.000378 3353.349261 ... 1555.894230 1020.851124 61.231978 std 2.160933e+06 0.816496 8883.814614 ... 4811.138407 3000.062130 179.871750 min 2.800000e+01 2015.000000 0.000000 ... 0.000000 0.000000 0.000000 25% 2.325192e+06 2015.000000 0.000000 ... 0.000000 0.000000 0.000000 50% 5.981916e+06 2016.000000 0.000000 ... 0.000000 0.000000 0.000000 75% 5.990992e+06 2017.000000 0.000000 ... 10.719000 41.000000 2.520000 max 5.999999e+06 2017.000000 84830.000000 ... 72925.920000 39720.000000 2383.200000 填充缺失数据 year_train_data # fill null new_year_train_data = fill_na(year_train_data) new_year_train_data.set_index([&#39;ID&#39;, &#39;year&#39;]) new_year_train_data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID year 从业人数 资产总额 负债总额 营业总收入 主营业务收入 利润总额 纳税总额 所有者权益合计 0 28 2015.0 794.0 16400.0 28700.0 72160.0 28864.0 7216.0 0.0 -12300.0 1 230 2015.0 485.0 23520.0 10080.0 115248.0 57624.0 57624.0 0.0 13440.0 2 693 2015.0 534.0 133760.0 125400.0 655424.0 262169.6 196627.2 0.0 8360.0 3 990 2015.0 863.0 33760.0 25320.0 145168.0 58067.2 14516.8 0.0 8440.0 4 1274 2015.0 254.0 74900.0 104325.0 277130.0 110852.0 55426.0 0.0 -29425.0 money_train_data # fill null new_money_train_data = fill_na(money_train_data) new_money_train_data.set_index([&#39;ID&#39;, &#39;year&#39;]) # new_money_train_data.head(8) new_money_train_data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID year 债权融资额度 债权融资成本 股权融资额度 股权融资成本 内部融资和贸易融资额度 内部融资和贸易融资成本 项目融资和政策融资额度 项目融资和政策融资成本 0 28 2015.0 0.0 0.0 0.0 0.000 21648.0 1298.88 0.0 0.000 1 230 2015.0 0.0 0.0 0.0 0.000 0.0 0.00 470.4 28.224 2 693 2015.0 0.0 0.0 0.0 0.000 0.0 0.00 5350.4 321.024 3 990 2015.0 0.0 0.0 0.0 0.000 0.0 0.00 675.2 40.512 4 1274 2015.0 0.0 0.0 11085.2 443.408 0.0 0.00 0.0 0.000 合并year data和money data数据集 # Merge new year and money data combined_new_year_money_train_data = combined_new_year_money_data( new_year_train_data, new_money_train_data ) combined_new_year_money_train_data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID year 从业人数 资产总额 ... 内部融资和贸易融资额度 内部融资和贸易融资成本 项目融资和政策融资额度 项目融资和政策融资成本 0 28 2015.0 794.0 16400.0 ... 21648.0 1298.88 0.0 0.000 1 230 2015.0 485.0 23520.0 ... 0.0 0.00 470.4 28.224 2 693 2015.0 534.0 133760.0 ... 0.0 0.00 5350.4 321.024 3 990 2015.0 863.0 33760.0 ... 0.0 0.00 675.2 40.512 4 1274 2015.0 254.0 74900.0 ... 0.0 0.00 0.0 0.000 拆分新特征 将合并后的数据集中每一年的数据拆分成新的特征，使之与base data通过ID一一对应。 splited_year_money_train_data = split_data(combined_new_year_money_train_data) splited_year_money_train_data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 从业人数_2015 资产总额_2015 负债总额_2015 ... 内部融资和贸易融资额度_2017 内部融资和贸易融资成本_2017 项目融资和政策融资额度_2017 项目融资和政策融资成本_2017 ID 28 794.0 16400.0 28700.0 ... 0.0 0.000 0.0 0.0 230 485.0 23520.0 10080.0 ... 0.0 0.000 0.0 0.0 693 534.0 133760.0 125400.0 ... 0.0 0.000 0.0 0.0 990 863.0 33760.0 25320.0 ... 111661.2 6699.672 0.0 0.0 1274 254.0 74900.0 104325.0 ... 0.0 0.000 0.0 0.0 5 rows × 48 columns 合并处理好的数据集 train = pd.merge(combined_base_knowledge_train_data, splited_year_money_train_data, on=[&#39;ID&#39;]) train.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 注册时间 注册资本 行业 ... 内部融资和贸易融资额度_2017 内部融资和贸易融资成本_2017 项目融资和政策融资额度_2017 项目融资和政策融资成本_2017 ID 5986361 2014.0 7090.0 服务业 ... 0.0 0.0 0.0 0.0 5991749 2007.0 5940.0 零售业 ... 80190.0 4811.4 0.0 0.0 5998154 2002.0 9720.0 工业 ... 0.0 0.0 0.0 0.0 5984390 2000.0 4800.0 商业服务业 ... 48960.0 2937.6 0.0 0.0 5980535 2004.0 4530.0 零售业 ... 0.0 0.0 0.0 0.0 5 rows × 59 columns 保存处理好的训练数据集 train.to_csv(&quot;data/train/train.csv&quot;) train.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 注册时间 注册资本 控制人持股比例 ... 内部融资和贸易融资额度_2017 内部融资和贸易融资成本_2017 项目融资和政策融资额度_2017 项目融资和政策融资成本_2017 count 28516.000000 28516.000000 28516.000000 ... 2.851600e+04 28516.000000 28516.000000 28516.000000 mean 2007.010836 5024.064385 0.754743 ... 2.850957e+04 1712.928322 1115.153493 67.013075 std 4.304831 2844.938780 0.144249 ... 8.651585e+04 5202.890113 3229.079861 193.992216 min 2000.000000 100.000000 0.510000 ... 0.000000e+00 0.000000 0.000000 0.000000 25% 2003.000000 2560.000000 0.630000 ... 0.000000e+00 0.000000 0.000000 0.000000 50% 2007.000000 5010.000000 0.750000 ... 0.000000e+00 0.000000 0.000000 0.000000 75% 2011.000000 7470.000000 0.880000 ... 0.000000e+00 0.000000 0.000000 0.000000 max 2014.000000 10000.000000 1.000000 ... 1.215432e+06 72925.920000 38930.000000 2335.800000 8 rows × 55 columns 训练数据集处理 按照刚刚处理训练集的流程处理测试数据集。 ### 加载原始数据集 # load testing data base_test_data = pd.read_csv(&quot;data/test/base-test.csv&quot;) year_test_data = pd.read_csv(&quot;data/test/year-test.csv&quot;) knowledge_test_data = pd.read_csv(&quot;data/test/knowledge-test.csv&quot;) money_test_data = pd.read_csv(&quot;data/test/money-test.csv&quot;) 合并 base data 和 knowledge data combined_base_knowledge_test_data = combined_base_knowledge_data( base_test_data, knowledge_test_data ) combined_base_knowledge_test_data.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 注册时间 注册资本 控制人持股比例 专利 商标 著作权 count 7132.000000 7132.000000 7132.000000 7132.000000 7132.000000 7132.000000 mean 2007.077257 5039.914470 0.754799 0.342821 0.358385 0.373528 std 4.321929 2839.476208 0.143953 0.474686 0.479560 0.483774 min 2000.000000 100.000000 0.510000 0.000000 0.000000 0.000000 25% 2003.000000 2640.000000 0.630000 0.000000 0.000000 0.000000 50% 2007.000000 5040.000000 0.750000 0.000000 0.000000 0.000000 75% 2011.000000 7450.000000 0.880000 1.000000 1.000000 1.000000 max 2014.000000 10000.000000 1.000000 1.000000 1.000000 1.000000 year data and money data 填充缺失值并验证填充结果 year_test_data # fill null new_year_test_data = fill_na(year_test_data) new_year_test_data.set_index([&#39;ID&#39;, &#39;year&#39;]) new_year_test_data.describe() print(&quot;unique ID count in base data:&quot;, base_test_data[&quot;ID&quot;] .nunique()) print(&quot;2015 unique ID count in year data:&quot;, new_year_test_data[&quot;ID&quot;] .loc[new_year_test_data.year==2015] .nunique()) print(&quot;2016 unique ID count in year data:&quot;, new_year_test_data[&quot;ID&quot;] .loc[new_year_test_data.year==2016] .nunique()) print(&quot;2017 unique ID count in year data:&quot;, new_year_test_data[&quot;ID&quot;] .loc[new_year_test_data.year==2017] .nunique()) unique ID count in base data: 7132 2015 unique ID count in year data: 7132 2016 unique ID count in year data: 7132 2017 unique ID count in year data: 7132 money_test_data # fill null new_money_test_data = fill_na(money_test_data) new_money_test_data.set_index([&#39;ID&#39;, &#39;year&#39;]) # new_money_train_data.head(8) new_money_test_data.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID year 债权融资额度 ... 内部融资和贸易融资额度 内部融资和贸易融资成本 项目融资和政策融资额度 项目融资和政策融资成本 count 2.139600e+04 21396.000000 21396.000000 ... 2.139600e+04 21396.000000 21396.000000 21396.000000 mean 4.332655e+06 2016.000000 3209.631146 ... 2.677436e+04 1598.629057 1025.091606 61.698997 std 2.163020e+06 0.816516 8711.231069 ... 8.272665e+04 4950.288392 3050.157292 183.387577 min 4.290000e+02 2015.000000 0.000000 ... 0.000000e+00 0.000000 0.000000 0.000000 25% 2.331607e+06 2015.000000 0.000000 ... 0.000000e+00 0.000000 0.000000 0.000000 50% 5.981952e+06 2016.000000 0.000000 ... 0.000000e+00 0.000000 0.000000 0.000000 75% 5.990780e+06 2017.000000 0.000000 ... 2.565000e+02 0.850500 0.000000 0.000000 max 5.999998e+06 2017.000000 ... 1.257150e+06 75429.000000 40970.000000 2458.200000 print(&quot;unique ID count in base data:&quot;, base_test_data[&quot;ID&quot;].nunique()) print(&quot;2015 unique ID count in money data:&quot;, new_money_test_data[&quot;ID&quot;] .loc[new_money_test_data.year==2015] .nunique()) print(&quot;2016 unique ID count in money data:&quot;, new_money_test_data[&quot;ID&quot;] .loc[new_money_test_data.year==2016] .nunique()) print(&quot;2017 unique ID count in money data:&quot;, new_money_test_data[&quot;ID&quot;] .loc[new_money_test_data.year==2017] .nunique()) unique ID count in base data: 7132 2015 unique ID count in money data: 7132 2016 unique ID count in money data: 7132 2017 unique ID count in money data: 7132 合并 year data 和 money data combined_new_year_money_test_data = combined_new_year_money_data( new_year_test_data, new_money_test_data ) combined_new_year_money_test_data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID year 从业人数 ... 内部融资和贸易融资额度 内部融资和贸易融资成本 项目融资和政策融资额度 项目融资和政策融资成本 0 429 2015.0 136.0 ... 0.0 0.000 0.0 0.00 1 727 2015.0 375.0 ... 0.0 0.000 0.0 0.00 2 1137 2015.0 289.0 ... 24460.8 1467.648 0.0 0.00 3 1873 2015.0 889.0 ... 0.0 0.000 0.0 0.00 4 2260 2015.0 689.0 ... 0.0 0.000 11287.5 677.25 print(&quot;unique ID count in combined data:&quot;, combined_new_year_money_test_data[&quot;ID&quot;].nunique()) unique ID count in combined data: 7132 拆分新特征 splited_year_money_test_data = split_data(combined_new_year_money_test_data) splited_year_money_test_data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 从业人数_2015 资产总额_2015 负债总额_2015 ... 内部融资和贸易融资额度_2017 内部融资和贸易融资成本_2017 项目融资和政策融资额度_2017 项目融资和政策融资成本_2017 ID 429 136.0 193400.0 183730.0 ... 0.0 0.000 0.0 0.00 727 375.0 366240.0 536280.0 ... 0.0 0.000 0.0 0.00 1137 289.0 87200.0 40320.0 ... 0.0 0.000 1008.0 60.48 1873 889.0 229320.0 222950.0 ... 12612.6 756.756 0.0 0.00 2260 689.0 225750.0 325080.0 ... 0.0 0.000 0.0 0.00 5 rows × 48 columns 合并处理好的数据集 根据ID合并处理好的数据集。 test = pd.merge(combined_base_knowledge_test_data, splited_year_money_test_data, on=[&#39;ID&#39;]) test.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 注册时间 注册资本 行业 ... 内部融资和贸易融资额度_2017 内部融资和贸易融资成本_2017 项目融资和政策融资额度_2017 项目融资和政策融资成本_2017 ID 5991927 2010.0 8790.0 工业 ... 341491.5 20489.49 0.0 0.000 5998351 2005.0 270.0 服务业 ... 0.0 0.00 194.4 11.664 5992703 2012.0 230.0 服务业 ... 0.0 0.00 0.0 0.000 5979231 2003.0 5980.0 商业服务业 ... 75348.0 4520.88 0.0 0.000 5995422 2007.0 160.0 工业 ... 8856.0 531.36 0.0 0.000 5 rows × 58 columns 保存处理好的测试数据集 test.to_csv(&quot;data/test/test.csv&quot;) 总结 这次数据处理比较简单，主要注意以下几个点： 1. 对于年份数据缺失值的处理，可以根据ID和年份判断缺失的年份应该是哪一年，然后填充相应的年份值即可，如果是同一ID缺失两年数据，这个就随缘了😆，我是按照从上到下的顺序填充的（可能有更好的方法，大家可以提出自己的想法），例如ID为123的企业缺失2015和2017的年份，那么依次将year属性值填充为2015和2017； 2. 对于其他数据我就直接粗暴的填充中位数，本来是想先这么填充然后看看效果再优化，结果训练测试后的结果还不错，所以也就没有再优化了； 下篇文章中我会对模型训练过程作一个说明，使用的是LightGBM框架（LightGBM是使用基于树的学习算法的梯度增强框架）。","categories":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Machine Learning","slug":"Technology/Machine-Learning","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/"},{"name":"Data pre-processing","slug":"Technology/Machine-Learning/Data-pre-processing","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/Data-pre-processing/"}],"tags":[{"name":"Data pre-processing","slug":"Data-pre-processing","permalink":"https://littlelittlemoon.github.io/tags/Data-pre-processing/"},{"name":"Categorical Data","slug":"Categorical-Data","permalink":"https://littlelittlemoon.github.io/tags/Categorical-Data/"},{"name":"Missing value","slug":"Missing-value","permalink":"https://littlelittlemoon.github.io/tags/Missing-value/"}],"keywords":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Machine Learning","slug":"Technology/Machine-Learning","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/"},{"name":"Data pre-processing","slug":"Technology/Machine-Learning/Data-pre-processing","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/Data-pre-processing/"}]},{"title":"Leetcode Note in Apri 2020 | part 2 |day 08-14","slug":"Technology/Leetcode-Note-in-Apri-2020-part-2-day-08-14","date":"2020-04-08T05:54:16.000Z","updated":"2020-04-16T08:15:49.574Z","comments":true,"path":"2020/04/08/Technology/Leetcode-Note-in-Apri-2020-part-2-day-08-14/","link":"","permalink":"https://littlelittlemoon.github.io/2020/04/08/Technology/Leetcode-Note-in-Apri-2020-part-2-day-08-14/","excerpt":"","text":"写在前面的话 第二次更新，继续前进~ Backspace String Compare Given two strings S and T, return if they are equal when both are typed into empty text editors. # means a backspace character. Examples: Input: S = \"ab#c\", T = \"ad#c\" Output: true Explanation: Both S and T become \"ac\". Input: S = \"ab##\", T = \"c#d#\" Output: true Explanation: Both S and T become \"\". Input: S = \"a##c\", T = \"#a#c\" Output: true Explanation: Both S and T become \"c\". Input: S = \"a#c\", T = \"b\" Output: false Explanation: S becomes \"c\" while T becomes \"b\". Solution 这个题对于我来说有点难度，昨天(9号)晚上做了两个小时吧，重点是通不过所有测试用例，总是有一些细节没有考虑到，而且代码越写越复杂，加上昨天中午没睡午觉，到最后自己把自己都搞懵了，气😠。后面睡觉的时候发现自己脑子真的是一根筋，换个思路这题会简单很多。先看看代码吧。 Mine 核心思路：从后往前找可能留下来的字符，并一一比对两个字符串对应位置能留下来的的字符是否相等。注意循环判断条件的设置！ class Solution: def backspaceCompare(self, S: str, T: str) -&gt; bool: s_i = len(S) - 1 t_i = len(T) - 1 s_back = t_back = 0 while True: # Loop will be stoped when any of the following situations occur: # 1. s_i completed the last character access # 2. S[s_i] is a letter (S[s_i] != &#39;#&#39;) and don&#39;t need to go back # currently (s_back = 0) # Same as T, t_i and t_back while s_i &gt;= 0: if S[s_i] == &#39;#&#39;: s_i, s_back = s_i - 1, s_back + 1 elif S[s_i] != &#39;#&#39; and s_back &gt; 0: s_i, s_back = s_i - 1, s_back - 1 else: break while t_i &gt;= 0: if T[t_i] == &#39;#&#39;: t_i, t_back = t_i - 1, t_back + 1 elif T[t_i] != &#39;#&#39; and t_back &gt; 0: t_i, t_back = t_i - 1, t_back - 1 else: break # There are only two situations will return True: # 1. both s_i and t_i are not out of index and S[s_i] = T[t_i] # 2. both s_i and t_i are out of index, it means no letter needs # to be compared and previous corresponding letters are equal. # otherwise, it will return false in situation 1 if s_i &gt;= 0 and t_i &gt;= 0: if S[s_i] != T[t_i]: return False s_i, t_i = s_i - 1, t_i - 1 else: return s_i &lt; 0 and t_i &lt; 0 其实还是蛮复杂的，可能有更好的解决方法，希望小伙伴们给出你们的思路和建议。我刚开始的思路是从前往后去找可能留下的字母，但是这个变化太大了，而且判断条件特别多，总是有很多情况考虑不到，整了一晚上也没整出来。后面睡觉的时候突然想起我为啥不从后往前找呢？🤣具体解法都在注释里，emmmm，可能还有语法错误，勿介😊。 Min Stack Design a stack that supports push, pop, top, and retrieving the minimum element in constant time. push(x) -- Push element x onto stack. pop() -- Removes the element on top of the stack. top() -- Get the top element. getMin() -- Retrieve the minimum element in the stack. Example: MinStack minStack = new MinStack(); minStack.push(-2); minStack.push(0); minStack.push(-3); minStack.getMin(); --&gt; Returns -3. minStack.pop(); minStack.top(); --&gt; Returns 0. minStack.getMin(); --&gt; Returns -2. Solution 这个题不难，并且有很多中实现方式。我们需要实现的这个栈是在传统的栈已有的功能上增加了返回最小值的功能，这就涉及到怎么存储最小值的问题，这里有三个思路，大家有更好的思路也可以在评论区给出： 时间换空间 只设计一个栈，返回最小值时通过排序方式返回。 class MinStack: def __init__(self): &quot;&quot;&quot; initialize your data structure here. &quot;&quot;&quot; self.stack = [] def push(self, x: int) -&gt; None: self.stack.append(x) def pop(self) -&gt; None: self.stack.pop() def top(self) -&gt; int: if len(self.stack) &lt; 0: return None return self.stack[len(self.stack)-1] def getMin(self) -&gt; int: if len(self.stack) &lt; 0: return None s_sorted = sorted(self.stack) return s_sorted[0] 更节省时间和空间的方式(更巧妙) 设计一个栈，一个min变量，但是栈里面只存放每个元素与最小值的差值（x-min），当出现更小的最小值时，保存的是负数，故课通过这个条件追溯之前的最小值，具体实现见下面的代码。 class MinStack: def __init__(self): &quot;&quot;&quot; initialize your data structure here. &quot;&quot;&quot; self.stack = [] self.s_min = None def push(self, x: int) -&gt; None: if self.s_min == None: self.s_min = x self.stack.append(x-self.s_min) self.s_min = min(self.s_min, x) def pop(self) -&gt; None: pop = self.stack.pop() if len(self.stack) &gt; 0: if pop &lt; 0: self.s_min = self.s_min - pop else: self.s_min = None def top(self) -&gt; int: if len(self.stack) &lt; 0: return None top = self.stack[len(self.stack)-1] if top &lt; 0: return self.s_min return top + self.s_min def getMin(self) -&gt; int: return self.s_min 空间换时间 设计两个栈，多出来的那个栈用来记录出现过的最小值，我这里没有去实现了，大家可以试试。 Diameter of Binary Tree Given a binary tree, you need to compute the length of the diameter of the tree. The diameter of a binary tree is the length of the longest path between any two nodes in a tree. This path may or may not pass through the root. Example: Given a binary tree Return 3, which is the length of the path [4,2,1,3] or [5,2,1,3]. Note: The length of path between two nodes is represented by the number of edges between them. Solution 核心思路：根据半径的定义可知，半径所在的路径一定有一个中心节点，故可通过判断二叉树每个节点（当前可能的中心点）左右子树的深度和的大小来确定半径。 # Definition for a binary tree node. class TreeNode: def __init__(self, x): self.val = x self.left = None self.right = None class Solution: def diameterOfBinaryTree(self, root: TreeNode) -&gt; int: self.diameter = 0 def count_depth(node): if not(node): return 0 l_dep, r_dep = count_depth(node.left), count_depth(node.right) self.diameter = max(self.diameter, l_dep+r_dep) # max depth: max(left depth, right depth) # +1: count node return 1 + max(l_dep, r_dep) count_depth(root) return self.diameter 这题刚开始我是没有什么好的思路的，太久没做关于二叉树的题了，不对，准确来讲应该是课后就丢了，哈哈哈，后来去查了下二叉树的相关资料，看到求二叉树的深度问题给了我灵感。希望能把以前丢掉的知识点慢慢捡起来，就拿这个树相关的知识点来说，其实很多算法底层原理都有涉及，为了以后能走快一点，现在应该多走几步。 Last Stone Weight We have a collection of stones, each stone has a positive integer weight. Each turn, we choose the two heaviest stones and smash them together. Suppose the stones have weights x and y with x &lt;= y. The result of this smash is: If x == y, both stones are totally destroyed; If x != y, the stone of weight x is totally destroyed, and the stone of weight y has new weight y-x. At the end, there is at most 1 stone left. Return the weight of this stone (or 0 if there are no stones left.) Example 1: Input: [2,7,4,1,8,1] Output: 1 Explanation: We combine 7 and 8 to get 1 so the array converts to [2,4,1,1,1] then, we combine 2 and 4 to get 2 so the array converts to [2,1,1,1] then, we combine 2 and 1 to get 1 so the array converts to [1,1,1] then, we combine 1 and 1 to get 0 so the array converts to [1] then that's the value of last stone. Solution 解法一 —— 大根堆 这个解法是更优的解法，得力于大根堆的特性，算法时间复杂度减少至O(Nlog(N))。 class Solution: def lastStoneWeight(self, stones: List[int]) -&gt; int: # The heap in python defaults to a small root heap # So heap pops the minimum value when use heappop, take the opposite # value of each list (the weight of each stone &gt; 0) to ensure that the # heaviest stone is poped. stones = list(map(lambda x : -x, stones)) # Convert stone list to heap heapq.heapify(stones) while len(stones) &gt; 1: # Pop and return the smallest element of stones, keeping the heap invariant y = heapq.heappop(stones) if stones: x = heapq.heappop(stones) # if x != y push x-y to heap if x != y: heapq.heappush(stones, y-x) if not(stones): return 0 return -stones[0] 时间复杂度：O(Nlog(N)) 解法二 这个解法是最容易想到的解法，思想也比较简单，时间复杂度O(\\(N^2\\))。 class Solution: def lastStoneWeight(self, stones: List[int]) -&gt; int: stones = sorted(stones) while len(stones) &gt; 1: y, x = stones.pop(), stones.pop() if x != y: stones.append(y-x) stones = sorted(stones) if not(stones): return 0 return stones[0] 时间复杂度：O(\\(N^2\\)) -----（not sure） 实际采用第二种方法的在LeetCode上的run time比第一种方法更少，所以第二种方法时间复杂度比第一种方式更小，我可能需要学习一下python的内置函数sorted方法，看看它的实现。初步了解到python中的sorted排序，用的Timsort算法，维基百科解释：Timsort是一种混合稳定的排序算法，源自合并排序和插入排序，旨在较好地处理真实世界中各种各样的数据。具体原理还需深究。 Contiguous Array Given a binary array, find the maximum length of a contiguous subarray with equal number of 0 and 1. Example 1: Input: [0,1] Output: 2 Explanation: [0, 1] is the longest contiguous subarray with equal number of 0 and 1. Example 2: Input: [0,1,0] Output: 2 Explanation: [0, 1] (or [1, 0]) is a longest contiguous subarray with equal number of 0 and 1. Solution 讲真心话，我第一遍没看懂题🤣，题目大意是给一个二值(0/1)数组，找出该数组的最大连续子串的长度，该子串中满足0和1的个数相同。 明白题意之后的第一想法是通过计数的形式去找子串，例如设置一个count变量，遇到0就-1，遇到1就+1。那么如何通过这个变量去判断什么时候会出现最大子串呢？ 考虑下面几种情况： 假设nums = [0, 1, 0, 0, 1, 1]， 那么count = [-1， 0， -1， -2， -1， 0] =&gt; max length：6（count数组的最后一个0的index+1） nums = [0, 0, 0, 0, 1, 1]，count = [-1, -2, -3, -4, -3, -2] =&gt; 很明显这种情况的最大长度不是最后一个0的index + 1 = 2，而是4，其实也是可以通过count的值推测出来，最大长度的子串是[1, 1, 0, 0]，下面用一个图来直观的表示如何通过count的值来推出max length： count初始值为0，故起点为(0, 0)，从count从index=1开始计数，从图中可以看出，最长的子数组是从索引2到6: 从上面的插图中，可以很容易地理解到，具有相同y轴值的两个点表示这两个点之间的序列具有相等的0和1。 nums = [0，0，1，0，0，0，1，1]，如下所示： 有3个点具有相同的y轴值-2。因此，从索引2到4的子数组具有相等的0和1，而从索引4到8的子数组具有相等的0和1。可以将它们加起来以形成从索引2到8的最长子数组，因此最大长度子数组的 8-2 = 6。 nums = [0，1，1，0，1，1，1，0]，如下所示： 最长的子数组的y轴值为0。 为了找到max length，这里可以考虑用一个字典来存储count的值（作为键）及其关联的index（作为值）。只需要在count第一次出现某值时保存其计数值及其索引，当相同的计数值再次出现时，使用新索引减去旧索引来计算子数组的长度。变量max_length用于跟踪当前的最大长度。 代码实现 class Solution: def findMaxLength(self, nums: List[int]) -&gt; int: count = 0 max_len = 0 dic = {0: 0} for i, num in enumerate(nums, 1): count += 1 if num == 1 else -1 if count in dic: max_len = max(max_len, i - dic[count]) else: dic[count] = i return max_len Reference Python O(n) Solution with Visual Explanation Perform String Shifts You are given a string s containing lowercase English letters, and a matrix shift, where shift[i] = [direction, amount]: 1. direction can be 0 (for left shift) or 1 (for right shift). 2. amount is the amount by which string s is to be shifted. 3. A left shift by 1 means remove the first character of s and append it to the end. 4. Similarly, a right shift by 1 means remove the last character of s and add it to the beginning. Return the final string after all operations. Example 1: Input: s = \"abc\", shift = [[0,1],[1,2]] Output: \"cab\" Explanation: [0,1] means shift to left by 1. \"abc\" -&gt; \"bca\" [1,2] means shift to right by 2. \"bca\" -&gt; \"cab\" Example 2: Input: s = \"abcdefg\", shift = [[1,1],[1,1],[0,2],[1,3]] Output: \"efgabcd\" Explanation: [1,1] means shift to right by 1. \"abcdefg\" -&gt; \"gabcdef\" [1,1] means shift to right by 1. \"gabcdef\" -&gt; \"fgabcde\" [0,2] means shift to left by 2. \"fgabcde\" -&gt; \"abcdefg\" [1,3] means shift to right by 3. \"abcdefg\" -&gt; \"efgabcd\" Solution 思路：这个题肯定不能用蛮力法，比如说你挨个去判断矩阵元素，然后根据要求去移动，这样复杂度太高了。核心思路是将要移动的步数统计在一起，然后只移动一次。 例如，首先设置一个move_steps变量，向左一步移就-1，向右移两步就+2。然后判断移动步数，如果移动步数超过字符串长度，那么就通过字符串长度取余（因为移动字符串长度那么多步最后又恢复原样，相当于没移）。最后统一向一个方向（例如向右，如果是左移，则通过字符串长度变为向右移动）移动。思路很简单，具体实现，请看代码~😊 class Solution: def stringShift(self, s: str, shift: List[List[int]]) -&gt; str: move_steps = 0 for data in shift: direction = data[0] move_steps += data[1] if direction == 1 else -data[1] s_len = len(s) move_steps %= s_len if move_steps &gt; 0 else -s_len # Do not need to move if move_steps == 0: return s # move right if move_steps &lt; 0: move_steps += s_len # move s_list = list(s) while move_steps &gt; 0: s_list.insert(0, s_list[-1]) s_list = s_list[:-1] move_steps -= 1 return &#39;&#39;.join(s_list) 总结 这周题的难度明显要比上周的高那么一点，希望自己能坚持下去，给自己一些信心。噢对了，我感觉一篇文章更新一周的内容还想有点太长了，下周我可能会考虑一篇文章只收纳2-3道题。这周的更新就到此为止了，期待下次更新吧~👋","categories":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Coding","slug":"Technology/Coding","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/"},{"name":"Leetcode","slug":"Technology/Coding/Leetcode","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/Leetcode/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://littlelittlemoon.github.io/tags/Leetcode/"},{"name":"Python","slug":"Python","permalink":"https://littlelittlemoon.github.io/tags/Python/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://littlelittlemoon.github.io/tags/Algorithm/"}],"keywords":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Coding","slug":"Technology/Coding","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/"},{"name":"Leetcode","slug":"Technology/Coding/Leetcode","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/Leetcode/"}]},{"title":"Leetcode Note in Apri 2020 | part 1 | day 01-07","slug":"Technology/Leetcode-Note-in-Apri-2020-part-1-day-01-07","date":"2020-04-01T01:51:55.000Z","updated":"2020-04-13T04:37:22.942Z","comments":true,"path":"2020/04/01/Technology/Leetcode-Note-in-Apri-2020-part-1-day-01-07/","link":"","permalink":"https://littlelittlemoon.github.io/2020/04/01/Technology/Leetcode-Note-in-Apri-2020-part-1-day-01-07/","excerpt":"","text":"写在前面的话 这一系列文章主要是用于记录我在LeetCode上刷题时遇到的我认为比较有难度和有意思的题，以及是挖掘到的其他小伙伴比较好的解法和思路。这是第一篇，不出意外这个系列会一直更新，也算是督促自己坚持下去吧。对了我写作水平真的很差，希望大家不要嫌弃，也可以和我留言给出建议什么的，期待和大家个共同进步！那我们开始吧 ~ Sigle number Given a non-empty array of integers, every element appears twice except for one. Find that single one. Note: Your algorithm should have a linear runtime complexity. Could you implement it without using extra memory? Example: Input: [4,1,2,1,2] Output: 4 Solution Mine: tuple + list class Solution: def singleNumber(self, nums: List[int]) -&gt; int: # store the count of positive number p_count = [0] * (max(tuple(nums)) + 1) # store the positive number p_nums = () # store the count of negative number n_count = [0] * (abs(min(tuple(nums))) + 1) # store the negative number n_nums = () # counting for num in nums: if num &gt;= 0: p_nums = p_nums + (num, ) p_count[num] = p_count[num] + 1 else: n_nums = n_nums + (num, ) n_count[abs(num)] = n_count[abs(num)] + 1 # find the sigle number for num in p_nums: if p_count[num] == 1: return num for num in n_nums: if n_count[abs(num)] == 1: return num return None Space complexity： O(n) Time complexity： O(n) Optimization using XOR The most crucial trick here is to recognize that if you XOR any same number together, you cancel it out (=0). Explanation: nums = [2, 4, 5, 4, 3, 5, 2] XORing everything together = 2 ^ 4 ^ 5 ^ 4 ^ 3 ^ 5 ^ 2 = (2^2) ^ (4^4) ^ (5^5) ^ 3 = 0 ^ 0 ^0 ^ 3 = 3 class Solution: def singleNumber(self, nums: List[int]) -&gt; int: return reduce(lambda x, y: x^y, nums, 0) Space complexity： O(1) time complexity： O(n) Reference Reduce list(map(str, [1, 2, 3, 4, 5, 6, 7, 8, 9])) # output: [&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;, &#39;6&#39;, &#39;7&#39;, &#39;8&#39;, &#39;9&#39;] Map reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4) # convert string to integer DIGITS = {&#39;0&#39;: 0, &#39;1&#39;: 1, &#39;2&#39;: 2, &#39;3&#39;: 3, &#39;4&#39;: 4, &#39;5&#39;: 5, &#39;6&#39;: 6, &#39;7&#39;: 7, &#39;8&#39;: 8, &#39;9&#39;: 9} def char2num(s): return DIGITS[s] def str2int(s): return reduce(lambda x, y: x * 10 + y, map(char2num, s)) Happy number A happy number is a number defined by the following process: Starting with any positive integer, replace the number by the sum of the squares of its digits, and repeat the process until the number equals 1 (where it will stay), or it loops endlessly in a cycle which does not include 1. Those numbers for which this process ends in 1 are happy numbers. Example: Input: 19 Output: true Explanation: \\(1^2 + 9^2 = 82\\) \\(8^2 + 2^2 = 68\\) \\(6^2 + 8^2 = 100\\) \\(1^2 + 0^2 + 0^2 = 1\\) Solution Floyd's cycle detection 核心思路：如果一个数字不是 happy number 那么它拆分后的数字的和一定会循环，通过Floyd's cycle detection算法做循环检测。 Short Version utilizing walrus operator := class Solution: def isHappy(self, n: int) -&gt; bool: def next_num(num): return sum(map(lambda x:int(x)**2, str(num))) slow, fast = n, next_num(n) while (slow:=next_num(slow)) != (fast:=next_num(next_num(fast))) and fast != 1: continue return fast == 1 or not slow == fast Easier to understand version class Solution: def isHappy(self, n: int) -&gt; bool: def next_num(num): return sum(map(lambda x:int(x)**2, str(num))) slow, fast = n, next_num(n) while slow != fast and fast != 1: slow = next_num(slow) fast = next_num(next_num(fast)) return fast == 1 or not slow == fast Reference Algorithm： Floyd's cycle detection What we need to do in case we need the starting point of the loop ? - Once we know for sure that a loop is present. - Move the slowPointer to start of the list,(i.e headNode) and let fastPointer remain there at the meeting point - Now move both the pointers one node at a time - The point where both pointers will meet, is our required start of the loop. The algorithm uses O(λ + μ) operations of these types, and O(1) storage space. Detecting start of a loop in singly Linked List Floyd's Cycle detection algorithm | Determining the starting point of cycle Another solution class Solution: def isHappy(self, n: int) -&gt; bool: # let&#39;s try different n: # true (1) -&gt; 1 # false (2) -&gt; 4 -&gt; 16 -&gt; 37 -&gt; 58 -&gt; 89 -&gt; 145 -&gt; 42 -&gt; 20 -&gt; 4 # false (3) -&gt; 9 -&gt; 81 -&gt; 65 -&gt; 61 -&gt; 37 (look at 2) # false (4) -&gt; (look at 2) # false (5) -&gt; 25 -&gt; 29 -&gt; 85 -&gt; 89 (look at 2) # false (6) -&gt; 36 -&gt; 45 -&gt; 41 -&gt; 17 -&gt; 50 -&gt; 25 (look at 5) # true (7) -&gt; 49 -&gt; 97 -&gt; 10 # false (8) -&gt; 64 -&gt; 52 -&gt; 29 (look at 5) # false (9) -&gt; 9 -&gt; 81 -&gt; 65 (look at 3) # # All other n &gt;= 10, while computing will become [1-9], # So there are two cases 1 and 7 which are true. # # Notice, that all falses has the same path as 2 (loop). counting = 0 num = n while True: counting = 0 for str_num in str(num): counting = counting + pow(int(str_num), 2) if counting &gt;= 1 and counting &lt;=9: if counting == 1 or counting == 7: return True else: return False else: num = counting Group Anagrams Given an array of strings, group anagrams together. Example: Input: [\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"], Output: [ [\"ate\",\"eat\",\"tea\"], [\"nat\",\"tan\"], [\"bat\"] ] My solution（bad） class Solution: def groupAnagrams(self, strs: List[str]) -&gt; List[List[str]]: group_list = [] group_list.append([strs[0]]) for i in range(1, len(strs)): sorted_str = sorted(strs[i]) for j in range(0, len(group_list)): sorted_comp_str = sorted(group_list[j][0]) if sorted_str == sorted_comp_str: group_list[j].append(strs[i]) break if j == len(group_list) - 1: group_list.append([strs[i]]) break return group_list Result: Time Limit Exceeded Summary 这个解法看起来没什么毛病，如果strs长度很小，也能正常工作，但是当字符串数组strs长度特别大时， 毛病就暴露出来了，速度很慢，效率低，会出现超时（Time Limit Exceeded）未完成的情况。 Nice solution with dictionary and tuple class Solution: def groupAnagrams(self, strs: List[str]) -&gt; List[List[str]]: # create a null dictionary group_list = {} for s in strs: # sort the string&#39;s letters and save as a tuple key = tuple(sorted(s)) # search dictionary with the str&#39;s tuple and save the new value group_list[key] = group_list.get(key, []) + [s] return group_list.values() Summary Tuple can be used for the dictionary's key. wow~ Dictionary can speed up the search. Maximum Subarray Given an integer array nums, find the contiguous subarray (containing at least one number) which has the largest sum and return its sum. Example: Input: [-2,1,-3,4,-1,2,1,-5,4], Output: 6 Explanation: [4,-1,2,1] has the largest sum = 6. Follow up: If you have figured out the O(n) solution, try coding another solution using the divide and conquer approach, which is more subtle. Solution 核心思路： 当sum&lt;0时，sum+x一定比x小，故当sum为负数时，可直接将sum置零。 class Solution: def maxSubArray(self, nums: List[int]) -&gt; int: sum_ = 0 max_sum = nums[0] for num in nums: sum_ = sum_ + num if sum_ &gt; max_sum: max_sum = sum_ sum_ = max(sum_, 0) return max_sum Best Time to Buy and Sell Stock II Say you have an array prices for which the ith element is the price of a given stock on day i. Design an algorithm to find the maximum profit. You may complete as many transactions as you like (i.e., buy one and sell one share of the stock multiple times). Note: You may not engage in multiple transactions at the same time (i.e., you must sell the stock before you buy again). Example 1: Input: [7,1,5,3,6,4] Output: 7 Explanation: Buy on day 2 (price = 1) and sell on day 3 (price = 5), profit = 5-1 = 4. Then buy on day 4 (price = 3) and sell on day 5 (price = 6), profit = 6-3 = 3. Solution 哇这个题，真的让我怀疑自己的智商了...😂，我刚开始的答案写了好多行代码，然后去讨论区学习的时候发现大家都是人才啊...比如下面这个： class Solution: def maxProfit(self, prices: List[int]) -&gt; int: max_profit = 0 for i in range(0, len(prices)-1): max_profit += max(prices[i+1]-prices[i], 0) return max_profit Mine class Solution: def maxProfit(self, prices: List[int]) -&gt; int: max_profit = 0 buy_i = 0 sell_i = 1 need_sell = 1 need_buy = 0 for i in range(1, len(prices)): if prices[sell_i] &lt; prices[buy_i]: need_buy = 1 need_sell = 0 else: need_buy = 0 need_sell = 1 if need_buy == 1: if prices[i] &lt; prices[buy_i]: buy_i = i if i &lt; len(prices) - 1: sell_i = i + 1 else: sell_i = i continue if need_sell == 1: if prices[i] &gt;= prices[sell_i]: sell_i = i if i == len(prices) - 1: max_profit += prices[sell_i] - prices[buy_i] else: max_profit += prices[sell_i] - prices[buy_i] buy_i = i if i &lt; len(prices) - 1: sell_i = i + 1 need_buy = 1 need_sell = 0 return max_profit emmmm...我需要反思一下😞 Counting Elements Given an integer array arr, count element x such that x + 1 is also in arr. If there're duplicates in arr, count them seperately. Examples: Input: arr = [1,2,3] Output: 2 Explanation: 1 and 2 are counted cause 2 and 3 are in arr. Input: arr = [1,1,3,3,5,5,7,7] Output: 0 Explanation: No numbers are counted, cause there's no 2, 4, 6, or 8 in arr. Input: arr = [1,3,2,3,5,0] Output: 3 Explanation: 0, 1 and 2 are counted cause 1, 2 and 3 are in arr. Solution Mine 这个题没有找到大家的讨论，所以我也不知道其他小伙伴的解题思路是什么样的，但是我总觉得大家会有更好的解决方案，我这边就先po出我的解法，欢迎大家提供自己的思路和建议。 思路： 现将数组排序，然后通过两个指针：pre和cur进行对比，需要注意的是数字相同的数应该同时被计数或都不计数。 class Solution: def countElements(self, arr: List[int]) -&gt; int: arr_sorted = sorted(arr) count = 0 # 指向当前需要判断是否能被计数的数 pre = 0 # 指向当前pre后面的数，用于判断pre是否能被计数 cur = 1 # 如果cur指向的数等于pre指向的数，则增加leave， # 如果pre可以被计数，则和pre相等的数也应该被计数 leave = 1 # 当pre和cur指向同一index时停止循环 while pre^cur: sub = arr_sorted[cur] - arr_sorted[pre] if sub &lt;= 1: if sub == 1: count += leave pre = cur leave = 1 elif cur == len(arr)-1: break; else: leave +=1 else: pre = cur leave = 1 cur = min(cur+1, len(arr)-1) return count Summary 我发现我的写作能力真的好差啊，有的时候知道怎么回事就是写不出来，捉急。。。希望看到的小伙伴不要介意，我在努力，希望以后会越来越好，唉😌，对不起高中语文老师一对一的辅导啊。好啦，这期就更新完了。 对了，我是准备一次更新一周的内容，然后可能想起来就会更新一部分发布出来，如果没更完最后会显示Updating...。一起期待第二期吧~😊","categories":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Coding","slug":"Technology/Coding","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/"},{"name":"Leetcode","slug":"Technology/Coding/Leetcode","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/Leetcode/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://littlelittlemoon.github.io/tags/Leetcode/"},{"name":"Python","slug":"Python","permalink":"https://littlelittlemoon.github.io/tags/Python/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://littlelittlemoon.github.io/tags/Algorithm/"}],"keywords":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Coding","slug":"Technology/Coding","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/"},{"name":"Leetcode","slug":"Technology/Coding/Leetcode","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/Leetcode/"}]},{"title":"Fraud Detection | Imbalanced data modeling","slug":"Technology/Credit Card Fraud Detection","date":"2020-03-21T13:53:06.000Z","updated":"2020-04-12T13:06:54.542Z","comments":true,"path":"2020/03/21/Technology/Credit Card Fraud Detection/","link":"","permalink":"https://littlelittlemoon.github.io/2020/03/21/Technology/Credit%20Card%20Fraud%20Detection/","excerpt":"","text":"LDA, QDA and LR for fraud detection | Imbalanced data modeling %matplotlib inline # import warnings filter from warnings import simplefilter # ignore all future warnings simplefilter(action=&#39;ignore&#39;, category=FutureWarning) prepare data import pandas as pd # load data default_data = pd.read_csv(&quot;data/Default.csv&quot;) # prepare data default_data.loc[default_data[&#39;default&#39;] == &#39;No&#39;, &quot;default&quot;] = 0 default_data.loc[default_data[&#39;default&#39;] == &#39;Yes&#39;, &quot;default&quot;] = 1 default_data.loc[default_data[&#39;student&#39;] == &#39;No&#39;, &quot;student&quot;] = 0 default_data.loc[default_data[&#39;student&#39;] == &#39;Yes&#39;, &quot;student&quot;] = 1 default_data.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Unnamed: 0 default student balance income count 10000.00000 10000.000000 10000.000000 10000.000000 10000.000000 mean 5000.50000 0.033300 0.294400 835.374886 33516.981876 std 2886.89568 0.179428 0.455795 483.714985 13336.639563 min 1.00000 0.000000 0.000000 0.000000 771.967729 25% 2500.75000 0.000000 0.000000 481.731105 21340.462903 50% 5000.50000 0.000000 0.000000 823.636973 34552.644802 75% 7500.25000 0.000000 1.000000 1166.308386 43807.729272 max 10000.00000 1.000000 1.000000 2654.322576 73554.233495 split training and testing set from sklearn.model_selection import train_test_split # create features and target features = [&quot;balance&quot;, &quot;income&quot;] X = default_data[features] y = default_data.default # slipt data set into training and testing set train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.7, random_state=1) import numpy as np import matplotlib as mpl from scipy import linalg from matplotlib import colors import matplotlib.pyplot as plt from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis from sklearn.linear_model import LogisticRegression Plot function # set colormap cmap = colors.LinearSegmentedColormap( &#39;red_blue_classes&#39;, {&#39;red&#39;: [(0, 1, 1), (1, 0.7, 0.7)], &#39;green&#39;: [(0, 0.7, 0.7), (1, 0.7, 0.7)], &#39;blue&#39;: [(0, 0.7, 0.7), (1, 1, 1)]}) plt.cm.register_cmap(cmap=cmap) # Plot function def plot_data(model, X, y, y_pred): plt.ylabel(&#39;income&#39;) plt.xlabel(&#39;balance&#39;) tp = (y == y_pred) # True Positive tp0, tp1 = tp[y == 0], tp[y == 1] X0, X1 = X[y == 0], X[y == 1] X0_tp, X0_fp = X0[tp0], X0[~tp0] X1_tp, X1_fp = X1[tp1], X1[~tp1] # true class 0: dots, false class 0: x plt.scatter(X0_tp[&quot;balance&quot;], X0_tp[&quot;income&quot;], marker=&#39;.&#39;, color=&#39;red&#39;) plt.scatter(X0_fp[&quot;balance&quot;], X0_fp[&quot;income&quot;], marker=&#39;x&#39;, s=20, color=&#39;#990000&#39;) # dark red # true class 1: dots, false class 1: x plt.scatter(X1_tp[&quot;balance&quot;], X1_tp[&quot;income&quot;], marker=&#39;.&#39;, color=&#39;blue&#39;) plt.scatter(X1_fp[&quot;balance&quot;], X1_fp[&quot;income&quot;], marker=&#39;x&#39;, s=20, color=&#39;#000099&#39;) # dark blue # class 0 and 1 : all areas for decision boundary nx, ny = 200, 100 x_min, x_max = plt.xlim() y_min, y_max = plt.ylim() xx, yy = np.meshgrid(np.linspace(x_min, x_max, nx), np.linspace(y_min, y_max, ny)) Z = model.predict_proba(np.c_[xx.ravel(), yy.ravel()]) Z = Z[:, 1].reshape(xx.shape) plt.pcolormesh(xx, yy, Z, cmap=&#39;red_blue_classes&#39;, norm=colors.Normalize(0., 1.), zorder=0) # plot decision boundary plt.contour(xx, yy, Z, [0.5], linewidths=2., colors=&#39;white&#39;) plt.axis(&#39;tight&#39;) plt.tight_layout() plt.subplots_adjust(top=0.92) plt.show() Linear Discriminant Analysis # Linear Discriminant Analysis plt.figure(figsize=(6, 7), facecolor=&#39;white&#39;) plt.title(&#39;Linear Discriminant Analysis&#39;, y=1, fontsize=15) lda = LinearDiscriminantAnalysis(solver=&quot;svd&quot;, store_covariance=True) y_pred = lda.fit(train_X, train_y).predict(test_X) plot_data(lda, test_X, test_y, y_pred) png Quadratic Discriminant Analysis # Quadratic Discriminant Analysis plt.figure(figsize=(6, 7), facecolor=&#39;white&#39;) plt.title(&#39;Quadratic Discriminant Analysis&#39;, y=1, fontsize=15) qda = QuadraticDiscriminantAnalysis(store_covariance=True) y_pred = qda.fit(train_X, train_y).predict(test_X) plot_data(qda, test_X, test_y, y_pred) png Use LogisticRegression directly to model the data If I use this data directly to feed the LogisticRegression model, the model will prefer to predict all as 0 for a high accuracy of 0 prediction. print(default_data.default.value_counts(dropna = False)) print(&quot;The mean of default: &quot;, default_data.default.mean()) 0 9667 1 333 Name: default, dtype: int64 The mean of default: 0.0333 NOTE: As it showing above: the provided data with very low proportion of positive signals. Conclusion: The provided data is imbalanced ! Solution: usually for imbalanced data, there are some solutions: 1. Collect more data 2. Down-Sampling or Over-Sampling to get balanced samples 3. Change the Thresholds to adjust the prediction 4. Assign class weights for the low rate class from sklearn.metrics import confusion_matrix, auc, roc_curve, roc_auc_score, recall_score, precision_recall_curve from sklearn.metrics import make_scorer, precision_score from sklearn.model_selection import GridSearchCV # Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = .33, stratify = y) logitreg_parameters = {&#39;C&#39;: np.power(10.0, np.arange(-3, 3))} logitreg = LogisticRegression(verbose = 3, warm_start = True) logitreg_grid = GridSearchCV(logitreg, param_grid = logitreg_parameters, scoring = &#39;roc_auc&#39;, n_jobs = 1) logitreg_grid.fit(train_X, train_y) GridSearchCV(cv=None, error_score=nan, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class=&#39;auto&#39;, n_jobs=None, penalty=&#39;l2&#39;, random_state=None, solver=&#39;lbfgs&#39;, tol=0.0001, verbose=3, warm_start=True), iid=&#39;deprecated&#39;, n_jobs=1, param_grid={&#39;C&#39;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])}, pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=False, scoring=&#39;roc_auc&#39;, verbose=0) # draw decision boundary with LogisticRegression directly plt.figure(figsize=(6, 7), facecolor=&#39;white&#39;) plt.title(&#39;Logistic Regression directly&#39;, y=1, fontsize=15) y_pred = logitreg_grid.predict(test_X) splot = plot_data(logitreg_grid, test_X, test_y, y_pred) png # on OVER-Sampled TRAINing data print(&quot;\\n The recall score on Training data is:&quot;, recall_score(train_y, logitreg_grid.predict(train_X))) # 0.32 print(&quot;\\n The precision score on Training data is:&quot;, precision_score(train_y, logitreg_grid.predict(train_X))) # 0.74 # on the separated TEST data print(&quot;\\n Thre recall score on Test data is:&quot;, recall_score(test_y, logitreg_grid.predict(test_X))) # 0.32 print(&quot;\\n Thre precision score on Test data is:&quot;, precision_score(test_y, logitreg_grid.predict(test_X))) # 0.75 print(&quot;\\n Thre Confusion Matrix on Test data is:&quot;, confusion_matrix(test_y, logitreg_grid.predict(test_X))) # [[3178 12][ 74 36]] The recall score on Training data is: 0.32231404958677684 The precision score on Training data is: 0.7222222222222222 Thre recall score on Test data is: 0.3626373626373626 Thre precision score on Test data is: 0.673469387755102 Thre Confusion Matrix on Test data is: [[2893 16] [ 58 33]] Conclusions: From the output above, on the training data, the recall score is 0.32 which means 32 over 100 of the True positive conditions are predicted correctly. And 74 over 100 of the predicted positives are True Positive. On the Test data, the model performance metric evalued by recall or precision are close to the Training data. There is a precision score of 0.81 on the Test data, which means 81 out of 100 predicted positives are True positives. From Confusion Matrix, 36 of 110 True Positives are predicted as positives. And of all 48 predicted as positive, 36 of them are True positives. Change the Thresholds plot roc curve def plot_roc(new_thresholds, logitreg_grid): y_train_pred_probas = logitreg_grid.predict_proba(train_X)[:, 1] # prob of predict as 1 fpr, tpr, thresholds = roc_curve(train_y, y_train_pred_probas) # precision_recall_curve roc = pd.DataFrame({&#39;FPR&#39;:fpr, &#39;TPR&#39;:tpr, &#39;Thresholds&#39;:thresholds}) plt.figure() plt.title(&#39;ROC Curve&#39;, y = 1, fontsize = 15) plt.plot(roc.FPR, roc.TPR) plt.axvline(new_thresholds, color = &#39;#00C851&#39;, linestyle = &#39;--&#39;) plt.xlabel(&quot;FPR&quot;) plt.ylabel(&quot;TPR&quot;) plt.show() new_threshold = 0.1 # 0.5 is the default value plot_roc(new_threshold, logitreg_grid) png By default, the threshold is 0.5. Since the recall score is low, I'm trying to lower the threshold to get more predicted as Positive. At the same time, more True Negative data will be falsely predicted as Positive. So the Precision score will be lower. y_test_pred_probas = logitreg_grid.predict_proba(test_X)[:, 1] y_test_pred = (y_test_pred_probas &gt;= new_threshold).astype(int) print(&quot;After change threshold to 0.1, the recall socre on Test data is:&quot;) print(recall_score(test_y, y_test_pred)) # 0.736 print(&quot;After change threshold to 0.1, the precision socre on Test data is:&quot;) print(precision_score(test_y, y_test_pred)) # 0.301 print(&quot;After change threshold to 0.1, the Confusion Matrix on Test data is:&quot;) print(confusion_matrix(test_y, y_test_pred)) # [[3002 188][ 29 81]] After change threshold to 0.1, the recall socre on Test data is: 0.7142857142857143 After change threshold to 0.1, the precision socre on Test data is: 0.25 After change threshold to 0.1, the Confusion Matrix on Test data is: [[2714 195] [ 26 65]] Create Over-sampling data and Fit the model oversample_ratio = sum(train_y == 0) / sum(train_y == 1) # size to repeat y == 1 # repeat the positive data for X and y y_train_pos_oversample = pd.concat([train_y[train_y==1]] * int(oversample_ratio), axis = 0) X_train_pos_oversample = pd.concat([train_X.loc[train_y==1, :]] * int(oversample_ratio), axis = 0) # concat the repeated data with the original data together y_train_oversample = pd.concat([train_y, y_train_pos_oversample], axis = 0).reset_index(drop = True) X_train_oversample = pd.concat([train_X, X_train_pos_oversample], axis = 0).reset_index(drop = True) print(y_train_oversample.value_counts(dropna = False, normalize = True)) logitreg_parameters = {&#39;C&#39;: np.power(10.0, np.arange(-3, 3))} logitreg = LogisticRegression(verbose = 3, warm_start = True) logitreg_grid = GridSearchCV(logitreg, param_grid = logitreg_parameters, scoring = &#39;roc_auc&#39;, n_jobs = 1) logitreg_grid.fit(X_train_oversample, y_train_oversample) 1 0.500665 0 0.499335 Name: default, dtype: float64 GridSearchCV(cv=None, error_score=nan, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class=&#39;auto&#39;, n_jobs=None, penalty=&#39;l2&#39;, random_state=None, solver=&#39;lbfgs&#39;, tol=0.0001, verbose=3, warm_start=True), iid=&#39;deprecated&#39;, n_jobs=1, param_grid={&#39;C&#39;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])}, pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=False, scoring=&#39;roc_auc&#39;, verbose=0) # Logistic Regression with Over-sampling plt.figure(figsize=(6, 7), facecolor=&#39;white&#39;) plt.title(&#39;Logistic Regression with Over-sampling&#39;, y=1, fontsize=15) y_pred = logitreg_grid.predict(test_X) plot_data(logitreg_grid, test_X, test_y, y_pred) png # on OVER-Sampled TRAINing data print(&quot;After Over-Sampling, the recall score on Training data is&quot;) print(recall_score(y_train_oversample, logitreg_grid.predict(X_train_oversample))) # 0.865 print(&quot;After Over-Sampling, the precision score on Training data is&quot;) print(precision_score(y_train_oversample, logitreg_grid.predict(X_train_oversample))) # 0.727 # on the TESTing data print(&quot;After Over-Sampling, the recall score on Test data is&quot;) print(recall_score(test_y, logitreg_grid.predict(test_X))) # 0.854 print(&quot;After Over-Sampling, the precision score on Test data is&quot;) print(precision_score(test_y, logitreg_grid.predict(test_X))) # 0.080 print(&quot;After Over-Sampling, the Confusion Matrix on Test data is&quot;) print(confusion_matrix(test_y, logitreg_grid.predict(test_X))) # [[2113 1077][ 16 94]] After Over-Sampling, the recall score on Training data is 0.8884297520661157 After Over-Sampling, the precision score on Training data is 0.8717057631045467 After Over-Sampling, the recall score on Test data is 0.8791208791208791 After Over-Sampling, the precision score on Test data is 0.17094017094017094 After Over-Sampling, the Confusion Matrix on Test data is [[2521 388] [ 11 80]] Conclusion: From the output above, on the training data, the recall score is 0.865 which means 86.5 over 100 of the True conditions are predicted correctly. And 85.4 over 100 of the predicted positives are really positive. However, there is only a precision score of 0.080 on the Test data, which means only 8 out of 100 predicted positives are real positives. From Confusion Matrix, 94 of 110 True Positives are predicted as positives. However, the model predicted 1077 Negative data as Positive. That is, this model has pretty strong over-fitting. Change the Thresholds new_threshold = 0.2 plot_roc(new_threshold, logitreg_grid) png y_test_pred_probas = logitreg_grid.predict_proba(test_X)[:, 1] y_test_pred = (y_test_pred_probas &gt;= new_threshold).astype(int) print(&quot;After change threshold to 0.2, the recall socre on Test data is:&quot;) print(recall_score(test_y, y_test_pred)) # 0.990 print(&quot;After change threshold to 0.2, the precision socre on Test data is:&quot;) print(precision_score(test_y, y_test_pred)) # 0.047 print(&quot;After change threshold to 0.2, the Confusion Matrix on Test data is:&quot;) print(confusion_matrix(test_y, y_test_pred)) # [[ 1013 2177][ 1 109]] After change threshold to 0.2, the recall socre on Test data is: 0.9340659340659341 After change threshold to 0.2, the precision socre on Test data is: 0.10023584905660378 After change threshold to 0.2, the Confusion Matrix on Test data is: [[2146 763] [ 6 85]] Conclusion: After over-sampling, the model will have higher recall rate. That is, the model will work better on detect the Frauds from True Frauds. The price is the lower precision rate. Logistic Regression with class_weight Rather than over-sampling, we can assign more weights to the lower rate class. we can write out the Likelihood function for Logistic Regression, the Over-Sampling and the assigning more Weights will be equivalent. positive_weight = sum(train_y == 0) / sum(train_y == 1) # size to repeat y == 1 logitreg_parameters = {&#39;C&#39;: np.power(10.0, np.arange(-3, 3))} logitreg = LogisticRegression(class_weight = {0 : 1, 1 : positive_weight}, verbose = 3, warm_start = True) logitreg_grid = GridSearchCV(logitreg, param_grid = logitreg_parameters, scoring = &#39;roc_auc&#39;, n_jobs = 1) logitreg_grid.fit(train_X, train_y) GridSearchCV(cv=None, error_score=nan, estimator=LogisticRegression(C=1.0, class_weight={0: 1, 1: 27.925619834710744}, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class=&#39;auto&#39;, n_jobs=None, penalty=&#39;l2&#39;, random_state=None, solver=&#39;lbfgs&#39;, tol=0.0001, verbose=3, warm_start=True), iid=&#39;deprecated&#39;, n_jobs=1, param_grid={&#39;C&#39;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])}, pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=False, scoring=&#39;roc_auc&#39;, verbose=0) # Logistic Regression with class_weight plt.figure(figsize=(6, 7), facecolor=&#39;white&#39;) plt.title(&#39;Logistic Regression&#39;, y=1, fontsize=15) y_pred = logitreg_grid.predict(test_X) plot_data(logitreg_grid, test_X, test_y, y_pred) png print(&quot;After assign class_weight, the recall score on Training data is&quot;) print(recall_score(y_train_oversample, logitreg_grid.predict(X_train_oversample))) # 0.856 print(&quot;After assign class_weight, the precision score on Training data is&quot;) print(precision_score(y_train_oversample, logitreg_grid.predict(X_train_oversample))) # 0.729 # on the separated TEST data print(&quot;After assign class_weight, the recall score on Test data is&quot;) print(recall_score(test_y, logitreg_grid.predict(test_X))) # 0.845 print(&quot;After assign class_weight, the precision score on Test data is&quot;) print(precision_score(test_y, logitreg_grid.predict(test_X))) # 0.081 print(&quot;After assign class_weight, the Confusion Matrix on Test data is&quot;) print(confusion_matrix(test_y, logitreg_grid.predict(test_X))) # [[2135 1055] [ 17 93]] print(&quot;After assign class_weight, the ROC AUC Score on Test data is&quot;) print(roc_auc_score(test_y, logitreg_grid.predict(test_X))) # 0.757 After assign class_weight, the recall score on Training data is 0.859504132231405 After assign class_weight, the precision score on Training data is 0.7171530599679843 After assign class_weight, the recall score on Test data is 0.8791208791208791 After assign class_weight, the precision score on Test data is 0.075046904315197 After assign class_weight, the Confusion Matrix on Test data is [[1923 986] [ 11 80]] After assign class_weight, the ROC AUC Score on Test data is 0.7700863934965 Conclusion: If I set up the class weight for the positive as the ratio of non-Fault / Fault, I will get the result close to the over-sampling. So, in summary: This specific data is about fraud detection. So the model should focus on to find the frauds to avoid potential loss for the bank. That is, we focus on recall rate. Conclusion If we use the imbalanced data directly, we will get low performance model since the model prefer to predict to the class with dominated frequency class. The recall rate is 0.31. That is, only 31% of the frauds can be detected by this model. To fix that, one way is to do over-sampling or down-sampling. If we use over-sampling, the model performance will be improved a lot. For this specific case, the recall rate on the independent test set will be improved from 0.31 to 0.87 Another way to improve the model performance is to assign more weights to the low frequency class. Generally speaking, for Logistic Regression, assigning weights is similar to over-sampling, from the likelihood function perspective. The final output results are close too as demonstrated above. Reference Credit Card Fraud Detection / Imbalanced data modeling - Part I: Logistic Regression Credit Fraud || Dealing with Imbalanced Datasets","categories":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Machine Learning","slug":"Technology/Machine-Learning","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/"},{"name":"Imbalanced Data Modeling","slug":"Technology/Machine-Learning/Imbalanced-Data-Modeling","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/Imbalanced-Data-Modeling/"}],"tags":[{"name":"LDA","slug":"LDA","permalink":"https://littlelittlemoon.github.io/tags/LDA/"},{"name":"QDA","slug":"QDA","permalink":"https://littlelittlemoon.github.io/tags/QDA/"},{"name":"LR","slug":"LR","permalink":"https://littlelittlemoon.github.io/tags/LR/"},{"name":"Imbalanced Data Modeling","slug":"Imbalanced-Data-Modeling","permalink":"https://littlelittlemoon.github.io/tags/Imbalanced-Data-Modeling/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://littlelittlemoon.github.io/tags/Machine-Learning/"},{"name":"Classify","slug":"Classify","permalink":"https://littlelittlemoon.github.io/tags/Classify/"}],"keywords":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Machine Learning","slug":"Technology/Machine-Learning","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/"},{"name":"Imbalanced Data Modeling","slug":"Technology/Machine-Learning/Imbalanced-Data-Modeling","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/Imbalanced-Data-Modeling/"}]},{"title":"Evalution of hair and scalp condition based on microscopy image analysis | Hair Thickness - part 1","slug":"Technology/Evalution of hair and scalp condition based on microscopy image analysis  | Hair Thickness - 1","date":"2019-12-29T13:21:24.000Z","updated":"2020-04-18T11:07:27.929Z","comments":true,"path":"2019/12/29/Technology/Evalution of hair and scalp condition based on microscopy image analysis  | Hair Thickness - 1/","link":"","permalink":"https://littlelittlemoon.github.io/2019/12/29/Technology/Evalution%20of%20hair%20and%20scalp%20condition%20based%20on%20microscopy%20image%20analysis%20%20|%20Hair%20Thickness%20-%201/","excerpt":"","text":"Paper: Evalution of hair and scalp condition based on microscopy image analysis &#x6458;&#x8981;&#x7FFB;&#x8BD1;&#xFF1A;&#x7531;&#x4E8E;IT&#x6280;&#x672F;&#x7684;&#x5FEB;&#x901F;&#x90E8;&#x7F72;, &#x533B;&#x7597;&#x4FDD;&#x5065;&#x670D;&#x52A1;&#x8FDB;&#x5165;&#x4E86;&#x4E00;&#x4E2A;&#x65B0;&#x65F6;&#x4EE3;&#x3002;&#x8BF8;&#x5982;&#x5FC3;&#x810F;&#x76D1;&#x62A4;&#x4E4B;&#x7C7B;&#x7684;&#x67D0;&#x4E9B;&#x670D;&#x52A1;&#x5BF9;&#x4E8E;&#x751F;&#x547D;&#x81F3;&#x5173;&#x91CD;&#x8981;, &#x5E76;&#x6709;&#x52A9;&#x4E8E;&#x633D;&#x6551;&#x751F;&#x547D;&#x3002;&#x53E6;&#x4E00;&#x65B9;&#x9762;, &#x76D1;&#x6D4B;&#x8131;&#x53D1;&#x662F;&#x53E6;&#x4E00;&#x79CD;&#x6709;&#x8DA3;&#x7684;&#x4FDD;&#x5065;&#x670D;&#x52A1;&#x3002;&#x5C3D;&#x7BA1;&#x8FD9;&#x5BF9;&#x751F;&#x6D3B;&#x5E76;&#x4E0D;&#x91CD;&#x8981;, &#x4F46;&#x4EBA;&#x4EEC;&#x8FD8;&#x662F;&#x4F1A;&#x975E;&#x5E38;&#x6CE8;&#x610F;&#x81EA;&#x5DF1;&#x7684;&#x5934;&#x53D1;&#x72B6;&#x51B5;&#x3002;&#x8131;&#x53D1;&#x662F;&#x4E0E;&#x5934;&#x53D1;&#x72B6;&#x51B5;&#x6709;&#x5173;&#x7684;&#x4E3B;&#x8981;&#x95EE;&#x9898;&#x4E4B;&#x4E00;, &#x56E0;&#x4E3A;&#x8FC7;&#x591A;&#x548C;&#x65E0;&#x610F;&#x7684;&#x8131;&#x53D1;&#x53EF;&#x80FD;&#x5BFC;&#x81F4;&#x79C3;&#x5934;&#x3002;&#x53EF;&#x4EE5;&#x5728;&#x62A4;&#x53D1;&#x5E97;&#x4E13;&#x4E1A;&#x8FDB;&#x884C;&#x62A4;&#x53D1;, &#x4F46;&#x662F;&#x8FD9;&#x9700;&#x8981;&#x5F88;&#x591A;&#x65F6;&#x95F4;&#x548C;&#x6210;&#x672C;&#x3002;&#x6700;&#x8FD1;, &#x7531;&#x4E8E;&#x5EC9;&#x4EF7;&#x7684;&#x667A;&#x80FD;&#x8BBE;&#x5907;, &#x5BF9;&#x5934;&#x53D1;&#x72B6;&#x51B5;&#x7684;&#x81EA;&#x6211;&#x8BCA;&#x65AD;&#x5DF2;&#x6210;&#x4E3A;&#x53EF;&#x80FD;&#x3002;&#x4ECD;&#x7136;&#x5F88;&#x5C11;&#x5F00;&#x53D1;&#x7528;&#x4E8E;&#x8BC4;&#x4F30;&#x5934;&#x53D1;&#x72B6;&#x51B5;&#x7684;&#x5E94;&#x7528;&#x3002;&#x5728;&#x672C;&#x6587;&#x4E2D;, &#x6211;&#x4EEC;&#x63D0;&#x51FA;&#x4E86;&#x4E00;&#x79CD;&#x65B0;&#x65B9;&#x6848;, &#x901A;&#x8FC7;&#x4ECE;&#x663E;&#x5FAE;&#x955C;&#x56FE;&#x50CF;&#x4E2D;&#x63D0;&#x53D6;&#x5404;&#x79CD;&#x7279;&#x5F81;&#x6765;&#x8BC4;&#x4F30;&#x5934;&#x53D1;&#x548C;&#x5934;&#x76AE;&#x7684;&#x72B6;&#x51B5;&#x3002;&#x5176;&#x7279;&#x5F81;&#x5305;&#x62EC;&#x5934;&#x53D1;&#x7684;&#x539A;&#x5EA6;, &#x5934;&#x53D1;&#x7684;&#x5BC6;&#x5EA6;&#x548C;&#x5934;&#x76AE;&#x7684;&#x6591;&#x70B9;&#x3002;&#x901A;&#x8FC7;&#x5BF9;&#x539F;&#x578B;&#x7CFB;&#x7EDF;&#x8FDB;&#x884C;&#x5E7F;&#x6CDB;&#x7684;&#x5B9E;&#x9A8C;, &#x6211;&#x4EEC;&#x8BC1;&#x660E;&#x4E86;&#x8BE5;&#x65B9;&#x6848;&#x7684;&#x6709;&#x6548;&#x6027;&#x3002; &#x4E3A;&#x4E86;&#x5206;&#x6790;&#x5934;&#x76AE;&#x56FE;&#x50CF;, &#x5E94;&#x8BE5;&#x5C06;&#x5934;&#x53D1;&#x548C;&#x5934;&#x76AE;&#x5F7C;&#x6B64;&#x5206;&#x5F00;&#x3002;&#x4E24;&#x8005;&#x4E4B;&#x95F4;&#x6700;&#x660E;&#x663E;&#x7684;&#x533A;&#x522B;&#x662F;&#x5B83;&#x4EEC;&#x7684;&#x989C;&#x8272;&#x3002;&#x5934;&#x76AE;&#x76F8;&#x5BF9;&#x660E;&#x4EAE;, &#x5934;&#x53D1;&#x76F8;&#x5BF9;&#x6DF1;&#x8272;&#x3002;&#x56E0;&#x6B64;, &#x5728;&#x8BB8;&#x591A;&#x7814;&#x7A76;&#x4E2D;, &#x6839;&#x636E;&#x989C;&#x8272;&#x5BF9;&#x5934;&#x53D1;&#x548C;&#x5934;&#x76AE;&#x533A;&#x57DF;&#x8FDB;&#x884C;&#x5206;&#x7C7B;, &#x5E76;&#x6839;&#x636E;&#x8FD9;&#x79CD;&#x5206;&#x79BB;&#x8FDB;&#x884C;&#x56FE;&#x50CF;&#x5206;&#x6790;&#x3002; ## Overall steps for feature extraction Pre-processing &#x8BE5;&#x8BBA;&#x6587;&#x4E2D;&#x6240;&#x63D0;&#x5230;&#x7684;&#x56FE;&#x7247;&#x9884;&#x5904;&#x7406;&#x65B9;&#x6CD5;&#x548C;&#x201C;An Unsupervised Hair Segmentation and Counting System in Microscopy Images&#x201D;&#x4E2D;&#x76F8;&#x4F3C;, &#x5177;&#x4F53;&#x53EF;&#x53C2;&#x8003;&#xFF1A;&#x8BBA;&#x6587;&#x89E3;&#x8BFB; - An Unsupervised Hair Segmentation and Counting System in Microscopy Images &#x4E4B;&#x5934;&#x53D1;&#x8BA1;&#x6570;&#x95EE;&#x9898;&#x3002; 1. &#x88C1;&#x5207;&#x56FE;&#x50CF; 2. &#x56FE;&#x50CF;&#x589E;&#x5F3A;: &#x4F7F;&#x7528;Contrast stretching&#x65B9;&#x6CD5;, &#x589E;&#x52A0;&#x56FE;&#x50CF;&#x7684;&#x5BF9;&#x6BD4;&#x5EA6; 3. Morphological opening&#xFF1A;&#x53BB;&#x9664;&#x6CB9;&#x6027;&#x548C;&#x6E7F;&#x6DA6;&#x7684;&#x5934;&#x53D1;&#x5728;&#x5176;&#x663E;&#x5FAE;&#x955C;&#x56FE;&#x50CF;&#x4E2D;&#x5F62;&#x6210;&#x7684;&#x4EAE;&#x70B9; 4. &#x4E8C;&#x503C;&#x5316;&#xFF1A;&#x7ECF;&#x8FC7;&#x4E0A;&#x8FF0;&#x9884;&#x5904;&#x7406;&#x540E;, &#x5C06;&#x6240;&#x5F97;&#x56FE;&#x50CF;&#x8F6C;&#x6362;&#x4E3A;&#x7070;&#x5EA6;&#x56FE;&#x50CF;, &#x7136;&#x540E;&#x6839;&#x636E;Otsu&#x9608;&#x503C;&#x8F6C;&#x6362;&#x4E3A;&#x4E8C;&#x8FDB;&#x5236;&#x56FE;&#x50CF;&#x3002; &#x5728;&#x4E8C;&#x503C;&#x56FE;&#x50CF;&#x4E2D;, &#x201C; 0&#x201D;&#x548C;&#x201C; 1&#x201D;&#x5206;&#x522B;&#x8868;&#x793A;&#x5934;&#x53D1;&#x50CF;&#x7D20;&#x548C;&#x5934;&#x76AE;&#x50CF;&#x7D20;&#x3002; hair/scalp image analysis &#x5934;&#x53D1;&#x68C0;&#x6D4B; &#x6280;&#x672F; &#x4F7F;&#x7528;Canny&#x8FB9;&#x7F18;&#x68C0;&#x6D4B;&#x7B97;&#x6CD5;&#x4ECE;&#x4E8C;&#x8FDB;&#x5236;&#x56FE;&#x50CF;&#x4E2D;&#x83B7;&#x53D6;&#x6BDB;&#x53D1;&#x8F6E;&#x5ED3;&#x3002; &#x7ED3;&#x679C; - &#x56FE;2&#x663E;&#x793A;&#x4E86;&#x68C0;&#x6D4B;&#x548C;&#x5EFA;&#x6A21;&#x5934;&#x53D1;&#x7684;&#x6240;&#x6709;&#x6B65;&#x9AA4;&#x3002;&#x5BF9;&#x4E8E;&#x56FE;2&#xFF08;a&#xFF09;&#x4E2D;&#x7684;&#x539F;&#x59CB;&#x663E;&#x5FAE;&#x955C;&#x56FE;&#x50CF;, &#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x8BA1;&#x7B97;&#x51FA;&#x5934;&#x53D1;&#x8F6E;&#x5ED3;&#x548C;&#x9AA8;&#x9ABC;&#x3002; - &#x901A;&#x8FC7;&#x4F7F;&#x7528;&#x4E8C;&#x8FDB;&#x5236;&#x56FE;&#x50CF;&#x4E0A;&#x7684;&#x7A00;&#x758F;&#x8FD0;&#x7B97;&#xFF08;Thinning operation&#xFF09; &#x6765;&#x8BA1;&#x7B97;&#x5934;&#x53D1;&#x9AA8;&#x67B6;&#x3002;Thinning&#x662F;&#x4E00;&#x79CD;&#x5F62;&#x6001;&#x5B66;&#x8FD0;&#x7B97;, &#x53EF;&#x53BB;&#x9664;&#x6574;&#x4E2A;&#x4E8C;&#x8FDB;&#x5236;&#x56FE;&#x50CF;&#x4E2D;&#x7684;&#x524D;&#x666F;&#x3002; - &#x56FE;2&#xFF08;d&#xFF09;&#x663E;&#x793A;&#x4E86;&#x901A;&#x8FC7;&#x53E0;&#x52A0;&#x5934;&#x53D1;&#x8F6E;&#x5ED3;&#x548C;&#x9AA8;&#x9ABC;&#x5F97;&#x5230;&#x7684;&#x6700;&#x7EC8;&#x56FE;&#x50CF;&#x3002; &#x5934;&#x53D1;&#x539A;&#x5EA6;&#x8BA1;&#x7B97; &#x5934;&#x53D1;&#x539A;&#x5EA6;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x4E0E;&#x5934;&#x53D1;&#x5782;&#x76F4;&#x7EBF;&#x7684;&#x957F;&#x5EA6;&#x6765;&#x5B9A;&#x4E49;&#x3002;&#x8981;&#x83B7;&#x5F97;&#x5782;&#x76F4;&#x7EBF;, &#x6211;&#x4EEC;&#x9996;&#x5148;&#x9700;&#x8981;&#x8BA1;&#x7B97;&#x5934;&#x53D1;&#x65B9;&#x5411;. &#x901A;&#x8FC7;&#x8003;&#x8651;&#x76F8;&#x90BB;&#x50CF;&#x7D20;&#x5E76;&#x5E94;&#x7528;PCA&#xFF08;&#x4E3B;&#x6210;&#x5206;&#x5206;&#x6790;&#xFF09;&#x7B97;&#x6CD5;&#x6765;&#x8BA1;&#x7B97;&#x6BCF;&#x4E2A;&#x50CF;&#x7D20;&#x7684;&#x65B9;&#x5411;. &#x5F53;&#x8BA1;&#x7B97;&#x5934;&#x53D1;&#x9AA8;&#x67B6;&#x4E0A;&#x6240;&#x6709;&#x70B9;&#x7684;&#x65B9;&#x5411;&#x65F6;, &#x53EF;&#x4EE5;&#x8BA1;&#x7B97;&#x51FA;&#x6BCF;&#x4E2A;&#x70B9;&#x7684;&#x5782;&#x76F4;&#x7EBF;&#x3002;&#x7136;&#x540E;, &#x5782;&#x76F4;&#x7EBF;&#x4E0E;&#x5934;&#x53D1;&#x8FB9;&#x754C;&#x7684;&#x4EA4;&#x70B9;&#x4E4B;&#x95F4;&#x7684;&#x8DDD;&#x79BB;&#x5C31;&#x662F;&#x5934;&#x53D1;&#x7684;&#x539A;&#x5EA6;, &#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x4F7F;&#x7528;&#x6B27;&#x6C0F;&#x8DDD;&#x79BB;&#x6765;&#x8BA1;&#x7B97;&#xFF1A; &#x3C1;=(x2&#x2212;x1)2+(y2&#x2212;y1)2 \\rho = \\sqrt{\\smash[b]{(x_2-x_1)^2 + (y_2-y_1)^2}} &#x3C1;=(x2&#x200B;&#x2212;x1&#x200B;)2+(y2&#x200B;&#x2212;y1&#x200B;)2&#x200B; &#x6839;&#x636E;&#x6B27;&#x5F0F;&#x8DDD;&#x79BB;&#x3C1;\\rho&#x3C1;&#x53EF;&#x8BA1;&#x7B97;&#x51FA;&#x5934;&#x53D1;&#x7684;&#x5E73;&#x5747;&#x539A;&#x5EA6;&#xFF1A; Thincknessavg=1n&#x2211;i=1n(xi2&#x2212;xi1)2+(yi2&#x2212;yi1)2 Thinckness_{avg} =\\frac{1}{n}\\displaystyle\\sum_{i=1}^n\\sqrt{\\smash[b]{(x_{i2}-x_{i1})^2 + (y_{i2}-y_{i1})^2}} Thincknessavg&#x200B;=n1&#x200B;i=1&#x2211;n&#x200B;(xi2&#x200B;&#x2212;xi1&#x200B;)2+(yi2&#x200B;&#x2212;yi1&#x200B;)2&#x200B; &#x8FD9;&#x91CC;ThincknessavgThinckness_{avg}Thincknessavg&#x200B;&#x7684;&#x5355;&#x4F4D;&#x662F;&#x50CF;&#x7D20;, &#x56E0;&#x6B64;&#x9700;&#x8981;&#x4F7F;&#x7528;&#x7B49;&#x5F0F;&#x5C06;&#x5176;&#x66F4;&#x6539;&#x4E3A;&#x4EEA;&#x8868;&#x5355;&#x4F4D;: Thincknessactual(um)=Thincknessavg(px)&#xD7;UL(um/px)mf Thinckness_{actual}(um) = \\frac{Thinckness_{avg}(px) &#xD7;UL(um/px)}{mf} Thincknessactual&#x200B;(um)=mfThincknessavg&#x200B;(px)&#xD7;UL(um/px)&#x200B; mfmfmf: &#x662F;&#x76F8;&#x673A;&#x7684;&#x653E;&#x5927;&#x500D;&#x7387; ULULUL: &#x662F;&#x5355;&#x4F4D;&#x957F;&#x5EA6;, &#x8868;&#x793A;&#x4E00;&#x4E2A;&#x50CF;&#x7D20;&#x7684;&#x5FAE;&#x7C73;&#x957F;&#x5EA6; &#x5B9E;&#x9A8C;&#x7ED3;&#x679C; &#x4E3A;&#x4E86;&#x8BC4;&#x4F30;&#x6211;&#x4EEC;&#x7684;&#x5934;&#x53D1;&#x539A;&#x5EA6;&#x8BC4;&#x4F30;&#x65B9;&#x6CD5;&#x7684;&#x51C6;&#x786E;&#x6027;, &#x6211;&#x4EEC;&#x4F7F;&#x7528;&#x7535;&#x5B50;&#x663E;&#x5FAE;&#x955C;&#x6D4B;&#x91CF;&#x4E86;&#x5B9E;&#x9645;&#x7684;&#x5934;&#x53D1;&#x539A;&#x5EA6;&#x3002;&#x5934;&#x53D1;&#x539A;&#x5EA6;&#x6D4B;&#x91CF;&#x7684;&#x51C6;&#x786E;&#x6027;&#x5982;&#x8868;1&#x6240;&#x793A;&#x3002; table_1_AVERAGE_HAIR_THICKNESS_AND_ERROR_RATE &#x636E;&#x62A5;&#x9053;, &#x97E9;&#x56FD;&#x4EBA;&#x7684;&#x5E73;&#x5747;&#x5934;&#x53D1;&#x539A;&#x5EA6;&#x4E3A;84.9&#x3BC;m&#x3002;&#x4E0E;&#x6B64;&#x76F8;&#x6BD4;, &#x6211;&#x4EEC;&#x7684;90.29&#x3BC;m&#x7684;&#x7ED3;&#x679C;&#x76F8;&#x5F53;&#x4E0D;&#x9519;&#x3002;&#x5B9E;&#x9645;&#x503C;&#xFF08;&#x901A;&#x8FC7;&#x7535;&#x5B50;&#x663E;&#x5FAE;&#x955C;&#x8BA1;&#x7B97;&#xFF09;&#x4E0E;&#x4F30;&#x8BA1;&#x503C;&#x4E4B;&#x95F4;&#x7684;&#x5DEE;&#x5F02;&#x5F88;&#x5C0F;&#x3002; &#x53EF;&#x80FD;&#x7684;&#x539F;&#x56E0;&#x4E4B;&#x4E00;&#x662F;&#x9634;&#x5F71;&#x6548;&#x679C;&#x3002;&#x53E6;&#x4E00;&#x4E2A;&#x53EF;&#x80FD;&#x7684;&#x539F;&#x56E0;&#x662F;&#x76F8;&#x673A;&#x955C;&#x5934;&#x53D8;&#x5F62;&#x3002; &#x56FE;&#x50CF;&#x5C3A;&#x5BF8;&#x4E3A;640x480&#x3002;&#x4F46;&#x662F;, &#x76F8;&#x673A;&#x6240;&#x8986;&#x76D6;&#x533A;&#x57DF;&#x7684;&#x771F;&#x5B9E;&#x5F62;&#x72B6;&#x51E0;&#x4E4E;&#x662F;&#x692D;&#x5706;&#x5F62;&#x3002;&#x56E0;&#x6B64;, &#x76F8;&#x673A;&#x653E;&#x5927;&#x7387;&#x5728;&#x884C;&#x548C;&#x5217;&#x4E4B;&#x95F4;&#x5177;&#x6709;&#x5DEE;&#x5F02;&#x3002;&#x6839;&#x636E;&#x62CD;&#x6444;&#x89D2;&#x5EA6;, &#x653E;&#x5927;&#x500D;&#x7387;&#x53EF;&#x80FD;&#x4F1A;&#x6709;&#x6240;&#x4E0D;&#x540C;&#x3002; &#x603B;&#x7ED3; &#x9488;&#x5BF9;&#x5934;&#x53D1;&#x7C97;&#x7EC6;&#xFF08;&#x539A;&#x5EA6;&#xFF09;&#x8BA1;&#x7B97;&#x95EE;&#x9898;, &#x4E0A;&#x8FF0;&#x8BBA;&#x6587;&#x63D0;&#x51FA;&#x4E86;&#x57FA;&#x4E8E;&#x5934;&#x53D1;&#x8F6E;&#x5ED3;&#x548C;&#x9AA8;&#x9ABC;&#x56FE;, &#x901A;&#x8FC7;&#x8BA1;&#x7B97;&#x6BCF;&#x4E2A;&#x50CF;&#x7D20;&#x70B9;&#x7684;&#x65B9;&#x5411;&#x548C;&#x5782;&#x7EBF;, &#x8FDB;&#x4E00;&#x6B65;&#x4F7F;&#x7528;&#x6B27;&#x5F0F;&#x8DDD;&#x79BB;&#x516C;&#x5F0F;&#x6765;&#x8BA1;&#x7B97;&#x5934;&#x53D1;&#x7684;&#x5782;&#x76F4;&#x76F4;&#x5F84;, &#x4F46;&#x5BF9;&#x76F8;&#x5173;&#x6280;&#x672F;&#x7684;&#x5E94;&#x7528;&#x7EC6;&#x8282;&#x63CF;&#x8FF0;&#x4E0D;&#x591A;&#x3002; &#x53C2;&#x8003;&#x6587;&#x732E; Evalution of hair and scalp condition based on microscopy image analysis An Unsupervised Hair Segmentation and Counting System in Microscopy Images Euclidean distance Principal component analysis","categories":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Paper Smash","slug":"Technology/Paper-Smash","permalink":"https://littlelittlemoon.github.io/categories/Technology/Paper-Smash/"}],"tags":[{"name":"Digital Image Processing","slug":"Digital-Image-Processing","permalink":"https://littlelittlemoon.github.io/tags/Digital-Image-Processing/"},{"name":"Line Detection","slug":"Line-Detection","permalink":"https://littlelittlemoon.github.io/tags/Line-Detection/"},{"name":"Paper","slug":"Paper","permalink":"https://littlelittlemoon.github.io/tags/Paper/"},{"name":"Hair Thickness","slug":"Hair-Thickness","permalink":"https://littlelittlemoon.github.io/tags/Hair-Thickness/"}],"keywords":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Paper Smash","slug":"Technology/Paper-Smash","permalink":"https://littlelittlemoon.github.io/categories/Technology/Paper-Smash/"}]},{"title":"An Unsupervised Hair Segmentation and Counting System in Microscopy Images | Hair Counting - part 2","slug":"Technology/An Unsupervised Hair Segmentation and Counting System in Microscopy Images | Hair Counting - 2","date":"2019-12-28T15:51:27.000Z","updated":"2020-04-18T11:10:10.219Z","comments":true,"path":"2019/12/28/Technology/An Unsupervised Hair Segmentation and Counting System in Microscopy Images | Hair Counting - 2/","link":"","permalink":"https://littlelittlemoon.github.io/2019/12/28/Technology/An%20Unsupervised%20Hair%20Segmentation%20and%20Counting%20System%20in%20Microscopy%20Images%20|%20Hair%20Counting%20-%202/","excerpt":"","text":"Paper: An Unsupervised Hair Segmentation and Counting System in Microscopy Images &#x6458;&#x8981;&#x7FFB;&#x8BD1;&#xFF1A;&#x672C;&#x6587;&#x91CD;&#x70B9;&#x4ECB;&#x7ECD;&#x4F7F;&#x7528;&#x9AD8;&#x7EA7;&#x56FE;&#x50CF;&#x5904;&#x7406;&#x7B97;&#x6CD5;&#x5F00;&#x53D1;&#x7528;&#x4E8E;&#x4E34;&#x5E8A;&#x7684;&#x533B;&#x5B66;&#x8F6F;&#x4EF6;&#x3002;&#x672C;&#x6587;&#x8BA8;&#x8BBA;&#x4E86;&#x5934;&#x53D1;&#x5206;&#x5272;&#x548C;&#x8BA1;&#x6570;&#x7684;&#x4E09;&#x4E2A;&#x5173;&#x952E;&#x95EE;&#x9898;: - &#x9996;&#x5148;, &#x53BB;&#x9664;&#x7531;&#x4E8E;&#x6CB9;&#x8102;&#x6216;&#x6C34;&#x5206;&#x5F15;&#x8D77;&#x7684;&#x4EFB;&#x4F55;&#x4EAE;&#x70B9;, &#x8FD9;&#x4E9B;&#x4EAE;&#x70B9;&#x5728;&#x5934;&#x53D1;&#x7684;&#x4E2D;&#x90E8;&#x5F62;&#x6210;&#x5706;&#x5F62;&#x56FE;&#x6848;, &#x5E76;&#x663E;&#x7740;&#x5F71;&#x54CD;&#x786E;&#x5B9A;&#x7EBF;&#x6761;&#x7684;&#x51C6;&#x786E;&#x6027;&#x3002; - &#x7B2C;&#x4E8C;, &#x8BC6;&#x522B;&#x51FA;&#x4E24;&#x4E2A;&#x63A5;&#x89E6;&#x6216;&#x91CD;&#x53E0;&#x7684;&#x5934;&#x53D1;, &#x5E76;&#x5C06;&#x5176;&#x89C6;&#x4E3A;&#x5355;&#x4E2A;&#x5934;&#x53D1;&#x3002;&#x4E3A;&#x4E86;&#x89E3;&#x51B3;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;, &#x6211;&#x4EEC;&#x63D0;&#x51FA;&#x4E86;&#x4E00;&#x79CD;&#x5934;&#x53D1;&#x6346;&#x7ED1;&#x7B97;&#x6CD5;(hair-bundling algorithm)&#x6765;&#x8BA1;&#x7B97;&#x4EFB;&#x4F55;&#x9690;&#x85CF;&#x7684;&#x5934;&#x53D1;&#x3002; - &#x6700;&#x540E;, &#x5934;&#x53D1;&#x53EF;&#x80FD;&#x5448;&#x6CE2;&#x6D6A;&#x72B6;&#x6216;&#x5377;&#x66F2;&#x72B6;, &#x8FD9;&#x4F7F;&#x4F20;&#x7EDF;&#x7684;&#x57FA;&#x4E8E;Hough&#x7684;&#x7EBF;&#x68C0;&#x6D4B;&#x7B97;&#x6CD5;&#x4E0D;&#x5408;&#x9002;, &#x56E0;&#x4E3A;&#x5B83;&#x4F1A;&#x53D7;&#x5230;&#x53C2;&#x6570;&#x9009;&#x62E9;&#x7684;&#x5F71;&#x54CD;, &#x4F8B;&#x5982;&#x7EBF;&#x6BB5;&#x7684;&#x6700;&#x5C0F;&#x957F;&#x5EA6;&#x4EE5;&#x53CA;&#x7EBF;&#x6BB5;&#x4E4B;&#x95F4;&#x7684;&#x8DDD;&#x79BB;&#x3002;&#x6211;&#x4EEC;&#x63D0;&#x51FA;&#x7684;&#x6BDB;&#x53D1;&#x8BA1;&#x6570;&#x7B97;&#x6CD5;&#x6BD4;&#x57FA;&#x4E8E;Hough&#x7684;&#x6BDB;&#x53D1;&#x8BA1;&#x6570;&#x7B97;&#x6CD5;&#x8981;&#x51C6;&#x786E;&#x5F97;&#x591A;, &#x5E76;&#x4E14;&#x5728;&#x5404;&#x79CD;&#x767D;&#x5E73;&#x8861;&#x4E0B;&#x5BF9;&#x5377;&#x53D1;, &#x6CB9;&#x6027;&#x5934;&#x76AE;, &#x566A;&#x58F0;&#x8150;&#x8680;&#x548C;&#x91CD;&#x53E0;&#x7684;&#x5934;&#x53D1;&#x90FD;&#x5177;&#x6709;&#x9002;&#x7528;&#x6027;&#x3002; - &#x5173;&#x952E;&#x8BCD;&#xFF1A;&#x6BDB;&#x53D1;&#x8BA1;&#x6570;, &#x5934;&#x76AE;&#x8BCA;&#x65AD;, &#x62A4;&#x53D1;&#x8BCA;&#x65AD;, &#x6BDB;&#x56CA;&#x8BCA;&#x65AD;, &#x7EBF;&#x6BB5;&#x68C0;&#x6D4B;&#x3002; System flowchart figure 1 System flowchart &#x9884;&#x5904;&#x7406;&#x9636;&#x6BB5; (Preprocessing Stage) &#x4F7F;&#x7528;&#x5BF9;&#x6BD4;&#x5EA6;&#x62C9;&#x4F38;&#x65B9;&#x6CD5;(the contrast-stretching method)&#x6765;&#x589E;&#x52A0;&#x5934;&#x76AE;&#x548C;&#x5934;&#x53D1;&#x50CF;&#x7D20;&#x4E4B;&#x95F4;&#x7684;&#x5BF9;&#x6BD4;&#x5EA6;; &#x4E3A;&#x4E86;&#x51CF;&#x5C11;&#x4EAE;&#x70B9;&#x7684;&#x5F71;&#x54CD;, &#x63D0;&#x51FA;&#x4E86;&#x4E00;&#x79CD;&#x5065;&#x58EE;&#x7684;&#x989C;&#x8272;&#x5F62;&#x6001;&#x7B97;&#x6CD5;(morphological algorithm), &#x4EE5;&#x4F7F;&#x989C;&#x8272;&#x5E73;&#x6ED1;&#x5E76;&#x4FDD;&#x6301;&#x5934;&#x53D1;&#x7684;&#x4FDD;&#x771F;&#x5EA6;; &#x4E3A;&#x6BCF;&#x4E2A;&#x989C;&#x8272;&#x5206;&#x91CF;&#x5E94;&#x7528;&#x4E86;Karhunen-Lo&#xE8;ve&#x53D8;&#x6362;(KLT), &#x5E76;&#x4FDD;&#x7559;&#x4E86;&#x5177;&#x6709;&#x6700;&#x9AD8;&#x80FD;&#x91CF;&#x7684;&#x5206;&#x91CF;, &#x5E76;&#x4F7F;&#x7528;Otsu&#x9608;&#x503C;&#x83B7;&#x5F97;&#x4E86;&#x53EF;&#x9760;&#x7684;&#x4E8C;&#x8FDB;&#x5236;&#x56FE;&#x50CF;&#x3002; &#x6570;&#x636E;&#x91C7;&#x96C6;&#x89C4;&#x5B9A; &#x8FD9;&#x9879;&#x7814;&#x7A76;&#x7684;&#x552F;&#x4E00;&#x5047;&#x8BBE;: &#x5934;&#x53D1;&#x7684;&#x989C;&#x8272;&#x6BD4;&#x76AE;&#x80A4;&#x7684;&#x989C;&#x8272;&#x6DF1;&#x3002; &#x5934;&#x53D1;&#x56FE;&#x50CF;&#x662F;&#x4ECE;&#x6570;&#x7801;&#x663E;&#x5FAE;&#x955C;&#x76F8;&#x673A;(DMC)&#x6355;&#x83B7;, &#x5185;&#x7F6E;LED&#x589E;&#x5F3A;, &#x53EF;&#x81EA;&#x52A8;&#x4FDD;&#x6301;&#x4EAE;&#x5EA6;&#x7A33;&#x5B9A;&#x3002;&#x5E94;&#x7528;85&#x500D;&#x7684;&#x53D8;&#x7126;&#x500D;&#x7387;&#x6355;&#x83B7;&#x56FE;&#x50CF;&#x3002;&#x901A;&#x5E38;, &#x4F7F;&#x7528;&#x5206;&#x8FA8;&#x7387;&#x4E3A;1024&#xD7;768, &#x76F8;&#x5F53;&#x4E8E;&#x5934;&#x76AE;&#x9762;&#x79EF;&#x662F;0.25&#xD7;0.19&#x82F1;&#x5BF8;&#x3002;&#x6B64;&#x5916;, &#x57FA;&#x4E8E;DMC&#x7684;&#x767D;&#x5E73;&#x8861;&#x5C06;&#x6355;&#x83B7;&#x7684;&#x56FE;&#x50CF;&#x5206;&#x4E3A;&#x4E24;&#x7EC4;&#xFF1A; &#x5177;&#x6709;&#x65E5;&#x5149;&#x7684;&#x56FE;&#x50CF;&#x88AB;&#x5206;&#x7C7B;&#x4E3A;&#x6570;&#x636E;&#x96C6;&#xFF03;1, &#x5177;&#x6709;&#x8367;&#x5149;&#x7684;&#x56FE;&#x50CF;&#x88AB;&#x5206;&#x7C7B;&#x4E3A;&#x6570;&#x636E;&#x96C6;&#xFF03;2&#x3002; &#x4F7F;&#x7528;&#x5BF9;&#x6BD4;&#x5EA6;&#x62C9;&#x4F38;(Contrast Stretching)&#x8FDB;&#x884C;&#x56FE;&#x50CF;&#x589E;&#x5F3A; &#x76EE;&#x7684; &#x589E;&#x52A0;&#x5934;&#x53D1;&#x548C;&#x5934;&#x76AE;&#x4E4B;&#x95F4;&#x7684;&#x5BF9;&#x6BD4;&#x5EA6;; &#x589E;&#x52A0;&#x5934;&#x53D1;&#x548C;&#x5934;&#x76AE;&#x50CF;&#x7D20;&#x4E4B;&#x95F4;&#x7684;&#x8272;&#x5DEE;&#x3002; &#x6280;&#x672F; &#x901A;&#x8FC7;&#x5206;&#x6BB5;&#x7EBF;&#x6027;&#x5BF9;&#x6BD4;&#x5EA6;&#x62C9;&#x4F38;(color transformation by means of piecewise linear contrast stretching)&#x8FDB;&#x884C;&#x989C;&#x8272;&#x53D8;&#x6362;&#x6765;&#x589E;&#x5F3A;&#x56FE;&#x50CF;, &#x63D0;&#x9AD8;&#x5BF9;&#x6BD4;&#x5EA6;&#xFF1B; stretched the middle-intensity level, and kept the levels of the low-intensity and high-intensity so as to prevent creating false colors. &#x7ED3;&#x679C; figure_2_image_enhancement_for_the_datasets &#x8FDB;&#x884C;&#x5BF9;&#x6BD4;&#x5EA6;&#x62C9;&#x4F38;&#x65F6;, &#x4E0D;&#x4F1A;&#x66F4;&#x6539;&#x539F;&#x59CB;&#x5934;&#x53D1;&#x50CF;&#x7D20;, &#x4E5F;&#x4E0D;&#x4F1A;&#x5938;&#x5927;&#x6CB9;&#x4EAE;&#x50CF;&#x7D20;&#xFF1A; &#x964D;&#x4F4E;&#x4E86;&#x5934;&#x76AE;&#x50CF;&#x7D20;&#x7684;&#x5F3A;&#x5EA6;; &#x589E;&#x52A0;&#x4E86;&#x5934;&#x76AE;&#x548C;&#x5934;&#x53D1;&#x4E4B;&#x95F4;&#x7684;&#x8272;&#x5DEE;; &#x4EAE;&#x70B9;&#x7684;&#x50CF;&#x7D20;&#x4FDD;&#x6301;&#x4E0D;&#x53D8;&#x3002; Bright Spot Removal (BSR) &#x76EE;&#x7684; &#x9664;&#x566A;: &#x53BB;&#x9664;&#x6CB9;&#x6027;&#x548C;&#x6E7F;&#x6DA6;&#x7684;&#x5934;&#x53D1;&#x5728;&#x5934;&#x53D1;&#x7684;&#x4E2D;&#x90E8;&#x4EA7;&#x751F;&#x7684;&#x4EAE;&#x70B9;: &#x6280;&#x672F; color morphological processing approach &#x975E;&#x7EBF;&#x6027;&#x4E2D;&#x503C;&#x6EE4;&#x6CE2;&#x5668;(nonlinear median filter)&#x6D88;&#x9664;&#x767D;&#x70B9;; &#x7A7A;&#x95F4;&#x5E73;&#x6ED1;&#x6EE4;&#x6CE2;&#x5668;(spatial smooth filter)&#x964D;&#x4F4E;&#x767D;&#x70B9;&#x7684;&#x5F3A;&#x5EA6;, &#x7F3A;&#x70B9;&#x662F;&#x6D4B;&#x8BD5;&#x56FE;&#x50CF;&#x7684;&#x975E;&#x6BDB;&#x53D1;&#x533A;&#x57DF;&#x4E5F;&#x5C06;&#x53D8;&#x5F97;&#x6A21;&#x7CCA;; color-based mathematical morphology (MM) method, used it as an ordering process. adopted the MM opening operator to depress the bright spot in the middle of the hairs. &#x4FB5;&#x8680;&#x56FE;&#x50CF; &#x653E;&#x5927;&#x56FE;&#x50CF; opening operation of image f : &#x3B3;M,nB(f) = &#x3C4;M,nB(&#x3B5;M,nB(f)), &#x5176;&#x4E2D;&#x3B5;M,nB&#x548C;&#x3C4;M,nB&#x5206;&#x522B;&#x8868;&#x793A;&#x7ED3;&#x6784;&#x5143;&#x7D20;B&#x5BF9;&#x5927;&#x5C0F;&#x4E3A;n&#x7684;&#x56FE;&#x50CF;f&#x7684;&#x5F62;&#x6001;&#x4FB5;&#x8680;&#x548C;&#x653E;&#x5927;, &#x5BF9;&#x4E8E;&#x50CF;&#x7D20;x: &#x3B5;M,nB(f)(x) = {f(y) : f(y) = &#x2227;M[f(z)],z &#x2208; n(Bx)} &#x3C4;M,nB(f)(x) = {f(y) : f(y) = &#x2228;M[f(z)],z &#x2208; n(Bx)} &#x2227;M&#x548C;&#x2228;M&#x5206;&#x522B;&#x8868;&#x793A;M-ordering&#x7684;&#x6700;&#x9AD8;&#x548C;&#x6700;&#x5C0F;&#x5CF0; &#x4F7F;&#x7528;KLT&#x5C06;&#x5F69;&#x8272;&#x56FE;&#x50CF;&#x8F6C;&#x6362;&#x4E3A;&#x7070;&#x5EA6;&#x56FE;&#x50CF;&#xFF1B; &#x56FE;&#x50CF;&#x4E8C;&#x503C;&#x5316;&#x6B65;&#x9AA4;&#x4E2D;, &#x4F7F;&#x7528;&#x4E86;Otsu&#x9608;&#x503C;(&#x6307;&#x4EAE;&#x5EA6;&#x7684;&#x80FD;&#x91CF;)&#x4EE5;&#x83B7;&#x5F97;&#x53EF;&#x9760;&#x7684;&#x4E8C;&#x503C;&#x56FE;&#x50CF;&#xFF1B; &#x7ED3;&#x679C; &#x56FE;3&#x793A;&#x51FA;&#x4E86;&#x53BB;&#x9664;&#x6CB9;&#x6027;&#x4EAE;&#x70B9;&#x7684;&#x7ED3;&#x679C;&#xFF1A; &#x56FE;4&#x6BD4;&#x8F83;&#x4E86;&#x4F7F;&#x7528;BSR&#x64CD;&#x4F5C;&#x65F6;&#x7684;&#x7EBF;&#x8DEF;&#x68C0;&#x6D4B;, &#x5E76;&#x663E;&#x793A;&#x4E86;&#x5BF9;&#x4E8C;&#x503C;&#x5316;&#x548C;&#x7EC6;&#x5316;&#x64CD;&#x4F5C;&#x7684;&#x660E;&#x663E;&#x5F71;&#x54CD;&#x3002;&#x5E26;&#x6709;BSR&#x7684;&#x4E8C;&#x503C;&#x5316;&#x56FE;&#x50CF;&#x5177;&#x6709;&#x51CF;&#x5C11;&#x7684;&#x4EAE;&#x70B9;&#x53CD;&#x5C04;, &#x5E76;&#x4E14;&#x5728;&#x7EC6;&#x5316;&#x56FE;&#x50CF;&#x4E2D;, &#x4EAE;&#x70B9;&#x88AB;&#x8F6C;&#x6362;&#x4E3A;&#x5C0F;&#x5706;&#x5708;&#x3002;&#x56FE;4(f)&#x663E;&#x793A;, &#x5728;&#x7EBF;&#x68C0;&#x6D4B;&#x9636;&#x6BB5;, &#x4F7F;&#x7528;BSR&#x751F;&#x6210;&#x7684;&#x56FE;&#x50CF;&#x5177;&#x6709;&#x8F83;&#x5C11;&#x7684;&#x4E0D;&#x5FC5;&#x8981;&#x7684;&#x7EBF;&#x6BB5;&#xFF1A; figure_4_comparisons_of_the_hair_thining_and_line_detection Multi-scale Line Detection Stage (MSLD) &#x91C7;&#x7528;&#x6539;&#x8FDB;&#x7684;&#x970D;&#x592B;&#x53D8;&#x6362;(the Hough transform)&#x7B97;&#x6CD5;&#x6765;&#x68C0;&#x6D4B;&#x4E0D;&#x540C;&#x7684;&#x5934;&#x53D1;&#x957F;&#x5EA6;, &#x5E76;&#x51CF;&#x5C11;&#x7531;&#x4E8E;&#x566A;&#x58F0;&#x5F15;&#x8D77;&#x7684;&#x4EFB;&#x4F55;&#x9519;&#x8BEF;&#x68C0;&#x6D4B;; &#x5C06;&#x5F2F;&#x66F2;&#x7684;&#x5934;&#x53D1;&#x89C6;&#x4E3A;&#x591A;&#x6761;&#x76F4;&#x7EBF;; &#x4E3A;&#x4E86;&#x907F;&#x514D;&#x5728;&#x5E94;&#x7528;&#x7A00;&#x758F;&#x8FC7;&#x7A0B;&#x65F6;&#x4E22;&#x5931;&#x5934;&#x53D1;, &#x6211;&#x4EEC;&#x4F7F;&#x7528;&#x8FB9;&#x7F18;&#x4FE1;&#x606F;(edge information)&#x6765;&#x53D1;&#x73B0;&#x4EFB;&#x4F55;&#x9690;&#x85CF;&#x6216;&#x91CD;&#x53E0;&#x7684;&#x5934;&#x53D1;&#x3002; &#x603B;&#x4F53;&#x7ED3;&#x6784;&#x5206;&#x6790; &#x76EE;&#x7684; &#x63D0;&#x51FA;&#x591A;&#x5C3A;&#x5EA6;&#x6846;&#x67B6;&#x6765;&#x662F;&#x4E3A;&#x4E86;&#x63D0;&#x9AD8;&#x5934;&#x53D1;&#x68C0;&#x6D4B;&#x7684;&#x51C6;&#x786E;&#x6027;&#xFF1B; &#x5E94;&#x7528;&#x5E73;&#x884C;&#x7EBF;&#x6346;&#x7ED1;(PLB)&#x7B97;&#x6CD5;(parallel line bundling algorithm)&#x6765;&#x8FD8;&#x539F;&#x4EFB;&#x4F55;&#x9690;&#x85CF;&#x6216;&#x91CD;&#x53E0;&#x7684;&#x5934;&#x53D1;&#x3002; &#x6700;&#x540E;, &#x5C06;&#x77E2;&#x91CF;&#x5316;&#x7684;&#x7EBF;&#x6BB5;&#x7528;&#x4F5C;&#x6BDB;&#x53D1;&#x6807;&#x8BB0;&#x548C;&#x8BA1;&#x6570;&#x6A21;&#x5757;&#x7684;&#x8F93;&#x5165;&#x6570;&#x636E;&#x3002; &#x6280;&#x672F; &#x5BF9;HT&#x5E94;&#x7528;&#x4E86;&#x4E09;&#x4E2A;&#x6BD4;&#x4F8B;&#x7684;&#x56FE;&#x50CF;&#xFF1A;1024&#xD7;768(&#x539F;&#x59CB;&#x6BD4;&#x4F8B;), 512&#xD7;384&#x548C;256&#xD7;192&#x3002;&#x5BF9;&#x7F29;&#x653E;&#x6BD4;&#x4F8B;&#x56FE;&#x50CF;&#x5E94;&#x7528;&#x4E86;&#x4E24;&#x79CD;&#x5904;&#x7406;&#x65B9;&#x6CD5;&#xFF1A;&#x8FB9;&#x7F18;&#x68C0;&#x6D4B;&#x548C;&#x7EC6;&#x5316;&#x5904;&#x7406;&#x3002; PLB&#x7B97;&#x6CD5;&#x5E94;&#x7528;&#x4E8E;&#x8FB9;&#x7F18;&#x56FE;&#x50CF;&#x4EE5;&#x53D1;&#x73B0;&#x7F3A;&#x5931;&#x7684;&#x7EBF;&#x6BB5; HT&#x88AB;&#x5E94;&#x7528;&#x4E8E;&#x7EC6;&#x5316;&#x56FE;&#x50CF;&#x4EE5;&#x63D0;&#x53D6;&#x7EBF;&#x6BB5;&#x3002;&#x901A;&#x8FC7;&#x5229;&#x7528;PLB&#x7B97;&#x6CD5;, &#x53EF;&#x4EE5;&#x6062;&#x590D;&#x9690;&#x85CF;&#x548C;&#x91CD;&#x53E0;&#x7684;&#x5934;&#x53D1;&#x3002; &#x6700;&#x540E;, &#x5C06;&#x77E2;&#x91CF;&#x5316;&#x7684;&#x7EBF;&#x6BB5;&#x91CD;&#x65B0;&#x7F29;&#x653E;&#x4E3A;&#x539F;&#x59CB;&#x5C3A;&#x5BF8;1024&#xD7;768, &#x5E76;&#x7531;&#x903B;&#x8F91;&#x6216;&#x8FD0;&#x7B97;&#x7B26;&#x8FDB;&#x884C;&#x6574;&#x5408;&#x3002; &#x7ED3;&#x679C; &#x5982;&#x56FE;5&#x6240;&#x793A;, &#x7531;&#x4E8E;&#x5934;&#x53D1;&#x7684;&#x957F;&#x5EA6;&#x548C;&#x5377;&#x66F2;&#x5EA6;&#x7684;&#x53D8;&#x5316;, &#x4F7F;&#x7528;&#x5355;&#x5C3A;&#x5EA6;HT&#x4E0D;&#x80FD;&#x68C0;&#x6D4B;&#x6240;&#x6709;&#x7684;&#x5934;&#x53D1;&#xFF1A; figure_5_comparison_of_the_single_scale_and_muti-scale_line_detection &#x56FE;5(a)&#x663E;&#x793A;, &#x5F53;&#x4E00;&#x6839;&#x5934;&#x53D1;&#x51E0;&#x4E4E;&#x5E73;&#x884C;&#x51FA;&#x73B0;, &#x4E0E;&#x5176;&#x4ED6;&#x5934;&#x53D1;&#x91CD;&#x53E0;&#x65F6;, &#x6216;&#x8005;&#x5982;&#x679C;&#x5934;&#x53D1;&#x7684;&#x66F2;&#x7387;&#x8D85;&#x8FC7;HT&#x7684;&#x5BB9;&#x9650;, &#x90A3;&#x4E48;&#x6700;&#x7EC8;&#x4F1A;&#x9057;&#x6F0F;&#x5927;&#x91CF;&#x7684;&#x5934;&#x53D1;, &#x8BB8;&#x591A;&#x7EBF;&#x6BB5;&#x6807;&#x7B7E;&#x9519;&#x8BEF;&#x3002; &#x56FE;5(b)&#x793A;&#x51FA;&#x4E86;&#x4F7F;&#x7528;&#x6765;&#x81EA;&#x6240;&#x6709;&#x7F29;&#x653E;&#x56FE;&#x7684;&#x7EBF;&#x6BB5;&#x7684;&#x7ED3;&#x679C;, &#x4ECE;&#x800C;&#x6539;&#x5584;&#x4E86;&#x5355;&#x4E2A;&#x523B;&#x5EA6;&#x7684;&#x4E0D;&#x8DB3;&#x3002; Parallel Line Bundling (PLB) &#x539F;&#x7406; &#x5E94;&#x7528;Canny&#x8FB9;&#x7F18;&#x68C0;&#x6D4B;&#x5668;&#x83B7;&#x5F97;&#x8FB9;&#x7F18;&#x56FE;&#x3002;&#x5728;&#x56FE;6&#x4E2D;, &#x5047;&#x8BBE;&#x68C0;&#x6D4B;&#x5230;&#x4E24;&#x6761;&#x5E73;&#x884C;&#x7EBF;A&#x548C;B, &#x7528; ax+by+ca=0ax + by + c_a = 0ax+by+ca&#x200B;=0&#x548C;ax+by+cb=0ax + by + c_b = 0ax+by+cb&#x200B;=0&#x8868;&#x793A;, d=&#x2223;ca&#x2212;cb&#x2223;a2+b2d=\\frac{|c_a - c_b|} {\\sqrt{a^2 + b^2}}d=a2+b2&#x200B;&#x2223;ca&#x200B;&#x2212;cb&#x200B;&#x2223;&#x200B;&#x8868;&#x793A;&#x7EBF;&#x6BB5;A,B&#x4E4B;&#x95F4;&#x7684;&#x8DDD;&#x79BB;; figure_6_Thining_line_sandwiched_by_two_parallel_lines_with_the_distances_d &#x8BA1;&#x7B97;&#x51FA;&#x5939;&#x6709;&#x7EC6;&#x7EBF;&#x7684;&#x5E73;&#x884C;&#x7EBF;&#x4E4B;&#x95F4;&#x7684;&#x5E73;&#x5747;&#x8DDD;&#x79BB;davgd_{avg}davg&#x200B;&#x3002; &#x5982;&#x679C;d&gt;davgd &gt; d_{avg}d&gt;davg&#x200B;, &#x5219;&#x5F53;(ddavg)&gt;wth(dd_{avg})&gt;w_{th}(ddavg&#x200B;)&gt;wth&#x200B;&#x65F6;, &#x5C06;&#x53D1;&#x73B0;&#x9690;&#x85CF;&#x7684;&#x5934;&#x53D1;, &#x5176;&#x4E2D;wthw_{th}wth&#x200B;&#x8868;&#x793A;&#x8FB9;&#x754C;&#x56E0;&#x5B50;, &#x5C06;&#x901A;&#x8FC7;&#x5934;&#x76AE;&#x56FE;&#x50CF;&#x7684;&#x5206;&#x8FA8;&#x7387;&#x6839;&#x636E;&#x7ECF;&#x9A8C;&#x8FDB;&#x884C;&#x4FEE;&#x6539;&#x3002; &#x7ED3;&#x679C; &#x5728;&#x56FE;7(a)&#x4E2D;, &#x5706;&#x5708;&#x8868;&#x793A;&#x9690;&#x85CF;&#x7684;&#x5934;&#x53D1;, &#x5982;&#x56FE;7(b)&#x6240;&#x793A;&#xFF1A; Hair Labling and Counting &#x4F7F;&#x7528;MSLD&#x6A21;&#x5757;, &#x5F97;&#x51FA;&#x4E86;&#x4E00;&#x7EC4;&#x7EBF;&#x6BB5;&#x3002;&#x6839;&#x636E;&#x5934;&#x53D1;&#x7684;&#x66F2;&#x7387;&#x548C;&#x65B9;&#x5411;, &#x5C06;&#x5934;&#x53D1;&#x5B9E;&#x73B0;&#x4E3A;&#x5177;&#x6709;&#x4E0D;&#x540C;&#x957F;&#x5EA6;&#x7684;&#x5206;&#x6BB5;&#x7EBF;&#x5411;&#x91CF;&#x7C07;&#x3002;&#x8FD9;&#x9879;&#x7814;&#x7A76;&#x7684;&#x76EE;&#x7684;&#x662F;&#x51C6;&#x786E;&#x8BA1;&#x7B97;&#x5934;&#x76AE;&#x4E0A;&#x7684;&#x6BDB;&#x53D1;&#x6570;&#x91CF;&#x3002;&#x8FD9;&#x53EF;&#x4EE5;&#x770B;&#x4F5C;&#x662F;&#x805A;&#x7C7B;&#x548C;&#x6807;&#x8BB0;&#x95EE;&#x9898;&#x3002;&#x76EE;&#x6807;&#x662F;&#x5C06;&#x4E00;&#x7EC4;&#x7EBF;&#x6BB5;&#x7EC4;&#x5408;&#x6210;&#x8BED;&#x4E49;&#x201C;&#x5934;&#x53D1;&#x201D;&#x5E76;&#x5206;&#x914D;&#x552F;&#x4E00;&#x7684;&#x6807;&#x7B7E;&#x3002;&#x7531;&#x4E8E;&#x6BCF;&#x6839;&#x5934;&#x53D1;&#x90FD;&#x7531;&#x76F8;&#x4E92;&#x5173;&#x8054;&#x7684;&#x7EBF;&#x6BB5;&#x7EC4;&#x6210;, &#x56E0;&#x6B64;&#x6211;&#x4EEC;&#x4E3A;&#x6BCF;&#x4E2A;&#x7C07;&#x5206;&#x914D;&#x4E86;&#x552F;&#x4E00;&#x7684;&#x6807;&#x7B7E;&#x3002; &#x6211;&#x4EEC;&#x91C7;&#x7528;&#x4E86;&#x677E;&#x5F1B;&#x6807;&#x8BB0;&#x7B97;&#x6CD5;(Relaxation labeling algorithm)&#x6765;&#x8BC6;&#x522B;&#x6BCF;&#x4E2A;&#x5355;&#x72EC;&#x7684;&#x7EBF;&#x6BB5;, &#x4EE5;&#x786E;&#x5B9A;&#x4E0E;&#x54EA;&#x4E2A;&#x7EBF;&#x6BB5;&#x76F8;&#x5173;&#x8054;&#x3002; &#x56FE;8(a)&#x663E;&#x793A;&#x4E86;10&#x4E2A;&#x5355;&#x72EC;&#x7684;&#x7EBF;&#x6BB5;&#x7684;&#x793A;&#x4F8B;, &#x8FD9;&#x4E9B;&#x7EBF;&#x6BB5;&#x88AB;&#x6807;&#x8BB0;&#x4E3A;&#x6765;&#x81EA;&#x540C;&#x4E00;&#x6839;&#x5934;&#x53D1;, &#x7136;&#x540E;&#x7ED8;&#x5236;&#x5230;(&#x3C1;,&#x3B8;)(&#x3C1;, &#x3B8;)(&#x3C1;,&#x3B8;)&#x5750;&#x6807;&#x7CFB;&#x4E0A;, &#x5982;&#x56FE;8(b)&#x6240;&#x793A;&#x3002; &#x4EA4;&#x53C9;&#x70B9;&#x5904;&#x7D2F;&#x79EF;&#x56FE;&#x7684;&#x7ED3;&#x679C;&#x5CF0;&#x503C;&#x4E3A;10&#x3002; figure_8_Example_of_line_segment_labeling Relaxation Labeling (RL) &#x677E;&#x5F1B;&#x6807;&#x6CE8;(RL)&#x662F;&#x4E00;&#x79CD;&#x76F8;&#x4E92;&#x5173;&#x8054;&#x7684;&#x56DE;&#x5F52;&#x65B9;&#x6CD5;, &#x5B83;&#x4F7F;&#x7528;&#x7B26;&#x53F7;&#x6765;&#x63CF;&#x8FF0;&#x6A21;&#x578B;&#x7684;&#x5F62;&#x72B6;&#x3002; &#x5B83;&#x65E8;&#x5728;&#x5C06;&#x76EE;&#x6807;&#x5BF9;&#x8C61;(&#x5373;&#x672C;&#x6587;&#x4E2D;&#x7684;&#x7EBF;&#x6BB5;)&#x4E0E;&#x7B26;&#x53F7;&#x6216;&#x6240;&#x8C13;&#x7684;&#x6807;&#x8BB0;(&#x5373;&#x5934;&#x53D1;&#x6807;&#x7B7E;)&#x8FDB;&#x884C;&#x5339;&#x914D;&#x3002;RL&#x7B97;&#x6CD5;&#x9996;&#x5148;&#x5206;&#x914D;&#x4E00;&#x7EC4;&#x968F;&#x673A;&#x6807;&#x8BB0;&#x3002;&#x7136;&#x540E;, &#x901A;&#x8FC7;&#x8FED;&#x4EE3;&#x8BA1;&#x7B97;, &#x53EF;&#x4EE5;&#x83B7;&#x5F97;&#x66F4;&#x51C6;&#x786E;, &#x66F4;&#x7CBE;&#x786E;&#x7684;&#x6807;&#x8BB0;&#x96C6;&#x3002;&#x5728;&#x672C;&#x7814;&#x7A76;&#x4E2D;, RL&#x7B97;&#x6CD5;&#x88AB;&#x89C6;&#x4E3A;&#x7528;&#x4E8E;&#x6807;&#x8BB0;&#x6BCF;&#x4E2A;&#x7EBF;&#x6BB5;&#x7684;&#x805A;&#x7C7B;&#x65B9;&#x6CD5;&#x3002; &#x539F;&#x7406; figure_9_Conceptual_schematics_of_the_labeling_algorithm &#x4EE4;C(i,&#x3BB;,j,&#x3BB;&#x2032;)C(i, &#x3BB;, j, &#x3BB;&apos;)C(i,&#x3BB;,j,&#x3BB;&#x2032;)&#x8868;&#x793A;&#x7EA6;&#x675F;&#x4E3A;&#x3BB;&#x7684;&#x7EBF;&#x6BB5;&#x4E0E;&#x7EA6;&#x675F;&#x4E3A;&#x3BB;&apos;&#x7684;&#x7EBF;&#x6BB5;j&#x7684;&#x517C;&#x5BB9;&#x6027;, &#x5176;&#x7EA6;&#x675F;&#x4E3A;: &#x2211;&#x3BB;C(i,&#x3BB;,j,&#x3BB;&#x2032;)=1\\displaystyle\\sum_{&#x3BB;}C(i, &#x3BB;, j, &#x3BB;&apos;) = 1&#x3BB;&#x2211;&#x200B;C(i,&#x3BB;,j,&#x3BB;&#x2032;)=1 for &#x2200;i,j,&#x3BB;,&#x3BB;&apos;&#x3002; &#x517C;&#x5BB9;&#x6027;C&#x8868;&#x793A;&#x6807;&#x8BB0;&#x4E3A;&#x3BB;&apos;&#x7684;&#x7EBF;&#x6BB5;j&#x548C;&#x6807;&#x8BB0;&#x4E3A;&#x3BB;&#x7684;&#x7EBF;&#x6BB5;i&#x4E4B;&#x95F4;&#x7684;&#x76F8;&#x4E92;&#x4F9D;&#x8D56;&#x6027;&#x3002; &#x5982;&#x679C;&#x517C;&#x5BB9;&#x6027;&#x4EC5;&#x7531;&#x5230;&#x539F;&#x70B9;&#x7684;&#x8DDD;&#x79BB;&#x51B3;&#x5B9A;, &#x5219;&#x53EF;&#x80FD;&#x4F1A;&#x51FA;&#x73B0;&#x9519;&#x8BEF;&#x7684;&#x89E3;&#x91CA;&#x3002; &#x56E0;&#x6B64;&#x5C06;&#x517C;&#x5BB9;&#x6027;&#x5B9A;&#x4E49;&#x5982;&#x4E0B;&#xFF1A; C(i,&#x3BB;,j,&#x3BB;&#x2032;)={&#x2212;1if&#xA0;i&#x2209;Sj&#x3B5;&#x2223;cos&#x2061;[&#x3B8;i(&#x3BB;)&#x2212;&#x3B8;j(&#x3BB;&#x2032;)]&#x2223;+(1&#x2212;&#x3B5;)&#x3C1;i(&#x3BB;)&#x3C1;j(&#x3BB;&#x2032;)if&#xA0;i&#x2208;Sj&#x2229;&#x3BB;=/&#x2009;&#x3BB;&#x2032;0otherwise&#xA0; C(i, &#x3BB;, j, &#x3BB;&apos;) = \\begin{cases} -1 &amp;\\text{if } i \\notin S_j \\\\ \\varepsilon |\\cos[\\theta_i(\\lambda) - \\theta_j(&#x3BB;&apos;)]| + (1-\\varepsilon) \\frac{\\rho_i(\\lambda)}{\\rho_j(&#x3BB;&apos;)} &amp;\\text{if } i&#x2208;S_j&#x2229;&#x3BB;{=}\\mathllap{/\\,}&#x3BB;&apos; \\\\ 0 &amp;\\text{otherwise } \\end{cases} C(i,&#x3BB;,j,&#x3BB;&#x2032;)=&#x23A9;&#x23AA;&#x23A8;&#x23AA;&#x23A7;&#x200B;&#x2212;1&#x3B5;&#x2223;cos[&#x3B8;i&#x200B;(&#x3BB;)&#x2212;&#x3B8;j&#x200B;(&#x3BB;&#x2032;)]&#x2223;+(1&#x2212;&#x3B5;)&#x3C1;j&#x200B;(&#x3BB;&#x2032;)&#x3C1;i&#x200B;(&#x3BB;)&#x200B;0&#x200B;if&#xA0;i&#x2208;/&#x200B;Sj&#x200B;if&#xA0;i&#x2208;Sj&#x200B;&#x2229;&#x3BB;=/&#x200B;&#x3BB;&#x2032;otherwise&#xA0;&#x200B; &#x4E0A;&#x5F0F;&#x4E2D;&#xFF1A; &#x3B5;&#x8868;&#x793A;&#x8DDD;&#x79BB;&#x548C;&#x65B9;&#x5411;&#x7F6E;&#x4FE1;&#x5EA6;&#x4E4B;&#x95F4;&#x7684;&#x52A0;&#x6743;&#x56E0;&#x5B50; SjS_jSj&#x200B;&#x8868;&#x793A;&#x7EBF;&#x6BB5;j&#x7684;&#x76F8;&#x90BB;&#x5047;&#x8BBE; &#x3B8;i(&#x3BB;)&#x3B8;_i(&#x3BB;)&#x3B8;i&#x200B;(&#x3BB;)&#x8868;&#x793A;&#x4ECE;&#x7EBF;&#x6BB5;i&#x5230;&#x6807;&#x8BB0;&#x4E3A;&#x3BB;&#x7684;&#x7EBF;&#x6BB5;j&#x7684;&#x65B9;&#x5411; &#x3C1;i(&#x3BB;)&#x3C1;_i(&#x3BB;)&#x3C1;i&#x200B;(&#x3BB;)&#x8868;&#x793A;&#x539F;&#x70B9;&#x5230;&#x7EBF;&#x6BB5;i&#x548C;&#x6807;&#x8BB0;&#x4E3A;&#x3BB;&#x7684;&#x7EBF;&#x6BB5;j&#x4E4B;&#x95F4;&#x7684;&#x8DDD;&#x79BB; &#x5982;&#x679C;&#x3C1;j(&#x3BB;)&#x3C1;_j(&#x3BB;)&#x3C1;j&#x200B;(&#x3BB;)&#x9AD8;, &#x4E14;C(i,&#x3BB;,j,&#x3BB;&#x2032;)C(i, &#x3BB;, j, &#x3BB;&apos;)C(i,&#x3BB;,j,&#x3BB;&#x2032;)&#x4E3A;&#x6B63;, &#x5219;&#x3C1;i(&#x3BB;)&#x3C1;_i(&#x3BB;)&#x3C1;i&#x200B;(&#x3BB;)&#x589E;&#x52A0;&#x3002; &#x6B64;&#x6807;&#x8BB0;&#x7B97;&#x6CD5;&#x662F;&#x4E00;&#x4E2A;&#x8FED;&#x4EE3;&#x5E76;&#x884C;&#x8FC7;&#x7A0B;, &#x7C7B;&#x4F3C;&#x4E8E;&#x6982;&#x7387;&#x677E;&#x5F1B;&#x4E2D;&#x4F7F;&#x7528;&#x7684;&#x6807;&#x8BB0;&#x4E22;&#x5F03;&#x89C4;&#x5219;, &#x64CD;&#x4F5C;&#x5458;&#x6839;&#x636E;&#x5176;&#x4ED6;&#x91CD;&#x91CF;&#x548C;&#x517C;&#x5BB9;&#x6027;&#x53CD;&#x590D;&#x8C03;&#x6574;&#x6807;&#x7B7E;&#x91CD;&#x91CF;&#x3002; &#x5BF9;&#x4E8E;&#x6BCF;&#x4E2A;&#x7EBF;&#x6BB5;&#x548C;&#x6BCF;&#x4E2A;&#x6807;&#x7B7E;, &#x65B0;&#x6743;&#x91CD;qi(r)(&#x3BB;)q_i^{(r)}(\\lambda)qi(r)&#x200B;(&#x3BB;)&#x7684;&#x8BA1;&#x7B97;&#x5982;&#x4E0B;&#xFF1A; qi(r)(&#x3BB;)=&#x2211;j,j=/&#x2009;i&#x2211;&#x3BB;&#x2032;C(i,&#x3BB;,j,&#x3BB;&#x2032;)pj(r)(&#x3BB;&#x2032;) q_i^{(r)}(\\lambda) = \\sum_{\\mathclap{j, j{=}\\mathllap{/\\,}i}} \\sum_{\\mathclap{&#x3BB;&apos;}}C(i, &#x3BB;, j, &#x3BB;&apos;)p_j^{(r)}(&#x3BB;&apos;) qi(r)&#x200B;(&#x3BB;)=j,j=/&#x200B;i&#x200B;&#x2211;&#x200B;&#x3BB;&#x2032;&#x2211;&#x200B;C(i,&#x3BB;,j,&#x3BB;&#x2032;)pj(r)&#x200B;(&#x3BB;&#x2032;) &#x5176;&#x4E2D;: r&#x8868;&#x793A;&#x7B2C;r&#x6B21;&#x8FED;&#x4EE3; &#x5728;&#x7B49;&#x5F0F;&#x4E2D;, &#x4E58;&#x79EF;&#x548C;&#x662F;&#x88AB;&#x6807;&#x8BB0;&#x4E3A;&#x3BB;&#x7684;&#x7ED9;&#x5B9A;&#x7EBF;&#x6BB5;i&#x7684;&#x671F;&#x671B; qi(r)(&#x3BB;)q_i^{(r)}(\\lambda)qi(r)&#x200B;(&#x3BB;)&#x662F;&#x5F53;&#x524D;&#x8D4B;&#x503C;pj(r)(&#x3BB;&#x2032;)p_j^{(r)}(&#x3BB;&apos;)pj(r)&#x200B;(&#x3BB;&#x2032;)&#x7684;&#x52A0;&#x6743;&#x548C;&#x3002; &#x65B0;&#x4EFB;&#x52A1;&#x53EF;&#x4EE5;&#x7528;&#x5DF2;&#x4E0B;&#x516C;&#x5F0F;&#x66F4;&#x65B0;&#xFF1A; pi(r+1)(&#x3BB;)=pi(r)(&#x3BB;)[1+qi(r)(&#x3BB;)]&#x2211;j=1mpi(r)(&#x3BB;&#x2032;)[1+qi(r)(&#x3BB;&#x2032;)] p_i^{(r+1)}(\\lambda) = \\frac{p_i^{(r)}(&#x3BB;)[1+q_i^{(r)}(&#x3BB;)]}{\\displaystyle\\sum_{j=1}^mp_i^{(r)}(&#x3BB;&apos;)[1+q_i^{(r)}(&#x3BB;&apos;)]} pi(r+1)&#x200B;(&#x3BB;)=j=1&#x2211;m&#x200B;pi(r)&#x200B;(&#x3BB;&#x2032;)[1+qi(r)&#x200B;(&#x3BB;&#x2032;)]pi(r)&#x200B;(&#x3BB;)[1+qi(r)&#x200B;(&#x3BB;)]&#x200B; &#x5728;&#x8FD9;&#x91CC;, &#x53EA;&#x9009;&#x62E9;pi(r)(&#x3BB;)p_i^{(r)}(\\lambda)pi(r)&#x200B;(&#x3BB;)&#x548C;C(i,&#x3BB;,j,&#x3BB;&#x2032;)C(i, &#x3BB;, j, &#x3BB;&apos;)C(i,&#x3BB;,j,&#x3BB;&#x2032;)&#x5E76;&#x5E94;&#x7528;&#x8BE5;&#x7B49;&#x5F0F;&#x9012;&#x5F52;&#x66F4;&#x65B0;pi(r)(&#x3BB;)p_i^{(r)}(\\lambda)pi(r)&#x200B;(&#x3BB;), &#x76F4;&#x5230;&#x5B83;&#x4EEC;&#x505C;&#x6B62;&#x53D8;&#x5316;&#x6216;&#x6536;&#x655B;&#x5230;1&#x3002;&#x5BF9;&#x6BCF;&#x4E2A;&#x7EBF;&#x6BB5;&#x8FDB;&#x884C;&#x8FED;&#x4EE3;&#x9A8C;&#x8BC1;, &#x76F4;&#x5230;&#x5C06;&#x5176;&#x5206;&#x914D;&#x7ED9;&#x6B63;&#x786E;&#x7684;&#x8BED;&#x4E49;&#x6807;&#x7B7E;&#x201C; hair&#x201D;&#x4E3A;&#x6B62;&#x3002; &#x5B9E;&#x9A8C;&#x7ED3;&#x679C; &#x4E3A;&#x4E86;&#x8BC4;&#x4F30;&#x8BE5;&#x7CFB;&#x7EDF;, &#x6211;&#x4EEC;&#x4ECE;UPMOST(UPG622)DMC&#x6355;&#x83B7;&#x4E86;40&#x4E2A;&#x5206;&#x8FA8;&#x7387;&#x4E3A;1024&#xD7;768&#x7684;&#x6BD4;&#x4F8B;&#x5C3A;&#x56FE;&#x50CF;&#x4F5C;&#x4E3A;&#x6D4B;&#x8BD5;&#x6570;&#x636E;&#x96C6;&#x3002;&#x6839;&#x636E;DMC&#x7684;&#x767D;&#x5E73;&#x8861;, &#x6211;&#x4EEC;&#x5C06;&#x6D4B;&#x8BD5;&#x56FE;&#x50CF;&#x5206;&#x4E3A;&#x4E24;&#x7EC4;, &#x5206;&#x522B;&#x662F;&#x6570;&#x636E;&#x96C6;1&#x548C;&#x6570;&#x636E;&#x96C6;2&#x3002; Experiment 1: Cross-Validation of the Line Detection figure_10_result_images_for_line_detection &#x56FE;10(b)-(d)&#x663E;&#x793A;&#x4E86;&#x9884;&#x5904;&#x7406;&#x6A21;&#x5757;&#x7684;&#x7ED3;&#x679C;, &#x5305;&#x62EC;&#x4EAE;&#x70B9;&#x53BB;&#x9664;(BSR), &#x4E8C;&#x503C;&#x5316;&#x548C;&#x7A00;&#x5316;&#x8FC7;&#x7A0B;&#x3002; &#x4E3A;&#x4E86;&#x8BC4;&#x4F30;&#x591A;&#x5C3A;&#x5EA6;&#x7EBF;&#x68C0;&#x6D4B;&#x7B97;&#x6CD5;&#x7684;&#x6027;&#x80FD;, &#x6D4B;&#x8BD5;&#x56FE;&#x50CF;&#x6211;&#x4EEC;&#x5C06;HT&#x5E94;&#x7528;&#x4E8E;&#x4E09;&#x79CD;&#x4E0D;&#x540C;&#x5C3A;&#x5EA6;, &#x4EE5;&#x63D0;&#x53D6;&#x7EBF;&#x6BB5;&#x3002; &#x7136;&#x540E;&#x4F7F;&#x7528;&#x5934;&#x53D1;&#x6807;&#x7B7E;&#x673A;&#x5236;&#x786E;&#x5B9A;&#x5934;&#x53D1;&#x7684;&#x6570;&#x91CF;&#x3002; &#x5982;&#x56FE;10(e)-(f)&#x6240;&#x793A;, &#x5F69;&#x8272;&#x7EBF;&#x4EE3;&#x8868;&#x5934;&#x53D1;&#x7684;&#x6807;&#x7B7E;&#x3002; &#x6362;&#x53E5;&#x8BDD;&#x8BF4;, &#x5373;&#x4F7F;&#x5934;&#x53D1;&#x4EA4;&#x53C9;&#x6216;&#x91CD;&#x53E0;, &#x4E5F;&#x53EF;&#x4EE5;&#x51C6;&#x786E;&#x5730;&#x6807;&#x8BB0;&#x5934;&#x53D1;&#x3002; &#x4EE5;&#x4E0B;&#x90E8;&#x5206;&#x6F14;&#x793A;&#x4E86;&#x6709;&#x5173;&#x7CBE;&#x786E;&#x5EA6;&#x548C;&#x53EC;&#x56DE;&#x7387;&#x7684;&#x6BDB;&#x53D1;&#x8BA1;&#x6570;&#x7684;&#x5BA2;&#x89C2;&#x6D4B;&#x91CF;&#x3002; &#x6211;&#x4EEC;&#x6BD4;&#x8F83;&#x4E86;&#x4F7F;&#x7528;BSR&#x548C;MSLD&#x6A21;&#x5757;&#x7EC4;&#x5408;&#x7684;&#x56DB;&#x79CD;&#x60C5;&#x51B5;, &#x5305;&#x62EC;BSR + MSLD, &#x800C;&#x6CA1;&#x6709;&#x540C;&#x65F6;&#x4F7F;&#x7528;BSR&#x548C;MSLD, &#x4EC5;BSR&#x548C;&#x4EC5;MSLD&#x3002; table_1_comarison_of_the_system_sensitivity_forthe_module_usages_in_the_line_detection &#x8868;I&#x6BD4;&#x8F83;&#x4E86;&#x57FA;&#x4E8E;&#x6A21;&#x5757;&#x4F7F;&#x7528;&#x60C5;&#x51B5;&#x7684;&#x7CFB;&#x7EDF;&#x654F;&#x611F;&#x6027;&#x3002;&#x57FA;&#x4E8E;&#x5F62;&#x6001;&#x5B66;&#x7684;BSR&#x548C;MSLD&#x673A;&#x5236;, &#x4EE5;&#x63D0;&#x9AD8;&#x5934;&#x53D1;&#x68C0;&#x6D4B;&#x7684;&#x6027;&#x80FD;, &#x5176;&#x51C6;&#x786E;&#x7387;&#x5206;&#x522B;&#x4E3A;94.98&#xFF05;&#x548C;98.05&#xFF05;&#x3002;&#x4E0E;&#x4F20;&#x7EDF;&#x7684;HT&#x7EBF;&#x68C0;&#x6D4B;&#x65B9;&#x6CD5;&#x76F8;&#x6BD4;, &#x6570;&#x636E;&#x96C6;1&#x548C;&#x6570;&#x636E;&#x96C6;2&#x5206;&#x522B;&#x63D0;&#x9AD8;&#x4E86;2&#xFF05;&#x548C;1.5&#xFF05;&#x3002;&#x4ECE;&#x53EC;&#x56DE;&#x7387;&#x7684;&#x89D2;&#x5EA6;&#x6765;&#x770B;, &#x5B83;&#x4E5F;&#x9AD8;&#x4E8E;&#x5176;&#x4ED6;&#x6A21;&#x5757;&#x7EC4;&#x5408;&#x3002; &#x5E73;&#x5747;&#x800C;&#x8A00;, &#x6211;&#x4EEC;&#x7684;&#x53EC;&#x56DE;&#x7387;&#x5206;&#x522B;&#x4E3A;9&#xFF05;&#x548C;10&#xFF05;&#x3002;&#x6839;&#x636E;&#x6211;&#x4EEC;&#x7684;&#x89C2;&#x5BDF;, &#x5E94;&#x7528;BSR&#x540E;, &#x51C6;&#x786E;&#x7387;&#x5F97;&#x5230;&#x4E86;&#x63D0;&#x9AD8;&#x3002; &#x4F46;&#x662F;, &#x5C06;MSLD&#x5E94;&#x7528;&#x4E8E;&#x6570;&#x636E;&#x96C6;&#xFF03;2&#x65F6;, &#x51C6;&#x786E;&#x7387;&#x4E0B;&#x964D;, &#x56E0;&#x4E3A;&#x5B83;&#x5728;&#x6CB9;&#x6027;&#x5934;&#x76AE;&#x533A;&#x57DF;&#x4E2D;&#x4EA7;&#x751F;&#x4E86;&#x5927;&#x91CF;&#x7684;&#x5149;&#x53CD;&#x5C04;&#x3002;&#x540C;&#x6837;, &#x5934;&#x53D1;&#x4E2D;&#x90E8;&#x7684;&#x4EAE;&#x70B9;&#x4E5F;&#x88AB;&#x5927;&#x5927;&#x589E;&#x5F3A;, &#x5BFC;&#x81F4;&#x7CBE;&#x786E;&#x5EA6;&#x964D;&#x4F4E;&#x3002; Experiment 2: System Refinement Using the PLB Algorithm table_2_system_performance_for_with_or_without_PLB &#x8868;II&#x663E;&#x793A;&#x4E86;PLB&#x7B97;&#x6CD5;&#x7684;&#x6548;&#x7387;&#x3002;PLB&#x65B9;&#x6CD5;&#x4F7F;&#x7CFB;&#x7EDF;&#x80FD;&#x591F;&#x63D0;&#x53D6;&#x7F3A;&#x5931;&#x7684;&#x6BDB;&#x53D1;, &#x7CBE;&#x786E;&#x7387;&#x63D0;&#x9AD8;&#x4E86;0.5&#xFF05;, &#x53EC;&#x56DE;&#x7387;&#x63D0;&#x9AD8;&#x4E86;5&#xFF05;&#x3002; PLB&#x7B97;&#x6CD5;&#x53EF;&#x4EE5;&#x7528;&#x4F5C;&#x7CFB;&#x7EDF;&#x5FAE;&#x8C03;&#x8FC7;&#x7A0B;, &#x5C06;&#x7CFB;&#x7EDF;&#x6027;&#x80FD;&#x5E73;&#x5747;&#x63D0;&#x9AD8;&#x5230;96.89&#xFF05;&#x3002;&#x8FD9;&#x662F;&#x5408;&#x7406;&#x7684;, &#x56E0;&#x4E3A;&#x9690;&#x85CF;&#x7684;&#x5934;&#x53D1;&#x4E0D;&#x7ECF;&#x5E38;&#x51FA;&#x73B0;&#x3002; &#x6B64;&#x5916;, &#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x663E;&#x5FAE;&#x955C;&#x63A7;&#x5236;&#x5934;&#x53D1;&#x56FE;&#x50CF;&#x7684;&#x5206;&#x8FA8;&#x7387;&#x548C;&#x89D2;&#x5EA6;, &#x4EE5;&#x907F;&#x514D;&#x8FD9;&#x79CD;&#x60C5;&#x51B5;&#x3002; Experiment 3: Complexity Analysis table_3_time_occupancy_of_each_module_compared_with_total_execution &#x5F53;&#x6D89;&#x53CA;&#x5230;&#x7CFB;&#x7EDF;&#x590D;&#x6742;&#x6027;&#x5206;&#x6790;&#x65F6;, &#x6211;&#x4EEC;&#x77E5;&#x9053;&#x62DF;&#x8BAE;&#x7684;&#x5934;&#x53D1;&#x8BA1;&#x6570;&#x7CFB;&#x7EDF;&#x4F1A;&#x82B1;&#x8D39;&#x66F4;&#x591A;&#x65F6;&#x95F4;&#x3002;&#x5E73;&#x5747;&#x800C;&#x8A00;, &#x9AD8;&#x5206;&#x8FA8;&#x7387;&#x6D4B;&#x8BD5;&#x56FE;&#x50CF;&#x9700;&#x8981;&#x4E0D;&#x5230;4&#x79D2;&#x7684;&#x65F6;&#x95F4;&#x5373;&#x53EF;&#x5F97;&#x51FA;&#x6BDB;&#x53D1;&#x8BA1;&#x6570;&#x4FE1;&#x606F;&#x3002; &#x8868;III&#x5217;&#x51FA;&#x4E86;&#x6BCF;&#x4E2A;&#x6A21;&#x5757;&#x6240;&#x9700;&#x7684;&#x65F6;&#x95F4;&#x4E0E;&#x603B;&#x6267;&#x884C;&#x65F6;&#x95F4;&#x7684;&#x6BD4;&#x8F83;&#x3002; MSLD&#x4F7F;&#x7528;&#x4E09;&#x4E2A;&#x6BD4;&#x4F8B;&#x5C3A;&#x6765;&#x83B7;&#x53D6;&#x4E00;&#x7EC4;&#x7EBF;&#x6BB5;, &#x8FD9;&#x9700;&#x8981;&#x5927;&#x90E8;&#x5206;&#x6267;&#x884C;&#x65F6;&#x95F4;&#x3002; HT&#x5C06;&#x8FB9;&#x7F18;&#x6295;&#x5F71;&#x5230;(&#x3C1;, &#x3B8;)&#x7A7A;&#x95F4;&#x4EE5;&#x63D0;&#x53D6;&#x5C40;&#x90E8;&#x6700;&#x5927;&#x503C;&#x7684;&#x8FC7;&#x7A0B;&#x975E;&#x5E38;&#x8017;&#x65F6;&#x3002; &#x4E3A;&#x4E86;&#x514B;&#x670D;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;, &#x6211;&#x4EEC;&#x5728;MSLD&#x4E2D;&#x4EC5;&#x4F7F;&#x7528;&#x4E86;&#x4E24;&#x4E2A;&#x6807;&#x5EA6;&#x3002;&#x4F46;&#x662F;, &#x6B64;&#x5C1D;&#x8BD5;&#x5BFC;&#x81F4;&#x6027;&#x80FD;&#x4E0B;&#x964D;&#x3002; &#x6B64;&#x5916;, &#x7EC6;&#x5316;&#x8FC7;&#x7A0B;&#x5360;&#x7528;&#x4E86;&#x603B;&#x5904;&#x7406;&#x65F6;&#x95F4;&#x7684;&#x56DB;&#x5206;&#x4E4B;&#x4E00;&#x4EE5;&#x4E0A;&#x3002;&#x8FD9;&#x662F;&#x6267;&#x884C;&#x65F6;&#x95F4;&#x548C;&#x7CFB;&#x7EDF;&#x7CBE;&#x5EA6;&#x4E4B;&#x95F4;&#x7684;&#x6743;&#x8861;&#x3002; &#x603B;&#x7ED3; &#x8FD9;&#x9879;&#x7814;&#x7A76;&#x63D0;&#x51FA;&#x4E86;&#x4E00;&#x79CD;&#x81EA;&#x52A8;&#x7684;&#x5934;&#x53D1;&#x5206;&#x5272;&#x548C;&#x8BA1;&#x6570;&#x7CFB;&#x7EDF;, &#x4EE5;&#x51CF;&#x5C11;&#x4EBA;&#x5DE5;&#x8BC4;&#x4F30;&#x8005;&#x8FDB;&#x884C;&#x8BE6;&#x7EC6;&#x5934;&#x76AE;&#x8BC4;&#x4F30;&#x6240;&#x9700;&#x7684;&#x65F6;&#x95F4;&#x3002; 1. &#x9996;&#x5148;, &#x6CB9;&#x6027;&#x548C;&#x6E7F;&#x6DA6;&#x7684;&#x5934;&#x53D1;&#x4F1A;&#x5728;&#x5934;&#x53D1;&#x4E2D;&#x95F4;&#x4EA7;&#x751F;&#x4EAE;&#x70B9;&#x3002;&#x5728;&#x8BA1;&#x7B97;&#x5934;&#x53D1;&#x6570;&#x4E4B;&#x524D;, &#x6211;&#x4EEC;&#x9700;&#x8981;&#x6D88;&#x9664;&#x5934;&#x53D1;&#x4E0A;&#x7684;&#x4EAE;&#x70B9;, &#x4EE5;&#x907F;&#x514D;&#x91CD;&#x590D;&#x8BA1;&#x7B97;&#x4E00;&#x4E9B;&#x5934;&#x53D1;&#x7684;&#x95EE;&#x9898;&#x3002; 2. &#x7B2C;&#x4E8C;, &#x6CE2;&#x6D6A;&#x72B6;&#x548C;&#x5377;&#x53D1;&#x5BB9;&#x6613;&#x5BFC;&#x81F4;&#x7EBF;&#x68C0;&#x6D4B;&#x6545;&#x969C;&#x3002;&#x5F53;&#x5934;&#x53D1;&#x4E0D;&#x76F4;&#x65F6;, &#x5E38;&#x89C4;&#x7684;&#x7EBF;&#x68C0;&#x6D4B;&#x7B97;&#x6CD5;&#x65E0;&#x6548;&#x3002; 3. &#x7B2C;&#x4E09;, &#x5F53;&#x5934;&#x53D1;&#x76F8;&#x4E92;&#x4EA4;&#x53C9;&#x5E76;&#x4E92;&#x76F8;&#x54AC;&#x5408;&#x65F6;, &#x4F1A;&#x51FA;&#x73B0;&#x5BF9;&#x5934;&#x53D1;&#x6570;&#x91CF;&#x7684;&#x4F4E;&#x4F30;, &#x8FD9;&#x4F7F;&#x5F97;&#x7CBE;&#x786E;&#x5B9A;&#x4F4D;&#x6240;&#x6709;&#x5934;&#x53D1;&#x975E;&#x5E38;&#x56F0;&#x96BE;&#x3002; 4. &#x6700;&#x540E;, &#x7531;&#x4E8E;&#x5934;&#x76AE;&#x76F8;&#x5BF9;&#x672A;&#x66DD;&#x5149;, &#x56E0;&#x6B64;&#x5934;&#x76AE;&#x7684;&#x56FE;&#x50CF;&#x901A;&#x5E38;&#x6A21;&#x7CCA;&#x6216;&#x96BE;&#x4EE5;&#x770B;&#x89C1;&#x3002;&#x53E6;&#x5916;, &#x5934;&#x76AE;&#x901A;&#x5E38;&#x7167;&#x660E;&#x4E0D;&#x8DB3;&#x6216;&#x66DD;&#x5149;&#x8FC7;&#x5EA6;&#x3002; &#x8BA1;&#x6570;&#x601D;&#x8DEF; &#x901A;&#x8FC7;&#x5BF9;&#x4E0D;&#x540C;&#x7F29;&#x7565;&#x56FE;&#x4E2D;&#x7684;&#x5934;&#x53D1;&#x505A;HT&#x7EBF;&#x6BB5;&#x68C0;&#x6D4B;, &#x7136;&#x540E;&#x5C06;&#x6240;&#x6709;&#x68C0;&#x6D4B;&#x7ED3;&#x679C;&#x8FDB;&#x884C;&#x201C;&#x903B;&#x8F91;&#x6216;&#x201D;&#x6574;&#x5408;, &#x4EE5;&#x51CF;&#x5C11;&#x7F3A;&#x5931;&#x5934;&#x53D1;&#x7684;&#x8BA1;&#x6570;, &#x89E3;&#x51B3;&#x91CD;&#x53E0;&#x5934;&#x53D1;&#x7684;&#x6F0F;&#x8BA1;&#x6570;&#x7684;&#x95EE;&#x9898;&#x3002; &#x672C;&#x6587;&#x7684;&#x6846;&#x67B6;&#x53EF;&#x4EE5;&#x88AB;&#x89C6;&#x4E3A;&#x8FC8;&#x5411;&#x5316;&#x5986;&#x54C1;&#x548C;&#x5934;&#x76AE;&#x6CBB;&#x7597;&#x5E94;&#x7528;&#x7684;&#x667A;&#x80FD;&#x8BA1;&#x7B97;&#x673A;&#x8F85;&#x52A9;&#x533B;&#x5B66;&#x56FE;&#x50CF;&#x5904;&#x7406;&#x7684;&#x7B2C;&#x4E00;&#x6B65;&#x3002; &#x6280;&#x672F;&#x603B;&#x7ED3; &#x9884;&#x5904;&#x7406;&#x9636;&#x6BB5; &#x5BF9;&#x8F93;&#x5165;&#x6570;&#x636E;(&#x5934;&#x76AE;&#x56FE;&#x7247;)&#x8FDB;&#x884C;&#x9884;&#x5904;&#x7406;, &#x4E3A;&#x4E0B;&#x4E00;&#x9636;&#x6BB5;&#x5BF9;&#x56FE;&#x7247;&#x4E2D;&#x5934;&#x53D1;&#x8FDB;&#x884C;&#x7CBE;&#x51C6;&#x8BA1;&#x6570;&#x7B49;&#x529F;&#x80FD;&#x6027;&#x64CD;&#x4F5C;&#x505A;&#x597D;&#x94FA;&#x57AB;&#x3002;&#x4E3B;&#x8981;&#x7528;&#x5230;&#x4EE5;&#x4E0B;&#x6280;&#x672F;&#xFF1A; Contrast Stretching (Normalization): &#x5BF9;&#x6BD4;&#x5EA6;&#x62C9;&#x4F38;(&#x901A;&#x5E38;&#x79F0;&#x4E3A;&#x5F52;&#x4E00;&#x5316;)&#x662F;&#x4E00;&#x79CD;&#x7B80;&#x5355;&#x7684;&#x56FE;&#x50CF;&#x589E;&#x5F3A;&#x6280;&#x672F;,&#x65E8;&#x5728;&#x901A;&#x8FC7;&#x201C;&#x62C9;&#x4F38;&#x201D;&#x56FE;&#x50CF;&#x6240;&#x5305;&#x542B;&#x7684;&#x5F3A;&#x5EA6;&#x503C;&#x8303;&#x56F4;&#x4EE5;&#x8986;&#x76D6;&#x6240;&#x9700;&#x7684;&#x503C;&#x8303;&#x56F4;&#x6765;&#x6539;&#x5584;&#x56FE;&#x50CF;&#x7684;&#x5BF9;&#x6BD4;&#x5EA6;&#x3002; &#x6280;&#x672F;&#x5E94;&#x7528;&#xFF1A;&#x589E;&#x52A0;&#x5934;&#x76AE;&#x4E0E;&#x5934;&#x53D1;&#x4E4B;&#x95F4;&#x7684;&#x5BF9;&#x6BD4;&#x5EA6;, &#x65B9;&#x4FBF;&#x4E0B;&#x9636;&#x6BB5;&#x5BF9;&#x5934;&#x53D1;&#x8FDB;&#x884C;&#x8BED;&#x4E49;&#x5206;&#x5272;&#x3002; Color Morphology EXTENDING MATHEMATICAL MORPHOLOGY TO COLOR IMAGE PROCESSING &#x6280;&#x672F;&#x5E94;&#x7528;&#xFF1A; &#x9664;&#x566A;, &#x53BB;&#x9664;&#x6CB9;&#x6027;&#x548C;&#x6E7F;&#x6DA6;&#x7684;&#x5934;&#x53D1;&#x5728;&#x5934;&#x53D1;&#x7684;&#x4E2D;&#x90E8;&#x4EA7;&#x751F;&#x7684;&#x4EAE;&#x70B9; Karhunen-Loeve Transform (KLT) Karhunen-Loeve&#x53D8;&#x6362;(KLT)(&#x4E5F;&#x79F0;&#x4E3A;Hotelling&#x53D8;&#x6362;&#x548C;&#x7279;&#x5F81;&#x5411;&#x91CF;&#x53D8;&#x6362;), &#x5B83;&#x4E0E;&#x4E3B;&#x6210;&#x5206;&#x5206;&#x6790;(PCA)&#x5BC6;&#x5207;&#x76F8;&#x5173;, &#x5E76;&#x5E7F;&#x6CDB;&#x7528;&#x4E8E;&#x8BB8;&#x591A;&#x9886;&#x57DF;&#x7684;&#x6570;&#x636E;&#x5206;&#x6790;&#x4E2D;, KL&#x53D8;&#x6362;&#x57FA;&#x4E8E;&#x56FE;&#x50CF;&#x7684;&#x7EDF;&#x8BA1;&#x5C5E;&#x6027;, &#x5E76;&#x5177;&#x6709;&#x4E00;&#x4E9B;&#x91CD;&#x8981;&#x7684;&#x5C5E;&#x6027;, &#x4F7F;&#x5176;&#x53EF;&#x7528;&#x4E8E;&#x56FE;&#x50CF;&#x5904;&#x7406;, &#x7279;&#x522B;&#x662F;&#x56FE;&#x50CF;&#x538B;&#x7F29;&#x3002; &#x6280;&#x672F;&#x5E94;&#x7528;&#xFF1A; &#x5C06;&#x5F69;&#x8272;&#x56FE;&#x50CF;&#x8F6C;&#x6362;&#x4E3A;&#x7070;&#x5EA6;&#x56FE;&#x50CF;&#x3002; Otsu thresholding Otsu thresholding&#xFF1A;&#x7B80;&#x5355;&#x8BF4;&#x6765;&#x8BE5;&#x65B9;&#x6CD5;&#x53EF;&#x5C06;&#x7070;&#x5EA6;&#x56FE;&#x50CF;&#x8FD8;&#x539F;&#x4E3A;&#x4E8C;&#x8FDB;&#x5236;&#x56FE;&#x50CF;&#x3002;&#x5728;&#x56FE;&#x50CF;&#x5904;&#x7406;&#x548C;&#x5206;&#x6790;&#x4E2D;, &#x6709;&#x65F6;&#x9700;&#x8981;&#x4E00;&#x79CD;&#x65B9;&#x6CD5;&#x6765;&#x5206;&#x79BB;&#x4E24;&#x4E2A;&#x76F8;&#x5173;&#x6570;&#x636E;, &#x4F8B;&#x5982;&#x80CC;&#x666F;&#x548C;&#x524D;&#x666F;&#x3002;Otsu&#x9608;&#x503C;&#x662F;&#x4E00;&#x79CD;&#x6570;&#x636E;&#x9A71;&#x52A8;&#x7684;&#x65B9;&#x6CD5;, &#x8BE5;&#x65B9;&#x6CD5;&#x53EF;&#x4EE5;&#x81EA;&#x9002;&#x5E94;&#x5730;&#x627E;&#x5230;&#x6700;&#x4F73;&#x9608;&#x503C;&#x4EE5;&#x533A;&#x5206;&#x4E24;&#x7C7B;&#x6570;&#x636E;&#x3002; &#x6280;&#x672F;&#x5E94;&#x7528;&#xFF1A; &#x56FE;&#x50CF;&#x5206;&#x5272;&#x548C;&#x56FE;&#x50CF;&#x4E8C;&#x503C;&#x5316;&#x3002; &#x591A;&#x5C3A;&#x5EA6;&#x7EBF;&#x68C0;&#x6D4B;&#x9636;&#x6BB5;(MSLD) &#x8BE5;&#x9636;&#x6BB5;&#x4E3B;&#x8981;&#x662F;&#x901A;&#x8FC7;&#x5404;&#x79CD;&#x6280;&#x672F;, &#x514B;&#x670D;&#x91CD;&#x53E0;&#x5934;&#x53D1;&#x65E0;&#x6CD5;&#x8BA1;&#x6570;, &#x4EE5;&#x53CA;&#x76F8;&#x90BB;&#x5934;&#x53D1;&#x4E4B;&#x95F4;&#x7684;&#x5934;&#x76AE;&#x88AB;&#x8BC6;&#x522B;&#x4E3A;&#x5934;&#x53D1;&#x7B49;&#x5F71;&#x54CD;&#x5934;&#x53D1;&#x8BA1;&#x6570;&#x7684;&#x76F8;&#x5173;&#x95EE;&#x9898;&#x3002;&#x4E3A;&#x4E0B;&#x9636;&#x6BB5;&#x5BF9;&#x5934;&#x53D1;&#x8FDB;&#x884C;&#x7CBE;&#x51C6;&#x8BA1;&#x6570;&#x7684;&#x505A;&#x597D;&#x94FA;&#x57AB;&#x3002;&#x4E3B;&#x8981;&#x7528;&#x5230;&#x4EE5;&#x4E0B;&#x6280;&#x672F;&#xFF1A; &#x970D;&#x592B;&#x53D8;&#x6362;(HT) &#x970D;&#x592B;&#x53D8;&#x6362;(HT) &#x970D;&#x592B;&#x53D8;&#x6362;&#x662F;&#x4E00;&#x79CD;&#x53EF;&#x7528;&#x4E8E;&#x9694;&#x79BB;&#x56FE;&#x50CF;&#x4E2D;&#x7279;&#x5B9A;&#x5F62;&#x72B6;&#x7684;&#x7279;&#x5F81;&#x7684;&#x6280;&#x672F;&#x3002;&#x56E0;&#x4E3A;&#x5B83;&#x8981;&#x6C42;&#x4EE5;&#x67D0;&#x79CD;&#x53C2;&#x6570;&#x5F62;&#x5F0F;&#x6307;&#x5B9A;&#x6240;&#x9700;&#x7684;&#x7279;&#x5F81;, &#x6240;&#x4EE5;&#x7ECF;&#x5178;&#x7684;Hough&#x53D8;&#x6362;&#x6700;&#x5E38;&#x7528;&#x4E8E;&#x68C0;&#x6D4B;&#x89C4;&#x5219;&#x66F2;&#x7EBF;(&#x4F8B;&#x5982;&#x76F4;&#x7EBF;, &#x5706;, &#x692D;&#x5706;&#x7B49;)&#x3002; &#x6280;&#x672F;&#x5E94;&#x7528;&#xFF1A; HT&#x662F;&#x6700;&#x5E38;&#x7528;&#x7684;&#x7EBF;&#x68C0;&#x6D4B;&#x6846;&#x67B6;&#x4E4B;&#x4E00;&#x3002;&#x4F46;&#x662F;&#x5F53;&#x4F7F;&#x7528;&#x5E38;&#x89C4;&#x7684;&#x5355;&#x5C3A;&#x5EA6;HT&#x65F6;, &#x53EF;&#x80FD;&#x4F1A;&#x4E22;&#x5931;&#x5927;&#x91CF;&#x7684;&#x5934;&#x53D1;&#x6BB5;&#x3002;&#x6545;&#x63D0;&#x51FA;&#x5C06;HT&#x5E94;&#x7528;&#x4E8E;&#x4E09;&#x4E2A;&#x6BD4;&#x4F8B;&#x7684;&#x56FE;&#x50CF;, &#x5305;&#x62EC;1024&#xD7;768(&#x539F;&#x59CB;&#x6BD4;&#x4F8B;), 512&#xD7;384&#x548C;256&#xD7;192, &#x6700;&#x540E;&#x901A;&#x8FC7;&#x903B;&#x8F91;&#x6216;&#x5C06;&#x4E09;&#x4E2A;&#x6BD4;&#x4F8B;&#x56FE;&#x50CF;&#x4E2D;&#x7684;&#x88AB;&#x68C0;&#x6D4B;&#x51FA;&#x7684;&#x5934;&#x53D1;&#x8FDB;&#x884C;&#x6574;&#x5408;, &#x4EE5;&#x63D0;&#x9AD8;&#x5934;&#x53D1;&#x8BA1;&#x6570;&#x51C6;&#x786E;&#x5EA6;&#x3002; Canny Edge Detection Canny&#x8FB9;&#x7F18;&#x68C0;&#x6D4B;&#x662F;&#x4E00;&#x79CD;&#x591A;&#x6B65;&#x9AA4;&#x7B97;&#x6CD5;, &#x53EF;&#x4EE5;&#x540C;&#x65F6;&#x68C0;&#x6D4B;&#x5230;&#x566A;&#x58F0;&#x88AB;&#x6291;&#x5236;&#x7684;&#x8FB9;&#x7F18;&#x3002;&#x5728;&#x56FE;&#x50CF;&#x4E8C;&#x503C;&#x5316;&#x6B65;&#x9AA4;&#x4E2D;, &#x7531;&#x4E8E;&#x9519;&#x8BEF;&#x5730;&#x5047;&#x5B9A;&#x4E86;&#x4E24;&#x6839;&#x5355;&#x72EC;&#x7684;&#x5934;&#x53D1;&#x7684;&#x8FDE;&#x63A5;, &#x4F4D;&#x4E8E;&#x4E24;&#x6839;&#x5934;&#x53D1;&#x4E4B;&#x95F4;&#x7684;&#x5934;&#x76AE;&#x50CF;&#x7D20;&#x88AB;&#x6807;&#x8BB0;&#x4E3A;&#x5934;&#x53D1;&#x7684;&#x4E00;&#x90E8;&#x5206;&#x3002;&#x800C;&#x4E14;, &#x5F53;&#x4E24;&#x6839;&#x5934;&#x53D1;&#x592A;&#x9760;&#x8FD1;&#x6216;&#x5F7C;&#x6B64;&#x91CD;&#x53E0;&#x65F6;, &#x5982;&#x679C;&#x76F4;&#x63A5;&#x5E94;&#x7528;&#x7A00;&#x758F;&#x7B97;&#x6CD5;, &#x5219;&#x4F1A;&#x9519;&#x8FC7;&#x4E00;&#x6839;&#x6216;&#x4E24;&#x6839;&#x5934;&#x53D1;&#x3002; &#x6280;&#x672F;&#x5E94;&#x7528;&#xFF1A; &#x4F7F;&#x7528;&#x8FB9;&#x7F18;&#x4FE1;&#x606F;&#x6765;&#x627E;&#x51FA;&#x9690;&#x85CF;&#x6216;&#x91CD;&#x53E0;&#x7684;&#x5934;&#x53D1;&#x3002;&#x53EF;&#x4EE5;&#x4ECE;&#x9690;&#x85CF;&#x7684;&#x5934;&#x53D1;&#x6216;&#x91CD;&#x53E0;&#x7684;&#x591A;&#x6839;&#x5934;&#x53D1;&#x4E2D;&#x63D0;&#x53D6;&#x4E24;&#x4E2A;&#x5E73;&#x884C;&#x7684;&#x8FB9;&#x7F18;&#x3002; Thinning Parallel Line Bundling (PLB) &#x5934;&#x53D1;&#x6807;&#x8BB0;&#x548C;&#x8BA1;&#x6570;&#x9636;&#x6BB5;(Hair Labling and Counting) &#x8BE5;&#x9636;&#x6BB5;&#x7684;&#x76EE;&#x7684;&#x662F;&#x51C6;&#x786E;&#x8BA1;&#x7B97;&#x5934;&#x76AE;&#x4E0A;&#x7684;&#x6BDB;&#x53D1;&#x6570;&#x91CF;&#x3002;&#x8FD9;&#x53EF;&#x4EE5;&#x770B;&#x4F5C;&#x662F;&#x805A;&#x7C7B;&#x548C;&#x6807;&#x8BB0;&#x95EE;&#x9898;&#x3002;&#x76EE;&#x6807;&#x662F;&#x5C06;&#x4E00;&#x7EC4;&#x7EBF;&#x6BB5;&#x7EC4;&#x5408;&#x6210;&#x8BED;&#x4E49;&#x201C;&#x5934;&#x53D1;&#x201D;&#x5E76;&#x5206;&#x914D;&#x552F;&#x4E00;&#x7684;&#x6807;&#x7B7E;&#x3002; &#x4E3B;&#x8981;&#x7528;&#x5230;&#x4EE5;&#x4E0B;&#x6280;&#x672F;&#xFF1A; Relaxation Labeling &#x677E;&#x5F1B;&#x6807;&#x8BB0;&#x662F;&#x4E00;&#x79CD;&#x56FE;&#x50CF;&#x5904;&#x7406;&#x65B9;&#x6CD5;&#x3002;&#x5176;&#x76EE;&#x6807;&#x662F;&#x5C06;&#x6807;&#x7B7E;&#x4E0E;&#x7ED9;&#x5B9A;&#x56FE;&#x50CF;&#x7684;&#x50CF;&#x7D20;&#x6216;&#x7ED9;&#x5B9A;&#x56FE;&#x7684;&#x8282;&#x70B9;&#x76F8;&#x5173;&#x8054;&#x3002; &#x6280;&#x672F;&#x5E94;&#x7528;&#xFF1A; &#x5728;&#x672C;&#x7814;&#x7A76;&#x4E2D;, RL&#x7B97;&#x6CD5;&#x88AB;&#x89C6;&#x4E3A;&#x7528;&#x4E8E;&#x6807;&#x8BB0;&#x6BCF;&#x4E2A;&#x7EBF;&#x6BB5;&#x7684;&#x805A;&#x7C7B;&#x65B9;&#x6CD5;&#x3002; &#x53C2;&#x8003;&#x6587;&#x732E; An Unsupervised Hair Segmentation and Counting System in Microscopy Images Contrast Stretching (Normalization) Color Morphology EXTENDING MATHEMATICAL MORPHOLOGY TO COLOR IMAGE PROCESSING Karhunen-Loeve Transform (KLT) Otsu thresholding Hough Transform(HT) Canny Edge Detection Thinning Evaluation of a Bundling Technique for Parallel Coordinates Relaxation Labeling","categories":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Paper Smash","slug":"Technology/Paper-Smash","permalink":"https://littlelittlemoon.github.io/categories/Technology/Paper-Smash/"}],"tags":[{"name":"Hair Counting","slug":"Hair-Counting","permalink":"https://littlelittlemoon.github.io/tags/Hair-Counting/"},{"name":"Digital Image Processing","slug":"Digital-Image-Processing","permalink":"https://littlelittlemoon.github.io/tags/Digital-Image-Processing/"},{"name":"Line Detection","slug":"Line-Detection","permalink":"https://littlelittlemoon.github.io/tags/Line-Detection/"},{"name":"Paper","slug":"Paper","permalink":"https://littlelittlemoon.github.io/tags/Paper/"}],"keywords":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Paper Smash","slug":"Technology/Paper-Smash","permalink":"https://littlelittlemoon.github.io/categories/Technology/Paper-Smash/"}]},{"title":"Evalution of hair and scalp condition based on microscopy image analysis | Hair Counting - part 1","slug":"Technology/Evalution of hair and scalp condition based on microscopy image analysis  | Hair Counting - 1","date":"2019-12-24T12:35:33.000Z","updated":"2020-04-12T13:06:54.541Z","comments":true,"path":"2019/12/24/Technology/Evalution of hair and scalp condition based on microscopy image analysis  | Hair Counting - 1/","link":"","permalink":"https://littlelittlemoon.github.io/2019/12/24/Technology/Evalution%20of%20hair%20and%20scalp%20condition%20based%20on%20microscopy%20image%20analysis%20%20|%20Hair%20Counting%20-%201/","excerpt":"","text":"Paper: Evalution of hair and scalp condition based on microscopy image analysis 计数方法 典型的便携式显微镜相机通常覆盖5mm x 5mm的矩形。因此，如果一根头发长于5毫米，则它必须超出矩形。基于此观察，我们对毛发计数有两个假设： 1. 每根头发由一个起点和一个终点表示; 2. 起点位于矩形内部，终点位于图像的边界上。 头发计数：使用预处理阶段获得的骨架图像，基于上述两点假设，如果头发的骨架线的一个点在矩形内而另一点在边界上，则我们对头发进行计数。 fig_3_Example_of_hair_counting 图3示出了头发计数的示例。在图中，计数的像素用红色点标记，并且这些点叠加在原始图像上。然后，可以通过将计数的像素数除以图像尺寸来计算头发密度。 实验结果 为了评估头发计数算法，我们对200个头皮图像的数据集进行了实验。 表2列出了根据我们的算法计算出的实际毛发数与估计毛发数之间的精确度/召回率。 平均准确度和召回率分别为91.35％和92.01％。即使性能相当好，精度/调用率也可以进一步提高。错误的一个关键原因是预处理和原始图像的质量。在我们的实验中，一旦图像中出现模糊点，就不可能在预处理步骤中消除所有噪音。因此，考虑到相机噪声，精度非常好。 同样，我们测试了毛孔计数算法，结果显示平均准确率约为90％。 总结 计数思路 将图片边缘看作一矩形； 对满足“头发由一个起点和一个终点表示，且起点位于矩形内部，终点位于图像的边界上”条件的头发进行计数； 使用通过细化操作获得的头发骨架图像对满足条件的头发进行计数； 通过将计数的像素数除以图像尺寸来计算头发密度。 参考文献 Evalution of hair and scalp condition based on microscopy image analysis","categories":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Paper Smash","slug":"Technology/Paper-Smash","permalink":"https://littlelittlemoon.github.io/categories/Technology/Paper-Smash/"}],"tags":[{"name":"Hair Counting","slug":"Hair-Counting","permalink":"https://littlelittlemoon.github.io/tags/Hair-Counting/"},{"name":"Digital Image Processing","slug":"Digital-Image-Processing","permalink":"https://littlelittlemoon.github.io/tags/Digital-Image-Processing/"},{"name":"Line Detection","slug":"Line-Detection","permalink":"https://littlelittlemoon.github.io/tags/Line-Detection/"},{"name":"Paper","slug":"Paper","permalink":"https://littlelittlemoon.github.io/tags/Paper/"}],"keywords":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Paper Smash","slug":"Technology/Paper-Smash","permalink":"https://littlelittlemoon.github.io/categories/Technology/Paper-Smash/"}]}]}