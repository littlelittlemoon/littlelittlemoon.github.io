{"meta":{"title":"LITTLEMEEMOON","subtitle":"Every day with dreams is wonderful.","description":"This is my place where I can share my things about life, academic or just for fun, enjoy. :)","author":"Kayleen","url":"https://littlelittlemoon.github.io"},"pages":[{"title":"about","date":"2019-12-12T14:14:36.000Z","updated":"2020-04-08T13:08:47.938Z","comments":false,"path":"about/index.html","permalink":"https://littlelittlemoon.github.io/about/index.html","excerpt":"","text":"[Bear Cave - Kayleen]] ä¸&nbsp; Kayleen&nbsp; ï¼ˆ çœŸï¼ˆã¾ï¼‰ç™½ï¼ˆã—ã‚ï¼‰ ï¼‰ å¯¹è¯ä¸­... bot_ui_ini()","keywords":"å…³äº"},{"title":"bangumi","date":"2019-02-10T13:32:48.000Z","updated":"2020-04-06T16:05:44.917Z","comments":false,"path":"bangumi/index.html","permalink":"https://littlelittlemoon.github.io/bangumi/index.html","excerpt":"","text":"","keywords":null},{"title":"categories","date":"2019-12-20T15:13:48.000Z","updated":"2020-04-12T13:55:28.953Z","comments":true,"path":"categories/index.html","permalink":"https://littlelittlemoon.github.io/categories/index.html","excerpt":"","text":"In maintenance Hi, æ­¤é¡µé¢è¿˜åœ¨ç»´æŠ¤ä¸­å“¦ï¼Œè°¢è°¢ä½ çš„æœŸå¾…ï¼Œå¯ä»¥ç•™è¨€ç»™æˆ‘å“¦~ [ Bear Cave ] Kayleen","keywords":"æ–‡ç« åˆ†ç±»"},{"title":"comment","date":"2019-12-20T15:13:48.000Z","updated":"2020-04-07T11:26:02.901Z","comments":true,"path":"comment/index.html","permalink":"https://littlelittlemoon.github.io/comment/index.html","excerpt":"","text":"å¿µä¸¤å¥è¯— äººé—²æ¡‚èŠ±è½ï¼Œå¤œé™æ˜¥å±±ç©ºã€‚ æœˆå‡ºæƒŠå±±é¸Ÿï¼Œæ—¶é¸£æ˜¥æ¶§ä¸­ã€‚ ç‹ç»´ Â·ã€Šé¸Ÿé¸£æ¶§ã€‹","keywords":"ç•™è¨€æ¿"},{"title":"client","date":"2018-12-20T15:13:35.000Z","updated":"2020-04-06T16:22:30.837Z","comments":false,"path":"client/index.html","permalink":"https://littlelittlemoon.github.io/client/index.html","excerpt":"","text":"ç›´æ¥ä¸‹è½½ or æ‰«ç ä¸‹è½½ï¼š","keywords":"Androidå®¢æˆ·ç«¯"},{"title":"donate","date":"2019-12-20T15:13:05.000Z","updated":"2020-04-07T11:26:06.240Z","comments":false,"path":"donate/index.html","permalink":"https://littlelittlemoon.github.io/donate/index.html","excerpt":"","text":"","keywords":"è°¢è°¢é¥²ä¸»äº†å–µ~"},{"title":"lab","date":"2019-01-05T13:47:59.000Z","updated":"2020-04-12T13:55:36.478Z","comments":false,"path":"lab/index.html","permalink":"https://littlelittlemoon.github.io/lab/index.html","excerpt":"","text":"In maintenance Hi, æ­¤é¡µé¢è¿˜åœ¨ç»´æŠ¤ä¸­å“¦ï¼Œè°¢è°¢ä½ çš„æœŸå¾…ï¼Œå¯ä»¥ç•™è¨€ç»™æˆ‘å“¦~ [ Bear Cave ] Kayleen","keywords":"Labå®éªŒå®¤"},{"title":"rss","date":"2018-12-20T15:09:03.000Z","updated":"2020-04-06T16:05:44.919Z","comments":true,"path":"rss/index.html","permalink":"https://littlelittlemoon.github.io/rss/index.html","excerpt":"","text":""},{"title":"music","date":"2018-12-20T15:14:28.000Z","updated":"2020-04-09T08:55:04.838Z","comments":false,"path":"music/index.html","permalink":"https://littlelittlemoon.github.io/music/index.html","excerpt":"","text":"","keywords":"å°æ‚¦é‚€ä½ åœä¸‹æ¥å¬ä¼šæ­ŒğŸ˜Š"},{"title":"tags","date":"2018-12-12T14:14:16.000Z","updated":"2020-04-12T13:56:00.798Z","comments":true,"path":"tags/index.html","permalink":"https://littlelittlemoon.github.io/tags/index.html","excerpt":"","text":"In maintenance Hi, æ­¤é¡µé¢è¿˜åœ¨ç»´æŠ¤ä¸­å“¦ï¼Œè°¢è°¢ä½ çš„æœŸå¾…ï¼Œå¯ä»¥ç•™è¨€ç»™æˆ‘å“¦~ [ Bear Cave ] Kayleen","keywords":"æ ‡ç­¾"},{"title":"theme-sakura","date":"2019-01-04T14:53:25.000Z","updated":"2020-04-06T16:05:44.919Z","comments":false,"path":"theme-sakura/index.html","permalink":"https://littlelittlemoon.github.io/theme-sakura/index.html","excerpt":"","text":"Hexoä¸»é¢˜Sakuraä¿®æ”¹è‡ªWordPressä¸»é¢˜Sakuraï¼Œæ„Ÿè°¢åŸä½œè€…Mashiro","keywords":"Hexo ä¸»é¢˜ Sakura ğŸŒ¸"},{"title":"video","date":"2018-12-20T15:14:38.000Z","updated":"2020-04-06T16:05:44.919Z","comments":false,"path":"video/index.html","permalink":"https://littlelittlemoon.github.io/video/index.html","excerpt":"","text":"var videos = [ { img: 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: 'æœèŠ±å¤•èª“â€”â€”äºç¦»åˆ«ä¹‹æœæŸèµ·çº¦å®šä¹‹èŠ±', status: 'å·²è¿½å®Œ', progress: 100, jp: 'ã•ã‚ˆãªã‚‰ã®æœã«ç´„æŸã®èŠ±ã‚’ã‹ã–ã‚ã†', time: 'æ”¾é€æ—¶é—´: 2018-02-24 SUN.', desc: ' ä½åœ¨è¿œç¦»å°˜åš£çš„åœŸåœ°ï¼Œä¸€è¾¹å°†æ¯å¤©çš„äº‹æƒ…ç¼–ç»‡æˆåä¸ºå¸Œæ¯”æ¬§çš„å¸ƒï¼Œä¸€è¾¹é™é™ç”Ÿæ´»çš„ä¼Šæ¬§å¤«äººæ°‘ã€‚åœ¨15å²å·¦å³å¤–è¡¨å°±åœæ­¢æˆé•¿ï¼Œæ‹¥æœ‰æ•°ç™¾å¹´å¯¿å‘½çš„ä»–ä»¬ï¼Œè¢«ç§°ä¸ºâ€œç¦»åˆ«çš„ä¸€æ—â€ï¼Œå¹¶è¢«è§†ä¸ºæ´»ç€çš„ä¼ è¯´ã€‚æ²¡æœ‰åŒäº²çš„ä¼Šæ¬§å¤«å°‘å¥³ç›å¥‡äºšï¼Œè¿‡ç€è¢«ä¼™ä¼´åŒ…å›´çš„å¹³ç¨³æ—¥å­ï¼Œå´æ€»æ„Ÿè§‰â€œå­¤èº«ä¸€äººâ€ã€‚ä»–ä»¬çš„è¿™ç§æ—¥å¸¸ï¼Œä¸€ç¬é—´å°±å´©æºƒæ¶ˆå¤±ã€‚è¿½æ±‚ä¼Šæ¬§å¤«çš„é•¿å¯¿ä¹‹è¡€ï¼Œæ¢…è¨è’‚å†›ä¹˜åç€åä¸ºé›·çº³ç‰¹çš„å¤ä»£å…½å‘åŠ¨äº†è¿›æ”»ã€‚åœ¨ç»æœ›ä¸æ··ä¹±ä¹‹ä¸­ï¼Œä¼Šæ¬§å¤«çš„ç¬¬ä¸€ç¾å¥³è•¾è‰äºšè¢«æ¢…è¨è’‚å¸¦èµ°ï¼Œè€Œç›å¥‡äºšæš—æ‹çš„å°‘å¹´å…‹é‡Œå§†ä¹Ÿå¤±è¸ªäº†ã€‚ç›å¥‡äºšè™½ç„¶æ€»ç®—é€ƒè„±äº†ï¼Œå´å¤±å»äº†ä¼™ä¼´å’Œå½’å»ä¹‹åœ°â€¦â€¦ã€‚' }, { img : 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: 'æœèŠ±å¤•èª“â€”â€”äºç¦»åˆ«ä¹‹æœæŸèµ·çº¦å®šä¹‹èŠ±', status: 'å·²è¿½å®Œ', progress: 100, jp: 'ã•ã‚ˆãªã‚‰ã®æœã«ç´„æŸã®èŠ±ã‚’ã‹ã–ã‚ã†', time: '2018-02-24 SUN.', desc: ' ä½åœ¨è¿œç¦»å°˜åš£çš„åœŸåœ°ï¼Œä¸€è¾¹å°†æ¯å¤©çš„äº‹æƒ…ç¼–ç»‡æˆåä¸ºå¸Œæ¯”æ¬§çš„å¸ƒï¼Œä¸€è¾¹é™é™ç”Ÿæ´»çš„ä¼Šæ¬§å¤«äººæ°‘ã€‚åœ¨15å²å·¦å³å¤–è¡¨å°±åœæ­¢æˆé•¿ï¼Œæ‹¥æœ‰æ•°ç™¾å¹´å¯¿å‘½çš„ä»–ä»¬ï¼Œè¢«ç§°ä¸ºâ€œç¦»åˆ«çš„ä¸€æ—â€ï¼Œå¹¶è¢«è§†ä¸ºæ´»ç€çš„ä¼ è¯´ã€‚æ²¡æœ‰åŒäº²çš„ä¼Šæ¬§å¤«å°‘å¥³ç›å¥‡äºšï¼Œè¿‡ç€è¢«ä¼™ä¼´åŒ…å›´çš„å¹³ç¨³æ—¥å­ï¼Œå´æ€»æ„Ÿè§‰â€œå­¤èº«ä¸€äººâ€ã€‚ä»–ä»¬çš„è¿™ç§æ—¥å¸¸ï¼Œä¸€ç¬é—´å°±å´©æºƒæ¶ˆå¤±ã€‚è¿½æ±‚ä¼Šæ¬§å¤«çš„é•¿å¯¿ä¹‹è¡€ï¼Œæ¢…è¨è’‚å†›ä¹˜åç€åä¸ºé›·çº³ç‰¹çš„å¤ä»£å…½å‘åŠ¨äº†è¿›æ”»ã€‚åœ¨ç»æœ›ä¸æ··ä¹±ä¹‹ä¸­ï¼Œä¼Šæ¬§å¤«çš„ç¬¬ä¸€ç¾å¥³è•¾è‰äºšè¢«æ¢…è¨è’‚å¸¦èµ°ï¼Œè€Œç›å¥‡äºšæš—æ‹çš„å°‘å¹´å…‹é‡Œå§†ä¹Ÿå¤±è¸ªäº†ã€‚ç›å¥‡äºšè™½ç„¶æ€»ç®—é€ƒè„±äº†ï¼Œå´å¤±å»äº†ä¼™ä¼´å’Œå½’å»ä¹‹åœ°â€¦â€¦ã€‚' } ] .should-ellipsis{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:95%;}.should-ellipsis-full{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:100%;}.should-ellipsis i{position:absolute;right:24px;}.grey-text{color:#9e9e9e !important}.grey-text.text-darken-4{color:#212121 !important}html{line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}img{border-style:none}progress{display:inline-block;vertical-align:baseline}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{-webkit-box-sizing:border-box;box-sizing:border-box}*,*:before,*:after{-webkit-box-sizing:inherit;box-sizing:inherit}ul:not(.browser-default){padding-left:0;list-style-type:none}ul:not(.browser-default)>li{list-style-type:none}.card{-webkit-box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2);box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2)}.hoverable{-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s}.hoverable:hover{-webkit-box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19);box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19)}i{line-height:inherit}i.right{float:right;margin-left:15px}.bangumi .right{float:right !important}.material-icons{text-rendering:optimizeLegibility;-webkit-font-feature-settings:'liga';-moz-font-feature-settings:'liga';font-feature-settings:'liga'}.row{margin-left:auto;margin-right:auto;margin-bottom:20px}.row:after{content:\"\";display:table;clear:both}.row .col{float:left;-webkit-box-sizing:border-box;box-sizing:border-box;padding:0 .75rem;min-height:1px}.row .col.s12{width:100%;margin-left:auto;left:auto;right:auto}@media only screen and (min-width:601px){.row .col.m6{width:50%;margin-left:auto;left:auto;right:auto}}html{line-height:1.5;font-family:-apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif;font-weight:normal;color:rgba(0,0,0,0.87)}@media only screen and (min-width:0){html{font-size:14px}}@media only screen and (min-width:992px){html{font-size:14.5px}}@media only screen and (min-width:1200px){html{font-size:15px}}.card{position:relative;margin:.5rem 0 1rem 0;background-color:#fff;-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s;border-radius:2px}.card .card-title{font-size:24px;font-weight:300}.card .card-title.activator{cursor:pointer}.card .card-image{position:relative}.card .card-image img{display:block;border-radius:2px 2px 0 0;position:relative;left:0;right:0;top:0;bottom:0;width:100%}.card .card-content{padding:24px;border-radius:0 0 2px 2px}.card .card-content p{margin:0}.card .card-content .card-title{display:block;line-height:32px;margin-bottom:8px}.card .card-content .card-title i{line-height:32px}.card .card-reveal{padding:24px;position:absolute;background-color:#fff;width:100%;overflow-y:auto;left:0;top:100%;height:100%;z-index:3;display:none}.card .card-reveal .card-title{cursor:pointer;display:block}.waves-effect{position:relative;cursor:pointer;display:inline-block;overflow:hidden;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-tap-highlight-color:transparent;vertical-align:middle;z-index:1;-webkit-transition:.3s ease-out;transition:.3s ease-out}.waves-effect img{position:relative;z-index:-1}.waves-block{display:block}::-webkit-input-placeholder{color:#d1d1d1}::-moz-placeholder{color:#d1d1d1}:-ms-input-placeholder{color:#d1d1d1}::-ms-input-placeholder{color:#d1d1d1}[type=\"radio\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"radio\"]:not(:checked)+span{position:relative;padding-left:35px;cursor:pointer;display:inline-block;height:25px;line-height:25px;font-size:1rem;-webkit-transition:.28s ease;transition:.28s ease;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border-radius:50%}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border:2px solid #5a5a5a}[type=\"radio\"]:not(:checked)+span:after{-webkit-transform:scale(0);transform:scale(0)}[type=\"checkbox\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"checkbox\"]:not(:checked):disabled+span:not(.lever):before{border:none;background-color:rgba(0,0,0,0.42)}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):before{width:0;height:0;border:3px solid transparent;left:6px;top:10px;-webkit-transform:rotateZ(37deg);transform:rotateZ(37deg);-webkit-transform-origin:100% 100%;transform-origin:100% 100%}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):after{height:20px;width:20px;background-color:transparent;border:2px solid #5a5a5a;top:0px;z-index:0}input[type=checkbox]:not(:disabled) ~ .lever:active:before,input[type=checkbox]:not(:disabled).tabbed:focus ~ .lever::before{-webkit-transform:scale(2.4);transform:scale(2.4);background-color:rgba(0,0,0,0.08)}input[type=range].focused:focus:not(.active)::-webkit-slider-thumb{-webkit-box-shadow:0 0 0 10px rgba(38,166,154,0.26);box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-moz-range-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-ms-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)} ç•ªç»„è®¡åˆ’ è¿™é‡Œå°†æ˜¯æ°¸è¿œçš„å›å¿† window.onload = function(){ videos.forEach(function(video, i){ $('#rootRow').append(` ${video.title} ${video.jp} ${video.status} ${video.title} ${video.jp} æ”¾é€æ—¶é—´: ${video.time} ${video.desc} ${video.status} `) }) }","keywords":"Bç«™"},{"title":"links","date":"2018-12-19T15:11:06.000Z","updated":"2020-04-12T14:21:27.604Z","comments":true,"path":"links/index.html","permalink":"https://littlelittlemoon.github.io/links/index.html","excerpt":"","text":"","keywords":"å‹äººå¸"},{"title":"Life","date":"2020-04-12T12:50:45.000Z","updated":"2020-04-12T14:06:41.057Z","comments":true,"path":"categories/Life/index.html","permalink":"https://littlelittlemoon.github.io/categories/Life/index.html","excerpt":"","text":"In maintenance Hi, æ­¤é¡µé¢è¿˜åœ¨ç»´æŠ¤ä¸­å“¦ï¼Œè°¢è°¢ä½ çš„æœŸå¾…ï¼Œå¯ä»¥ç•™è¨€ç»™æˆ‘å“¦~ [ Bear Cave ] Kayleen","keywords":null},{"title":"Repost","date":"2020-04-12T12:51:48.000Z","updated":"2020-04-12T14:06:35.642Z","comments":true,"path":"categories/Repost/index.html","permalink":"https://littlelittlemoon.github.io/categories/Repost/index.html","excerpt":"","text":"In maintenance Hi, æ­¤é¡µé¢è¿˜åœ¨ç»´æŠ¤ä¸­å“¦ï¼Œè°¢è°¢ä½ çš„æœŸå¾…ï¼Œå¯ä»¥ç•™è¨€ç»™æˆ‘å“¦~ [ Bear Cave ] Kayleen","keywords":null},{"title":"Thoughts","date":"2020-04-12T12:51:27.000Z","updated":"2020-04-12T13:55:23.553Z","comments":true,"path":"categories/Thoughts/index.html","permalink":"https://littlelittlemoon.github.io/categories/Thoughts/index.html","excerpt":"","text":"In maintenance Hi, æ­¤é¡µé¢è¿˜åœ¨ç»´æŠ¤ä¸­å“¦ï¼Œè°¢è°¢ä½ çš„æœŸå¾…ï¼Œå¯ä»¥ç•™è¨€ç»™æˆ‘å“¦~ [ Bear Cave ] Kayleen","keywords":null},{"title":"initial page","date":"2020-04-12T12:53:20.000Z","updated":"2020-04-12T13:55:45.127Z","comments":true,"path":"tags/Cave/index.html","permalink":"https://littlelittlemoon.github.io/tags/Cave/index.html","excerpt":"","text":"In maintenance Hi, æ­¤é¡µé¢è¿˜åœ¨ç»´æŠ¤ä¸­å“¦ï¼Œè°¢è°¢ä½ çš„æœŸå¾…ï¼Œå¯ä»¥ç•™è¨€ç»™æˆ‘å“¦~ [ Bear Cave ] Kayleen","keywords":null},{"title":"initial page","date":"2020-04-12T12:53:20.000Z","updated":"2020-04-16T08:36:05.588Z","comments":true,"path":"tags/Reading/index.html","permalink":"https://littlelittlemoon.github.io/tags/Reading/index.html","excerpt":"","text":"In maintenance Hi, æ­¤é¡µé¢è¿˜åœ¨ç»´æŠ¤ä¸­å“¦ï¼Œè°¢è°¢ä½ çš„æœŸå¾…ï¼Œå¯ä»¥ç•™è¨€ç»™æˆ‘å“¦~ [ Bear Cave ] Kayleen","keywords":null},{"title":"initial page","date":"2020-04-12T12:53:20.000Z","updated":"2020-04-12T14:05:59.298Z","comments":true,"path":"tags/Pictures/index.html","permalink":"https://littlelittlemoon.github.io/tags/Pictures/index.html","excerpt":"","text":"In maintenance Hi, æ­¤é¡µé¢è¿˜åœ¨ç»´æŠ¤ä¸­å“¦ï¼Œè°¢è°¢ä½ çš„æœŸå¾…ï¼Œå¯ä»¥ç•™è¨€ç»™æˆ‘å“¦~ [ Bear Cave ] Kayleen","keywords":null},{"title":"Updating...","date":"2020-04-12T12:53:20.000Z","updated":"2020-04-16T08:33:49.463Z","comments":false,"path":"tags/Updating/index.html","permalink":"https://littlelittlemoon.github.io/tags/Updating/index.html","excerpt":"","text":"æš‚æ—¶æ²¡æœ‰æ­£åœ¨æ›´æ–°çš„å†…å®¹å“¦~","keywords":null}],"posts":[{"title":"Leetcode Note in Apri 2020 | part 3 | day 15-21 | (äºŒ).","slug":"Technology/Leetcode-Note-in-Apri-2020-part-3-day-15-21-(äºŒ)","date":"2020-04-18T06:35:52.000Z","updated":"2020-04-18T09:47:23.535Z","comments":true,"path":"2020/04/18/Technology/Leetcode-Note-in-Apri-2020-part-3-day-15-21-(äºŒ)/","link":"","permalink":"https://littlelittlemoon.github.io/2020/04/18/Technology/Leetcode-Note-in-Apri-2020-part-3-day-15-21-(%E4%BA%8C)/","excerpt":"","text":"å†™åœ¨å‰é¢çš„è¯ è¿™ç¯‡æ–‡ç« åªä¼šæ›´æ–°ä¸€é“é¢˜ï¼Œè¿™é“é¢˜æ˜¯æˆ‘ç›®å‰åšLeetCodeä»¥æ¥ç¬¬ä¸€æ¬¡åšåˆ°çš„å’Œå›¾è®ºç›¸å…³çš„é¢˜ï¼Œæ‰€ä»¥æƒ³å•ç‹¬æ‹¿å‡ºæ¥åšä¸€ä¸ªæ€»ç»“ï¼Œå€Ÿè¯¥é¢˜å·©å›ºä»¥å‰å­¦è¿‡çš„ç›¸å…³ç®—æ³•ä»¥åŠåœ¨è¯¥é¢˜ä¸­çš„åº”ç”¨ã€‚ ç›¸å…³ç®—æ³•ä¸æ•°æ®ç»“æ„ ç®—æ³• æ·±åº¦ä¼˜å…ˆæœç´¢ç®—æ³•ï¼ˆDepth-First-Searchï¼ŒDFSï¼‰ æ·±åº¦ä¼˜å…ˆæœç´¢ç®—æ³•ï¼ˆè‹±è¯­ï¼šDepth-First-Searchï¼ŒDFSï¼‰æ˜¯ä¸€ç§ç”¨äºéå†æˆ–æœç´¢æ ‘æˆ–å›¾çš„ç®—æ³•ã€‚è¿™ä¸ªç®—æ³•ä¼šå°½å¯èƒ½æ·±çš„æœç´¢æ ‘çš„åˆ†æ”¯ã€‚å½“èŠ‚ç‚¹vçš„æ‰€åœ¨è¾¹éƒ½å·±è¢«æ¢å¯»è¿‡ï¼Œæœç´¢å°†å›æº¯åˆ°å‘ç°èŠ‚ç‚¹vçš„é‚£æ¡è¾¹çš„èµ·å§‹èŠ‚ç‚¹ã€‚è¿™ä¸€è¿‡ç¨‹ä¸€ç›´è¿›è¡Œåˆ°å·²å‘ç°ä»æºèŠ‚ç‚¹å¯è¾¾çš„æ‰€æœ‰èŠ‚ç‚¹ä¸ºæ­¢ã€‚å¦‚æœè¿˜å­˜åœ¨æœªè¢«å‘ç°çš„èŠ‚ç‚¹ï¼Œåˆ™é€‰æ‹©å…¶ä¸­ä¸€ä¸ªä½œä¸ºæºèŠ‚ç‚¹å¹¶é‡å¤ä»¥ä¸Šè¿‡ç¨‹ï¼Œæ•´ä¸ªè¿›ç¨‹åå¤è¿›è¡Œç›´åˆ°æ‰€æœ‰èŠ‚ç‚¹éƒ½è¢«è®¿é—®ä¸ºæ­¢ã€‚è¿™ç§ç®—æ³•ä¸ä¼šæ ¹æ®å›¾çš„ç»“æ„ç­‰ä¿¡æ¯è°ƒæ•´æ‰§è¡Œç­–ç•¥ã€‚ æ·±åº¦ä¼˜å…ˆæœç´¢æ˜¯å›¾è®ºä¸­çš„ç»å…¸ç®—æ³•ï¼Œåˆ©ç”¨æ·±åº¦ä¼˜å…ˆæœç´¢ç®—æ³•å¯ä»¥äº§ç”Ÿç›®æ ‡å›¾çš„æ‹“æ‰‘æ’åºè¡¨ï¼Œåˆ©ç”¨æ‹“æ‰‘æ’åºè¡¨å¯ä»¥æ–¹ä¾¿çš„è§£å†³å¾ˆå¤šç›¸å…³çš„å›¾è®ºé—®é¢˜ï¼Œå¦‚æ— æƒæœ€é•¿è·¯å¾„é—®é¢˜ç­‰ç­‰ã€‚ ç»´åŸºç™¾ç§‘ åŠ¨ç”»æ¼”ç¤º dfs å®ç°æ–¹æ³• é¦–å…ˆå°†æ ¹èŠ‚ç‚¹æ”¾å…¥stackä¸­ã€‚ ä»stackä¸­å–å‡ºç¬¬ä¸€ä¸ªèŠ‚ç‚¹ï¼Œå¹¶æ£€éªŒå®ƒæ˜¯å¦ä¸ºç›®æ ‡ã€‚ 2.1 å¦‚æœæ‰¾åˆ°ç›®æ ‡ï¼Œåˆ™ç»“æŸæœå¯»å¹¶å›ä¼ ç»“æœã€‚ 2.2 å¦åˆ™å°†å®ƒæŸä¸€ä¸ªå°šæœªæ£€éªŒè¿‡çš„ç›´æ¥å­èŠ‚ç‚¹åŠ å…¥stackä¸­ã€‚ é‡å¤æ­¥éª¤2ã€‚ å¦‚æœä¸å­˜åœ¨æœªæ£€æµ‹è¿‡çš„ç›´æ¥å­èŠ‚ç‚¹ã€‚ 4.1 å°†ä¸Šä¸€çº§èŠ‚ç‚¹åŠ å…¥stackä¸­ã€‚ 4.2 é‡å¤æ­¥éª¤2ã€‚ é‡å¤æ­¥éª¤4ã€‚ è‹¥stackä¸ºç©ºï¼Œè¡¨ç¤ºæ•´å¼ å›¾éƒ½æ£€æŸ¥è¿‡äº†â€”â€”äº¦å³å›¾ä¸­æ²¡æœ‰æ¬²æœå¯»çš„ç›®æ ‡ã€‚ç»“æŸæœå¯»å¹¶å›ä¼ â€œæ‰¾ä¸åˆ°ç›®æ ‡â€ã€‚ ä¼ªä»£ç  bool visited[MAX_VERTEX_NUM]; void DFSTraverse(Graph G){ for(v = 0; v &lt; G.vexnum; ++i) visited[v] = false; for(v = 0; v &lt; G.vexnum; ++v) if(!visited[v]) DFS(G,v); } void DFS(Graph G,int v) { visitï¼ˆvï¼‰; visited[v] = true; for(w = FirstNeighbor(G,v); w &gt;= 0; w = NextNeighbor(G,v,w)) if(!visited[w]) DFS(G,w); } å¹¿åº¦ä¼˜å…ˆæœç´¢ç®—æ³•ï¼ˆBreadth-First Searchï¼ŒBFSï¼‰ å¹¿åº¦ä¼˜å…ˆæœç´¢ç®—æ³•ï¼ˆè‹±è¯­ï¼šBreadth-First Searchï¼Œç¼©å†™ä¸ºBFSï¼‰ï¼Œåˆè¯‘ä½œå®½åº¦ä¼˜å…ˆæœç´¢ï¼Œæˆ–æ¨ªå‘ä¼˜å…ˆæœç´¢ï¼Œæ˜¯ä¸€ç§å›¾å½¢æœç´¢ç®—æ³•ã€‚ç®€å•çš„è¯´ï¼ŒBFSæ˜¯ä»æ ¹èŠ‚ç‚¹å¼€å§‹ï¼Œæ²¿ç€æ ‘çš„å®½åº¦éå†æ ‘çš„èŠ‚ç‚¹ã€‚å¦‚æœæ‰€æœ‰èŠ‚ç‚¹å‡è¢«è®¿é—®ï¼Œåˆ™ç®—æ³•ä¸­æ­¢ã€‚å¹¿åº¦ä¼˜å…ˆæœç´¢çš„å®ç°ä¸€èˆ¬é‡‡ç”¨open-closedè¡¨ã€‚ ç»´åŸºç™¾ç§‘ åŠ¨ç”»æ¼”ç¤º bfs å®ç°æ–¹æ³• é¦–å…ˆå°†æ ¹èŠ‚ç‚¹æ”¾å…¥é˜Ÿåˆ—ä¸­; ä»é˜Ÿåˆ—ä¸­å–å‡ºç¬¬ä¸€ä¸ªèŠ‚ç‚¹ï¼Œå¹¶æ£€éªŒå®ƒæ˜¯å¦ä¸ºç›®æ ‡; 2.1 å¦‚æœæ‰¾åˆ°ç›®æ ‡ï¼Œåˆ™ç»“æŸæœç´¢å¹¶å›ä¼ ç»“æœ; 2.2 å¦åˆ™å°†å®ƒæ‰€æœ‰å°šæœªæ£€éªŒè¿‡çš„ç›´æ¥å­èŠ‚ç‚¹åŠ å…¥é˜Ÿåˆ—ä¸­ã€‚ è‹¥é˜Ÿåˆ—ä¸ºç©ºï¼Œè¡¨ç¤ºæ•´å¼ å›¾éƒ½æ£€æŸ¥è¿‡äº†â€”â€”äº¦å³å›¾ä¸­æ²¡æœ‰æ¬²æœç´¢çš„ç›®æ ‡ã€‚ç»“æŸæœç´¢å¹¶å›ä¼ â€œæ‰¾ä¸åˆ°ç›®æ ‡â€; é‡å¤æ­¥éª¤2ã€‚ ä¼ªä»£ç  bfs_code Flood fillç®—æ³• Flood fillç®—æ³•æ˜¯ä»ä¸€ä¸ªåŒºåŸŸä¸­æå–è‹¥å¹²ä¸ªè¿é€šçš„ç‚¹ä¸å…¶ä»–ç›¸é‚»åŒºåŸŸåŒºåˆ†å¼€ï¼ˆæˆ–åˆ†åˆ«æŸ“æˆä¸åŒé¢œè‰²ï¼‰çš„ç»å…¸ç®—æ³•ã€‚å› ä¸ºå…¶æ€è·¯ç±»ä¼¼æ´ªæ°´ä»ä¸€ä¸ªåŒºåŸŸæ‰©æ•£åˆ°æ‰€æœ‰èƒ½åˆ°è¾¾çš„åŒºåŸŸè€Œå¾—åã€‚åœ¨GNU Goå’Œæ‰«é›·ä¸­ï¼ŒFlood Fillç®—æ³•è¢«ç”¨æ¥è®¡ç®—éœ€è¦è¢«æ¸…é™¤çš„åŒºåŸŸã€‚ç»´åŸºç™¾ç§‘ã€‚è¯¥ç®—æ³•å¯ç”¨æ·±åº¦ä¼˜å…ˆéå†ç®—æ³•æˆ–å¹¿åº¦ä¼˜å…ˆéå†ç®—æ³•å®ç°ã€‚ ç®—æ³•å®ç° Flood fillç®—æ³•æ¥å—ä¸‰ä¸ªå‚æ•°ï¼šèµ·å§‹èŠ‚ç‚¹ï¼Œç›®æ ‡é¢œè‰²å’Œæ›¿æ¢é¢œè‰²ã€‚ ç®—æ³•éå†æ‰€æœ‰çš„èŠ‚ç‚¹ä»¥å¯»æ‰¾å’Œèµ·å§‹èŠ‚ç‚¹ç›¸è¿çš„èŠ‚ç‚¹ï¼ˆé€šè¿‡ä¸€æ¡ç›®æ ‡é¢œè‰²çš„è·¯å¾„ç›¸è¿ï¼‰ï¼Œç„¶å æ”¹å˜ä»–ä»¬çš„é¢œè‰²ä¸ºæ›¿æ¢é¢œè‰²ã€‚ç›®å‰æœ‰è®¸å¤šflood-fillç®—æ³•çš„æ„å»ºæ–¹å¼ï¼Œä½†æ˜¯ä»–ä»¬éƒ½æ˜¾ç¤ºæˆ–éšå¼çš„ä½¿ç”¨é˜Ÿåˆ—æˆ–è€…æ ˆ æ ¹æ®æˆ‘ä»¬æ˜¯å¦è€ƒè™‘å½“å‰èŠ‚ç‚¹å¯¹è§’çº¿æ–¹å‘çš„èŠ‚ç‚¹ï¼Œç®—æ³•åˆ†ä¸ºå››è·¯ç®—æ³•ï¼ˆä¸è€ƒè™‘å¯¹è§’çº¿æ–¹å‘çš„èŠ‚ç‚¹ï¼‰å’Œå…«è·¯ç®—æ³•ï¼ˆè€ƒè™‘å¯¹è§’çº¿æ–¹å‘çš„èŠ‚ç‚¹ï¼‰ã€‚ ä¼ªä»£ç  /*å‡è®¾MAX_Xä¸MAX_Yæ˜¯å›¾çš„å®½å’Œé«˜*/ void flood_fill(int x,int y,int color) { area[x][y] = color; if(x &gt; 0 &amp;&amp; area[x-1][y] == 0) flood_fill(x-1, y, color); if(y &gt; 0 &amp;&amp; area[x][y-1] == 0) flood_fill(x, y-1, color); if(x &lt; MAX_X &amp;&amp; area[x+1][y] == 0) flood_fill(x+1, y, color); if(y &lt; MAX_Y &amp;&amp; area[x][y+1] == 0) flood_fill(x, y+1, color); } åŠ¨ç”»æ¼”ç¤º å››ä¸ªæ–¹å‘ä¸Šçš„Flood Fill flood_fill_4 å…«ä¸ªæ–¹å‘ä¸Šçš„Flood Fill flood_fill_8 æ•°æ®ç»“æ„ å¹¶æŸ¥é›† åœ¨è®¡ç®—æœºç§‘å­¦ä¸­ï¼Œå¹¶æŸ¥é›†æ˜¯ä¸€ç§æ ‘å‹çš„æ•°æ®ç»“æ„ï¼Œç”¨äºå¤„ç†ä¸€äº›ä¸äº¤é›†ï¼ˆDisjoint Setsï¼‰çš„åˆå¹¶åŠæŸ¥è¯¢é—®é¢˜ã€‚æœ‰ä¸€ä¸ªè”åˆ-æŸ¥æ‰¾ç®—æ³•ï¼ˆunion-find algorithmï¼‰å®šä¹‰äº†ä¸¤ä¸ªç”¨äºæ­¤æ•°æ®ç»“æ„çš„æ“ä½œï¼š - Findï¼šç¡®å®šå…ƒç´ å±äºå“ªä¸€ä¸ªå­é›†ã€‚å®ƒå¯ä»¥è¢«ç”¨æ¥ç¡®å®šä¸¤ä¸ªå…ƒç´ æ˜¯å¦å±äºåŒä¸€å­é›†ã€‚ - Unionï¼šå°†ä¸¤ä¸ªå­é›†åˆå¹¶æˆåŒä¸€ä¸ªé›†åˆã€‚ ç”±äºæ”¯æŒè¿™ä¸¤ç§æ“ä½œï¼Œä¸€ä¸ªä¸ç›¸äº¤é›†ä¹Ÿå¸¸è¢«ç§°ä¸ºè”åˆ-æŸ¥æ‰¾æ•°æ®ç»“æ„ï¼ˆunion-find data structureï¼‰æˆ–åˆå¹¶-æŸ¥æ‰¾é›†åˆï¼ˆmerge-find setï¼‰ã€‚å…¶ä»–çš„é‡è¦æ–¹æ³•ï¼ŒMakeSetï¼Œç”¨äºåˆ›å»ºå•å…ƒç´ é›†åˆã€‚æœ‰äº†è¿™äº›æ–¹æ³•ï¼Œè®¸å¤šç»å…¸çš„åˆ’åˆ†é—®é¢˜å¯ä»¥è¢«è§£å†³ã€‚ ä¸ºäº†æ›´åŠ ç²¾ç¡®çš„å®šä¹‰è¿™äº›æ–¹æ³•ï¼Œéœ€è¦å®šä¹‰å¦‚ä½•è¡¨ç¤ºé›†åˆã€‚ä¸€ç§å¸¸ç”¨çš„ç­–ç•¥æ˜¯ä¸ºæ¯ä¸ªé›†åˆé€‰å®šä¸€ä¸ªå›ºå®šçš„å…ƒç´ ï¼Œç§°ä¸ºä»£è¡¨ï¼Œä»¥è¡¨ç¤ºæ•´ä¸ªé›†åˆã€‚æ¥ç€ï¼ŒFind(x) è¿”å›xæ‰€å±é›†åˆçš„ä»£è¡¨ï¼Œè€ŒUnionä½¿ç”¨ä¸¤ä¸ªé›†åˆçš„ä»£è¡¨ä½œä¸ºå‚æ•°ã€‚ç»´åŸºç™¾ç§‘ ä¼ªä»£ç  åœ¨å¹¶æŸ¥é›†æ£®æ—ä¸­ï¼Œæ¯ä¸ªé›†åˆçš„ä»£è¡¨å³æ˜¯é›†åˆçš„æ ¹èŠ‚ç‚¹ã€‚â€œæŸ¥æ‰¾â€æ ¹æ®å…¶çˆ¶èŠ‚ç‚¹çš„å¼•ç”¨å‘æ ¹è¡Œè¿›ç›´åˆ°åˆ°åº•æ ‘æ ¹ã€‚â€œè”åˆâ€å°†ä¸¤æ£µæ ‘åˆå¹¶åˆ°ä¸€èµ·ï¼Œè¿™é€šè¿‡å°†ä¸€æ£µæ ‘çš„æ ¹è¿æ¥åˆ°å¦ä¸€æ£µæ ‘çš„æ ¹ã€‚å®ç°è¿™æ ·æ“ä½œçš„ä¸€ç§æ–¹æ³•æ˜¯ï¼š function MakeSet(x) x.parent := x x.rank := 0 function Union(x, y) xRoot := Find(x) yRoot := Find(y) if xRoot == yRoot return // xå’Œyä¸åœ¨åŒä¸€ä¸ªé›†åˆï¼Œåˆå¹¶å®ƒä»¬ã€‚ if xRoot.rank &lt; yRoot.rank xRoot.parent := yRoot else if xRoot.rank &gt; yRoot.rank yRoot.parent := xRoot else yRoot.parent := xRoot xRoot.rank := xRoot.rank + 1 function Find(x) if x.parent != x x.parent := Find(x.parent) return x.parent åº”ç”¨ Number of Islands Given a 2d grid map of '1's (land) and '0's (water), count the number of islands. An island is surrounded by water and is formed by connecting adjacent lands horizontally or vertically. You may assume all four edges of the grid are all surrounded by water. Example 1: Input: 11110 11010 11000 00000 Output: 1 Example 2: Input: 11000 11000 00100 00011 Output: 3 Solutions è¯¥é¢˜çš„è§£é¢˜æ€è·¯æœ‰ä¸¤ä¸ªï¼Œä¸€ä¸ªæ˜¯ä½¿ç”¨Flood fillç®—æ³•ï¼Œä¸€ä¸ªæ˜¯é‡‡ç”¨å¹¶æŸ¥é›†çš„æ–¹æ³•ã€‚ åŸºäºFlood Fillç®—æ³• æ ¹æ®ç®—æ³•ç‰¹ç‚¹ï¼Œæˆ‘ä»¬å¯ä»¥ä»ä¸€ä¸ªç‚¹å‡ºå‘ï¼Œç„¶åæ‰¾åˆ°ä¸å…¶è¿é€šçš„ç‚¹ï¼ˆå¯é€šè¿‡æ·±åº¦ä¼˜å…ˆæˆ–è€…å¹¿åº¦ä¼˜å…ˆç®—æ³•å®ç°ï¼‰ã€‚è€Œè¿™ä¸€ç‰‡è¿ç€çš„åŒºåŸŸå°±æ˜¯æˆ‘ä»¬è¦æ‰¾çš„å²›å±¿ã€‚æ ¹æ®é¢˜æ„ï¼Œè¯¥é¢˜åº”é‡‡ç”¨å››ä¸ªæ–¹å‘çš„flood fillç®—æ³•ã€‚å…·ä½“çœ‹ä»£ç å®ç°ã€‚ é‡‡ç”¨æ·±åº¦ä¼˜å…ˆéå†å®ç° class Solution: def __dfs(self, grid, i, j, m, n, marked): marked[i][j] = True for direction in self.directions: new_i = i + direction[0] new_j = j + direction[1] if 0 &lt;= new_i &lt; m and 0 &lt;= new_j &lt; n and not(marked[new_i][new_j]) and grid[new_i][new_j] == &#39;1&#39;: self.__dfs(grid, new_i, new_j, m, n, marked) # x-1,y # x,y-1 x,y x,y+1 # x+1,y # æ–¹å‘æ•°ç»„ï¼Œå®ƒè¡¨ç¤ºäº†ç›¸å¯¹äºå½“å‰ä½ç½®çš„ 4 ä¸ªæ–¹å‘çš„æ¨ªã€çºµåæ ‡çš„åç§»é‡ï¼Œè¿™æ˜¯ä¸€ä¸ªå¸¸è§çš„æŠ€å·§ directions = [(-1, 0), (0, -1), (1, 0), (0, 1)] def numIslands(self, grid: List[List[str]]) -&gt; int: m = len(grid) # ç‰¹åˆ¤ if m == 0: return 0 n = len(grid[0]) marked = [[False for _ in range(n)] for _ in range(m)] count = 0 # ä»ç¬¬ 1 è¡Œã€ç¬¬ 1 æ ¼å¼€å§‹ï¼Œå¯¹æ¯ä¸€æ ¼å°è¯•è¿›è¡Œä¸€æ¬¡ DFS æ“ä½œ for i in range(m): for j in range(n): # åªè¦æ˜¯é™†åœ°ï¼Œä¸”æ²¡æœ‰è¢«è®¿é—®è¿‡çš„ï¼Œå°±å¯ä»¥ä½¿ç”¨ DFS å‘ç°ä¸ä¹‹ç›¸è¿çš„é™†åœ°ï¼Œå¹¶è¿›è¡Œæ ‡è®° if not(marked[i][j]) and grid[i][j] == &#39;1&#39;: # count å¯ä»¥ç†è§£ä¸ºè¿é€šåˆ†é‡ count += 1 self.__dfs(grid, i, j, m, n, marked) return count é‡‡ç”¨å¹¿åº¦ä¼˜å…ˆéå†å®ç° ä½¿ç”¨å¹¿åº¦ä¼˜å…ˆéå†ä¸ç”¨å›æº¯ï¼Œä½†éœ€è¦ä¸€ä¸ªè¾…åŠ©é˜Ÿåˆ—ã€‚ class Solution: def __bfs(self, grid, queue, cur_x, cur_y, m, n, marked): # å¾—åˆ° 4 ä¸ªæ–¹å‘çš„åæ ‡ for direction in self.directions: new_i = cur_x + direction[0] new_j = cur_y + direction[1] # å¦‚æœä¸è¶Šç•Œã€æ²¡æœ‰è¢«è®¿é—®è¿‡å¹¶ä¸”æ˜¯é™†åœ°ï¼Œç»§ç»­æ”¾å…¥é˜Ÿåˆ—ï¼Œæ”¾å…¥é˜Ÿåˆ—çš„åŒæ—¶æ ‡è®°å·²ç»è®¿é—®è¿‡ if 0 &lt;= new_i &lt; m and 0 &lt;= new_j &lt; n and not(marked[new_i][new_j]) and grid[new_i][new_j] == &#39;1&#39;: queue.append((new_i, new_j)) # åœ¨æ”¾å…¥é˜Ÿåˆ—ä»¥åï¼Œé©¬ä¸Šæ ‡è®°æˆå·²ç»è®¿é—®è¿‡ï¼Œå› ä¸ºåªè¦è¿›å…¥äº†é˜Ÿåˆ—ï¼Œè¿Ÿæ—©éƒ½ä¼šéå†åˆ°å®ƒ # å¦‚æœæ˜¯å‡ºé˜Ÿåˆ—çš„æ—¶å€™å†æ ‡è®°ï¼Œä¼šé€ æˆå¾ˆå¤šé‡å¤çš„ç»“ç‚¹è¿›å…¥é˜Ÿåˆ—ï¼Œé€ æˆé‡å¤çš„æ“ä½œ marked[new_i][new_j] = True directions = [(-1, 0), (0, -1), (1, 0), (0, 1)] def numIslands(self, grid: List[List[str]]) -&gt; int: m = len(grid) if m == 0: return 0 n = len(grid[0]) marked = [[False for _ in range(n)] for _ in range(m)] count = 0 # ä»ç¬¬ 1 è¡Œã€ç¬¬ 1 æ ¼å¼€å§‹ï¼Œå¯¹æ¯ä¸€æ ¼å°è¯•è¿›è¡Œä¸€æ¬¡ DFS æ“ä½œ for i in range(m): for j in range(n): # åªè¦æ˜¯é™†åœ°ï¼Œä¸”æ²¡æœ‰è¢«è®¿é—®è¿‡çš„ï¼Œå°±å¯ä»¥ä½¿ç”¨ BFS å‘ç°ä¸ä¹‹ç›¸è¿çš„é™†åœ°ï¼Œå¹¶è¿›è¡Œæ ‡è®° if not(marked[i][j]) and grid[i][j] == &#39;1&#39;: # count å¯ä»¥ç†è§£ä¸ºè¿é€šåˆ†é‡ count += 1 queue = deque() queue.append((i, j)) # æ ‡è®°ä¸Šå·²ç»è®¿é—®è¿‡ marked[i][j] = True while queue: cur_x, cur_y = queue.popleft() self.__bfs(grid, queue, cur_x, cur_y, m, n, marked) return count åŸºäºå¹¶æŸ¥é›† ä½¿ç”¨å¹¶æŸ¥é›†è§£å†³æœ¬é—®é¢˜çš„åŸºæœ¬æ€æƒ³ï¼š 1. å¦‚æœå½“å‰æ˜¯â€œé™†åœ°â€ï¼Œå°è¯•ä¸å‘¨å›´åˆå¹¶ï¼› 2. å¦‚æœå½“å‰æ˜¯â€œæ°´åŸŸâ€ï¼Œå°±æŠŠæ‰€æœ‰çš„â€œæ°´åŸŸâ€åˆå¹¶åœ¨ä¸€èµ·ï¼Œä¸ºæ­¤ï¼Œå¯è®¾ç½®äº†ä¸€ä¸ªè™šæ‹Ÿçš„ç»“ç‚¹ï¼Œè¡¨ç¤ºâ€œæ‰€æœ‰çš„æ°´åŸŸéƒ½å’Œè¿™ä¸ªè™šæ‹Ÿç»“ç‚¹æ˜¯è¿æ¥çš„â€ã€‚ class Solution: def numIslands(self, grid: List[List[str]]) -&gt; int: class UnionFind: def __init__(self, n): self.count = n self.parent = [i for i in range(n)] self.rank = [1 for _ in range(n)] def get_count(self): return self.count def find(self, p): while p != self.parent[p]: self.parent[p] = self.parent[self.parent[p]] p = self.parent[p] return p def is_connected(self, p, q): return self.find(p) == self.find(q) def union(self, p, q): p_root = self.find(p) q_root = self.find(q) if p_root == q_root: return if self.rank[p_root] &gt; self.rank[q_root]: self.parent[q_root] = p_root elif self.rank[p_root] &lt; self.rank[q_root]: self.parent[p_root] = q_root else: self.parent[q_root] = p_root self.rank[p_root] += 1 self.count -= 1 row = len(grid) # ç‰¹åˆ¤ if row == 0: return 0 col = len(grid[0]) def get_index(x, y): return x * col + y # æ³¨æ„ï¼šæˆ‘ä»¬ä¸ç”¨åƒ DFS å’Œ BFS ä¸€æ ·ï¼Œ4 ä¸ªæ–¹å‘éƒ½è¦å°è¯•ï¼Œåªè¦çœ‹ä¸€çœ‹å³è¾¹å’Œä¸‹é¢å°±å¯ä»¥äº† directions = [(1, 0), (0, 1)] # å¤šå¼€ä¸€ä¸ªç©ºé—´ï¼ŒæŠŠæ°´åŸŸ &quot;0&quot; éƒ½å½’åˆ°è¿™ä¸ªè™šæ‹Ÿç©ºé—´ dummy_node = row * col uf = UnionFind(dummy_node + 1) for i in range(row): for j in range(col): # å¦‚æœæ˜¯æ°´åŸŸï¼Œéƒ½è¿åˆ°é‚£ä¸ªè™šæ‹Ÿçš„ç©ºé—´å» if grid[i][j] == &#39;0&#39;: uf.union(get_index(i, j), dummy_node) if grid[i][j] == &#39;1&#39;: # å‘ä¸‹å‘å³å¦‚æœéƒ½æ˜¯é™†åœ°ï¼Œå°±åˆå¹¶ for direction in directions: new_x = i + direction[0] new_y = j + direction[1] if new_x &lt; row and new_y &lt; col and grid[new_x][new_y] == &#39;1&#39;: uf.union(get_index(i, j), get_index(new_x, new_y)) # å‡å»è™šæ‹Ÿç»“ç‚¹ return uf.get_count() - 1 å‚è€ƒèµ„æ–™ Flood fill æ·±åº¦ä¼˜å…ˆç®—æ³• å¹¿åº¦ä¼˜å…ˆç®—æ³• å¹¶æŸ¥é›† https://leetcode-cn.com/problems/number-of-islands/solution/dfs-bfs-bing-cha-ji-python-dai-ma-java-dai-ma-by-l/","categories":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Coding","slug":"Technology/Coding","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/"},{"name":"Leetcode","slug":"Technology/Coding/Leetcode","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/Leetcode/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://littlelittlemoon.github.io/tags/Leetcode/"},{"name":"Python","slug":"Python","permalink":"https://littlelittlemoon.github.io/tags/Python/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://littlelittlemoon.github.io/tags/Algorithm/"},{"name":"DFS","slug":"DFS","permalink":"https://littlelittlemoon.github.io/tags/DFS/"},{"name":"BFS","slug":"BFS","permalink":"https://littlelittlemoon.github.io/tags/BFS/"},{"name":"å¹¶æŸ¥é›†","slug":"å¹¶æŸ¥é›†","permalink":"https://littlelittlemoon.github.io/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/"}],"keywords":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Coding","slug":"Technology/Coding","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/"},{"name":"Leetcode","slug":"Technology/Coding/Leetcode","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/Leetcode/"}]},{"title":"Paper Smash|Blockchain Technology for Healthcare-Facilitating the Transition to Patient-Driven Interoperability","slug":"Technology/BlockChain-Patient-Driven-Interoperability","date":"2020-04-16T07:47:09.000Z","updated":"2020-04-16T10:00:40.315Z","comments":true,"path":"2020/04/16/Technology/BlockChain-Patient-Driven-Interoperability/","link":"","permalink":"https://littlelittlemoon.github.io/2020/04/16/Technology/BlockChain-Patient-Driven-Interoperability/","excerpt":"","text":"æ‘˜è¦ ã€èƒŒæ™¯ã€‘ä¼ ç»Ÿä¸Šï¼ŒåŸºäºæœºæ„é©±åŠ¨çš„åŒ»ç–—ä¿å¥çš„äº’æ“ä½œæ€§é›†ä¸­äºä¸šåŠ¡å®ä½“ï¼ˆä¾‹å¦‚ï¼Œä¸åŒçš„åŒ»é™¢ç³»ç»Ÿï¼‰ä¹‹é—´çš„æ•°æ®äº¤æ¢ã€‚æœ€è¿‘æœ‰ä¸€ç§æ¨åŠ¨ä»¥æ‚£è€…ä¸ºä¸»å¯¼çš„äº’æ“ä½œæ€§çš„æ–¹æ³•ï¼Œå…¶ä¸­ï¼Œå¥åº·æ•°æ®äº¤æ¢æ˜¯ç”±æ‚£è€…ä¸»å¯¼å¹¶ç”±æ‚£è€…é©±åŠ¨çš„ã€‚ ã€é—®é¢˜ã€‘ä»¥æ‚£è€…ä¸ºä¸­å¿ƒçš„äº’æ“ä½œæ€§å¸¦æ¥äº†å›´ç»•å®‰å…¨æ€§å’Œéšç§ï¼ŒæŠ€æœ¯ï¼Œæ¿€åŠ±æªæ–½å’Œæ²»ç†çš„æ–°æŒ‘æˆ˜å’Œæ–°è¦æ±‚ï¼Œè€Œè¿™ç±»æŒ‘æˆ˜å¿…é¡»æ»¡è¶³æ­¤ç±»æ•°æ®å…±äº«æ‰èƒ½æˆåŠŸè·å¾—æˆåŠŸã€‚å¹¶ä¸”å…¶ä¸­è®¸å¤šæŒ‘æˆ˜åœ¨ä¼ ç»Ÿçš„äº’æ“ä½œæ€§ä¸­ä¹Ÿè¿˜æ²¡æœ‰å¾—ä»¥è§£å†³ ã€æœ¬æ–‡æå‡ºçš„è§£å†³æ–¹æ³•ã€‘ 3.1 ç ”ç©¶äº†åŒºå—é“¾æŠ€æœ¯å¦‚ä½•é€šè¿‡äº”ç§æœºåˆ¶ä¿ƒè¿›è¿™ç§è½¬å˜ï¼š ï¼ˆ1ï¼‰æ•°å­—è®¿é—®è§„åˆ™ ï¼ˆ2ï¼‰æ•°æ®èšåˆ ï¼ˆ3ï¼‰æ•°æ®æµåŠ¨æ€§ ï¼ˆ4ï¼‰æ‚£è€…èº«ä»½ ï¼ˆ5ï¼‰æ•°æ®ä¸å˜æ€§ 3.2 ç ”ç©¶äº†é˜»ç¢åŒºå—é“¾çš„æ‚£è€…é©±åŠ¨çš„äº’æ“ä½œæ€§çš„éšœç¢ï¼Œç‰¹åˆ«æ˜¯ä¸´åºŠæ•°æ®äº¤æ˜“é‡ï¼Œéšç§å’Œå®‰å…¨æ€§ï¼Œæ‚£è€…å‚ä¸åº¦å’Œæ¿€åŠ±æªæ–½ã€‚ ã€ç»“è®ºã€‘å°½ç®¡ä»¥æ‚£è€…ä¸ºä¸»å¯¼çš„äº’æ“ä½œæ€§æ–¹æ³•æ˜¯åŒ»ç–—ä¿å¥ä¸­ä»¤äººå…´å¥‹çš„è¶‹åŠ¿ï¼Œä½†é‰´äºè¿™äº›æŒ‘æˆ˜ï¼ŒåŒºå—é“¾èƒ½å¦ä¿ƒè¿›ä»ä»¥æœºæ„ä¸ºä¸­å¿ƒçš„æ•°æ®å…±äº«å‘ä»¥æ‚£è€…ä¸ºä¸­å¿ƒçš„æ•°æ®å…±äº«è¿‡æ¸¡å°šå¾…è§‚å¯Ÿã€‚ ç ”ç©¶å†…å®¹ whyåŒºå—é“¾ ä»æ‘˜è¦å’Œä»‹ç»éƒ¨åˆ†å¯ä»¥å¾—çŸ¥ï¼Œæœ¬æ–‡å°±åŒ»ç–—ä¿å¥çš„äº’æ“ä½œæ€§ï¼Œç”¨æˆ·åŒ»ç–—æ•°æ®äº¤æ¢æå‡ºäº†ä¸€äº›ç›®å‰é¢ä¸´çš„æŒ‘æˆ˜ã€‚åœ¨ä»¥æ‚£è€…ä¸ºä¸»å¯¼çš„äº’æ“ä½œæ€§çš„æ–¹æ³•çš„è¶‹åŠ¿ä»¥åŠä¼ ç»Ÿæ–¹å¼ä¾æ—§é¢ä¸´è®¸å¤šæŒ‘æˆ˜å°šæœªè§£å†³çš„å‰æä¸‹ï¼Œä½œè€…æå‡ºäº†é‡‡ç”¨åŒºå—é“¾è¿™æ ·ä¸€ç§æ–°é¢–çš„æŠ€æœ¯ï¼Œä½¿å…¶åœ¨æé«˜äº’æ“ä½œæ€§æ–¹é¢å‘æŒ¥ä½œç”¨ã€‚è¿™æ˜¯å› ä¸ºåŒºå—é“¾å¯¹å…±äº«ï¼Œåˆ†å‘å’ŒåŠ å¯†çš„é‡è§†ï¼Œå¯¹å¥åº·æ•°æ®ç‰¹åˆ«æœ‰å¸å¼•åŠ›ã€‚å°¤å…¶æ˜¯ï¼Œæ›´æ–°çš„åŒºå—é“¾å·¥ä½œï¼ˆæ™ºèƒ½åˆçº¦ï¼Œç¬¬äºŒå±‚ç³»ç»Ÿï¼Œè®¸å¯çš„åŒºå—é“¾ï¼‰è¿›ä¸€æ­¥æä¾›äº†æ½œåœ¨çš„åŒ»ç–—ç”¨ä¾‹ï¼Œå¹¶ä¸”åœ¨åŒ»ç–—ä¿å¥é¢†åŸŸä¸ä¹å¯¹æŠ€æœ¯æ½œåŠ›çš„å¤§è‚†å®£ä¼ ã€‚æ•…å¯ä»¥åˆ©ç”¨åŒºå—é“¾æŠ€æœ¯ä¿ƒè¿›ä»æœºæ„é©±åŠ¨çš„äº’æ“ä½œæ€§åˆ°ä»¥æ‚£è€…ä¸ºä¸­å¿ƒçš„äº’æ“ä½œæ€§çš„è½¬å˜ã€‚ ä¸»è¦å·¥ä½œ å¥åº·æ•°æ®çš„äº’æ“ä½œæ€§é—®é¢˜ äº’æ“ä½œæ€§(Interoperability)çš„å®šä¹‰ä¸ä½œç”¨ å«ç”Ÿä¿¡æ¯ä¸ç®¡ç†ç³»ç»Ÿå­¦ä¼šå°†Interoperabilityå®šä¹‰ä¸ºï¼šä¸åŒä¿¡æ¯æŠ€æœ¯ç³»ç»Ÿå’Œè½¯ä»¶åº”ç”¨ç¨‹åºè¿›è¡Œé€šä¿¡ï¼Œäº¤æ¢æ•°æ®å’Œä½¿ç”¨å·²äº¤æ¢ä¿¡æ¯çš„èƒ½åŠ›ã€‚ å¯¹äºåŒ»ç–—ä¿å¥è€Œè¨€ï¼Œäº’æ“ä½œæ€§å…·æœ‰å¤šä¸ªæ½œåœ¨ä¼˜åŠ¿ï¼š 1. é€šè®¯è‰¯å¥½çš„ç³»ç»Ÿå¯ä»¥æé«˜è¿è¥æ•ˆç‡ï¼Œå‡å°‘è¯¸å¦‚æ‰‹åŠ¨è¾“å…¥ä»ä¼ çœŸæ¥æ”¶çš„æ•°æ®ä¹‹ç±»çš„è¡Œæ”¿ä»»åŠ¡æ‰€èŠ±è´¹çš„æ—¶é—´ï¼› 2. å‡å°‘é‡å¤çš„ä¸´åºŠå¹²é¢„ï¼Œä¾‹å¦‚å›¾åƒç ”ç©¶æˆ–å®éªŒå®¤è®¢å•ï¼› 3. é™ä½æ€»ä½“å«ç”Ÿç³»ç»Ÿæˆæœ¬ï¼Œå‡å°‘æµªè´¹ï¼› 4. é€šè¿‡å‡å°‘æš´éœ²äºè¾å°„æˆ–ä¾µå…¥æ€§ç¨‹åºæ¥æé«˜æ‚£è€…å®‰å…¨æ€§ï¼› 5. é€šè¿‡ä¿ƒè¿›åœ¨ç°åœºå³æ—¶è®¿é—®ç›¸å…³çš„çºµå‘ä¸´åºŠæ•°æ®çš„é€”å¾„æ¥æ”¹å–„ä¸´åºŠæŠ¤ç†ã€‚ äº’æ“ä½œæ€§çš„è½¬å˜ ä¼ ç»Ÿäº’æ“ä½œæ€§ï¼ˆæœºæ„é©±åŠ¨çš„äº’æ“ä½œæ€§ï¼‰ ä¼ ç»ŸåŒ»ç–—ä¿å¥äº’æ“ä½œæ€§æ ¼å±€é€šå¸¸ä»¥ä¸šåŠ¡å®ä½“ä¸ºä¸­å¿ƒï¼Œä¾‹å¦‚åŒ»é™¢ï¼Œç§äººè¯Šæ‰€å’Œè¯æˆ¿ï¼Œå¹¶ä¸”é€šå¸¸åœ¨åˆ›å»ºæ•°æ®çš„ä¿¡æ¯ç³»ç»Ÿä¸­åˆ›å»ºå’Œéš”ç¦»æ•°æ®ï¼ˆä¾‹å¦‚ï¼šåŒ»é™¢çš„ç”µå­å¥åº·è®°å½•ï¼‰ã€‚å¦‚å›¾1Aæ‰€ç¤ºï¼š å›¾1AB é¢ä¸´çš„æŒ‘æˆ˜ å•ä¸ªæ‚£è€…çš„å¥åº·æ•°æ®åˆ†æ•£åœ¨ä¼—å¤šç³»ç»Ÿä¸­ï¼Œå¹¶ä¸”æ²¡æœ‰æœºæ„èƒ½å¤Ÿæä¾›å®Œæ•´çš„ä¿¡æ¯ï¼› å³ä½¿ä¸åŒçš„ç³»ç»Ÿå…·æœ‰é«˜åº¦çš„äº’æ“ä½œæ€§ï¼Œæ‚£è€…ä»ç„¶ä¼šä¸¢å¤±æ•°æ®ï¼› ä¸åŒæœºæ„ä¹‹é—´çš„äº¤æµå¯èƒ½ä¼šåœ¨è¿è¥ä¸Šå¸¦æ¥æŒ‘æˆ˜ï¼Œå¹¶ä¸”éœ€è¦æ‰€æ¶‰å®ä½“ä¹‹é—´è¿›è¡Œå¤§é‡åˆä½œï¼› æ•°æ®å…±äº«åè®®ï¼Œå¤æ‚çš„æ‚£è€…åŒ¹é…ç®—æ³•ï¼Œç¨‹åºå’Œç®¡ç†è§„åˆ™ï¼› è®¸å¤šæŠ€æœ¯éšœç¢ã€‚ä¾‹å¦‚ï¼Œäº‹åŠ¡å’Œå®ä½“è®¤è¯å¿…é¡»æ˜¯å¥å£®çš„ï¼ˆå¹¶ä¸”å¯¹äºæ¯ä¸ªå®ä½“å¯¹å®ä½“çš„å…³ç³»éƒ½å¿…é¡»é‡å¤è¿›è¡Œï¼‰ã€‚è¿˜åº”è¯¥è¿›è¡Œæ´»åŠ¨å’Œé˜ˆå€¼ç›‘è§†ä»¥åŠä¸€äº›å¼‚å¸¸æ£€æµ‹ï¼› æ•°æ®äº¤æ¢çš„å®‰å…¨æ€§è‡³å…³é‡è¦ï¼Œæ•°æ®äº¤æ¢çš„æ ‡å‡†ï¼ˆä¾‹å¦‚FHIRæˆ–CDAï¼‰ä¹Ÿå¿…é¡»è¾¾æˆå…±è¯†ï¼› æ‚£è€…èƒ½å¤Ÿè®¿é—®å…¶å¥åº·æ•°æ®çš„éœ€æ±‚ï¼› è½¬å˜è¶‹åŠ¿ ä»¥æ‚£è€…ä¸ºä¸»å¯¼çš„äº’æ“ä½œæ€§çš„æ–¹æ³•ï¼Œå¥åº·æ•°æ®äº¤æ¢æ˜¯ç”±æ‚£è€…ä»‹å¯¼å¹¶ç”±æ‚£è€…é©±åŠ¨ã€‚ åŒºå—é“¾å¦‚ä½•ä¿ƒè¿›è½¬å˜ é™ä½éªŒè¯å’Œè”ç½‘æˆæœ¬ åŒºå—é“¾æŠ€æœ¯å¯ä»¥å…è®¸å¤šä¸ªåˆ©ç›Šç›¸å…³è€…å®šæœŸå°±å…±äº«æ•°æ®çš„çœŸå®çŠ¶æ€è¾¾æˆä¸€è‡´ï¼Œè¿™æ ·çš„å…±äº«æ•°æ®å¯ä»¥ä»£è¡¨æœ‰å…³ä¸ªäººï¼Œå®ä½“çš„ä¿¡æ¯äº¤æ˜“çš„å‡­è¯å’Œå±æ€§ç­‰ã€‚æ ¹æ®æŠ€æœ¯çš„è®¾è®¡å’Œå®æ–½æ–¹å¼ï¼Œå®ƒè¿˜å¯ä»¥åˆ©ç”¨æ¿€åŠ±æ‰‹æ®µæ¥æ¨åŠ¨å»ºè®¾ï¼Œç®¡ç†æ›´æ–°å’Œåè°ƒè®°å½•ã€‚è€Œâ€œæ™ºèƒ½åˆçº¦â€æ˜¯ä»¥å¤ªåŠç­‰å¹³å°çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œå®ƒå¯ä»¥ä½¿å„æ–¹ä¹‹é—´çš„åè®®å¯ä»¥ç”±å­˜å‚¨åœ¨åŒºå—é“¾ä¸­çš„è®¡ç®—æœºä»£ç æ¥æ§åˆ¶å’Œæ‰§è¡Œã€‚ åŒºå—é“¾å¯ä»¥æä¾›ä¸åŒç¨‹åº¦çš„éšç§å’Œè®°å½•åŒ¿åæ€§ï¼Œé€æ˜æ€§å’Œä¸å˜æ€§ã€‚ä¾‹å¦‚ï¼Œè™½ç„¶â€œæ¯”ç‰¹å¸â€æ˜¯å…¬å¼€çš„ï¼Œä½†â€œè®¸å¯çš„â€åŒºå—é“¾ç½‘ç»œå¯èƒ½ä¼šé€šè¿‡é™åˆ¶æˆå‘˜èµ„æ ¼å’Œè¯»å†™æ§åˆ¶ï¼Œå›´ç»•å…±è¯†æœºåˆ¶æˆ–æ™ºèƒ½åˆçº¦åˆ›å»ºè€Œå…·æœ‰æ›´ä¸¥æ ¼çš„è®¿é—®æ§åˆ¶ã€‚ å¯¹ä¸¤ä¸ªæˆæœ¬çš„è€ƒç©¶ ç¬¬ä¸€æˆæœ¬æ˜¯æŒ‡åŒºå—é“¾éªŒè¯äº¤æ˜“å±æ€§çš„èƒ½åŠ›ï¼ˆä¾‹å¦‚ï¼Œäº¤æ˜“æ˜¯å¦å‘ç”Ÿï¼Œç‰µæ¶‰åˆ°è°ï¼Œç‰µæ¶‰åˆ°çš„ä¸ªäººçš„å‡­è¯æ˜¯ä»€ä¹ˆç­‰ï¼‰ï¼Œå¹¶ä»¥æ¯”ä¼ ç»Ÿç³»ç»Ÿæ›´ä½çš„æˆæœ¬ç¡®ä¿æ•°æ®å®Œæ•´æ€§ã€‚ ç¬¬äºŒæˆæœ¬æ˜¯æŒ‡æ— éœ€ä¾é ä¼ ç»Ÿçš„ä¸­ä»‹æœºæ„ï¼ˆä¾‹å¦‚é‡‘èæœºæ„ï¼Œæˆ–è€…å°±åŒ»ç–—æ•°æ®è€Œè¨€çš„åŒ»é™¢ä¿¡æ¯ç®¡ç†åŠå…¬å®¤ï¼‰å°±èƒ½å¤Ÿå¼•å¯¼å’Œè¿è¥å¸‚åœºçš„èƒ½åŠ›ã€‚ äº†è§£å¦‚ä½•é€šè¿‡åŒºå—é“¾æŠ€æœ¯å¯ä»¥å¢å¼ºæ‚£è€…é©±åŠ¨çš„äº’æ“ä½œæ€§æ–¹é¢ï¼Œè¿™ä¸¤ç§æˆæœ¬éƒ½èµ·ç€å…³é”®ä½œç”¨ã€‚ ç»“è®º é™ä½éªŒè¯å’Œè”ç½‘æˆæœ¬éƒ½å¾ˆé‡è¦ï¼Œå› ä¸ºå®ƒä»¬å¯ä»¥æé«˜ä¸åŒå®ä½“è¿›è¡Œäº’æ“ä½œçš„èƒ½åŠ›ä»¥åŠä¸´åºŠæ•°æ®äº¤æ¢çš„å¯èƒ½æ€§å’Œå½±å“ã€‚ ç«äº‰èƒ½åŠ›è¾ƒå¼±çš„å¸‚åœºå°†å‡å°‘å…±äº«æ•°æ®çš„å®ä½“çš„æ•°é‡ï¼Œä»è€Œå¯¼è‡´ä¸´åºŠæ•°æ®äº¤æ¢çš„å…¨é¢æ€§é™ä½ã€‚ åŒæ ·ï¼Œé«˜æ˜‚çš„éªŒè¯è´¹ç”¨å¯èƒ½ä¼šå¯¼è‡´ä¸è‰¯çš„ä¸´åºŠäº‹ä»¶ï¼Œä¾‹å¦‚ç”±äºæ‚£è€…åŒ¹é…ä¸å½“è€Œå¯¼è‡´å®éªŒå®¤ç»“æœé—æ¼ã€‚ åŒºå—é“¾å¯ä»¥æä¾›é‡è¦çš„å‚¬åŒ–å‰‚ï¼Œä»¥æ”¹å–„æ•°æ®äº¤æ¢ï¼Œå°¤å…¶æ˜¯æ‚£è€…é©±åŠ¨çš„äº’æ“ä½œæ€§ã€‚ åŒºå—é“¾åœ¨æ‚£è€…é©±åŠ¨çš„äº’æ“ä½œæ€§ä¸­çš„ä½œç”¨ ä»é«˜å±‚æ¬¡ä¸Šè®²ï¼Œå¯ä»¥å°†åŒºå—é“¾æŠ€æœ¯è§†ä¸ºæ•°å­—äº¤æ¢çš„å¹³å°ï¼Œè¯¥å¹³å°æ— éœ€ä¼ ç»Ÿçš„ä¸­ä»‹å°±å¯ä»¥è¿è¡Œã€‚ å¥åº·æ•°æ®å¯ä»¥å­˜åœ¨äºå¤šä¸ªç³»ç»Ÿä¸­ï¼Œå¹¶ä¸”å…±äº«æ•°æ®éœ€è¦å®ä½“ä¹‹é—´çš„è®¸å¤šåä½œç‚¹ã€‚ éšç€äº’æ“ä½œæ€§å˜å¾—æ›´åŠ ä»¥æ‚£è€…ä¸ºä¸­å¿ƒï¼Œå°±æœ‰æœºä¼šåˆ©ç”¨åŒºå—é“¾æŠ€æœ¯æ¥ä¿ƒè¿›è¿™ç§äº¤æ¢ï¼Œå¹¶è®©æ‚£è€…å¯¹å…¶æ•°æ®æœ‰æ›´å¤§çš„æ§åˆ¶æƒã€‚ å¯ä»¥å®ç°æ‚£è€…é©±åŠ¨çš„äº’æ“ä½œæ€§çš„åŒºå—é“¾ç‰¹æ€§ åŒºå—é“¾åŠŸèƒ½ æ‚£è€…é©±åŠ¨çš„äº’æ“ä½œæ€§ä¸­çš„åº”ç”¨ç¤ºä¾‹ æ•°å­—è®¿é—®è§„åˆ™ ä¸´åºŠæ•°æ®ï¼ˆé“¾ä¸‹æˆ–é“¾ä¸Šå­˜å‚¨ï¼‰ä¸æ‚£è€…çš„å…¬é’¥é“¾æ¥ã€‚æ‚£è€…å¯ä»¥ä½¿ç”¨è¯¸å¦‚æ™ºèƒ½åˆçº¦ä¹‹ç±»çš„åŒºå—é“¾å±æ€§æ¥ä¸ºæ•°æ®åˆ†é…è®¿é—®è§„åˆ™ã€‚ä¾‹å¦‚ï¼Œæˆæƒåœ¨å›ºå®šçš„æ—¶é—´æ®µå†…é‡Šæ”¾ç»™ç ”ç©¶æ‚£è€…æ³¨å†Œè¡¨ã€‚ æ•°æ®æ±‡æ•´ æ‚£è€…ä½¿ç”¨ç‰¹å®šäºæœºæ„çš„ç™»å½•åè¿æ¥åˆ°ä¸åŒçš„æœºæ„ç•Œé¢ï¼Œå‘è¯¥æœºæ„æä¾›å…¶åŒºå—é“¾å…¬é’¥ä»¥åŠå°†æ•°æ®å®‰å…¨ä¼ è¾“åˆ°åŒºå—é“¾çš„æƒé™ã€‚å› æ­¤ï¼Œè·¨å¤šä¸ªæœºæ„å®Œæˆçš„ä¸´åºŠæ•°æ®å¯ä»¥ä½¿ç”¨è¯¥æŠ€æœ¯è¿›è¡Œæ±‡æ€»ã€‚ æ•°æ®æµåŠ¨æ€§ é«˜åº¦æ•æ„Ÿçš„ä¸´åºŠæ•°æ®ï¼ˆä¾‹å¦‚ï¼Œé«˜çº§æŠ¤ç†è®¡åˆ’çš„â€œä»£ç çŠ¶æ€â€æˆ–è¯ç‰©è¿‡æ•ï¼‰å¯ä»¥åœ¨å…¬å…±åŒºå—é“¾ä¸Šå‘å¸ƒï¼Œä»¥ç¡®ä¿é€‚å½“åœ°ï¼Œå³æ—¶åœ°è®¿é—®æ­¤ä¿¡æ¯ã€‚ æ‚£è€…èº«ä»½ æ‚£è€…å¯ä»¥é€šè¿‡å¤šç­¾åé’±åŒ…æˆ–ç§»åŠ¨è®¾å¤‡ç®¡ç†å…¬å…±å¯†é’¥ï¼Œå¹¶ä½¿ç”¨å…¬å…±å¯†é’¥åŸºç¡€ç»“æ„ï¼ˆPKIï¼‰æ¥å»ºç«‹è‡ªå·±çš„èº«ä»½ï¼Œä»¥ä»åŒºå—é“¾ä¸­æ£€ç´¢ä¸´åºŠæ•°æ®ï¼Œä»¥åŠæ·»åŠ æ–°ä¿¡æ¯ï¼ˆä¾‹å¦‚å®¶åº­ç›‘æ§è®¾å¤‡ï¼‰ã€‚PKIç¡®ä¿æä¾›è€…å’Œæœºæ„å¯ä»¥ç›¸ä¿¡æ‚£è€…æ­£åœ¨ç”Ÿæˆæ•°æ®ã€‚ æ•°æ®ä¸å˜æ€§ ä¸´åºŠæ•°æ®å®‰å…¨åœ°åˆ†å¸ƒåœ¨å¤šä¸ªå®ä½“ä¸­ï¼Œä»è€Œç¡®ä¿å®Œæ•´æ€§ï¼Œé™ä½ä¸¢å¤±é£é™©å¹¶æä¾›å®¡è®¡è·Ÿè¸ªï¼ˆä»¥é˜²æ¶æ„è¡Œä¸ºè€…ï¼‰ã€‚åŒºå—é“¾çš„Append-onlyæ¨¡å‹å¯ç¡®ä¿æ‰€æœ‰å¯è®¿é—®ä¿¡æ¯çš„æä¾›å•†éƒ½å…·æœ‰å®Œæ•´çš„ä¸´åºŠå›¾æ™¯ã€‚ åŒºå—é“¾æ”¹å–„æ–¹æ³• æ•°å­—è®¿é—®è§„åˆ™çš„ç®¡ç† æˆäºˆä¸´åºŠæ•°æ®å‘å¸ƒæƒé™æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„åŠŸèƒ½ï¼Œé€šå¸¸ç”±æ•°æ®å­¤å²›æ‰€æœ‰è€…æ§åˆ¶ã€‚åŒºå—é“¾ä¸ºé›†ä¸­ç®¡ç†å…±äº«æ•°æ®çš„èº«ä»½éªŒè¯å’Œæˆæƒè§„åˆ™æä¾›äº†ä¸€ç§é›†ä¸­å’Œå…±äº«çš„æœºåˆ¶ã€‚ ä¾‹å¦‚ï¼Œä¸€ä¸ªåŒºå—é“¾å¯èƒ½å…·æœ‰â€œæ™ºèƒ½è´¢äº§â€ï¼ˆä¸€ä¸ªé€šè¿‡åŒºå—é“¾ç®¡ç†æ‰€æœ‰æƒçš„å®ä½“ï¼‰ï¼Œä»¥å…è®¸æŸç§å½¢å¼çš„æ•°å­—è´¢äº§æ‹¥æœ‰æ˜ç¡®çš„æ‰€æœ‰æƒã€‚æ•°æ®çš„ä¿ç®¡äººæ¸…æ™°åœ°æ˜¾ç¤ºåœ¨åŒºå—é“¾ä¸Šï¼Œå¹¶ä¸”å¯ä»¥éšåä¸ºå…¶æ•°æ®åˆ†é…è®¿é—®è§„åˆ™å’Œæƒé™ï¼Œä»è€Œä½¿å…±äº«æ›´åŠ å®¹æ˜“ã€‚ æ•°æ®èšåˆ éšç€æ‚£è€…é€æ¸æ‹¥æœ‰æ›´å¤šçš„å¥åº·æ•°æ®æ‰€æœ‰æƒï¼Œä»–ä»¬çš„é¦–è¦ä»»åŠ¡ä¹‹ä¸€å°±æ˜¯å°†æ‰€æœ‰ä¸´åºŠæ•°æ®æ”¶é›†åœ¨ä¸€èµ·ï¼Œä¾‹å¦‚ï¼Œé€šè¿‡å»ºç«‹ä¸æ¯ä¸ªè¦ä½¿ç”¨æ•°æ®çš„ç³»ç»Ÿçš„APIè¿æ¥ã€‚ä¸€æ—¦æ‚£è€…å»ºç«‹äº†è¿™äº›è”ç³»ï¼Œä»–ä»¬å°±å¯ä»¥é€‚å½“åœ°æ”¶é›†å’Œæ±‡æ€»å…¶å¥åº·æ•°æ®ã€‚åŒºå—é“¾å¹³å°å¯ä»¥ä¿ƒè¿›è¿™ä¸€ç‚¹-å°¤å…¶æ˜¯ä¸æ”¯æŒåŒºå—é“¾çš„æ•°å­—è®¿é—®è§„åˆ™ç»“åˆä½¿ç”¨ã€‚ä¾‹å¦‚ï¼Œä¾‹å¦‚ï¼Œä¸´åºŠä¼šè¯Šå¯ä»¥å®‰å…¨åœ°å¹¿æ’­åˆ°ç½‘ç»œå¹¶è¿æ¥åˆ°æ‚£è€…çš„åŒ¿åæ•°å­—èº«ä»½ã€‚å¦‚æœæ‰€æœ‰æœºæ„çš„æ‰€æœ‰ä¸´åºŠç»éªŒéƒ½éµå¾ªè¿™ä¸€èŒƒä¾‹ï¼Œåˆ™æ‚£è€…åªéœ€ä¸ä¸€ä¸ªå¹³å°è¿›è¡Œäº¤äº’ï¼Œå› ä¸ºæ‰€æœ‰å¥åº·æ•°æ®éƒ½å¯ä»¥é€šè¿‡ç›¸åŒçš„åè®®å’Œæ ‡å‡†è·å¾—ã€‚æ­¤å¤–ï¼Œæ‚£è€…å¯ä»¥å°†è‡ªå·±çš„æ‚£è€…ç”Ÿæˆçš„å¥åº·æ•°æ®ï¼ˆPGHDï¼‰å‘å¸ƒåˆ°åŒºå—é“¾ç½‘ç»œã€‚å¦‚æœæ‚£è€…æˆæƒä¹¦å‘å¸ƒï¼Œæ­¤ç±»PGHDå¯ä»¥æä¾›æ´»åŠ¨ç›‘æµ‹æˆ–åœ¨æ­£å¼åŒ»ç–—ä¿å¥åœºæ‰€ä¹‹å¤–æ•è·çš„å…¶ä»–ä¸ªäººå¥åº·æ•°æ®ã€‚ æ•°æ®æµåŠ¨æ€§ -&gt; å¿«é€Ÿè®¿é—®ä¸´åºŠä¿¡æ¯ åŒºå—é“¾æé«˜äº†æ•°æ®æµåŠ¨æ€§å’Œæ•°æ®å¯ç”¨æ€§ï¼Œå¹¶ä½¿æ‚£è€…æ›´å®¹æ˜“ä¸å…¶ä»–å®ä½“å…±äº«æ•°æ® å›´ç»•æ‚£è€…èº«ä»½ æ²¡æœ‰ç¾å›½å›½æ°‘çš„æ‚£è€…è¯†åˆ«ç ï¼Œä¸´åºŠä¿¡æ¯ç³»ç»Ÿç»å¸¸æœ‰ä¸€ä¸ªäººçš„å¤šä¸ªè®°å½•ã€‚è¿™äº›è®°å½•çš„å®ä½“è§£ææ˜¯è¿è¥å’Œç ”ç©¶å…´è¶£çš„æ´»è·ƒé¢†åŸŸï¼Œå¹¶ä¸”åœ¨è§„æ¨¡ä¸Šå¯èƒ½å…·æœ‰å¾ˆå¤§æŒ‘æˆ˜æ€§ã€‚ åŒºå—é“¾å¯¹å…¬é’¥åŸºç¡€è®¾æ–½ï¼ˆPKIï¼‰çš„ä½¿ç”¨æä¾›äº†ä¸€ç§é›†ä¸­å¼è¯†åˆ«æ–¹æ³•ï¼ˆä¸ªäººçš„å…¬é’¥ï¼‰ï¼Œå¯ç”¨äºåœ¨æœºæ„ä¹‹é—´é“¾æ¥è¯¥æ‚£è€…çš„è®°å½•ã€‚å¦‚æœæ¯ä¸ªæœºæ„éƒ½çŸ¥é“æ‚£è€…çš„å…¬å…±å¯†é’¥ï¼Œå¹¶ä¸”è¯¥å¯†é’¥å·²é“¾æ¥åˆ°å…¶è‡ªå·±çš„å†…éƒ¨æ ‡è¯†ç¬¦ï¼ˆä¾‹å¦‚ï¼Œæ‚£è€…åœ¨æ³¨å†Œæ—¶å°†å…¶å…¬å…±å¯†é’¥é“¾æ¥åˆ°å…¶æ‚£è€…é—¨æˆ·å¸æˆ·ï¼‰ï¼Œåˆ™éšåçš„ä¸´åºŠäº‹ä»¶ä¼šå¹¿æ’­åˆ°åŒºå—é“¾ç½‘ç»œå¯ä»¥å°†è¯¥å…¬é’¥ä½œä¸ºæ‚£è€…å‚è€ƒï¼Œä»¥æ–¹ä¾¿æ‚£è€…åŒ¹é…ã€‚ æ•°æ®ä¸å˜æ€§ï¼ˆç¨³å®šæ€§ï¼‰ ç”±äºåŒºå—é“¾é€šå¸¸æ˜¯ä¸å¯å˜çš„ï¼Œå› æ­¤æ·»åŠ åˆ°é“¾ä¸­çš„æ•°æ®å°†æŒç»­å­˜åœ¨ã€‚è¿™é™ä½äº†ä¸¢å¤±çš„é£é™©ï¼Œæä¾›äº†å®¡è®¡è·Ÿè¸ªï¼ˆä¾‹å¦‚ï¼Œåœ¨æ¶æ„è¡Œä¸ºè€…çš„æƒ…å†µä¸‹ï¼‰ï¼Œå¹¶ç¡®ä¿æ‰€æœ‰æ–¹éƒ½å¯ä»¥è·å¾—å®Œæ•´çš„æ•°å­—å†å²è®°å½•ï¼ˆæä¾›é€‚å½“çš„è®¿é—®æ§åˆ¶ï¼‰ã€‚ å›¾1Cæè¿°äº†ä¸€ç§æ–¹æ³•ï¼Œå…¶ä¸­ä¸¤ä¸ªæ²¡æœ‰æ­£å¼ä¸šåŠ¡å…³ç³»ï¼ˆä½†å…·æœ‰æ ‡å‡†æ•°æ®æ¥å£ï¼‰çš„ç»„ç»‡å¯ä»¥åˆ©ç”¨åŒºå—é“¾å±‚è¿›è¡Œæ•°æ®è®¿é—®å’Œæˆæƒè§„åˆ™ã€‚ åŒºå—é“¾æ”¯æŒçš„åŸºäºæ‚£è€…é©±åŠ¨çš„äº’æ“ä½œæ€§çš„å¼ åŠ›å’Œéšœç¢ éšœç¢ å¤§æ‰¹é‡ï¼Œé«˜é¢‘äº¤æ˜“æ˜¯ä¸´åºŠæ•°æ®çš„æŒ‘æˆ˜ å¤§æ‰¹é‡ï¼Œé«˜é¢‘äº¤æ˜“æ˜¯ä¸´åºŠæ•°æ®çš„åŸºçŸ³ï¼Œå¹¶ä¸”éšç€ç°ä»£æŠ€æœ¯çš„è¿›æ­¥ï¼Œä¸´åºŠæ•°æ®çš„è§„æ¨¡å‘ˆæŒ‡æ•°å¢é•¿ã€‚ä¾‹å¦‚ï¼Œå•ä¸ªå¿ƒè„ç£å…±æŒ¯å›¾åƒå¯èƒ½éœ€è¦200å…†å­—èŠ‚çš„å­˜å‚¨ç©ºé—´ã€‚è€ƒè™‘åˆ°åŒºå—é“¾çš„åˆ†å¸ƒå¼æ€§è´¨ï¼Œä½¿ç”¨å½“å‰æŠ€æœ¯å°†æ•°æ®å­˜å‚¨åœ¨é“¾ä¸Šæ˜¯ä¸å¯è¡Œçš„ã€‚æ­¤å¤–ï¼ŒåŸºäºå·¥ä½œé‡è¯æ˜ï¼ˆä¾‹å¦‚æ¯”ç‰¹å¸ï¼‰ï¼ŒéªŒè¯æ–°äº¤æ˜“å¯èƒ½éœ€è¦èŠ±è´¹å¤§é‡æ—¶é—´åœ¨åŒºå—é“¾ä¸Šã€‚è¿™äº›é™åˆ¶æœ‰åˆ©äºå°è§„æ¨¡ï¼Œç›¸å¯¹å°‘è§çš„äº¤æ˜“ã€‚ æœ‰å¾ˆå¤šæ–¹æ³•å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä¾‹å¦‚æ¯”ç‰¹å¸çš„é—ªç”µç½‘ç»œï¼ŒåŸºäºå…±è¯†çš„æ›¿ä»£æ–¹æ³•ï¼ˆä¾‹å¦‚ï¼Œè‚¡æƒè¯æ˜ï¼‰æˆ–è®¸å¯çš„åŒºå—é“¾çš„åŒºå—é“¾ï¼Œä½†æ˜¯éœ€è¦è¿›ä¸€æ­¥çš„å·¥ä½œæ¥äº†è§£è¿™äº›è§£å†³æ–¹æ¡ˆæ˜¯å¦å¯ä»¥é¿å…è§„æ¨¡æ‰©å¼ æŒ‘æˆ˜ã€‚ æ¶‰åŠéšç§å’Œå®‰å…¨æ€§çš„æŒ‘æˆ˜ åŒºå—é“¾æŠ€æœ¯çš„æŸäº›å®ç°æ˜¯åŒ¿åçš„â€”èº«ä»½é€šå¸¸åœ¨å…¬é’¥åè¢«æ©ç›–ï¼Œä½†æ˜¯äº¤æ˜“çš„å…¶ä»–å±æ€§æ˜¯å…¬å¼€å…±äº«çš„ã€‚è¿™å¯¹äºå¥åº·æ•°æ®æ˜¯æœ‰é—®é¢˜çš„ã€‚ é¦–å…ˆï¼ŒåŸºæœ¬çš„äººå£ç»Ÿè®¡ä¿¡æ¯å¯ä»¥è¯†åˆ«äººï¼Œå¹¶ä¸”å¦‚æœä¸€ä¸ªäººçš„å…¬é’¥ä¸ä»–ä»¬çš„èº«ä»½åŒ¹é…ï¼Œåˆ™ä¸è¯¥å…¬é’¥ç›¸å…³çš„æ‰€æœ‰äº¤æ˜“éƒ½å°†è¢«é“¾æ¥åˆ°ä¸ªäººã€‚ç„¶è€Œå¯¹å…¬å…±åŒºå—é“¾é€ æˆç¾éš¾æ€§å½±å“çš„åŒæ—¶ï¼Œç§æœ‰åŒºå—é“¾ä¹Ÿå­˜åœ¨é—®é¢˜ï¼Œå› ä¸ºä¸ªäººå¯èƒ½ä¸å¸Œæœ›ç§æœ‰åŒºå—é“¾çš„æ‰€æœ‰æˆå‘˜éƒ½å¯ä»¥è®¿é—®åŒä¸€æ•°æ®ï¼Œæˆ–è€…ä»–ä»¬å¯èƒ½å¸Œæœ›åœ¨ä¹‹åçš„æŸä¸ªæ—¶é—´ç‚¹æ’¤æ¶ˆå¯¹å…¶æ•°æ®çš„æˆæƒï¼Œä½†æ˜¯ç”¨æˆ·ä¸€æ—¦å°†å…¶èº«ä»½é“¾æ¥åˆ°å…¶å…¬é’¥ï¼Œåˆ™ä¸¤è€…å‡æ— æ³•å®ç°ã€‚ä¿å¥è¡Œä¸šå°†éœ€è¦åŒºå—é“¾çš„å®ç°å…è®¸é€‰æ‹©æ€§åœ°å…¬å¼€ç§äººä¿¡æ¯ï¼ˆä¾‹å¦‚Zcashï¼‰ï¼Œå¹¶ä¾é é›¶çŸ¥è¯†å¯†ç å­¦æ¥æä¾›å¯¹åº•å±‚æ•°æ®å…·æœ‰é«˜åº¦éšç§æ€§çš„äº¤æ˜“éªŒè¯ã€‚ æ‚£è€…å‚ä¸çš„æŒ‘æˆ˜ ä»¥æ‚£è€…ä¸ºä¸»å¯¼çš„äº’æ“ä½œæ€§æ¡†æ¶ä¸æœºæ„é©±åŠ¨çš„æ¶æ„ç›¸æ¯”ï¼Œå¿…ç„¶éœ€è¦æ›´å¤šçš„æ‚£è€…å‚ä¸ã€‚ å¦‚æœæ‚£è€…è¦æˆä¸ºè‡ªä¸»çš„æ•°å­—ç®¡ç†å‘˜ï¼Œä»–ä»¬å°†éœ€è¦æŸç§æ–¹å¼æ¥ç®¡ç†å…¶æ•°å­—èµ„äº§ï¼ˆä¾‹å¦‚é’¥åŒ™æˆ–å¯†ç ï¼‰ã€‚ éœ€è¦è€ƒè™‘ç”¨äºç®¡ç†ä¸¢å¤±çš„æ•°å­—èµ„äº§çš„æœºåˆ¶ï¼ˆä¾‹å¦‚å¿˜è®°å¯†ç ï¼Œä¸¢å¤±å¯†é’¥ç­‰ï¼‰ã€‚ è¿™å¯èƒ½éœ€è¦é¢å¤–çš„ä¸­ä»‹ï¼Œè€Œä¸”å°šä¸æ¸…æ¥šè°å°†æ‰®æ¼”è¿™ä¸ªè§’è‰²â€”ä¹Ÿè®¸æ˜¯ä¸€ä¸ªæ–°çš„å•†ä¸šå¸‚åœºçš„æœºä¼šï¼Œç±»ä¼¼äºåŠ å¯†è´§å¸äº¤æ˜“æ‰€ã€‚ æ¿€åŠ±æªæ–½çš„æŒ‘æˆ˜ å°½ç®¡æ³•å¾‹ç°åœ¨è¦æ±‚EHRå¿…é¡»å…·æœ‰é¢å‘æ‚£è€…çš„APIï¼Œä½†å¹¶éæ‰€æœ‰åŒ»ç–—æ•°æ®éƒ½ä¸€æ ·ï¼Œå¹¶ä¸”æ¿€åŠ±æœºæ„åœ¨æ²¡æœ‰ç»æµåŠ¨æœºçš„æƒ…å†µä¸‹å»ºç«‹é¢å‘æ‚£è€…çš„æ•°æ®è¿æ¥å°†å…·æœ‰æŒ‘æˆ˜æ€§â€“åˆè§„æ€§ä¸çœŸå®æ€§ä¹‹é—´çš„åŒºåˆ«ã€‚ ä¾‹å¦‚ï¼Œè™½ç„¶è¯ç‰©æ¸…å•å¯èƒ½æ˜¯åŒ»é™¢é¢å‘æ‚£è€…çš„EHR APIçš„å¿…å¡«æ•°æ®è¾“å‡ºï¼Œä½†å°šä¸æ¸…æ¥šåˆ¶è¯æ”¶ç›Šç®¡ç†è€…æ˜¯å¦éœ€è¦åœ¨æ²¡æœ‰æ˜ç¡®ä¸šåŠ¡ä»·å€¼çš„æƒ…å†µä¸‹æ„é€ å’Œå…¬å¼€æ‰€æœ‰è¯ç‰©æ‰¹å‡†æˆ–äº¤æ˜“ã€‚å›´ç»•æ•°æ®å…±äº«çš„è¿›ä¸€æ­¥æ¿€åŠ±æªæ–½å°†è¿›ä¸€æ­¥åŠ å¼ºAPIç»æµæ€§ï¼Œå¹¶å¯¼è‡´æ›´å¤šçš„æ‚£è€…æ•°æ®è‡ªä¸»æƒã€‚ è¡¨2æè¿°äº†è¿™äº›æŒ‘æˆ˜ä»¥åŠæ½œåœ¨çš„ç¼“è§£æªæ–½ï¼š æŒ‘æˆ˜ ç¼“è§£æªæ–½ ä¸´åºŠæ•°æ®äº¤æ˜“é‡ 1. å°†æ•°æ®äº¤æ¢é›†ä¸­åœ¨æ±‡æ€»çš„ä¸´åºŠæ•°æ®ä¸Šï¼›2. æœ¬åœ°åœ°ç†åŒºåŸŸçš„è®¸å¯åŒºå—é“¾å¯å¤„ç†å¤§é‡äº¤æ˜“è€Œæ— éœ€æ—¶é—´å¯†é›†éªŒè¯ï¼›3. åŒºå—é“¾æ‰©å±•æ–¹æ³•å­¦çš„æ–°æŠ€æœ¯å’Œç ”ç©¶ éšç§ä¸å®‰å…¨ 1.æˆæƒçš„ä»…é™ä¼šå‘˜çš„åŒºå—é“¾åœˆï¼Œä»¥æœ€å¤§ç¨‹åº¦åœ°å‡å°‘å…¬ä¼—æ›å…‰ï¼›2. é“¾ä¸‹æ•°æ®å­˜å‚¨ï¼Œé“¾ä¸Šä¾§é‡äºæƒé™æˆ–å…¶ä»–å…ƒæ•°æ® æ‚£è€…å‚ä¸ ä¸­ä»‹äººâ€œAPPâ€ç”Ÿæ€ç³»ç»Ÿï¼Œç”¨äºç®¡ç†å…¬å…±å¯†é’¥å’Œæƒé™ æ¿€åŠ±æªæ–½ 1. è”é‚¦æ”¿åºœç»§ç»­é¼“åŠ±æ‰©å¤§APIè¦†ç›–èŒƒå›´ï¼›2. å¼€æ”¾æ•°æ®ä¸æŠ¥é”€ä»·å€¼çš„å…³è”ï¼›3.æ”¯æŒAPIçš„ç³»ç»Ÿçš„ç«äº‰å‹åŠ›ï¼Œé¼“åŠ±ä¸æ”¯æŒAPIçš„ç³»ç»ŸæŠ•èµ„APIåŸºç¡€è®¾æ–½ æ€»ç»“ è¿™ç¯‡æ–‡ç« å¥½åƒåªæ˜¯æå‡ºäº†æ¦‚å¿µï¼Œä½†æ˜¯å¹¶æ²¡æœ‰å¯¹å…·ä½“æ–¹æ¡ˆå®æ–½è¿›è¡Œè§£è¯´ã€‚","categories":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Paper Smash","slug":"Technology/Paper-Smash","permalink":"https://littlelittlemoon.github.io/categories/Technology/Paper-Smash/"}],"tags":[{"name":"Paper","slug":"Paper","permalink":"https://littlelittlemoon.github.io/tags/Paper/"},{"name":"Patient-Driven Interoperability","slug":"Patient-Driven-Interoperability","permalink":"https://littlelittlemoon.github.io/tags/Patient-Driven-Interoperability/"},{"name":"Blockchain","slug":"Blockchain","permalink":"https://littlelittlemoon.github.io/tags/Blockchain/"}],"keywords":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Paper Smash","slug":"Technology/Paper-Smash","permalink":"https://littlelittlemoon.github.io/categories/Technology/Paper-Smash/"}]},{"title":"Leetcode Note in Apri 2020 | part 3 | day 15-21 | (ä¸€).","slug":"Technology/Leetcode-Note-in-Apri-2020-part-3-day-15-21-(ä¸€)","date":"2020-04-15T12:33:23.000Z","updated":"2020-04-18T06:30:33.176Z","comments":true,"path":"2020/04/15/Technology/Leetcode-Note-in-Apri-2020-part-3-day-15-21-(ä¸€)/","link":"","permalink":"https://littlelittlemoon.github.io/2020/04/15/Technology/Leetcode-Note-in-Apri-2020-part-3-day-15-21-(%E4%B8%80)/","excerpt":"","text":"å†™åœ¨å‰é¢çš„è¯ ç¬¬ä¸‰æ¬¡æ›´æ–°ï¼Œè¿™æ¬¡æ›´æ–°å¯èƒ½ä¼šæŠŠä¸€å‘¨çš„å†…å®¹åˆ†ä¸ºä¸¤ç¯‡æ–‡ç« ï¼Œå› ä¸ºæ”¾ä¸€ç¯‡æ–‡ç« çš„è¯å†…å®¹æœ‰ç‚¹å¤ªé•¿äº†ã€‚æ–°çš„æŒ‘æˆ˜ï¼ç»§ç»­å‰è¿›~ Product of Array Except Self Given an array nums of n integers where n &gt; 1, return an array output such that output[i] is equal to the product of all the elements of nums except nums[i]. Example: Input: [1,2,3,4] Output: [24,12,8,6] Constraint: It's guaranteed that the product of the elements of any prefix or suffix of the array (including the whole array) fits in a 32 bit integer. Note: Please solve it without division and in O(n). Follow up: Could you solve it with constant space complexity? (The output array does not count as extra space for the purpose of space complexity analysis.) Solution å…·ä½“æ€è·¯åœ¨ä»£ç æ³¨é‡Šä¸­å·²ç»è¯´çš„å¾ˆæ¸…æ¥šäº†ï¼Œæˆ‘è¿™é‡Œç®€å•æ¦‚æ‹¬ä¸€ä¸‹ï¼š è¿™ä¸ªé¢˜æœ‰ä¸ªé™åˆ¶ï¼šä¸èƒ½ä½¿ç”¨é™¤æ³•ï¼Œè¿™ä¸ªé™åˆ¶è®©è¿™é“é¢˜å˜å¾—æœ‰ç‚¹éš¾åº¦ã€‚æœ¬æ¥æˆ‘ä»¬å¯ä»¥æŠŠæ•°ç»„é‡Œé¢æ‰€æœ‰å…ƒç´ ç›¸ä¹˜ï¼Œç„¶åé€šè¿‡é™¤ä»¥ç›¸åº”indexçš„æ•°å°±å¯ä»¥å¾—åˆ°æ¯ä¸ªæ•°å¯¹åº”çš„é™¤è‡ªå·±ä»¥å¤–çš„æ•°çš„ç§¯ã€‚ æœ‰äº†é™åˆ¶æ¡ä»¶ä¹‹åï¼Œæˆ‘æƒ³äº†å¾ˆä¹…ä¹Ÿæ²¡æœ‰æƒ³åˆ°å¾ˆå¥½çš„æ–¹æ³•ï¼Œä¹‹åçœ‹åˆ°å…¶ä»–å°ä¼™ä¼´çš„è§£é¢˜æ€è·¯ï¼Œå°±çªç„¶æ¥äº†çµæ„Ÿã€‚æˆ‘ä»¬å¯ä»¥å°†æ•°ç»„æ ¹æ®å½“å‰å…ƒç´ åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼ˆå·¦è¾¹å’Œå³è¾¹ï¼‰ã€‚ç„¶ååˆ†åˆ«è®¡ç®—å…ƒç´ ä¸¤è¾¹çš„æ‰€æœ‰å…ƒç´ çš„ç§¯ï¼Œå†å°†ä¸¤è¾¹æ‰€å¾—çš„ç§¯ç›¸ä¹˜ï¼Œå°±å¾—åˆ°äº†å½“å‰å…ƒç´ åº”è¯¥å¯¹åº”çš„ç§¯ã€‚å…·ä½“çœ‹ä»£ç å®ç°å’Œæ³¨é‡Šã€‚ class Solution: def productExceptSelf(self, nums: List[int]) -&gt; List[int]: # The length of the input array n_len = len(nums) # The product array to be returned product = [0] * n_len # product[i] contains the product of all the elements to the left # Note: for the element at index &#39;0&#39;, there are no elements to the left, # so the product[0] would be 1 product[0] = 1 for i in range(1, n_len): # product[i - 1] already contains the product of elements to the left of &#39;i - 1&#39; # Simply multiplying it with nums[i - 1] would give the product of all # elements to the left of index &#39;i&#39; product[i] = nums[i - 1] * product[i - 1] # R contains the product of all the elements to the right # Note: for the element at index &#39;length - 1&#39;, there are no elements to the right, # so the R would be 1 R = 1; for i in reversed(range(n_len)): # For the index &#39;i&#39;, R would contain the # product of all elements to the right. We update R accordingly product[i] = product[i] * R R *= nums[i] return product Valid Parenthesis String Given a string containing only three types of characters: '(', ')' and '', write a function to check whether this string is valid. We define the validity of a string by these rules: 1. Any left parenthesis '(' must have a corresponding right parenthesis ')'. 2. Any right parenthesis ')' must have a corresponding left parenthesis '('. 3. Left parenthesis '(' must go before the corresponding right parenthesis ')'. 4. '' could be treated as a single right parenthesis ')' or a single left parenthesis '(' or an empty string. 5. An empty string is also valid. Example 1: Input: \"()\" Output: True Example 2: Input: \"()\" Output: True Example 3: Input: \"())\" Output: True Solution è¿™ä¸ªé¢˜çš„æ€è·¯ä¹Ÿæ˜¯æ¯”è¾ƒå¸¸è§„ï¼Œå¯ä»¥é€šè¿‡åˆ¤æ–­å¼€æ‹¬å·çš„ä¸ªæ•°æ¥åˆ¤æ–­å½“å‰å­—ç¬¦ä¸²æ˜¯å¦æœ‰æ•ˆï¼ˆ=0ï¼šæœ‰æ•ˆï¼Œå…¶ä»–æ— æ•ˆï¼‰ã€‚ä½†æ˜¯ç”±äº*å¯ä»¥ä»£æ›¿å·¦æ‹¬å·(ï¼Œä¹Ÿå¯ä»¥ä»£æ›¿å³æ‹¬å·)ï¼Œæ‰€ä»¥é’ˆå¯¹è¿™é“é¢˜ï¼Œæˆ‘ä»¬ä¸èƒ½ç®€å•çš„ç”¨ä¸€ä¸ªå˜é‡æ¥è®¡ç®—å¼€æ‹¬å·çš„ä¸ªæ•°ã€‚ä½†æ€è·¯æ˜¯ä¸€è‡´çš„ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å¿…é¡»è¦å¿…é…çš„å¼€æ‹¬å·ä¸ªæ•°ï¼ˆæœ€å°å¼€æ‹¬å·ä¸ªæ•°ï¼‰å’Œæœ€å¤§éœ€è¦åŒ¹é…çš„å¼€æ‹¬å·ä¸ªæ•°æ¥åˆ¤æ–­å­—ç¬¦ä¸²æ˜¯å¦æœ‰æ•ˆï¼Œæ•…æˆ‘ä»¬éœ€è¦ä¸¤ä¸ªå˜é‡ï¼šnrp_min(è®°å½•éœ€è¦è¢«åŒ¹é…çš„æœ€å°å¼€æ‹¬å·ä¸ªæ•°)ï¼Œnrp_maxï¼ˆè®°å½•æœ€å¤§éœ€è¦è¢«åŒ¹é…çš„å¼€æ‹¬å·ä¸ªæ•°ï¼‰ã€‚å…·ä½“å®ç°è¯´æ˜è§ä»£ç åŠæ³¨é‡Šã€‚ class Solution: def checkValidString(self, s: str) -&gt; bool: # nrp_min: counts the minimum open parenthesis # nrp_max: counts the maximum open parenthesis, nrp_min = nrp_max = 0 for i in s: # when we meet a &#39;(&#39;, we need a &#39;)&#39; to match if i == &#39;(&#39;: nrp_max += 1 nrp_min += 1 # when we meet a &#39;)&#39;, we can match a &#39;(&#39; if i == &#39;)&#39;: nrp_max -= 1 nrp_min = max(nrp_min - 1, 0) # when we meet &#39;*&#39;, we can match a &#39;(&#39; and also may need a &#39;)&#39; to match # so the max number of &#39;)&#39; we need should +1, and the min number of &#39;)&#39; # we need should -1 if i == &#39;*&#39;: nrp_max += 1 nrp_min = max(nrp_min - 1, 0) # if at the end of the loop, the max number of &#39;)&#39; we need is &lt; 0, it means the # number of &#39;(&#39; is bigger than the number of &#39;)&#39;,this string is invalid. if nrp_max &lt; 0: return False # if the min number of &#39;)&#39; we need is 0, it means all of the &#39;(&#39; have one &#39;)&#39; be paired return nrp_min == 0 æ€»ç»“ è¿™å‘¨çš„é¢˜æ¯”ä¹‹å‰çš„è¦éš¾ä¸€ç‚¹ï¼Œä»Šå¤©åšäº†ä¸€é“é¢˜è®©æˆ‘æ‡µåœˆäº†ï¼Œå› ä¸ºæˆ‘å·²ç»æŠŠä¹‹å‰å­¦çš„å…³äºå›¾çš„ç›¸å…³ç®—æ³•å¿˜å®Œäº†ï¼Œå…¶å®ä¹Ÿä¸ç®—æ˜¯å¿˜äº†ç›¸å…³ç®—æ³•ï¼Œè€Œæ˜¯ä¸èƒ½å°†å­¦è¿‡çš„ç®—æ³•å’Œå®é™…é—®é¢˜è”ç³»èµ·æ¥ï¼Œä¸‹ä¸€ç¯‡æ–‡ç« æˆ‘ä¼šè¯¦ç»†å†™ä¸€ç¯‡å…³äºè¿™é“é¢˜çš„è§£æ³•ï¼Œä¹Ÿç®—æ˜¯å·©å›ºå’Œåº”ç”¨ä»¥å‰å­¦è¿‡çš„çŸ¥è¯†å§ï¼å†æ¥å†å‰ï¼","categories":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Coding","slug":"Technology/Coding","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/"},{"name":"Leetcode","slug":"Technology/Coding/Leetcode","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/Leetcode/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://littlelittlemoon.github.io/tags/Leetcode/"},{"name":"Python","slug":"Python","permalink":"https://littlelittlemoon.github.io/tags/Python/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://littlelittlemoon.github.io/tags/Algorithm/"}],"keywords":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Coding","slug":"Technology/Coding","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/"},{"name":"Leetcode","slug":"Technology/Coding/Leetcode","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/Leetcode/"}]},{"title":"åƒµå°¸ä¼ä¸šåˆ†ç±»|æ¨¡å‹è®­ç»ƒ|LightGBM","slug":"Technology/åƒµå°¸ä¼ä¸šåˆ†ç±»-æ¨¡å‹è®­ç»ƒ-LightGBM","date":"2020-04-11T11:25:37.000Z","updated":"2020-04-12T13:06:54.541Z","comments":true,"path":"2020/04/11/Technology/åƒµå°¸ä¼ä¸šåˆ†ç±»-æ¨¡å‹è®­ç»ƒ-LightGBM/","link":"","permalink":"https://littlelittlemoon.github.io/2020/04/11/Technology/%E5%83%B5%E5%B0%B8%E4%BC%81%E4%B8%9A%E5%88%86%E7%B1%BB-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83-LightGBM/","excerpt":"","text":"å†™åˆ°å‰é¢çš„è¯ åœ¨ä¸Šä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘å¯¹åƒµå°¸ä¼ä¸šåˆ†ç±»é—®é¢˜çš„æ•°æ®é¢„å¤„ç†åšäº†ä»‹ç»ï¼Œè¿™ç¯‡æ–‡ç« ä¸»è¦ä»‹ç»æ¨¡å‹è®­ç»ƒéƒ¨åˆ†ï¼Œé‡‡ç”¨çš„ç®—æ³•æ¡†æ¶æ˜¯LightGBM(Light Gradient Boosting Machine)ï¼Œæ˜¯ä¸€ä¸ªå®ç° GBDT ç®—æ³•çš„æ¡†æ¶ã€‚è€ŒGBDT(Gradient Boosting Decision Tree)çš„ä¸»è¦æ€æƒ³æ˜¯åˆ©ç”¨å¼±åˆ†ç±»å™¨ï¼ˆå†³ç­–æ ‘ï¼‰è¿­ä»£è®­ç»ƒä»¥å¾—åˆ°æœ€ä¼˜æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å…·æœ‰è®­ç»ƒæ•ˆæœå¥½ã€ä¸æ˜“è¿‡æ‹Ÿåˆç­‰ä¼˜ç‚¹ã€‚ LightGBMæœ‰å„ç§å¾ˆå¥½çš„ç‰¹æ€§ï¼Œç±»æ¯”å¾ˆå¤šboosting toolsä¼˜åŒ–é€Ÿåº¦å’Œå†…å­˜çš„ä½¿ç”¨ä¸Šé‡‡ç”¨åŸºäºé¢„æ’åºçš„ç®—æ³•è¿›è¡Œå†³ç­–æ ‘å­¦ä¹ ï¼ŒLightGBMä½¿ç”¨åŸºäºç›´æ–¹å›¾çš„ç®—æ³•ï¼Œæ”¯æŒé«˜æ•ˆç‡çš„å¹¶è¡Œè®­ç»ƒï¼Œå¹¶ä¸”å…·æœ‰ä»¥ä¸‹ä¼˜ç‚¹ï¼š 1. æ›´å¿«çš„è®­ç»ƒé€Ÿåº¦ 2. æ›´ä½çš„å†…å­˜æ¶ˆè€— 3. æ›´å¥½çš„å‡†ç¡®ç‡ 4. åˆ†å¸ƒå¼æ”¯æŒï¼Œå¯ä»¥å¿«é€Ÿå¤„ç†æµ·é‡æ•°æ® å…·ä½“ç®—æ³•åŸç†æˆ‘ä¹Ÿæ²¡æå¤ªæ˜ç™½ï¼Œå“ˆå“ˆã€‚æˆ‘å‡†å¤‡åé¢å¥½å¥½å­¦ä¹ ä¸€ç•ªï¼Œç„¶åå†å†™ä¸€ç¯‡å…³äºLightGBMçš„æ–‡ç« ï¼Œä¸»è¦æ˜¯è®°å½•è‡ªå·±çš„å­¦ä¹ è¿‡ç¨‹ï¼Œå†™ä¸€äº›è‡ªå·±çš„ç†è§£ã€‚è¿™é‡Œå¤§å®¶å¦‚æœæ„Ÿå…´è¶£å¯ä»¥å»çœ‹çœ‹å®˜æ–¹æ–‡æ¡£. æ¨¡å‹è®­ç»ƒ å®šä¹‰æ¨¡å‹è®­ç»ƒå‡½æ•° import lightgbm as lgb from sklearn import metrics def train_model(X_train, y_train, X_valid, y_valid, test=None, feature_cols=None, is_base=True): if feature_cols is None: feature_cols = X_train.columns.drop([&quot;è¡Œä¸š&quot;, &quot;åŒºåŸŸ&quot;, &quot;ä¼ä¸šç±»å‹&quot;, &quot;æ§åˆ¶äººç±»å‹&quot;]) dtrain = lgb.Dataset(X_train[feature_cols], label=y_train) dvalid = lgb.Dataset(X_valid[feature_cols], label=y_valid) param = {&#39;num_leaves&#39;: 64, &#39;objective&#39;: &#39;binary&#39;, &#39;metric&#39;: &#39;auc&#39;, &#39;seed&#39;: 7} num_round = 1000 print(&quot;Training model!&quot;) bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], early_stopping_rounds=20, verbose_eval=False) # é¢„æµ‹ç»“æœæ˜¯æ¦‚ç‡å€¼ï¼Œå°†å…¶è½¬æ¢ä¸ºbinary value valid_pred = bst.predict(X_valid[feature_cols]) valid_pred = valid_pred &gt; 0.5 valid_pred = valid_pred.astype(int) valid_score = metrics.roc_auc_score(y_valid, valid_pred) print(&quot;precision recall fscore support:&quot;) print(metrics.precision_recall_fscore_support(y_valid, valid_pred, average=&#39;micro&#39;)) print(f&quot;Validation AUC score: {valid_score}&quot;) if test is not None: test_pred = bst.predict(test[feature_cols]) test_pred = test_pred &gt; 0.5 test_pred = test_pred.astype(int) test_pred = test[[&#39;ID&#39;]].join(pd.DataFrame({&#39;flag&#39;: test_pred})) if is_base: test_pred.to_csv(&#39;test_base.txt&#39;, sep=&#39;,&#39;, index=False) else: test_pred.to_csv(&#39;test_.txt&#39;, sep=&#39;,&#39;, index=False) return bst, valid_score else: return bst, valid_score åŠ è½½å¤„ç†å¥½çš„æ•°æ®é›† import pandas as pd # load training data all_data = pd.read_csv(&quot;data/train/train.csv&quot;) # load testing data test = pd.read_csv(&quot;data/test/test.csv&quot;) test_base = pd.read_csv(&quot;data/test/base-test.csv&quot;) å°†è®­ç»ƒæ•°æ®é›†æ‹†åˆ†ä¸ºè®­ç»ƒé›†ä¸éªŒè¯é›† from sklearn.preprocessing import OneHotEncoder, LabelEncoder from sklearn.model_selection import train_test_split import category_encoders as ce from sklearn.utils import shuffle all_data_X = all_data[all_data.columns.drop([&quot;flag&quot;])] all_data_y = all_data[&quot;flag&quot;] # shuffle dataï¼ˆoptionalï¼‰ all_data_X, all_data_y = shuffle(all_data_X, all_data_y) # test = shuffle(test) train_X, valid_X, train_y, valid_y = train_test_split(all_data_X, all_data_y, random_state=66) ç±»å‹å˜é‡å¤„ç† é€šå¸¸ï¼Œæœ¬è´¨ä¸Šæ˜¯åˆ†ç±»çš„ä»»ä½•æ•°æ®å±æ€§éƒ½æ˜¯ç¦»æ•£å€¼ï¼Œè¿™äº›ç¦»æ•£å€¼å±äºç±»åˆ«æˆ–ç±»çš„ç‰¹å®šæœ‰é™é›†åˆã€‚åœ¨å±æ€§æˆ–ç”±æ¨¡å‹é¢„æµ‹çš„å˜é‡çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œé€šå¸¸ä¹Ÿç§°ä¸ºç±»æˆ–æ ‡ç­¾ã€‚ è¿™äº›ç¦»æ•£å€¼æœ¬è´¨ä¸Šå¯ä»¥æ˜¯æ–‡æœ¬æˆ–æ•°å­—ã€‚è¿™æ¬¡base dataé‡Œé¢çš„è¡Œä¸šï¼ŒåŒºåŸŸï¼Œä¼ä¸šç±»å‹ï¼Œæ§åˆ¶äººç±»å‹ç­‰å°±æ˜¯å±äºè¿™ä¸€ç±»å±æ€§ï¼Œæˆ‘åˆšå¼€å§‹çš„æƒ³æ³•æ˜¯æŠŠè¿™ç±»å±æ€§å€¼åšä¸€ä¸ªencodingï¼Œå…·ä½“ä»€ä¹ˆç±»å‹çš„encodingå¯ä»¥æ ¹æ®å±æ€§å¯¹æ¨¡å‹çš„å½±å“ç¨‹åº¦å’Œæ¨¡å‹è®­ç»ƒæ•ˆæœæ¥ç¡®å®šã€‚è¿™é‡Œåªç»™å‡ºäº†count encodingçš„ä¾‹å­ï¼Œå¦‚æœåé¢æœ‰æ—¶é—´æˆ‘ä¼šä¸“é—¨å†™ä¸€ç¯‡å¤„ç†è¿™ç±»å±æ€§çš„å¸¸ç”¨æ–¹æ³•ï¼Œåšä¸€ä¸ªè¯¦ç»†çš„æ€»ç»“ï¼Œè¿™é‡Œå°±ä¸å±•å¼€äº†ã€‚ Count Encoding for categorical variables cat_features = [&quot;è¡Œä¸š&quot;, &quot;åŒºåŸŸ&quot;, &quot;ä¼ä¸šç±»å‹&quot;, &quot;æ§åˆ¶äººç±»å‹&quot;] count_enc = ce.CountEncoder(cols=cat_features) # Learn encoding from the training set count_enc.fit(train_X[cat_features]) train_encoded_X = train_X.join(count_enc.transform(train_X[cat_features]) .add_suffix(&quot;_count&quot;)) valid_encoded_X = valid_X.join(count_enc.transform(valid_X[cat_features]) .add_suffix(&quot;_count&quot;)) test_encoded = test.join(count_enc.transform(test[cat_features]) .add_suffix(&quot;_count&quot;)) æ¨¡å‹è®­ç»ƒ åŸå§‹æ•°æ® ä¸ºäº†çœ‹åˆ†ç±»æ•°æ®å¤„ç†å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œä¸‹é¢çš„è®­ç»ƒæ²¡æœ‰ç”¨ç¼–ç åçš„ç±»åˆ«æ•°æ®ï¼Œè®­ç»ƒçš„æ—¶å€™ä¼šæŠŠç±»åˆ«å±æ€§åˆ—åˆ æ‰ã€‚ print(&quot;Baseline model&quot;) _ = train_model(train_X, train_y, valid_X, valid_y, test, is_base=True) Baseline model Training model! precision recall fscore support: (1.0, 1.0, 1.0, None) Validation AUC score: 1.0 ç»“æœè¶…å‡ºæ„æ–™ï¼Œå°±æ˜¯æœ€ç²—ç³™çš„æ•°æ®ï¼Œæ²¡æœ‰åšä»»ä½•ç‰¹å¾é€‰æ‹©å’Œä¼˜åŒ–ï¼Œå°±å¯ä»¥å¾—åˆ°è¿™ä¹ˆæå¾—ç²¾åº¦ï¼Œè¯´å®è¯æˆ‘å½“æ—¶æ˜¯æ€€ç–‘è‡ªå·±çš„ï¼Œåå¤ç¡®è®¤äº†å¥½å‡ éä»£ç ï¼Œå‘ç°æ²¡å•¥é—®é¢˜ã€‚ğŸ¤£å†æ¬¡è¯æ˜æ•°æ®é¢„å¤„ç†çš„é‡è¦æ€§ï¼Œæ•°æ®å¤„ç†å¥½äº†ï¼Œæœ€ç®€å•çš„æ¨¡å‹ä¹Ÿå¯ä»¥è¾¾åˆ°å¾ˆå¥½çš„æ•ˆæœã€‚ Count Encodingç±»åˆ«å±æ€§åçš„æ•°æ® print(&quot;Count Encoding model&quot;) _ = train_model(train_encoded_X, train_y, valid_encoded_X, valid_y, test_encoded, is_base=False) Count Encoding model Training model! precision recall fscore support: (1.0, 1.0, 1.0, None) Validation AUC score: 1.0 ä¸¤æ¬¡çš„è®­ç»ƒç»“æœæ²¡æœ‰ä»»ä½•å·®åˆ«ï¼Œä¹Ÿå¤±å»äº†ç‰¹å¾ä¼˜åŒ–çš„åŠ¨åŠ›ğŸ˜ƒ","categories":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Machine Learning","slug":"Technology/Machine-Learning","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/"},{"name":"Modeling","slug":"Technology/Machine-Learning/Modeling","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/Modeling/"}],"tags":[{"name":"LightGBM","slug":"LightGBM","permalink":"https://littlelittlemoon.github.io/tags/LightGBM/"},{"name":"Count Encoding","slug":"Count-Encoding","permalink":"https://littlelittlemoon.github.io/tags/Count-Encoding/"}],"keywords":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Machine Learning","slug":"Technology/Machine-Learning","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/"},{"name":"Modeling","slug":"Technology/Machine-Learning/Modeling","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/Modeling/"}]},{"title":"åƒµå°¸ä¼ä¸šåˆ†ç±»|æ•°æ®é¢„å¤„ç†","slug":"Technology/åƒµå°¸ä¼ä¸šåˆ†ç±»-æ•°æ®é¢„å¤„ç†","date":"2020-04-10T12:02:34.000Z","updated":"2020-04-18T10:31:56.322Z","comments":true,"path":"2020/04/10/Technology/åƒµå°¸ä¼ä¸šåˆ†ç±»-æ•°æ®é¢„å¤„ç†/","link":"","permalink":"https://littlelittlemoon.github.io/2020/04/10/Technology/%E5%83%B5%E5%B0%B8%E4%BC%81%E4%B8%9A%E5%88%86%E7%B1%BB-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/","excerpt":"","text":"é—®é¢˜æè¿° åƒµå°¸ä¼ä¸šæ˜¯æŒ‡ç¼ºä¹ç›ˆåˆ©èƒ½åŠ›å´èƒ½å¤Ÿä»¥ä½äºå¸‚åœºæœ€ä¼˜åˆ©ç‡æˆæœ¬è·å¾—ä¿¡è´·èµ„æºï¼Œä¾é å¤–ç•Œè¾“è¡€è€Œç¼ºä¹è‡ªç”Ÿèƒ½åŠ›çš„ä¼ä¸šã€‚åƒµå°¸ä¼ä¸šçš„å­˜åœ¨ç ´åäº†å¸‚åœºæœºåˆ¶ï¼ŒåŠ å‰§äº†ä¿¡è´·èµ„æºçš„é”™é…ï¼Œå¸¦æ¥äº†ä¸¥é‡çš„äº§èƒ½è¿‡å‰©é—®é¢˜ï¼Œè¿˜å¯¹å…¶ä»–éåƒµå°¸ä¼ä¸šäº§ç”Ÿäº†æŠ•èµ„æŒ¤å‡ºæ•ˆåº”ã€‚ å› æ­¤éœ€è¦å¯¹æ­£å¸¸ä¼ä¸šå’Œåƒµå°¸ä¼ä¸šè¿›è¡Œåˆ†ç±»ï¼Œç°ç»™å‡ºä¸€æ‰¹æœ‰æ ‡ç­¾çš„ä¼ä¸šæ•°æ®ä½œä¸ºè®­ç»ƒé›†ï¼Œæ ‡ç­¾ä¸º0è¡¨ç¤ºæ­£å¸¸ä¼ä¸šï¼Œæ ‡ç­¾ä¸º1è¡¨ç¤ºåƒµå°¸ä¼ä¸šï¼›åŒæ—¶ç»™å‡ºæ— æ ‡ç­¾æ•°æ®ä½œä¸ºæµ‹è¯•é›†ï¼Œè¯·å¯¹æ— æ ‡ç­¾æ•°æ®è¿›è¡Œåˆ†ç±»ã€‚ æ•°æ®é›†è¯´æ˜ æ•°æ®é›†åŒ…æ‹¬è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸¤éƒ¨åˆ†ï¼Œæ¯ä¸ªéƒ¨åˆ†åˆåŒ…æ‹¬: 1. ä¼ä¸šåŸºæœ¬æ•°æ®: åŒ…å«ä¼ä¸šçš„ä¸€äº›åŸºæœ¬å±æ€§ä»¥åŠä¼ä¸šçš„æ ‡ç­¾ï¼ˆå³flag--0ï¼šæ­£å¸¸ä¼ä¸šï¼Œ1ï¼šåƒµå°¸ä¼ä¸šï¼‰; 2. ä¼ä¸šçŸ¥è¯†äº§æƒæ•°æ®: åŒ…å«ä¼ä¸šçš„çŸ¥è¯†äº§æƒç›¸å…³ä¿¡æ¯ï¼Œæ ¹æ®idå¯ä¸åŸºæœ¬æ•°æ®ä¸€ä¸€å¯¹åº”; 3. ä¼ä¸šé‡‘èæ•°æ®: åŒ…å«ä¼ä¸š2015~2017ä¸‰å¹´çš„é‡‘èç›¸å…³ä¿¡æ¯ï¼Œæ ¹æ®idå¯ä¸åŸºæœ¬æ•°æ®ç›¸å¯¹åº”; 4. ä¼ä¸šå¹´æŠ¥æ•°æ®: åŒ…å«ä¼ä¸š2015~2017ä¸‰å¹´çš„å¹´æŠ¥æ•°æ®ï¼Œæ ¹æ®idå¯ä¸åŸºæœ¬æ•°æ®ç›¸å¯¹åº”ã€‚ æ•°æ®é¢„å¤„ç† å·¥å…·å‡½æ•°å®šä¹‰ combined_base_knowledge_data å‡½æ•°è¯´æ˜ è¯¥å‡½æ•°ç”¨äºæ ¹æ®IDåˆå¹¶base dataå’Œknowledge dataæ•°æ®é›†ã€‚ å‡½æ•°å®ç° def combined_base_knowledge_data(base_data, knowledge_data): combined_base_knowledge_data = base_data .set_index(&#39;ID&#39;) .join(knowledge_data .set_index(&#39;ID&#39;)) combined_base_knowledge_data = combined_base_knowledge_data .fillna(combined_base_knowledge_data .median()) return combined_base_knowledge_data fill_na å‡½æ•°è¯´æ˜ è¯¥å‡½æ•°ç”¨äºå¡«å……æ•°æ®é›†ä¸­ç¼ºå¤±çš„æ•°æ®ï¼š 1. å¹´ä»½æ•°æ®ï¼šæ ¹æ®IDå’Œå¹´ä»½æŸ¥æ‰¾å‡ºå¯¹åº”IDç¼ºå¤±çš„å¹´ä»½ï¼Œç„¶åè¡¥å…¨ç¼ºå¤±çš„å¹´ä»½ï¼› 2. å…¶ä»–ç¼ºå¤±æ•°æ®ç»Ÿä¸€ç”¨ä¸­ä½æ•°è¡¥é½ã€‚ å‡½æ•°å®ç° # fill null year def fill(oragin_data, years = [2015, 2016, 2017]): # pick null year data null_years = oragin_data.loc[oragin_data.year.isna()] # fill year for year in years: IDs = oragin_data[[&quot;ID&quot;]].loc[oragin_data.year == year] for null_year_id in null_years[&quot;ID&quot;].unique(): tmp = IDs.loc[IDs.ID == null_year_id] if tmp.empty: index = oragin_data.loc[( oragin_data.ID == null_year_id) &amp; (oragin_data.year.isna() )].index.tolist() if len(index) != 0: oragin_data.loc[index[0]:index[0], &quot;year&quot;] = year # fill other missing value with median value new_data = oragin_data.fillna(oragin_data.median()) return new_data; combined_new_year_money_data å‡½æ•°è¯´æ˜ è¯¥æ–¹æ³•ç”¨äºæ ¹æ®IDå’Œyearåˆå¹¶year dataå’Œmoney dataã€‚ å‡½æ•°å®ç° def combined_new_year_money_data(new_year_data, new_money_data): return pd.merge(new_year_data, new_money_data, on=[&#39;ID&#39;, &#39;year&#39;]) split_data å‡½æ•°è¯´æ˜ è¯¥å‡½æ•°ç”¨äºæ ¹æ®IDå’Œyearæ‹†åˆ†æ–°ç‰¹å¾ï¼Œå°†åŸæ•°æ®é›†ä¸‰å¹´çš„æ•°æ®æŒ‰å¹´ä»½æ‹†åˆ†æˆæ–°çš„ç‰¹å¾ï¼Œä½¿æ‹†åˆ†åçš„æ•°æ®é›†å¯ä¸base dataæ•°æ®é›†ç”¨IDä¸€ä¸€å¯¹åº”ã€‚ä¸»è¦ç”¨äºyear dataæ•°æ®é›†å’Œmoney dataæ•°æ®é›†çš„æ‹†åˆ†ã€‚ å‡½æ•°å®ç° def split_data(combined_new_year_money_data): # split data with year combined_new_year_data_2015 = combined_new_year_money_data.loc[ combined_new_year_money_data.year == 2015] .set_index(&#39;ID&#39;) .add_suffix(&quot;_2015&quot;).drop(columns=[&#39;year_2015&#39;]) combined_new_year_data_2016 = combined_new_year_money_data.loc[ combined_new_year_money_data.year == 2016] .set_index(&#39;ID&#39;) .add_suffix(&quot;_2016&quot;).drop(columns=[&#39;year_2016&#39;]) combined_new_year_data_2017 = combined_new_year_money_data.loc[ combined_new_year_money_data.year == 2017] .set_index(&#39;ID&#39;) .add_suffix(&quot;_2017&quot;).drop(columns=[&#39;year_2017&#39;]) # marge data with ID combined_new_splited_year_money_data = pd.merge( combined_new_year_data_2015, combined_new_year_data_2016, on=[&#39;ID&#39;]) combined_new_splited_year_money_data = pd.merge( combined_new_splited_year_money_data, combined_new_year_data_2017, on=[&#39;ID&#39;]) return combined_new_splited_year_money_data è®­ç»ƒæ•°æ®é›†å¤„ç† åŠ è½½åŸå§‹æ•°æ® import pandas as pd # load training data base_train_data = pd.read_csv(&quot;data/train/base-train.csv&quot;) year_train_data = pd.read_csv(&quot;data/train/year-train.csv&quot;) knowledge_train_data = pd.read_csv(&quot;data/train/knowledge-train.csv&quot;) money_train_data = pd.read_csv(&quot;data/train/money-train.csv&quot;) æŸ¥çœ‹åŸå§‹æ•°æ®é›†ä¿¡æ¯ï¼šbase data and knowledge data base_train_data base_train_data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID æ³¨å†Œæ—¶é—´ æ³¨å†Œèµ„æœ¬ è¡Œä¸š åŒºåŸŸ ä¼ä¸šç±»å‹ æ§åˆ¶äººç±»å‹ æ§åˆ¶äººæŒè‚¡æ¯”ä¾‹ flag 0 5986361 2014.0 7090.0 æœåŠ¡ä¸š æ¹–åŒ— æœ‰é™è´£ä»»å…¬å¸ è‡ªç„¶äºº 0.93 0 1 5991749 2007.0 5940.0 é›¶å”®ä¸š æ¹–å— åˆä¼™ä¼ä¸š ä¼ä¸šæ³•äºº 0.57 0 2 5998154 2002.0 9720.0 å·¥ä¸š ç¦å»º åˆä¼™ä¼ä¸š è‡ªç„¶äºº 0.74 0 3 5984390 2000.0 4800.0 å•†ä¸šæœåŠ¡ä¸š å±±ä¸œ è‚¡ä»½æœ‰é™å…¬å¸ NaN 0.90 0 4 5980535 2004.0 4530.0 é›¶å”®ä¸š å¹¿ä¸œ å†œæ°‘ä¸“ä¸šåˆä½œç¤¾ è‡ªç„¶äºº 0.95 0 base_train_data.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID æ³¨å†Œæ—¶é—´ æ³¨å†Œèµ„æœ¬ æ§åˆ¶äººæŒè‚¡æ¯”ä¾‹ flag count 2.851900e+04 28230.000000 28220.000000 28223.000000 28519.000000 mean 4.332423e+06 2007.010627 5024.659816 0.754786 0.392721 std 2.161092e+06 4.326800 2860.157458 0.145008 0.488364 min 2.800000e+01 2000.000000 100.000000 0.510000 0.000000 25% 2.324856e+06 2003.000000 2530.000000 0.630000 0.000000 50% 5.981915e+06 2007.000000 5010.000000 0.750000 0.000000 75% 5.990992e+06 2011.000000 7490.000000 0.880000 1.000000 max 6.000000e+06 2014.000000 10000.000000 1.000000 1.000000 knowledge_train_data knowledge_train_data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID ä¸“åˆ© å•†æ ‡ è‘—ä½œæƒ 0 28 0.0 1.0 1.0 1 230 0.0 0.0 0.0 2 693 0.0 0.0 0.0 3 990 0.0 0.0 0.0 4 1274 0.0 0.0 0.0 knowledge_train_data.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID ä¸“åˆ© å•†æ ‡ è‘—ä½œæƒ count 2.851900e+04 28233.000000 28216.00000 28237.000000 mean 4.332423e+06 0.342507 0.36334 0.371428 std 2.161092e+06 0.474557 0.48097 0.483195 min 2.800000e+01 0.000000 0.00000 0.000000 25% 2.324856e+06 0.000000 0.00000 0.000000 50% 5.981915e+06 0.000000 0.00000 0.000000 75% 5.990992e+06 1.000000 1.00000 1.000000 max 6.000000e+06 1.000000 1.00000 1.000000 åˆå¹¶ base data å’Œ knowledge data combined_base_knowledge_train_data = combined_base_knowledge_data( base_train_data, knowledge_train_data ) combined_base_knowledge_train_data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } æ³¨å†Œæ—¶é—´ æ³¨å†Œèµ„æœ¬ è¡Œä¸š åŒºåŸŸ ä¼ä¸šç±»å‹ æ§åˆ¶äººç±»å‹ æ§åˆ¶äººæŒè‚¡æ¯”ä¾‹ flag ä¸“åˆ© å•†æ ‡ è‘—ä½œæƒ ID 5986361 2014.0 7090.0 æœåŠ¡ä¸š æ¹–åŒ— æœ‰é™è´£ä»»å…¬å¸ è‡ªç„¶äºº 0.93 0 0.0 0.0 0.0 5991749 2007.0 5940.0 é›¶å”®ä¸š æ¹–å— åˆä¼™ä¼ä¸š ä¼ä¸šæ³•äºº 0.57 0 1.0 1.0 0.0 5998154 2002.0 9720.0 å·¥ä¸š ç¦å»º åˆä¼™ä¼ä¸š è‡ªç„¶äºº 0.74 0 1.0 1.0 0.0 5984390 2000.0 4800.0 å•†ä¸šæœåŠ¡ä¸š å±±ä¸œ è‚¡ä»½æœ‰é™å…¬å¸ NaN 0.90 0 0.0 0.0 0.0 5980535 2004.0 4530.0 é›¶å”®ä¸š å¹¿ä¸œ å†œæ°‘ä¸“ä¸šåˆä½œç¤¾ è‡ªç„¶äºº 0.95 0 0.0 1.0 1.0 æŸ¥çœ‹ year data å’Œ money dataæ•°æ®é›†ä¿¡æ¯ year_train_data year_train_data.head(10) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID year ä»ä¸šäººæ•° èµ„äº§æ€»é¢ è´Ÿå€ºæ€»é¢ è¥ä¸šæ€»æ”¶å…¥ ä¸»è¥ä¸šåŠ¡æ”¶å…¥ åˆ©æ¶¦æ€»é¢ çº³ç¨æ€»é¢ æ‰€æœ‰è€…æƒç›Šåˆè®¡ 0 28 2015.0 794.0 16400.0 28700.0 72160.0 28864.0 7216.0 0.0 -12300.0 1 230 2015.0 485.0 23520.0 10080.0 115248.0 57624.0 57624.0 0.0 13440.0 2 693 2015.0 534.0 133760.0 125400.0 655424.0 262169.6 196627.2 0.0 8360.0 3 990 2015.0 863.0 33760.0 25320.0 145168.0 58067.2 14516.8 0.0 8440.0 4 1274 2015.0 254.0 74900.0 104325.0 277130.0 110852.0 55426.0 0.0 -29425.0 5 1560 2015.0 491.0 105000.0 98000.0 147000.0 73500.0 29400.0 0.0 7000.0 6 3261 2015.0 799.0 417000.0 822880.0 1751400.0 1401120.0 350280.0 0.0 -405880.0 7 3313 2015.0 784.0 501600.0 986480.0 2156880.0 1294128.0 431376.0 0.0 -484880.0 8 3537 2015.0 647.0 17800.0 13350.0 8900.0 4450.0 2670.0 0.0 4450.0 9 3719 2015.0 369.0 317000.0 465990.0 380400.0 228240.0 152160.0 0.0 -148990.0 year_train_data.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID year ä»ä¸šäººæ•° ... åˆ©æ¶¦æ€»é¢ çº³ç¨æ€»é¢ æ‰€æœ‰è€…æƒç›Šåˆè®¡ count 8.554800e+04 84692.000000 84743.000000 ... 8.469900e+04 8.473100e+04 84673.000000 mean 4.332626e+06 2015.999870 510.808421 ... 1.027939e+05 7.079659e+04 -27390.880033 std 2.160933e+06 0.816398 283.129690 ... 1.536672e+05 1.588261e+05 108355.730296 min 2.800000e+01 2015.000000 20.000000 ... 7.800000e+00 0.000000e+00 -828340.000000 25% 2.325192e+06 2015.000000 266.000000 ... 1.396755e+04 0.000000e+00 -53130.000000 50% 5.981916e+06 2016.000000 512.000000 ... 4.514400e+04 1.240200e+03 250.000000 75% 5.990992e+06 2017.000000 756.000000 ... 1.238400e+05 6.668040e+04 8900.000000 max 5.999999e+06 2017.000000 1000.000000 ... 1.807398e+06 2.089620e+06 429570.000000 year_train_data money_train_data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID year å€ºæƒèèµ„é¢åº¦ å€ºæƒèèµ„æˆæœ¬ è‚¡æƒèèµ„é¢åº¦ è‚¡æƒèèµ„æˆæœ¬ å†…éƒ¨èèµ„å’Œè´¸æ˜“èèµ„é¢åº¦ å†…éƒ¨èèµ„å’Œè´¸æ˜“èèµ„æˆæœ¬ é¡¹ç›®èèµ„å’Œæ”¿ç­–èèµ„é¢åº¦ é¡¹ç›®èèµ„å’Œæ”¿ç­–èèµ„æˆæœ¬ 0 28 2015.0 0.0 0.0 0.0 0.000 21648.0 1298.88 0.0 0.000 1 230 2015.0 0.0 0.0 0.0 0.000 0.0 0.00 470.4 28.224 2 693 2015.0 0.0 0.0 0.0 0.000 0.0 0.00 5350.4 321.024 3 990 NaN 0.0 0.0 0.0 0.000 0.0 0.00 675.2 40.512 4 1274 2015.0 0.0 0.0 11085.2 443.408 0.0 0.00 NaN 0.000 money_train_data.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID year å€ºæƒèèµ„é¢åº¦ ... å†…éƒ¨èèµ„å’Œè´¸æ˜“èèµ„æˆæœ¬ é¡¹ç›®èèµ„å’Œæ”¿ç­–èèµ„é¢åº¦ é¡¹ç›®èèµ„å’Œæ”¿ç­–èèµ„æˆæœ¬ count 8.554800e+04 84703.000000 84739.000000 ... 84720.000000 84686.000000 84695.000000 mean 4.332626e+06 2016.000378 3353.349261 ... 1555.894230 1020.851124 61.231978 std 2.160933e+06 0.816496 8883.814614 ... 4811.138407 3000.062130 179.871750 min 2.800000e+01 2015.000000 0.000000 ... 0.000000 0.000000 0.000000 25% 2.325192e+06 2015.000000 0.000000 ... 0.000000 0.000000 0.000000 50% 5.981916e+06 2016.000000 0.000000 ... 0.000000 0.000000 0.000000 75% 5.990992e+06 2017.000000 0.000000 ... 10.719000 41.000000 2.520000 max 5.999999e+06 2017.000000 84830.000000 ... 72925.920000 39720.000000 2383.200000 å¡«å……ç¼ºå¤±æ•°æ® year_train_data # fill null new_year_train_data = fill_na(year_train_data) new_year_train_data.set_index([&#39;ID&#39;, &#39;year&#39;]) new_year_train_data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID year ä»ä¸šäººæ•° èµ„äº§æ€»é¢ è´Ÿå€ºæ€»é¢ è¥ä¸šæ€»æ”¶å…¥ ä¸»è¥ä¸šåŠ¡æ”¶å…¥ åˆ©æ¶¦æ€»é¢ çº³ç¨æ€»é¢ æ‰€æœ‰è€…æƒç›Šåˆè®¡ 0 28 2015.0 794.0 16400.0 28700.0 72160.0 28864.0 7216.0 0.0 -12300.0 1 230 2015.0 485.0 23520.0 10080.0 115248.0 57624.0 57624.0 0.0 13440.0 2 693 2015.0 534.0 133760.0 125400.0 655424.0 262169.6 196627.2 0.0 8360.0 3 990 2015.0 863.0 33760.0 25320.0 145168.0 58067.2 14516.8 0.0 8440.0 4 1274 2015.0 254.0 74900.0 104325.0 277130.0 110852.0 55426.0 0.0 -29425.0 money_train_data # fill null new_money_train_data = fill_na(money_train_data) new_money_train_data.set_index([&#39;ID&#39;, &#39;year&#39;]) # new_money_train_data.head(8) new_money_train_data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID year å€ºæƒèèµ„é¢åº¦ å€ºæƒèèµ„æˆæœ¬ è‚¡æƒèèµ„é¢åº¦ è‚¡æƒèèµ„æˆæœ¬ å†…éƒ¨èèµ„å’Œè´¸æ˜“èèµ„é¢åº¦ å†…éƒ¨èèµ„å’Œè´¸æ˜“èèµ„æˆæœ¬ é¡¹ç›®èèµ„å’Œæ”¿ç­–èèµ„é¢åº¦ é¡¹ç›®èèµ„å’Œæ”¿ç­–èèµ„æˆæœ¬ 0 28 2015.0 0.0 0.0 0.0 0.000 21648.0 1298.88 0.0 0.000 1 230 2015.0 0.0 0.0 0.0 0.000 0.0 0.00 470.4 28.224 2 693 2015.0 0.0 0.0 0.0 0.000 0.0 0.00 5350.4 321.024 3 990 2015.0 0.0 0.0 0.0 0.000 0.0 0.00 675.2 40.512 4 1274 2015.0 0.0 0.0 11085.2 443.408 0.0 0.00 0.0 0.000 åˆå¹¶year dataå’Œmoney dataæ•°æ®é›† # Merge new year and money data combined_new_year_money_train_data = combined_new_year_money_data( new_year_train_data, new_money_train_data ) combined_new_year_money_train_data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID year ä»ä¸šäººæ•° èµ„äº§æ€»é¢ ... å†…éƒ¨èèµ„å’Œè´¸æ˜“èèµ„é¢åº¦ å†…éƒ¨èèµ„å’Œè´¸æ˜“èèµ„æˆæœ¬ é¡¹ç›®èèµ„å’Œæ”¿ç­–èèµ„é¢åº¦ é¡¹ç›®èèµ„å’Œæ”¿ç­–èèµ„æˆæœ¬ 0 28 2015.0 794.0 16400.0 ... 21648.0 1298.88 0.0 0.000 1 230 2015.0 485.0 23520.0 ... 0.0 0.00 470.4 28.224 2 693 2015.0 534.0 133760.0 ... 0.0 0.00 5350.4 321.024 3 990 2015.0 863.0 33760.0 ... 0.0 0.00 675.2 40.512 4 1274 2015.0 254.0 74900.0 ... 0.0 0.00 0.0 0.000 æ‹†åˆ†æ–°ç‰¹å¾ å°†åˆå¹¶åçš„æ•°æ®é›†ä¸­æ¯ä¸€å¹´çš„æ•°æ®æ‹†åˆ†æˆæ–°çš„ç‰¹å¾ï¼Œä½¿ä¹‹ä¸base dataé€šè¿‡IDä¸€ä¸€å¯¹åº”ã€‚ splited_year_money_train_data = split_data(combined_new_year_money_train_data) splited_year_money_train_data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ä»ä¸šäººæ•°_2015 èµ„äº§æ€»é¢_2015 è´Ÿå€ºæ€»é¢_2015 ... å†…éƒ¨èèµ„å’Œè´¸æ˜“èèµ„é¢åº¦_2017 å†…éƒ¨èèµ„å’Œè´¸æ˜“èèµ„æˆæœ¬_2017 é¡¹ç›®èèµ„å’Œæ”¿ç­–èèµ„é¢åº¦_2017 é¡¹ç›®èèµ„å’Œæ”¿ç­–èèµ„æˆæœ¬_2017 ID 28 794.0 16400.0 28700.0 ... 0.0 0.000 0.0 0.0 230 485.0 23520.0 10080.0 ... 0.0 0.000 0.0 0.0 693 534.0 133760.0 125400.0 ... 0.0 0.000 0.0 0.0 990 863.0 33760.0 25320.0 ... 111661.2 6699.672 0.0 0.0 1274 254.0 74900.0 104325.0 ... 0.0 0.000 0.0 0.0 5 rows Ã— 48 columns åˆå¹¶å¤„ç†å¥½çš„æ•°æ®é›† train = pd.merge(combined_base_knowledge_train_data, splited_year_money_train_data, on=[&#39;ID&#39;]) train.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } æ³¨å†Œæ—¶é—´ æ³¨å†Œèµ„æœ¬ è¡Œä¸š ... å†…éƒ¨èèµ„å’Œè´¸æ˜“èèµ„é¢åº¦_2017 å†…éƒ¨èèµ„å’Œè´¸æ˜“èèµ„æˆæœ¬_2017 é¡¹ç›®èèµ„å’Œæ”¿ç­–èèµ„é¢åº¦_2017 é¡¹ç›®èèµ„å’Œæ”¿ç­–èèµ„æˆæœ¬_2017 ID 5986361 2014.0 7090.0 æœåŠ¡ä¸š ... 0.0 0.0 0.0 0.0 5991749 2007.0 5940.0 é›¶å”®ä¸š ... 80190.0 4811.4 0.0 0.0 5998154 2002.0 9720.0 å·¥ä¸š ... 0.0 0.0 0.0 0.0 5984390 2000.0 4800.0 å•†ä¸šæœåŠ¡ä¸š ... 48960.0 2937.6 0.0 0.0 5980535 2004.0 4530.0 é›¶å”®ä¸š ... 0.0 0.0 0.0 0.0 5 rows Ã— 59 columns ä¿å­˜å¤„ç†å¥½çš„è®­ç»ƒæ•°æ®é›† train.to_csv(&quot;data/train/train.csv&quot;) train.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } æ³¨å†Œæ—¶é—´ æ³¨å†Œèµ„æœ¬ æ§åˆ¶äººæŒè‚¡æ¯”ä¾‹ ... å†…éƒ¨èèµ„å’Œè´¸æ˜“èèµ„é¢åº¦_2017 å†…éƒ¨èèµ„å’Œè´¸æ˜“èèµ„æˆæœ¬_2017 é¡¹ç›®èèµ„å’Œæ”¿ç­–èèµ„é¢åº¦_2017 é¡¹ç›®èèµ„å’Œæ”¿ç­–èèµ„æˆæœ¬_2017 count 28516.000000 28516.000000 28516.000000 ... 2.851600e+04 28516.000000 28516.000000 28516.000000 mean 2007.010836 5024.064385 0.754743 ... 2.850957e+04 1712.928322 1115.153493 67.013075 std 4.304831 2844.938780 0.144249 ... 8.651585e+04 5202.890113 3229.079861 193.992216 min 2000.000000 100.000000 0.510000 ... 0.000000e+00 0.000000 0.000000 0.000000 25% 2003.000000 2560.000000 0.630000 ... 0.000000e+00 0.000000 0.000000 0.000000 50% 2007.000000 5010.000000 0.750000 ... 0.000000e+00 0.000000 0.000000 0.000000 75% 2011.000000 7470.000000 0.880000 ... 0.000000e+00 0.000000 0.000000 0.000000 max 2014.000000 10000.000000 1.000000 ... 1.215432e+06 72925.920000 38930.000000 2335.800000 8 rows Ã— 55 columns è®­ç»ƒæ•°æ®é›†å¤„ç† æŒ‰ç…§åˆšåˆšå¤„ç†è®­ç»ƒé›†çš„æµç¨‹å¤„ç†æµ‹è¯•æ•°æ®é›†ã€‚ ### åŠ è½½åŸå§‹æ•°æ®é›† # load testing data base_test_data = pd.read_csv(&quot;data/test/base-test.csv&quot;) year_test_data = pd.read_csv(&quot;data/test/year-test.csv&quot;) knowledge_test_data = pd.read_csv(&quot;data/test/knowledge-test.csv&quot;) money_test_data = pd.read_csv(&quot;data/test/money-test.csv&quot;) åˆå¹¶ base data å’Œ knowledge data combined_base_knowledge_test_data = combined_base_knowledge_data( base_test_data, knowledge_test_data ) combined_base_knowledge_test_data.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } æ³¨å†Œæ—¶é—´ æ³¨å†Œèµ„æœ¬ æ§åˆ¶äººæŒè‚¡æ¯”ä¾‹ ä¸“åˆ© å•†æ ‡ è‘—ä½œæƒ count 7132.000000 7132.000000 7132.000000 7132.000000 7132.000000 7132.000000 mean 2007.077257 5039.914470 0.754799 0.342821 0.358385 0.373528 std 4.321929 2839.476208 0.143953 0.474686 0.479560 0.483774 min 2000.000000 100.000000 0.510000 0.000000 0.000000 0.000000 25% 2003.000000 2640.000000 0.630000 0.000000 0.000000 0.000000 50% 2007.000000 5040.000000 0.750000 0.000000 0.000000 0.000000 75% 2011.000000 7450.000000 0.880000 1.000000 1.000000 1.000000 max 2014.000000 10000.000000 1.000000 1.000000 1.000000 1.000000 year data and money data å¡«å……ç¼ºå¤±å€¼å¹¶éªŒè¯å¡«å……ç»“æœ year_test_data # fill null new_year_test_data = fill_na(year_test_data) new_year_test_data.set_index([&#39;ID&#39;, &#39;year&#39;]) new_year_test_data.describe() print(&quot;unique ID count in base data:&quot;, base_test_data[&quot;ID&quot;] .nunique()) print(&quot;2015 unique ID count in year data:&quot;, new_year_test_data[&quot;ID&quot;] .loc[new_year_test_data.year==2015] .nunique()) print(&quot;2016 unique ID count in year data:&quot;, new_year_test_data[&quot;ID&quot;] .loc[new_year_test_data.year==2016] .nunique()) print(&quot;2017 unique ID count in year data:&quot;, new_year_test_data[&quot;ID&quot;] .loc[new_year_test_data.year==2017] .nunique()) unique ID count in base data: 7132 2015 unique ID count in year data: 7132 2016 unique ID count in year data: 7132 2017 unique ID count in year data: 7132 money_test_data # fill null new_money_test_data = fill_na(money_test_data) new_money_test_data.set_index([&#39;ID&#39;, &#39;year&#39;]) # new_money_train_data.head(8) new_money_test_data.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID year å€ºæƒèèµ„é¢åº¦ ... å†…éƒ¨èèµ„å’Œè´¸æ˜“èèµ„é¢åº¦ å†…éƒ¨èèµ„å’Œè´¸æ˜“èèµ„æˆæœ¬ é¡¹ç›®èèµ„å’Œæ”¿ç­–èèµ„é¢åº¦ é¡¹ç›®èèµ„å’Œæ”¿ç­–èèµ„æˆæœ¬ count 2.139600e+04 21396.000000 21396.000000 ... 2.139600e+04 21396.000000 21396.000000 21396.000000 mean 4.332655e+06 2016.000000 3209.631146 ... 2.677436e+04 1598.629057 1025.091606 61.698997 std 2.163020e+06 0.816516 8711.231069 ... 8.272665e+04 4950.288392 3050.157292 183.387577 min 4.290000e+02 2015.000000 0.000000 ... 0.000000e+00 0.000000 0.000000 0.000000 25% 2.331607e+06 2015.000000 0.000000 ... 0.000000e+00 0.000000 0.000000 0.000000 50% 5.981952e+06 2016.000000 0.000000 ... 0.000000e+00 0.000000 0.000000 0.000000 75% 5.990780e+06 2017.000000 0.000000 ... 2.565000e+02 0.850500 0.000000 0.000000 max 5.999998e+06 2017.000000 ... 1.257150e+06 75429.000000 40970.000000 2458.200000 print(&quot;unique ID count in base data:&quot;, base_test_data[&quot;ID&quot;].nunique()) print(&quot;2015 unique ID count in money data:&quot;, new_money_test_data[&quot;ID&quot;] .loc[new_money_test_data.year==2015] .nunique()) print(&quot;2016 unique ID count in money data:&quot;, new_money_test_data[&quot;ID&quot;] .loc[new_money_test_data.year==2016] .nunique()) print(&quot;2017 unique ID count in money data:&quot;, new_money_test_data[&quot;ID&quot;] .loc[new_money_test_data.year==2017] .nunique()) unique ID count in base data: 7132 2015 unique ID count in money data: 7132 2016 unique ID count in money data: 7132 2017 unique ID count in money data: 7132 åˆå¹¶ year data å’Œ money data combined_new_year_money_test_data = combined_new_year_money_data( new_year_test_data, new_money_test_data ) combined_new_year_money_test_data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ID year ä»ä¸šäººæ•° ... å†…éƒ¨èèµ„å’Œè´¸æ˜“èèµ„é¢åº¦ å†…éƒ¨èèµ„å’Œè´¸æ˜“èèµ„æˆæœ¬ é¡¹ç›®èèµ„å’Œæ”¿ç­–èèµ„é¢åº¦ é¡¹ç›®èèµ„å’Œæ”¿ç­–èèµ„æˆæœ¬ 0 429 2015.0 136.0 ... 0.0 0.000 0.0 0.00 1 727 2015.0 375.0 ... 0.0 0.000 0.0 0.00 2 1137 2015.0 289.0 ... 24460.8 1467.648 0.0 0.00 3 1873 2015.0 889.0 ... 0.0 0.000 0.0 0.00 4 2260 2015.0 689.0 ... 0.0 0.000 11287.5 677.25 print(&quot;unique ID count in combined data:&quot;, combined_new_year_money_test_data[&quot;ID&quot;].nunique()) unique ID count in combined data: 7132 æ‹†åˆ†æ–°ç‰¹å¾ splited_year_money_test_data = split_data(combined_new_year_money_test_data) splited_year_money_test_data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ä»ä¸šäººæ•°_2015 èµ„äº§æ€»é¢_2015 è´Ÿå€ºæ€»é¢_2015 ... å†…éƒ¨èèµ„å’Œè´¸æ˜“èèµ„é¢åº¦_2017 å†…éƒ¨èèµ„å’Œè´¸æ˜“èèµ„æˆæœ¬_2017 é¡¹ç›®èèµ„å’Œæ”¿ç­–èèµ„é¢åº¦_2017 é¡¹ç›®èèµ„å’Œæ”¿ç­–èèµ„æˆæœ¬_2017 ID 429 136.0 193400.0 183730.0 ... 0.0 0.000 0.0 0.00 727 375.0 366240.0 536280.0 ... 0.0 0.000 0.0 0.00 1137 289.0 87200.0 40320.0 ... 0.0 0.000 1008.0 60.48 1873 889.0 229320.0 222950.0 ... 12612.6 756.756 0.0 0.00 2260 689.0 225750.0 325080.0 ... 0.0 0.000 0.0 0.00 5 rows Ã— 48 columns åˆå¹¶å¤„ç†å¥½çš„æ•°æ®é›† æ ¹æ®IDåˆå¹¶å¤„ç†å¥½çš„æ•°æ®é›†ã€‚ test = pd.merge(combined_base_knowledge_test_data, splited_year_money_test_data, on=[&#39;ID&#39;]) test.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } æ³¨å†Œæ—¶é—´ æ³¨å†Œèµ„æœ¬ è¡Œä¸š ... å†…éƒ¨èèµ„å’Œè´¸æ˜“èèµ„é¢åº¦_2017 å†…éƒ¨èèµ„å’Œè´¸æ˜“èèµ„æˆæœ¬_2017 é¡¹ç›®èèµ„å’Œæ”¿ç­–èèµ„é¢åº¦_2017 é¡¹ç›®èèµ„å’Œæ”¿ç­–èèµ„æˆæœ¬_2017 ID 5991927 2010.0 8790.0 å·¥ä¸š ... 341491.5 20489.49 0.0 0.000 5998351 2005.0 270.0 æœåŠ¡ä¸š ... 0.0 0.00 194.4 11.664 5992703 2012.0 230.0 æœåŠ¡ä¸š ... 0.0 0.00 0.0 0.000 5979231 2003.0 5980.0 å•†ä¸šæœåŠ¡ä¸š ... 75348.0 4520.88 0.0 0.000 5995422 2007.0 160.0 å·¥ä¸š ... 8856.0 531.36 0.0 0.000 5 rows Ã— 58 columns ä¿å­˜å¤„ç†å¥½çš„æµ‹è¯•æ•°æ®é›† test.to_csv(&quot;data/test/test.csv&quot;) æ€»ç»“ è¿™æ¬¡æ•°æ®å¤„ç†æ¯”è¾ƒç®€å•ï¼Œä¸»è¦æ³¨æ„ä»¥ä¸‹å‡ ä¸ªç‚¹ï¼š 1. å¯¹äºå¹´ä»½æ•°æ®ç¼ºå¤±å€¼çš„å¤„ç†ï¼Œå¯ä»¥æ ¹æ®IDå’Œå¹´ä»½åˆ¤æ–­ç¼ºå¤±çš„å¹´ä»½åº”è¯¥æ˜¯å“ªä¸€å¹´ï¼Œç„¶åå¡«å……ç›¸åº”çš„å¹´ä»½å€¼å³å¯ï¼Œå¦‚æœæ˜¯åŒä¸€IDç¼ºå¤±ä¸¤å¹´æ•°æ®ï¼Œè¿™ä¸ªå°±éšç¼˜äº†ğŸ˜†ï¼Œæˆ‘æ˜¯æŒ‰ç…§ä»ä¸Šåˆ°ä¸‹çš„é¡ºåºå¡«å……çš„ï¼ˆå¯èƒ½æœ‰æ›´å¥½çš„æ–¹æ³•ï¼Œå¤§å®¶å¯ä»¥æå‡ºè‡ªå·±çš„æƒ³æ³•ï¼‰ï¼Œä¾‹å¦‚IDä¸º123çš„ä¼ä¸šç¼ºå¤±2015å’Œ2017çš„å¹´ä»½ï¼Œé‚£ä¹ˆä¾æ¬¡å°†yearå±æ€§å€¼å¡«å……ä¸º2015å’Œ2017ï¼› 2. å¯¹äºå…¶ä»–æ•°æ®æˆ‘å°±ç›´æ¥ç²—æš´çš„å¡«å……ä¸­ä½æ•°ï¼Œæœ¬æ¥æ˜¯æƒ³å…ˆè¿™ä¹ˆå¡«å……ç„¶åçœ‹çœ‹æ•ˆæœå†ä¼˜åŒ–ï¼Œç»“æœè®­ç»ƒæµ‹è¯•åçš„ç»“æœè¿˜ä¸é”™ï¼Œæ‰€ä»¥ä¹Ÿå°±æ²¡æœ‰å†ä¼˜åŒ–äº†ï¼› ä¸‹ç¯‡æ–‡ç« ä¸­æˆ‘ä¼šå¯¹æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä½œä¸€ä¸ªè¯´æ˜ï¼Œä½¿ç”¨çš„æ˜¯LightGBMæ¡†æ¶ï¼ˆLightGBMæ˜¯ä½¿ç”¨åŸºäºæ ‘çš„å­¦ä¹ ç®—æ³•çš„æ¢¯åº¦å¢å¼ºæ¡†æ¶ï¼‰ã€‚","categories":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Machine Learning","slug":"Technology/Machine-Learning","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/"},{"name":"Data pre-processing","slug":"Technology/Machine-Learning/Data-pre-processing","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/Data-pre-processing/"}],"tags":[{"name":"Data pre-processing","slug":"Data-pre-processing","permalink":"https://littlelittlemoon.github.io/tags/Data-pre-processing/"},{"name":"Categorical Data","slug":"Categorical-Data","permalink":"https://littlelittlemoon.github.io/tags/Categorical-Data/"},{"name":"Missing value","slug":"Missing-value","permalink":"https://littlelittlemoon.github.io/tags/Missing-value/"}],"keywords":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Machine Learning","slug":"Technology/Machine-Learning","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/"},{"name":"Data pre-processing","slug":"Technology/Machine-Learning/Data-pre-processing","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/Data-pre-processing/"}]},{"title":"Leetcode Note in Apri 2020 | part 2 |day 08-14","slug":"Technology/Leetcode-Note-in-Apri-2020-part-2-day-08-14","date":"2020-04-08T05:54:16.000Z","updated":"2020-04-16T08:15:49.574Z","comments":true,"path":"2020/04/08/Technology/Leetcode-Note-in-Apri-2020-part-2-day-08-14/","link":"","permalink":"https://littlelittlemoon.github.io/2020/04/08/Technology/Leetcode-Note-in-Apri-2020-part-2-day-08-14/","excerpt":"","text":"å†™åœ¨å‰é¢çš„è¯ ç¬¬äºŒæ¬¡æ›´æ–°ï¼Œç»§ç»­å‰è¿›~ Backspace String Compare Given two strings S and T, return if they are equal when both are typed into empty text editors. # means a backspace character. Examples: Input: S = \"ab#c\", T = \"ad#c\" Output: true Explanation: Both S and T become \"ac\". Input: S = \"ab##\", T = \"c#d#\" Output: true Explanation: Both S and T become \"\". Input: S = \"a##c\", T = \"#a#c\" Output: true Explanation: Both S and T become \"c\". Input: S = \"a#c\", T = \"b\" Output: false Explanation: S becomes \"c\" while T becomes \"b\". Solution è¿™ä¸ªé¢˜å¯¹äºæˆ‘æ¥è¯´æœ‰ç‚¹éš¾åº¦ï¼Œæ˜¨å¤©(9å·)æ™šä¸Šåšäº†ä¸¤ä¸ªå°æ—¶å§ï¼Œé‡ç‚¹æ˜¯é€šä¸è¿‡æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹ï¼Œæ€»æ˜¯æœ‰ä¸€äº›ç»†èŠ‚æ²¡æœ‰è€ƒè™‘åˆ°ï¼Œè€Œä¸”ä»£ç è¶Šå†™è¶Šå¤æ‚ï¼ŒåŠ ä¸Šæ˜¨å¤©ä¸­åˆæ²¡ç¡åˆè§‰ï¼Œåˆ°æœ€åè‡ªå·±æŠŠè‡ªå·±éƒ½ææ‡µäº†ï¼Œæ°”ğŸ˜ ã€‚åé¢ç¡è§‰çš„æ—¶å€™å‘ç°è‡ªå·±è„‘å­çœŸçš„æ˜¯ä¸€æ ¹ç­‹ï¼Œæ¢ä¸ªæ€è·¯è¿™é¢˜ä¼šç®€å•å¾ˆå¤šã€‚å…ˆçœ‹çœ‹ä»£ç å§ã€‚ Mine æ ¸å¿ƒæ€è·¯ï¼šä»åå¾€å‰æ‰¾å¯èƒ½ç•™ä¸‹æ¥çš„å­—ç¬¦ï¼Œå¹¶ä¸€ä¸€æ¯”å¯¹ä¸¤ä¸ªå­—ç¬¦ä¸²å¯¹åº”ä½ç½®èƒ½ç•™ä¸‹æ¥çš„çš„å­—ç¬¦æ˜¯å¦ç›¸ç­‰ã€‚æ³¨æ„å¾ªç¯åˆ¤æ–­æ¡ä»¶çš„è®¾ç½®ï¼ class Solution: def backspaceCompare(self, S: str, T: str) -&gt; bool: s_i = len(S) - 1 t_i = len(T) - 1 s_back = t_back = 0 while True: # Loop will be stoped when any of the following situations occur: # 1. s_i completed the last character access # 2. S[s_i] is a letter (S[s_i] != &#39;#&#39;) and don&#39;t need to go back # currently (s_back = 0) # Same as T, t_i and t_back while s_i &gt;= 0: if S[s_i] == &#39;#&#39;: s_i, s_back = s_i - 1, s_back + 1 elif S[s_i] != &#39;#&#39; and s_back &gt; 0: s_i, s_back = s_i - 1, s_back - 1 else: break while t_i &gt;= 0: if T[t_i] == &#39;#&#39;: t_i, t_back = t_i - 1, t_back + 1 elif T[t_i] != &#39;#&#39; and t_back &gt; 0: t_i, t_back = t_i - 1, t_back - 1 else: break # There are only two situations will return True: # 1. both s_i and t_i are not out of index and S[s_i] = T[t_i] # 2. both s_i and t_i are out of index, it means no letter needs # to be compared and previous corresponding letters are equal. # otherwise, it will return false in situation 1 if s_i &gt;= 0 and t_i &gt;= 0: if S[s_i] != T[t_i]: return False s_i, t_i = s_i - 1, t_i - 1 else: return s_i &lt; 0 and t_i &lt; 0 å…¶å®è¿˜æ˜¯è›®å¤æ‚çš„ï¼Œå¯èƒ½æœ‰æ›´å¥½çš„è§£å†³æ–¹æ³•ï¼Œå¸Œæœ›å°ä¼™ä¼´ä»¬ç»™å‡ºä½ ä»¬çš„æ€è·¯å’Œå»ºè®®ã€‚æˆ‘åˆšå¼€å§‹çš„æ€è·¯æ˜¯ä»å‰å¾€åå»æ‰¾å¯èƒ½ç•™ä¸‹çš„å­—æ¯ï¼Œä½†æ˜¯è¿™ä¸ªå˜åŒ–å¤ªå¤§äº†ï¼Œè€Œä¸”åˆ¤æ–­æ¡ä»¶ç‰¹åˆ«å¤šï¼Œæ€»æ˜¯æœ‰å¾ˆå¤šæƒ…å†µè€ƒè™‘ä¸åˆ°ï¼Œæ•´äº†ä¸€æ™šä¸Šä¹Ÿæ²¡æ•´å‡ºæ¥ã€‚åé¢ç¡è§‰çš„æ—¶å€™çªç„¶æƒ³èµ·æˆ‘ä¸ºå•¥ä¸ä»åå¾€å‰æ‰¾å‘¢ï¼ŸğŸ¤£å…·ä½“è§£æ³•éƒ½åœ¨æ³¨é‡Šé‡Œï¼Œemmmmï¼Œå¯èƒ½è¿˜æœ‰è¯­æ³•é”™è¯¯ï¼Œå‹¿ä»‹ğŸ˜Šã€‚ Min Stack Design a stack that supports push, pop, top, and retrieving the minimum element in constant time. push(x) -- Push element x onto stack. pop() -- Removes the element on top of the stack. top() -- Get the top element. getMin() -- Retrieve the minimum element in the stack. Example: MinStack minStack = new MinStack(); minStack.push(-2); minStack.push(0); minStack.push(-3); minStack.getMin(); --&gt; Returns -3. minStack.pop(); minStack.top(); --&gt; Returns 0. minStack.getMin(); --&gt; Returns -2. Solution è¿™ä¸ªé¢˜ä¸éš¾ï¼Œå¹¶ä¸”æœ‰å¾ˆå¤šä¸­å®ç°æ–¹å¼ã€‚æˆ‘ä»¬éœ€è¦å®ç°çš„è¿™ä¸ªæ ˆæ˜¯åœ¨ä¼ ç»Ÿçš„æ ˆå·²æœ‰çš„åŠŸèƒ½ä¸Šå¢åŠ äº†è¿”å›æœ€å°å€¼çš„åŠŸèƒ½ï¼Œè¿™å°±æ¶‰åŠåˆ°æ€ä¹ˆå­˜å‚¨æœ€å°å€¼çš„é—®é¢˜ï¼Œè¿™é‡Œæœ‰ä¸‰ä¸ªæ€è·¯ï¼Œå¤§å®¶æœ‰æ›´å¥½çš„æ€è·¯ä¹Ÿå¯ä»¥åœ¨è¯„è®ºåŒºç»™å‡ºï¼š æ—¶é—´æ¢ç©ºé—´ åªè®¾è®¡ä¸€ä¸ªæ ˆï¼Œè¿”å›æœ€å°å€¼æ—¶é€šè¿‡æ’åºæ–¹å¼è¿”å›ã€‚ class MinStack: def __init__(self): &quot;&quot;&quot; initialize your data structure here. &quot;&quot;&quot; self.stack = [] def push(self, x: int) -&gt; None: self.stack.append(x) def pop(self) -&gt; None: self.stack.pop() def top(self) -&gt; int: if len(self.stack) &lt; 0: return None return self.stack[len(self.stack)-1] def getMin(self) -&gt; int: if len(self.stack) &lt; 0: return None s_sorted = sorted(self.stack) return s_sorted[0] æ›´èŠ‚çœæ—¶é—´å’Œç©ºé—´çš„æ–¹å¼(æ›´å·§å¦™) è®¾è®¡ä¸€ä¸ªæ ˆï¼Œä¸€ä¸ªminå˜é‡ï¼Œä½†æ˜¯æ ˆé‡Œé¢åªå­˜æ”¾æ¯ä¸ªå…ƒç´ ä¸æœ€å°å€¼çš„å·®å€¼ï¼ˆx-minï¼‰ï¼Œå½“å‡ºç°æ›´å°çš„æœ€å°å€¼æ—¶ï¼Œä¿å­˜çš„æ˜¯è´Ÿæ•°ï¼Œæ•…è¯¾é€šè¿‡è¿™ä¸ªæ¡ä»¶è¿½æº¯ä¹‹å‰çš„æœ€å°å€¼ï¼Œå…·ä½“å®ç°è§ä¸‹é¢çš„ä»£ç ã€‚ class MinStack: def __init__(self): &quot;&quot;&quot; initialize your data structure here. &quot;&quot;&quot; self.stack = [] self.s_min = None def push(self, x: int) -&gt; None: if self.s_min == None: self.s_min = x self.stack.append(x-self.s_min) self.s_min = min(self.s_min, x) def pop(self) -&gt; None: pop = self.stack.pop() if len(self.stack) &gt; 0: if pop &lt; 0: self.s_min = self.s_min - pop else: self.s_min = None def top(self) -&gt; int: if len(self.stack) &lt; 0: return None top = self.stack[len(self.stack)-1] if top &lt; 0: return self.s_min return top + self.s_min def getMin(self) -&gt; int: return self.s_min ç©ºé—´æ¢æ—¶é—´ è®¾è®¡ä¸¤ä¸ªæ ˆï¼Œå¤šå‡ºæ¥çš„é‚£ä¸ªæ ˆç”¨æ¥è®°å½•å‡ºç°è¿‡çš„æœ€å°å€¼ï¼Œæˆ‘è¿™é‡Œæ²¡æœ‰å»å®ç°äº†ï¼Œå¤§å®¶å¯ä»¥è¯•è¯•ã€‚ Diameter of Binary Tree Given a binary tree, you need to compute the length of the diameter of the tree. The diameter of a binary tree is the length of the longest path between any two nodes in a tree. This path may or may not pass through the root. Example: Given a binary tree Return 3, which is the length of the path [4,2,1,3] or [5,2,1,3]. Note: The length of path between two nodes is represented by the number of edges between them. Solution æ ¸å¿ƒæ€è·¯ï¼šæ ¹æ®åŠå¾„çš„å®šä¹‰å¯çŸ¥ï¼ŒåŠå¾„æ‰€åœ¨çš„è·¯å¾„ä¸€å®šæœ‰ä¸€ä¸ªä¸­å¿ƒèŠ‚ç‚¹ï¼Œæ•…å¯é€šè¿‡åˆ¤æ–­äºŒå‰æ ‘æ¯ä¸ªèŠ‚ç‚¹ï¼ˆå½“å‰å¯èƒ½çš„ä¸­å¿ƒç‚¹ï¼‰å·¦å³å­æ ‘çš„æ·±åº¦å’Œçš„å¤§å°æ¥ç¡®å®šåŠå¾„ã€‚ # Definition for a binary tree node. class TreeNode: def __init__(self, x): self.val = x self.left = None self.right = None class Solution: def diameterOfBinaryTree(self, root: TreeNode) -&gt; int: self.diameter = 0 def count_depth(node): if not(node): return 0 l_dep, r_dep = count_depth(node.left), count_depth(node.right) self.diameter = max(self.diameter, l_dep+r_dep) # max depth: max(left depth, right depth) # +1: count node return 1 + max(l_dep, r_dep) count_depth(root) return self.diameter è¿™é¢˜åˆšå¼€å§‹æˆ‘æ˜¯æ²¡æœ‰ä»€ä¹ˆå¥½çš„æ€è·¯çš„ï¼Œå¤ªä¹…æ²¡åšå…³äºäºŒå‰æ ‘çš„é¢˜äº†ï¼Œä¸å¯¹ï¼Œå‡†ç¡®æ¥è®²åº”è¯¥æ˜¯è¯¾åå°±ä¸¢äº†ï¼Œå“ˆå“ˆå“ˆï¼Œåæ¥å»æŸ¥äº†ä¸‹äºŒå‰æ ‘çš„ç›¸å…³èµ„æ–™ï¼Œçœ‹åˆ°æ±‚äºŒå‰æ ‘çš„æ·±åº¦é—®é¢˜ç»™äº†æˆ‘çµæ„Ÿã€‚å¸Œæœ›èƒ½æŠŠä»¥å‰ä¸¢æ‰çš„çŸ¥è¯†ç‚¹æ…¢æ…¢æ¡èµ·æ¥ï¼Œå°±æ‹¿è¿™ä¸ªæ ‘ç›¸å…³çš„çŸ¥è¯†ç‚¹æ¥è¯´ï¼Œå…¶å®å¾ˆå¤šç®—æ³•åº•å±‚åŸç†éƒ½æœ‰æ¶‰åŠï¼Œä¸ºäº†ä»¥åèƒ½èµ°å¿«ä¸€ç‚¹ï¼Œç°åœ¨åº”è¯¥å¤šèµ°å‡ æ­¥ã€‚ Last Stone Weight We have a collection of stones, each stone has a positive integer weight. Each turn, we choose the two heaviest stones and smash them together. Suppose the stones have weights x and y with x &lt;= y. The result of this smash is: If x == y, both stones are totally destroyed; If x != y, the stone of weight x is totally destroyed, and the stone of weight y has new weight y-x. At the end, there is at most 1 stone left. Return the weight of this stone (or 0 if there are no stones left.) Example 1: Input: [2,7,4,1,8,1] Output: 1 Explanation: We combine 7 and 8 to get 1 so the array converts to [2,4,1,1,1] then, we combine 2 and 4 to get 2 so the array converts to [2,1,1,1] then, we combine 2 and 1 to get 1 so the array converts to [1,1,1] then, we combine 1 and 1 to get 0 so the array converts to [1] then that's the value of last stone. Solution è§£æ³•ä¸€ â€”â€” å¤§æ ¹å † è¿™ä¸ªè§£æ³•æ˜¯æ›´ä¼˜çš„è§£æ³•ï¼Œå¾—åŠ›äºå¤§æ ¹å †çš„ç‰¹æ€§ï¼Œç®—æ³•æ—¶é—´å¤æ‚åº¦å‡å°‘è‡³O(Nlog(N))ã€‚ class Solution: def lastStoneWeight(self, stones: List[int]) -&gt; int: # The heap in python defaults to a small root heap # So heap pops the minimum value when use heappop, take the opposite # value of each list (the weight of each stone &gt; 0) to ensure that the # heaviest stone is poped. stones = list(map(lambda x : -x, stones)) # Convert stone list to heap heapq.heapify(stones) while len(stones) &gt; 1: # Pop and return the smallest element of stones, keeping the heap invariant y = heapq.heappop(stones) if stones: x = heapq.heappop(stones) # if x != y push x-y to heap if x != y: heapq.heappush(stones, y-x) if not(stones): return 0 return -stones[0] æ—¶é—´å¤æ‚åº¦ï¼šO(Nlog(N)) è§£æ³•äºŒ è¿™ä¸ªè§£æ³•æ˜¯æœ€å®¹æ˜“æƒ³åˆ°çš„è§£æ³•ï¼Œæ€æƒ³ä¹Ÿæ¯”è¾ƒç®€å•ï¼Œæ—¶é—´å¤æ‚åº¦O(\\(N^2\\))ã€‚ class Solution: def lastStoneWeight(self, stones: List[int]) -&gt; int: stones = sorted(stones) while len(stones) &gt; 1: y, x = stones.pop(), stones.pop() if x != y: stones.append(y-x) stones = sorted(stones) if not(stones): return 0 return stones[0] æ—¶é—´å¤æ‚åº¦ï¼šO(\\(N^2\\)) -----ï¼ˆnot sureï¼‰ å®é™…é‡‡ç”¨ç¬¬äºŒç§æ–¹æ³•çš„åœ¨LeetCodeä¸Šçš„run timeæ¯”ç¬¬ä¸€ç§æ–¹æ³•æ›´å°‘ï¼Œæ‰€ä»¥ç¬¬äºŒç§æ–¹æ³•æ—¶é—´å¤æ‚åº¦æ¯”ç¬¬ä¸€ç§æ–¹å¼æ›´å°ï¼Œæˆ‘å¯èƒ½éœ€è¦å­¦ä¹ ä¸€ä¸‹pythonçš„å†…ç½®å‡½æ•°sortedæ–¹æ³•ï¼Œçœ‹çœ‹å®ƒçš„å®ç°ã€‚åˆæ­¥äº†è§£åˆ°pythonä¸­çš„sortedæ’åºï¼Œç”¨çš„Timsortç®—æ³•ï¼Œç»´åŸºç™¾ç§‘è§£é‡Šï¼šTimsortæ˜¯ä¸€ç§æ··åˆç¨³å®šçš„æ’åºç®—æ³•ï¼Œæºè‡ªåˆå¹¶æ’åºå’Œæ’å…¥æ’åºï¼Œæ—¨åœ¨è¾ƒå¥½åœ°å¤„ç†çœŸå®ä¸–ç•Œä¸­å„ç§å„æ ·çš„æ•°æ®ã€‚å…·ä½“åŸç†è¿˜éœ€æ·±ç©¶ã€‚ Contiguous Array Given a binary array, find the maximum length of a contiguous subarray with equal number of 0 and 1. Example 1: Input: [0,1] Output: 2 Explanation: [0, 1] is the longest contiguous subarray with equal number of 0 and 1. Example 2: Input: [0,1,0] Output: 2 Explanation: [0, 1] (or [1, 0]) is a longest contiguous subarray with equal number of 0 and 1. Solution è®²çœŸå¿ƒè¯ï¼Œæˆ‘ç¬¬ä¸€éæ²¡çœ‹æ‡‚é¢˜ğŸ¤£ï¼Œé¢˜ç›®å¤§æ„æ˜¯ç»™ä¸€ä¸ªäºŒå€¼(0/1)æ•°ç»„ï¼Œæ‰¾å‡ºè¯¥æ•°ç»„çš„æœ€å¤§è¿ç»­å­ä¸²çš„é•¿åº¦ï¼Œè¯¥å­ä¸²ä¸­æ»¡è¶³0å’Œ1çš„ä¸ªæ•°ç›¸åŒã€‚ æ˜ç™½é¢˜æ„ä¹‹åçš„ç¬¬ä¸€æƒ³æ³•æ˜¯é€šè¿‡è®¡æ•°çš„å½¢å¼å»æ‰¾å­ä¸²ï¼Œä¾‹å¦‚è®¾ç½®ä¸€ä¸ªcountå˜é‡ï¼Œé‡åˆ°0å°±-1ï¼Œé‡åˆ°1å°±+1ã€‚é‚£ä¹ˆå¦‚ä½•é€šè¿‡è¿™ä¸ªå˜é‡å»åˆ¤æ–­ä»€ä¹ˆæ—¶å€™ä¼šå‡ºç°æœ€å¤§å­ä¸²å‘¢ï¼Ÿ è€ƒè™‘ä¸‹é¢å‡ ç§æƒ…å†µï¼š å‡è®¾nums = [0, 1, 0, 0, 1, 1]ï¼Œ é‚£ä¹ˆcount = [-1ï¼Œ 0ï¼Œ -1ï¼Œ -2ï¼Œ -1ï¼Œ 0] =&gt; max lengthï¼š6ï¼ˆcountæ•°ç»„çš„æœ€åä¸€ä¸ª0çš„index+1ï¼‰ nums = [0, 0, 0, 0, 1, 1]ï¼Œcount = [-1, -2, -3, -4, -3, -2] =&gt; å¾ˆæ˜æ˜¾è¿™ç§æƒ…å†µçš„æœ€å¤§é•¿åº¦ä¸æ˜¯æœ€åä¸€ä¸ª0çš„index + 1 = 2ï¼Œè€Œæ˜¯4ï¼Œå…¶å®ä¹Ÿæ˜¯å¯ä»¥é€šè¿‡countçš„å€¼æ¨æµ‹å‡ºæ¥ï¼Œæœ€å¤§é•¿åº¦çš„å­ä¸²æ˜¯[1, 1, 0, 0]ï¼Œä¸‹é¢ç”¨ä¸€ä¸ªå›¾æ¥ç›´è§‚çš„è¡¨ç¤ºå¦‚ä½•é€šè¿‡countçš„å€¼æ¥æ¨å‡ºmax lengthï¼š countåˆå§‹å€¼ä¸º0ï¼Œæ•…èµ·ç‚¹ä¸º(0, 0)ï¼Œä»countä»index=1å¼€å§‹è®¡æ•°ï¼Œä»å›¾ä¸­å¯ä»¥çœ‹å‡ºï¼Œæœ€é•¿çš„å­æ•°ç»„æ˜¯ä»ç´¢å¼•2åˆ°6: ä»ä¸Šé¢çš„æ’å›¾ä¸­ï¼Œå¯ä»¥å¾ˆå®¹æ˜“åœ°ç†è§£åˆ°ï¼Œå…·æœ‰ç›¸åŒyè½´å€¼çš„ä¸¤ä¸ªç‚¹è¡¨ç¤ºè¿™ä¸¤ä¸ªç‚¹ä¹‹é—´çš„åºåˆ—å…·æœ‰ç›¸ç­‰çš„0å’Œ1ã€‚ nums = [0ï¼Œ0ï¼Œ1ï¼Œ0ï¼Œ0ï¼Œ0ï¼Œ1ï¼Œ1]ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š æœ‰3ä¸ªç‚¹å…·æœ‰ç›¸åŒçš„yè½´å€¼-2ã€‚å› æ­¤ï¼Œä»ç´¢å¼•2åˆ°4çš„å­æ•°ç»„å…·æœ‰ç›¸ç­‰çš„0å’Œ1ï¼Œè€Œä»ç´¢å¼•4åˆ°8çš„å­æ•°ç»„å…·æœ‰ç›¸ç­‰çš„0å’Œ1ã€‚å¯ä»¥å°†å®ƒä»¬åŠ èµ·æ¥ä»¥å½¢æˆä»ç´¢å¼•2åˆ°8çš„æœ€é•¿å­æ•°ç»„ï¼Œå› æ­¤æœ€å¤§é•¿åº¦å­æ•°ç»„çš„ 8-2 = 6ã€‚ nums = [0ï¼Œ1ï¼Œ1ï¼Œ0ï¼Œ1ï¼Œ1ï¼Œ1ï¼Œ0]ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š æœ€é•¿çš„å­æ•°ç»„çš„yè½´å€¼ä¸º0ã€‚ ä¸ºäº†æ‰¾åˆ°max lengthï¼Œè¿™é‡Œå¯ä»¥è€ƒè™‘ç”¨ä¸€ä¸ªå­—å…¸æ¥å­˜å‚¨countçš„å€¼ï¼ˆä½œä¸ºé”®ï¼‰åŠå…¶å…³è”çš„indexï¼ˆä½œä¸ºå€¼ï¼‰ã€‚åªéœ€è¦åœ¨countç¬¬ä¸€æ¬¡å‡ºç°æŸå€¼æ—¶ä¿å­˜å…¶è®¡æ•°å€¼åŠå…¶ç´¢å¼•ï¼Œå½“ç›¸åŒçš„è®¡æ•°å€¼å†æ¬¡å‡ºç°æ—¶ï¼Œä½¿ç”¨æ–°ç´¢å¼•å‡å»æ—§ç´¢å¼•æ¥è®¡ç®—å­æ•°ç»„çš„é•¿åº¦ã€‚å˜é‡max_lengthç”¨äºè·Ÿè¸ªå½“å‰çš„æœ€å¤§é•¿åº¦ã€‚ ä»£ç å®ç° class Solution: def findMaxLength(self, nums: List[int]) -&gt; int: count = 0 max_len = 0 dic = {0: 0} for i, num in enumerate(nums, 1): count += 1 if num == 1 else -1 if count in dic: max_len = max(max_len, i - dic[count]) else: dic[count] = i return max_len Reference Python O(n) Solution with Visual Explanation Perform String Shifts You are given a string s containing lowercase English letters, and a matrix shift, where shift[i] = [direction, amount]: 1. direction can be 0 (for left shift) or 1 (for right shift). 2. amount is the amount by which string s is to be shifted. 3. A left shift by 1 means remove the first character of s and append it to the end. 4. Similarly, a right shift by 1 means remove the last character of s and add it to the beginning. Return the final string after all operations. Example 1: Input: s = \"abc\", shift = [[0,1],[1,2]] Output: \"cab\" Explanation: [0,1] means shift to left by 1. \"abc\" -&gt; \"bca\" [1,2] means shift to right by 2. \"bca\" -&gt; \"cab\" Example 2: Input: s = \"abcdefg\", shift = [[1,1],[1,1],[0,2],[1,3]] Output: \"efgabcd\" Explanation: [1,1] means shift to right by 1. \"abcdefg\" -&gt; \"gabcdef\" [1,1] means shift to right by 1. \"gabcdef\" -&gt; \"fgabcde\" [0,2] means shift to left by 2. \"fgabcde\" -&gt; \"abcdefg\" [1,3] means shift to right by 3. \"abcdefg\" -&gt; \"efgabcd\" Solution æ€è·¯ï¼šè¿™ä¸ªé¢˜è‚¯å®šä¸èƒ½ç”¨è›®åŠ›æ³•ï¼Œæ¯”å¦‚è¯´ä½ æŒ¨ä¸ªå»åˆ¤æ–­çŸ©é˜µå…ƒç´ ï¼Œç„¶åæ ¹æ®è¦æ±‚å»ç§»åŠ¨ï¼Œè¿™æ ·å¤æ‚åº¦å¤ªé«˜äº†ã€‚æ ¸å¿ƒæ€è·¯æ˜¯å°†è¦ç§»åŠ¨çš„æ­¥æ•°ç»Ÿè®¡åœ¨ä¸€èµ·ï¼Œç„¶ååªç§»åŠ¨ä¸€æ¬¡ã€‚ ä¾‹å¦‚ï¼Œé¦–å…ˆè®¾ç½®ä¸€ä¸ªmove_stepså˜é‡ï¼Œå‘å·¦ä¸€æ­¥ç§»å°±-1ï¼Œå‘å³ç§»ä¸¤æ­¥å°±+2ã€‚ç„¶ååˆ¤æ–­ç§»åŠ¨æ­¥æ•°ï¼Œå¦‚æœç§»åŠ¨æ­¥æ•°è¶…è¿‡å­—ç¬¦ä¸²é•¿åº¦ï¼Œé‚£ä¹ˆå°±é€šè¿‡å­—ç¬¦ä¸²é•¿åº¦å–ä½™ï¼ˆå› ä¸ºç§»åŠ¨å­—ç¬¦ä¸²é•¿åº¦é‚£ä¹ˆå¤šæ­¥æœ€ååˆæ¢å¤åŸæ ·ï¼Œç›¸å½“äºæ²¡ç§»ï¼‰ã€‚æœ€åç»Ÿä¸€å‘ä¸€ä¸ªæ–¹å‘ï¼ˆä¾‹å¦‚å‘å³ï¼Œå¦‚æœæ˜¯å·¦ç§»ï¼Œåˆ™é€šè¿‡å­—ç¬¦ä¸²é•¿åº¦å˜ä¸ºå‘å³ç§»åŠ¨ï¼‰ç§»åŠ¨ã€‚æ€è·¯å¾ˆç®€å•ï¼Œå…·ä½“å®ç°ï¼Œè¯·çœ‹ä»£ç ~ğŸ˜Š class Solution: def stringShift(self, s: str, shift: List[List[int]]) -&gt; str: move_steps = 0 for data in shift: direction = data[0] move_steps += data[1] if direction == 1 else -data[1] s_len = len(s) move_steps %= s_len if move_steps &gt; 0 else -s_len # Do not need to move if move_steps == 0: return s # move right if move_steps &lt; 0: move_steps += s_len # move s_list = list(s) while move_steps &gt; 0: s_list.insert(0, s_list[-1]) s_list = s_list[:-1] move_steps -= 1 return &#39;&#39;.join(s_list) æ€»ç»“ è¿™å‘¨é¢˜çš„éš¾åº¦æ˜æ˜¾è¦æ¯”ä¸Šå‘¨çš„é«˜é‚£ä¹ˆä¸€ç‚¹ï¼Œå¸Œæœ›è‡ªå·±èƒ½åšæŒä¸‹å»ï¼Œç»™è‡ªå·±ä¸€äº›ä¿¡å¿ƒã€‚å™¢å¯¹äº†ï¼Œæˆ‘æ„Ÿè§‰ä¸€ç¯‡æ–‡ç« æ›´æ–°ä¸€å‘¨çš„å†…å®¹è¿˜æƒ³æœ‰ç‚¹å¤ªé•¿äº†ï¼Œä¸‹å‘¨æˆ‘å¯èƒ½ä¼šè€ƒè™‘ä¸€ç¯‡æ–‡ç« åªæ”¶çº³2-3é“é¢˜ã€‚è¿™å‘¨çš„æ›´æ–°å°±åˆ°æ­¤ä¸ºæ­¢äº†ï¼ŒæœŸå¾…ä¸‹æ¬¡æ›´æ–°å§~ğŸ‘‹","categories":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Coding","slug":"Technology/Coding","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/"},{"name":"Leetcode","slug":"Technology/Coding/Leetcode","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/Leetcode/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://littlelittlemoon.github.io/tags/Leetcode/"},{"name":"Python","slug":"Python","permalink":"https://littlelittlemoon.github.io/tags/Python/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://littlelittlemoon.github.io/tags/Algorithm/"}],"keywords":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Coding","slug":"Technology/Coding","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/"},{"name":"Leetcode","slug":"Technology/Coding/Leetcode","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/Leetcode/"}]},{"title":"Leetcode Note in Apri 2020 | part 1 | day 01-07","slug":"Technology/Leetcode-Note-in-Apri-2020-part-1-day-01-07","date":"2020-04-01T01:51:55.000Z","updated":"2020-04-13T04:37:22.942Z","comments":true,"path":"2020/04/01/Technology/Leetcode-Note-in-Apri-2020-part-1-day-01-07/","link":"","permalink":"https://littlelittlemoon.github.io/2020/04/01/Technology/Leetcode-Note-in-Apri-2020-part-1-day-01-07/","excerpt":"","text":"å†™åœ¨å‰é¢çš„è¯ è¿™ä¸€ç³»åˆ—æ–‡ç« ä¸»è¦æ˜¯ç”¨äºè®°å½•æˆ‘åœ¨LeetCodeä¸Šåˆ·é¢˜æ—¶é‡åˆ°çš„æˆ‘è®¤ä¸ºæ¯”è¾ƒæœ‰éš¾åº¦å’Œæœ‰æ„æ€çš„é¢˜ï¼Œä»¥åŠæ˜¯æŒ–æ˜åˆ°çš„å…¶ä»–å°ä¼™ä¼´æ¯”è¾ƒå¥½çš„è§£æ³•å’Œæ€è·¯ã€‚è¿™æ˜¯ç¬¬ä¸€ç¯‡ï¼Œä¸å‡ºæ„å¤–è¿™ä¸ªç³»åˆ—ä¼šä¸€ç›´æ›´æ–°ï¼Œä¹Ÿç®—æ˜¯ç£ä¿ƒè‡ªå·±åšæŒä¸‹å»å§ã€‚å¯¹äº†æˆ‘å†™ä½œæ°´å¹³çœŸçš„å¾ˆå·®ï¼Œå¸Œæœ›å¤§å®¶ä¸è¦å«Œå¼ƒï¼Œä¹Ÿå¯ä»¥å’Œæˆ‘ç•™è¨€ç»™å‡ºå»ºè®®ä»€ä¹ˆçš„ï¼ŒæœŸå¾…å’Œå¤§å®¶ä¸ªå…±åŒè¿›æ­¥ï¼é‚£æˆ‘ä»¬å¼€å§‹å§ ~ Sigle number Given a non-empty array of integers, every element appears twice except for one. Find that single one. Note: Your algorithm should have a linear runtime complexity. Could you implement it without using extra memory? Example: Input: [4,1,2,1,2] Output: 4 Solution Mine: tuple + list class Solution: def singleNumber(self, nums: List[int]) -&gt; int: # store the count of positive number p_count = [0] * (max(tuple(nums)) + 1) # store the positive number p_nums = () # store the count of negative number n_count = [0] * (abs(min(tuple(nums))) + 1) # store the negative number n_nums = () # counting for num in nums: if num &gt;= 0: p_nums = p_nums + (num, ) p_count[num] = p_count[num] + 1 else: n_nums = n_nums + (num, ) n_count[abs(num)] = n_count[abs(num)] + 1 # find the sigle number for num in p_nums: if p_count[num] == 1: return num for num in n_nums: if n_count[abs(num)] == 1: return num return None Space complexityï¼š O(n) Time complexityï¼š O(n) Optimization using XOR The most crucial trick here is to recognize that if you XOR any same number together, you cancel it out (=0). Explanation: nums = [2, 4, 5, 4, 3, 5, 2] XORing everything together = 2 ^ 4 ^ 5 ^ 4 ^ 3 ^ 5 ^ 2 = (2^2) ^ (4^4) ^ (5^5) ^ 3 = 0 ^ 0 ^0 ^ 3 = 3 class Solution: def singleNumber(self, nums: List[int]) -&gt; int: return reduce(lambda x, y: x^y, nums, 0) Space complexityï¼š O(1) time complexityï¼š O(n) Reference Reduce list(map(str, [1, 2, 3, 4, 5, 6, 7, 8, 9])) # output: [&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;, &#39;6&#39;, &#39;7&#39;, &#39;8&#39;, &#39;9&#39;] Map reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4) # convert string to integer DIGITS = {&#39;0&#39;: 0, &#39;1&#39;: 1, &#39;2&#39;: 2, &#39;3&#39;: 3, &#39;4&#39;: 4, &#39;5&#39;: 5, &#39;6&#39;: 6, &#39;7&#39;: 7, &#39;8&#39;: 8, &#39;9&#39;: 9} def char2num(s): return DIGITS[s] def str2int(s): return reduce(lambda x, y: x * 10 + y, map(char2num, s)) Happy number A happy number is a number defined by the following process: Starting with any positive integer, replace the number by the sum of the squares of its digits, and repeat the process until the number equals 1 (where it will stay), or it loops endlessly in a cycle which does not include 1. Those numbers for which this process ends in 1 are happy numbers. Example: Input: 19 Output: true Explanation: \\(1^2 + 9^2 = 82\\) \\(8^2 + 2^2 = 68\\) \\(6^2 + 8^2 = 100\\) \\(1^2 + 0^2 + 0^2 = 1\\) Solution Floyd's cycle detection æ ¸å¿ƒæ€è·¯ï¼šå¦‚æœä¸€ä¸ªæ•°å­—ä¸æ˜¯ happy number é‚£ä¹ˆå®ƒæ‹†åˆ†åçš„æ•°å­—çš„å’Œä¸€å®šä¼šå¾ªç¯ï¼Œé€šè¿‡Floyd's cycle detectionç®—æ³•åšå¾ªç¯æ£€æµ‹ã€‚ Short Version utilizing walrus operator := class Solution: def isHappy(self, n: int) -&gt; bool: def next_num(num): return sum(map(lambda x:int(x)**2, str(num))) slow, fast = n, next_num(n) while (slow:=next_num(slow)) != (fast:=next_num(next_num(fast))) and fast != 1: continue return fast == 1 or not slow == fast Easier to understand version class Solution: def isHappy(self, n: int) -&gt; bool: def next_num(num): return sum(map(lambda x:int(x)**2, str(num))) slow, fast = n, next_num(n) while slow != fast and fast != 1: slow = next_num(slow) fast = next_num(next_num(fast)) return fast == 1 or not slow == fast Reference Algorithmï¼š Floyd's cycle detection What we need to do in case we need the starting point of the loop ? - Once we know for sure that a loop is present. - Move the slowPointer to start of the list,(i.e headNode) and let fastPointer remain there at the meeting point - Now move both the pointers one node at a time - The point where both pointers will meet, is our required start of the loop. The algorithm uses O(Î» + Î¼) operations of these types, and O(1) storage space. Detecting start of a loop in singly Linked List Floyd's Cycle detection algorithm | Determining the starting point of cycle Another solution class Solution: def isHappy(self, n: int) -&gt; bool: # let&#39;s try different n: # true (1) -&gt; 1 # false (2) -&gt; 4 -&gt; 16 -&gt; 37 -&gt; 58 -&gt; 89 -&gt; 145 -&gt; 42 -&gt; 20 -&gt; 4 # false (3) -&gt; 9 -&gt; 81 -&gt; 65 -&gt; 61 -&gt; 37 (look at 2) # false (4) -&gt; (look at 2) # false (5) -&gt; 25 -&gt; 29 -&gt; 85 -&gt; 89 (look at 2) # false (6) -&gt; 36 -&gt; 45 -&gt; 41 -&gt; 17 -&gt; 50 -&gt; 25 (look at 5) # true (7) -&gt; 49 -&gt; 97 -&gt; 10 # false (8) -&gt; 64 -&gt; 52 -&gt; 29 (look at 5) # false (9) -&gt; 9 -&gt; 81 -&gt; 65 (look at 3) # # All other n &gt;= 10, while computing will become [1-9], # So there are two cases 1 and 7 which are true. # # Notice, that all falses has the same path as 2 (loop). counting = 0 num = n while True: counting = 0 for str_num in str(num): counting = counting + pow(int(str_num), 2) if counting &gt;= 1 and counting &lt;=9: if counting == 1 or counting == 7: return True else: return False else: num = counting Group Anagrams Given an array of strings, group anagrams together. Example: Input: [\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"], Output: [ [\"ate\",\"eat\",\"tea\"], [\"nat\",\"tan\"], [\"bat\"] ] My solutionï¼ˆbadï¼‰ class Solution: def groupAnagrams(self, strs: List[str]) -&gt; List[List[str]]: group_list = [] group_list.append([strs[0]]) for i in range(1, len(strs)): sorted_str = sorted(strs[i]) for j in range(0, len(group_list)): sorted_comp_str = sorted(group_list[j][0]) if sorted_str == sorted_comp_str: group_list[j].append(strs[i]) break if j == len(group_list) - 1: group_list.append([strs[i]]) break return group_list Result: Time Limit Exceeded Summary è¿™ä¸ªè§£æ³•çœ‹èµ·æ¥æ²¡ä»€ä¹ˆæ¯›ç—…ï¼Œå¦‚æœstrsé•¿åº¦å¾ˆå°ï¼Œä¹Ÿèƒ½æ­£å¸¸å·¥ä½œï¼Œä½†æ˜¯å½“å­—ç¬¦ä¸²æ•°ç»„strsé•¿åº¦ç‰¹åˆ«å¤§æ—¶ï¼Œ æ¯›ç—…å°±æš´éœ²å‡ºæ¥äº†ï¼Œé€Ÿåº¦å¾ˆæ…¢ï¼Œæ•ˆç‡ä½ï¼Œä¼šå‡ºç°è¶…æ—¶ï¼ˆTime Limit Exceededï¼‰æœªå®Œæˆçš„æƒ…å†µã€‚ Nice solution with dictionary and tuple class Solution: def groupAnagrams(self, strs: List[str]) -&gt; List[List[str]]: # create a null dictionary group_list = {} for s in strs: # sort the string&#39;s letters and save as a tuple key = tuple(sorted(s)) # search dictionary with the str&#39;s tuple and save the new value group_list[key] = group_list.get(key, []) + [s] return group_list.values() Summary Tuple can be used for the dictionary's key. wow~ Dictionary can speed up the search. Maximum Subarray Given an integer array nums, find the contiguous subarray (containing at least one number) which has the largest sum and return its sum. Example: Input: [-2,1,-3,4,-1,2,1,-5,4], Output: 6 Explanation: [4,-1,2,1] has the largest sum = 6. Follow up: If you have figured out the O(n) solution, try coding another solution using the divide and conquer approach, which is more subtle. Solution æ ¸å¿ƒæ€è·¯ï¼š å½“sum&lt;0æ—¶ï¼Œsum+xä¸€å®šæ¯”xå°ï¼Œæ•…å½“sumä¸ºè´Ÿæ•°æ—¶ï¼Œå¯ç›´æ¥å°†sumç½®é›¶ã€‚ class Solution: def maxSubArray(self, nums: List[int]) -&gt; int: sum_ = 0 max_sum = nums[0] for num in nums: sum_ = sum_ + num if sum_ &gt; max_sum: max_sum = sum_ sum_ = max(sum_, 0) return max_sum Best Time to Buy and Sell Stock II Say you have an array prices for which the ith element is the price of a given stock on day i. Design an algorithm to find the maximum profit. You may complete as many transactions as you like (i.e., buy one and sell one share of the stock multiple times). Note: You may not engage in multiple transactions at the same time (i.e., you must sell the stock before you buy again). Example 1: Input: [7,1,5,3,6,4] Output: 7 Explanation: Buy on day 2 (price = 1) and sell on day 3 (price = 5), profit = 5-1 = 4. Then buy on day 4 (price = 3) and sell on day 5 (price = 6), profit = 6-3 = 3. Solution å“‡è¿™ä¸ªé¢˜ï¼ŒçœŸçš„è®©æˆ‘æ€€ç–‘è‡ªå·±çš„æ™ºå•†äº†...ğŸ˜‚ï¼Œæˆ‘åˆšå¼€å§‹çš„ç­”æ¡ˆå†™äº†å¥½å¤šè¡Œä»£ç ï¼Œç„¶åå»è®¨è®ºåŒºå­¦ä¹ çš„æ—¶å€™å‘ç°å¤§å®¶éƒ½æ˜¯äººæ‰å•Š...æ¯”å¦‚ä¸‹é¢è¿™ä¸ªï¼š class Solution: def maxProfit(self, prices: List[int]) -&gt; int: max_profit = 0 for i in range(0, len(prices)-1): max_profit += max(prices[i+1]-prices[i], 0) return max_profit Mine class Solution: def maxProfit(self, prices: List[int]) -&gt; int: max_profit = 0 buy_i = 0 sell_i = 1 need_sell = 1 need_buy = 0 for i in range(1, len(prices)): if prices[sell_i] &lt; prices[buy_i]: need_buy = 1 need_sell = 0 else: need_buy = 0 need_sell = 1 if need_buy == 1: if prices[i] &lt; prices[buy_i]: buy_i = i if i &lt; len(prices) - 1: sell_i = i + 1 else: sell_i = i continue if need_sell == 1: if prices[i] &gt;= prices[sell_i]: sell_i = i if i == len(prices) - 1: max_profit += prices[sell_i] - prices[buy_i] else: max_profit += prices[sell_i] - prices[buy_i] buy_i = i if i &lt; len(prices) - 1: sell_i = i + 1 need_buy = 1 need_sell = 0 return max_profit emmmm...æˆ‘éœ€è¦åæ€ä¸€ä¸‹ğŸ˜ Counting Elements Given an integer array arr, count element x such that x + 1 is also in arr. If there're duplicates in arr, count them seperately. Examples: Input: arr = [1,2,3] Output: 2 Explanation: 1 and 2 are counted cause 2 and 3 are in arr. Input: arr = [1,1,3,3,5,5,7,7] Output: 0 Explanation: No numbers are counted, cause there's no 2, 4, 6, or 8 in arr. Input: arr = [1,3,2,3,5,0] Output: 3 Explanation: 0, 1 and 2 are counted cause 1, 2 and 3 are in arr. Solution Mine è¿™ä¸ªé¢˜æ²¡æœ‰æ‰¾åˆ°å¤§å®¶çš„è®¨è®ºï¼Œæ‰€ä»¥æˆ‘ä¹Ÿä¸çŸ¥é“å…¶ä»–å°ä¼™ä¼´çš„è§£é¢˜æ€è·¯æ˜¯ä»€ä¹ˆæ ·çš„ï¼Œä½†æ˜¯æˆ‘æ€»è§‰å¾—å¤§å®¶ä¼šæœ‰æ›´å¥½çš„è§£å†³æ–¹æ¡ˆï¼Œæˆ‘è¿™è¾¹å°±å…ˆpoå‡ºæˆ‘çš„è§£æ³•ï¼Œæ¬¢è¿å¤§å®¶æä¾›è‡ªå·±çš„æ€è·¯å’Œå»ºè®®ã€‚ æ€è·¯ï¼š ç°å°†æ•°ç»„æ’åºï¼Œç„¶åé€šè¿‡ä¸¤ä¸ªæŒ‡é’ˆï¼špreå’Œcurè¿›è¡Œå¯¹æ¯”ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯æ•°å­—ç›¸åŒçš„æ•°åº”è¯¥åŒæ—¶è¢«è®¡æ•°æˆ–éƒ½ä¸è®¡æ•°ã€‚ class Solution: def countElements(self, arr: List[int]) -&gt; int: arr_sorted = sorted(arr) count = 0 # æŒ‡å‘å½“å‰éœ€è¦åˆ¤æ–­æ˜¯å¦èƒ½è¢«è®¡æ•°çš„æ•° pre = 0 # æŒ‡å‘å½“å‰preåé¢çš„æ•°ï¼Œç”¨äºåˆ¤æ–­preæ˜¯å¦èƒ½è¢«è®¡æ•° cur = 1 # å¦‚æœcuræŒ‡å‘çš„æ•°ç­‰äºpreæŒ‡å‘çš„æ•°ï¼Œåˆ™å¢åŠ leaveï¼Œ # å¦‚æœpreå¯ä»¥è¢«è®¡æ•°ï¼Œåˆ™å’Œpreç›¸ç­‰çš„æ•°ä¹Ÿåº”è¯¥è¢«è®¡æ•° leave = 1 # å½“preå’ŒcuræŒ‡å‘åŒä¸€indexæ—¶åœæ­¢å¾ªç¯ while pre^cur: sub = arr_sorted[cur] - arr_sorted[pre] if sub &lt;= 1: if sub == 1: count += leave pre = cur leave = 1 elif cur == len(arr)-1: break; else: leave +=1 else: pre = cur leave = 1 cur = min(cur+1, len(arr)-1) return count Summary æˆ‘å‘ç°æˆ‘çš„å†™ä½œèƒ½åŠ›çœŸçš„å¥½å·®å•Šï¼Œæœ‰çš„æ—¶å€™çŸ¥é“æ€ä¹ˆå›äº‹å°±æ˜¯å†™ä¸å‡ºæ¥ï¼Œæ‰æ€¥ã€‚ã€‚ã€‚å¸Œæœ›çœ‹åˆ°çš„å°ä¼™ä¼´ä¸è¦ä»‹æ„ï¼Œæˆ‘åœ¨åŠªåŠ›ï¼Œå¸Œæœ›ä»¥åä¼šè¶Šæ¥è¶Šå¥½ï¼Œå”‰ğŸ˜Œï¼Œå¯¹ä¸èµ·é«˜ä¸­è¯­æ–‡è€å¸ˆä¸€å¯¹ä¸€çš„è¾…å¯¼å•Šã€‚å¥½å•¦ï¼Œè¿™æœŸå°±æ›´æ–°å®Œäº†ã€‚ å¯¹äº†ï¼Œæˆ‘æ˜¯å‡†å¤‡ä¸€æ¬¡æ›´æ–°ä¸€å‘¨çš„å†…å®¹ï¼Œç„¶åå¯èƒ½æƒ³èµ·æ¥å°±ä¼šæ›´æ–°ä¸€éƒ¨åˆ†å‘å¸ƒå‡ºæ¥ï¼Œå¦‚æœæ²¡æ›´å®Œæœ€åä¼šæ˜¾ç¤ºUpdating...ã€‚ä¸€èµ·æœŸå¾…ç¬¬äºŒæœŸå§~ğŸ˜Š","categories":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Coding","slug":"Technology/Coding","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/"},{"name":"Leetcode","slug":"Technology/Coding/Leetcode","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/Leetcode/"}],"tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://littlelittlemoon.github.io/tags/Leetcode/"},{"name":"Python","slug":"Python","permalink":"https://littlelittlemoon.github.io/tags/Python/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://littlelittlemoon.github.io/tags/Algorithm/"}],"keywords":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Coding","slug":"Technology/Coding","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/"},{"name":"Leetcode","slug":"Technology/Coding/Leetcode","permalink":"https://littlelittlemoon.github.io/categories/Technology/Coding/Leetcode/"}]},{"title":"Fraud Detection | Imbalanced data modeling","slug":"Technology/Credit Card Fraud Detection","date":"2020-03-21T13:53:06.000Z","updated":"2020-04-12T13:06:54.542Z","comments":true,"path":"2020/03/21/Technology/Credit Card Fraud Detection/","link":"","permalink":"https://littlelittlemoon.github.io/2020/03/21/Technology/Credit%20Card%20Fraud%20Detection/","excerpt":"","text":"LDA, QDA and LR for fraud detection | Imbalanced data modeling %matplotlib inline # import warnings filter from warnings import simplefilter # ignore all future warnings simplefilter(action=&#39;ignore&#39;, category=FutureWarning) prepare data import pandas as pd # load data default_data = pd.read_csv(&quot;data/Default.csv&quot;) # prepare data default_data.loc[default_data[&#39;default&#39;] == &#39;No&#39;, &quot;default&quot;] = 0 default_data.loc[default_data[&#39;default&#39;] == &#39;Yes&#39;, &quot;default&quot;] = 1 default_data.loc[default_data[&#39;student&#39;] == &#39;No&#39;, &quot;student&quot;] = 0 default_data.loc[default_data[&#39;student&#39;] == &#39;Yes&#39;, &quot;student&quot;] = 1 default_data.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Unnamed: 0 default student balance income count 10000.00000 10000.000000 10000.000000 10000.000000 10000.000000 mean 5000.50000 0.033300 0.294400 835.374886 33516.981876 std 2886.89568 0.179428 0.455795 483.714985 13336.639563 min 1.00000 0.000000 0.000000 0.000000 771.967729 25% 2500.75000 0.000000 0.000000 481.731105 21340.462903 50% 5000.50000 0.000000 0.000000 823.636973 34552.644802 75% 7500.25000 0.000000 1.000000 1166.308386 43807.729272 max 10000.00000 1.000000 1.000000 2654.322576 73554.233495 split training and testing set from sklearn.model_selection import train_test_split # create features and target features = [&quot;balance&quot;, &quot;income&quot;] X = default_data[features] y = default_data.default # slipt data set into training and testing set train_X, test_X, train_y, test_y = train_test_split(X, y, train_size=0.7, random_state=1) import numpy as np import matplotlib as mpl from scipy import linalg from matplotlib import colors import matplotlib.pyplot as plt from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis from sklearn.linear_model import LogisticRegression Plot function # set colormap cmap = colors.LinearSegmentedColormap( &#39;red_blue_classes&#39;, {&#39;red&#39;: [(0, 1, 1), (1, 0.7, 0.7)], &#39;green&#39;: [(0, 0.7, 0.7), (1, 0.7, 0.7)], &#39;blue&#39;: [(0, 0.7, 0.7), (1, 1, 1)]}) plt.cm.register_cmap(cmap=cmap) # Plot function def plot_data(model, X, y, y_pred): plt.ylabel(&#39;income&#39;) plt.xlabel(&#39;balance&#39;) tp = (y == y_pred) # True Positive tp0, tp1 = tp[y == 0], tp[y == 1] X0, X1 = X[y == 0], X[y == 1] X0_tp, X0_fp = X0[tp0], X0[~tp0] X1_tp, X1_fp = X1[tp1], X1[~tp1] # true class 0: dots, false class 0: x plt.scatter(X0_tp[&quot;balance&quot;], X0_tp[&quot;income&quot;], marker=&#39;.&#39;, color=&#39;red&#39;) plt.scatter(X0_fp[&quot;balance&quot;], X0_fp[&quot;income&quot;], marker=&#39;x&#39;, s=20, color=&#39;#990000&#39;) # dark red # true class 1: dots, false class 1: x plt.scatter(X1_tp[&quot;balance&quot;], X1_tp[&quot;income&quot;], marker=&#39;.&#39;, color=&#39;blue&#39;) plt.scatter(X1_fp[&quot;balance&quot;], X1_fp[&quot;income&quot;], marker=&#39;x&#39;, s=20, color=&#39;#000099&#39;) # dark blue # class 0 and 1 : all areas for decision boundary nx, ny = 200, 100 x_min, x_max = plt.xlim() y_min, y_max = plt.ylim() xx, yy = np.meshgrid(np.linspace(x_min, x_max, nx), np.linspace(y_min, y_max, ny)) Z = model.predict_proba(np.c_[xx.ravel(), yy.ravel()]) Z = Z[:, 1].reshape(xx.shape) plt.pcolormesh(xx, yy, Z, cmap=&#39;red_blue_classes&#39;, norm=colors.Normalize(0., 1.), zorder=0) # plot decision boundary plt.contour(xx, yy, Z, [0.5], linewidths=2., colors=&#39;white&#39;) plt.axis(&#39;tight&#39;) plt.tight_layout() plt.subplots_adjust(top=0.92) plt.show() Linear Discriminant Analysis # Linear Discriminant Analysis plt.figure(figsize=(6, 7), facecolor=&#39;white&#39;) plt.title(&#39;Linear Discriminant Analysis&#39;, y=1, fontsize=15) lda = LinearDiscriminantAnalysis(solver=&quot;svd&quot;, store_covariance=True) y_pred = lda.fit(train_X, train_y).predict(test_X) plot_data(lda, test_X, test_y, y_pred) png Quadratic Discriminant Analysis # Quadratic Discriminant Analysis plt.figure(figsize=(6, 7), facecolor=&#39;white&#39;) plt.title(&#39;Quadratic Discriminant Analysis&#39;, y=1, fontsize=15) qda = QuadraticDiscriminantAnalysis(store_covariance=True) y_pred = qda.fit(train_X, train_y).predict(test_X) plot_data(qda, test_X, test_y, y_pred) png Use LogisticRegression directly to model the data If I use this data directly to feed the LogisticRegression model, the model will prefer to predict all as 0 for a high accuracy of 0 prediction. print(default_data.default.value_counts(dropna = False)) print(&quot;The mean of default: &quot;, default_data.default.mean()) 0 9667 1 333 Name: default, dtype: int64 The mean of default: 0.0333 NOTE: As it showing above: the provided data with very low proportion of positive signals. Conclusion: The provided data is imbalanced ! Solution: usually for imbalanced data, there are some solutions: 1. Collect more data 2. Down-Sampling or Over-Sampling to get balanced samples 3. Change the Thresholds to adjust the prediction 4. Assign class weights for the low rate class from sklearn.metrics import confusion_matrix, auc, roc_curve, roc_auc_score, recall_score, precision_recall_curve from sklearn.metrics import make_scorer, precision_score from sklearn.model_selection import GridSearchCV # Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = .33, stratify = y) logitreg_parameters = {&#39;C&#39;: np.power(10.0, np.arange(-3, 3))} logitreg = LogisticRegression(verbose = 3, warm_start = True) logitreg_grid = GridSearchCV(logitreg, param_grid = logitreg_parameters, scoring = &#39;roc_auc&#39;, n_jobs = 1) logitreg_grid.fit(train_X, train_y) GridSearchCV(cv=None, error_score=nan, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class=&#39;auto&#39;, n_jobs=None, penalty=&#39;l2&#39;, random_state=None, solver=&#39;lbfgs&#39;, tol=0.0001, verbose=3, warm_start=True), iid=&#39;deprecated&#39;, n_jobs=1, param_grid={&#39;C&#39;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])}, pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=False, scoring=&#39;roc_auc&#39;, verbose=0) # draw decision boundary with LogisticRegression directly plt.figure(figsize=(6, 7), facecolor=&#39;white&#39;) plt.title(&#39;Logistic Regression directly&#39;, y=1, fontsize=15) y_pred = logitreg_grid.predict(test_X) splot = plot_data(logitreg_grid, test_X, test_y, y_pred) png # on OVER-Sampled TRAINing data print(&quot;\\n The recall score on Training data is:&quot;, recall_score(train_y, logitreg_grid.predict(train_X))) # 0.32 print(&quot;\\n The precision score on Training data is:&quot;, precision_score(train_y, logitreg_grid.predict(train_X))) # 0.74 # on the separated TEST data print(&quot;\\n Thre recall score on Test data is:&quot;, recall_score(test_y, logitreg_grid.predict(test_X))) # 0.32 print(&quot;\\n Thre precision score on Test data is:&quot;, precision_score(test_y, logitreg_grid.predict(test_X))) # 0.75 print(&quot;\\n Thre Confusion Matrix on Test data is:&quot;, confusion_matrix(test_y, logitreg_grid.predict(test_X))) # [[3178 12][ 74 36]] The recall score on Training data is: 0.32231404958677684 The precision score on Training data is: 0.7222222222222222 Thre recall score on Test data is: 0.3626373626373626 Thre precision score on Test data is: 0.673469387755102 Thre Confusion Matrix on Test data is: [[2893 16] [ 58 33]] Conclusions: From the output above, on the training data, the recall score is 0.32 which means 32 over 100 of the True positive conditions are predicted correctly. And 74 over 100 of the predicted positives are True Positive. On the Test data, the model performance metric evalued by recall or precision are close to the Training data. There is a precision score of 0.81 on the Test data, which means 81 out of 100 predicted positives are True positives. From Confusion Matrix, 36 of 110 True Positives are predicted as positives. And of all 48 predicted as positive, 36 of them are True positives. Change the Thresholds plot roc curve def plot_roc(new_thresholds, logitreg_grid): y_train_pred_probas = logitreg_grid.predict_proba(train_X)[:, 1] # prob of predict as 1 fpr, tpr, thresholds = roc_curve(train_y, y_train_pred_probas) # precision_recall_curve roc = pd.DataFrame({&#39;FPR&#39;:fpr, &#39;TPR&#39;:tpr, &#39;Thresholds&#39;:thresholds}) plt.figure() plt.title(&#39;ROC Curve&#39;, y = 1, fontsize = 15) plt.plot(roc.FPR, roc.TPR) plt.axvline(new_thresholds, color = &#39;#00C851&#39;, linestyle = &#39;--&#39;) plt.xlabel(&quot;FPR&quot;) plt.ylabel(&quot;TPR&quot;) plt.show() new_threshold = 0.1 # 0.5 is the default value plot_roc(new_threshold, logitreg_grid) png By default, the threshold is 0.5. Since the recall score is low, I'm trying to lower the threshold to get more predicted as Positive. At the same time, more True Negative data will be falsely predicted as Positive. So the Precision score will be lower. y_test_pred_probas = logitreg_grid.predict_proba(test_X)[:, 1] y_test_pred = (y_test_pred_probas &gt;= new_threshold).astype(int) print(&quot;After change threshold to 0.1, the recall socre on Test data is:&quot;) print(recall_score(test_y, y_test_pred)) # 0.736 print(&quot;After change threshold to 0.1, the precision socre on Test data is:&quot;) print(precision_score(test_y, y_test_pred)) # 0.301 print(&quot;After change threshold to 0.1, the Confusion Matrix on Test data is:&quot;) print(confusion_matrix(test_y, y_test_pred)) # [[3002 188][ 29 81]] After change threshold to 0.1, the recall socre on Test data is: 0.7142857142857143 After change threshold to 0.1, the precision socre on Test data is: 0.25 After change threshold to 0.1, the Confusion Matrix on Test data is: [[2714 195] [ 26 65]] Create Over-sampling data and Fit the model oversample_ratio = sum(train_y == 0) / sum(train_y == 1) # size to repeat y == 1 # repeat the positive data for X and y y_train_pos_oversample = pd.concat([train_y[train_y==1]] * int(oversample_ratio), axis = 0) X_train_pos_oversample = pd.concat([train_X.loc[train_y==1, :]] * int(oversample_ratio), axis = 0) # concat the repeated data with the original data together y_train_oversample = pd.concat([train_y, y_train_pos_oversample], axis = 0).reset_index(drop = True) X_train_oversample = pd.concat([train_X, X_train_pos_oversample], axis = 0).reset_index(drop = True) print(y_train_oversample.value_counts(dropna = False, normalize = True)) logitreg_parameters = {&#39;C&#39;: np.power(10.0, np.arange(-3, 3))} logitreg = LogisticRegression(verbose = 3, warm_start = True) logitreg_grid = GridSearchCV(logitreg, param_grid = logitreg_parameters, scoring = &#39;roc_auc&#39;, n_jobs = 1) logitreg_grid.fit(X_train_oversample, y_train_oversample) 1 0.500665 0 0.499335 Name: default, dtype: float64 GridSearchCV(cv=None, error_score=nan, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class=&#39;auto&#39;, n_jobs=None, penalty=&#39;l2&#39;, random_state=None, solver=&#39;lbfgs&#39;, tol=0.0001, verbose=3, warm_start=True), iid=&#39;deprecated&#39;, n_jobs=1, param_grid={&#39;C&#39;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])}, pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=False, scoring=&#39;roc_auc&#39;, verbose=0) # Logistic Regression with Over-sampling plt.figure(figsize=(6, 7), facecolor=&#39;white&#39;) plt.title(&#39;Logistic Regression with Over-sampling&#39;, y=1, fontsize=15) y_pred = logitreg_grid.predict(test_X) plot_data(logitreg_grid, test_X, test_y, y_pred) png # on OVER-Sampled TRAINing data print(&quot;After Over-Sampling, the recall score on Training data is&quot;) print(recall_score(y_train_oversample, logitreg_grid.predict(X_train_oversample))) # 0.865 print(&quot;After Over-Sampling, the precision score on Training data is&quot;) print(precision_score(y_train_oversample, logitreg_grid.predict(X_train_oversample))) # 0.727 # on the TESTing data print(&quot;After Over-Sampling, the recall score on Test data is&quot;) print(recall_score(test_y, logitreg_grid.predict(test_X))) # 0.854 print(&quot;After Over-Sampling, the precision score on Test data is&quot;) print(precision_score(test_y, logitreg_grid.predict(test_X))) # 0.080 print(&quot;After Over-Sampling, the Confusion Matrix on Test data is&quot;) print(confusion_matrix(test_y, logitreg_grid.predict(test_X))) # [[2113 1077][ 16 94]] After Over-Sampling, the recall score on Training data is 0.8884297520661157 After Over-Sampling, the precision score on Training data is 0.8717057631045467 After Over-Sampling, the recall score on Test data is 0.8791208791208791 After Over-Sampling, the precision score on Test data is 0.17094017094017094 After Over-Sampling, the Confusion Matrix on Test data is [[2521 388] [ 11 80]] Conclusion: From the output above, on the training data, the recall score is 0.865 which means 86.5 over 100 of the True conditions are predicted correctly. And 85.4 over 100 of the predicted positives are really positive. However, there is only a precision score of 0.080 on the Test data, which means only 8 out of 100 predicted positives are real positives. From Confusion Matrix, 94 of 110 True Positives are predicted as positives. However, the model predicted 1077 Negative data as Positive. That is, this model has pretty strong over-fitting. Change the Thresholds new_threshold = 0.2 plot_roc(new_threshold, logitreg_grid) png y_test_pred_probas = logitreg_grid.predict_proba(test_X)[:, 1] y_test_pred = (y_test_pred_probas &gt;= new_threshold).astype(int) print(&quot;After change threshold to 0.2, the recall socre on Test data is:&quot;) print(recall_score(test_y, y_test_pred)) # 0.990 print(&quot;After change threshold to 0.2, the precision socre on Test data is:&quot;) print(precision_score(test_y, y_test_pred)) # 0.047 print(&quot;After change threshold to 0.2, the Confusion Matrix on Test data is:&quot;) print(confusion_matrix(test_y, y_test_pred)) # [[ 1013 2177][ 1 109]] After change threshold to 0.2, the recall socre on Test data is: 0.9340659340659341 After change threshold to 0.2, the precision socre on Test data is: 0.10023584905660378 After change threshold to 0.2, the Confusion Matrix on Test data is: [[2146 763] [ 6 85]] Conclusion: After over-sampling, the model will have higher recall rate. That is, the model will work better on detect the Frauds from True Frauds. The price is the lower precision rate. Logistic Regression with class_weight Rather than over-sampling, we can assign more weights to the lower rate class. we can write out the Likelihood function for Logistic Regression, the Over-Sampling and the assigning more Weights will be equivalent. positive_weight = sum(train_y == 0) / sum(train_y == 1) # size to repeat y == 1 logitreg_parameters = {&#39;C&#39;: np.power(10.0, np.arange(-3, 3))} logitreg = LogisticRegression(class_weight = {0 : 1, 1 : positive_weight}, verbose = 3, warm_start = True) logitreg_grid = GridSearchCV(logitreg, param_grid = logitreg_parameters, scoring = &#39;roc_auc&#39;, n_jobs = 1) logitreg_grid.fit(train_X, train_y) GridSearchCV(cv=None, error_score=nan, estimator=LogisticRegression(C=1.0, class_weight={0: 1, 1: 27.925619834710744}, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class=&#39;auto&#39;, n_jobs=None, penalty=&#39;l2&#39;, random_state=None, solver=&#39;lbfgs&#39;, tol=0.0001, verbose=3, warm_start=True), iid=&#39;deprecated&#39;, n_jobs=1, param_grid={&#39;C&#39;: array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])}, pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=False, scoring=&#39;roc_auc&#39;, verbose=0) # Logistic Regression with class_weight plt.figure(figsize=(6, 7), facecolor=&#39;white&#39;) plt.title(&#39;Logistic Regression&#39;, y=1, fontsize=15) y_pred = logitreg_grid.predict(test_X) plot_data(logitreg_grid, test_X, test_y, y_pred) png print(&quot;After assign class_weight, the recall score on Training data is&quot;) print(recall_score(y_train_oversample, logitreg_grid.predict(X_train_oversample))) # 0.856 print(&quot;After assign class_weight, the precision score on Training data is&quot;) print(precision_score(y_train_oversample, logitreg_grid.predict(X_train_oversample))) # 0.729 # on the separated TEST data print(&quot;After assign class_weight, the recall score on Test data is&quot;) print(recall_score(test_y, logitreg_grid.predict(test_X))) # 0.845 print(&quot;After assign class_weight, the precision score on Test data is&quot;) print(precision_score(test_y, logitreg_grid.predict(test_X))) # 0.081 print(&quot;After assign class_weight, the Confusion Matrix on Test data is&quot;) print(confusion_matrix(test_y, logitreg_grid.predict(test_X))) # [[2135 1055] [ 17 93]] print(&quot;After assign class_weight, the ROC AUC Score on Test data is&quot;) print(roc_auc_score(test_y, logitreg_grid.predict(test_X))) # 0.757 After assign class_weight, the recall score on Training data is 0.859504132231405 After assign class_weight, the precision score on Training data is 0.7171530599679843 After assign class_weight, the recall score on Test data is 0.8791208791208791 After assign class_weight, the precision score on Test data is 0.075046904315197 After assign class_weight, the Confusion Matrix on Test data is [[1923 986] [ 11 80]] After assign class_weight, the ROC AUC Score on Test data is 0.7700863934965 Conclusion: If I set up the class weight for the positive as the ratio of non-Fault / Fault, I will get the result close to the over-sampling. So, in summary: This specific data is about fraud detection. So the model should focus on to find the frauds to avoid potential loss for the bank. That is, we focus on recall rate. Conclusion If we use the imbalanced data directly, we will get low performance model since the model prefer to predict to the class with dominated frequency class. The recall rate is 0.31. That is, only 31% of the frauds can be detected by this model. To fix that, one way is to do over-sampling or down-sampling. If we use over-sampling, the model performance will be improved a lot. For this specific case, the recall rate on the independent test set will be improved from 0.31 to 0.87 Another way to improve the model performance is to assign more weights to the low frequency class. Generally speaking, for Logistic Regression, assigning weights is similar to over-sampling, from the likelihood function perspective. The final output results are close too as demonstrated above. Reference Credit Card Fraud Detection / Imbalanced data modeling - Part I: Logistic Regression Credit Fraud || Dealing with Imbalanced Datasets","categories":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Machine Learning","slug":"Technology/Machine-Learning","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/"},{"name":"Imbalanced Data Modeling","slug":"Technology/Machine-Learning/Imbalanced-Data-Modeling","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/Imbalanced-Data-Modeling/"}],"tags":[{"name":"LDA","slug":"LDA","permalink":"https://littlelittlemoon.github.io/tags/LDA/"},{"name":"QDA","slug":"QDA","permalink":"https://littlelittlemoon.github.io/tags/QDA/"},{"name":"LR","slug":"LR","permalink":"https://littlelittlemoon.github.io/tags/LR/"},{"name":"Imbalanced Data Modeling","slug":"Imbalanced-Data-Modeling","permalink":"https://littlelittlemoon.github.io/tags/Imbalanced-Data-Modeling/"},{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://littlelittlemoon.github.io/tags/Machine-Learning/"},{"name":"Classify","slug":"Classify","permalink":"https://littlelittlemoon.github.io/tags/Classify/"}],"keywords":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Machine Learning","slug":"Technology/Machine-Learning","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/"},{"name":"Imbalanced Data Modeling","slug":"Technology/Machine-Learning/Imbalanced-Data-Modeling","permalink":"https://littlelittlemoon.github.io/categories/Technology/Machine-Learning/Imbalanced-Data-Modeling/"}]},{"title":"Evalution of hair and scalp condition based on microscopy image analysis | Hair Thickness - part 1","slug":"Technology/Evalution of hair and scalp condition based on microscopy image analysis  | Hair Thickness - 1","date":"2019-12-29T13:21:24.000Z","updated":"2020-04-12T13:06:54.540Z","comments":true,"path":"2019/12/29/Technology/Evalution of hair and scalp condition based on microscopy image analysis  | Hair Thickness - 1/","link":"","permalink":"https://littlelittlemoon.github.io/2019/12/29/Technology/Evalution%20of%20hair%20and%20scalp%20condition%20based%20on%20microscopy%20image%20analysis%20%20|%20Hair%20Thickness%20-%201/","excerpt":"","text":"Paper: Evalution of hair and scalp condition based on microscopy image analysis æ‘˜è¦ç¿»è¯‘ï¼šç”±äºITæŠ€æœ¯çš„å¿«é€Ÿéƒ¨ç½²ï¼ŒåŒ»ç–—ä¿å¥æœåŠ¡è¿›å…¥äº†ä¸€ä¸ªæ–°æ—¶ä»£ã€‚è¯¸å¦‚å¿ƒè„ç›‘æŠ¤ä¹‹ç±»çš„æŸäº›æœåŠ¡å¯¹äºç”Ÿå‘½è‡³å…³é‡è¦ï¼Œå¹¶æœ‰åŠ©äºæŒ½æ•‘ç”Ÿå‘½ã€‚å¦ä¸€æ–¹é¢ï¼Œç›‘æµ‹è„±å‘æ˜¯å¦ä¸€ç§æœ‰è¶£çš„ä¿å¥æœåŠ¡ã€‚å°½ç®¡è¿™å¯¹ç”Ÿæ´»å¹¶ä¸é‡è¦ï¼Œä½†äººä»¬è¿˜æ˜¯ä¼šéå¸¸æ³¨æ„è‡ªå·±çš„å¤´å‘çŠ¶å†µã€‚è„±å‘æ˜¯ä¸å¤´å‘çŠ¶å†µæœ‰å…³çš„ä¸»è¦é—®é¢˜ä¹‹ä¸€ï¼Œå› ä¸ºè¿‡å¤šå’Œæ— æ„çš„è„±å‘å¯èƒ½å¯¼è‡´ç§ƒå¤´ã€‚å¯ä»¥åœ¨æŠ¤å‘åº—ä¸“ä¸šè¿›è¡ŒæŠ¤å‘ï¼Œä½†æ˜¯è¿™éœ€è¦å¾ˆå¤šæ—¶é—´å’Œæˆæœ¬ã€‚æœ€è¿‘ï¼Œç”±äºå»‰ä»·çš„æ™ºèƒ½è®¾å¤‡ï¼Œå¯¹å¤´å‘çŠ¶å†µçš„è‡ªæˆ‘è¯Šæ–­å·²æˆä¸ºå¯èƒ½ã€‚ä»ç„¶å¾ˆå°‘å¼€å‘ç”¨äºè¯„ä¼°å¤´å‘çŠ¶å†µçš„åº”ç”¨ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°æ–¹æ¡ˆï¼Œé€šè¿‡ä»æ˜¾å¾®é•œå›¾åƒä¸­æå–å„ç§ç‰¹å¾æ¥è¯„ä¼°å¤´å‘å’Œå¤´çš®çš„çŠ¶å†µã€‚å…¶ç‰¹å¾åŒ…æ‹¬å¤´å‘çš„åšåº¦ï¼Œå¤´å‘çš„å¯†åº¦å’Œå¤´çš®çš„æ–‘ç‚¹ã€‚é€šè¿‡å¯¹åŸå‹ç³»ç»Ÿè¿›è¡Œå¹¿æ³›çš„å®éªŒï¼Œæˆ‘ä»¬è¯æ˜äº†è¯¥æ–¹æ¡ˆçš„æœ‰æ•ˆæ€§ã€‚ ä¸ºäº†åˆ†æå¤´çš®å›¾åƒï¼Œåº”è¯¥å°†å¤´å‘å’Œå¤´çš®å½¼æ­¤åˆ†å¼€ã€‚ä¸¤è€…ä¹‹é—´æœ€æ˜æ˜¾çš„åŒºåˆ«æ˜¯å®ƒä»¬çš„é¢œè‰²ã€‚å¤´çš®ç›¸å¯¹æ˜äº®ï¼Œå¤´å‘ç›¸å¯¹æ·±è‰²ã€‚å› æ­¤ï¼Œåœ¨è®¸å¤šç ”ç©¶ä¸­ï¼Œæ ¹æ®é¢œè‰²å¯¹å¤´å‘å’Œå¤´çš®åŒºåŸŸè¿›è¡Œåˆ†ç±»ï¼Œå¹¶æ ¹æ®è¿™ç§åˆ†ç¦»è¿›è¡Œå›¾åƒåˆ†æã€‚ ## Overall steps for feature extraction Pre-processing è¯¥è®ºæ–‡ä¸­æ‰€æåˆ°çš„å›¾ç‰‡é¢„å¤„ç†æ–¹æ³•å’Œâ€œAn Unsupervised Hair Segmentation and Counting System in Microscopy Imagesâ€ä¸­ç›¸ä¼¼ï¼Œå…·ä½“å¯å‚è€ƒï¼šè®ºæ–‡è§£è¯» - An Unsupervised Hair Segmentation and Counting System in Microscopy Images ä¹‹å¤´å‘è®¡æ•°é—®é¢˜ã€‚ 1. è£åˆ‡å›¾åƒ 2. å›¾åƒå¢å¼º: ä½¿ç”¨Contrast stretchingæ–¹æ³•ï¼Œå¢åŠ å›¾åƒçš„å¯¹æ¯”åº¦ 3. Morphological openingï¼šå»é™¤æ²¹æ€§å’Œæ¹¿æ¶¦çš„å¤´å‘åœ¨å…¶æ˜¾å¾®é•œå›¾åƒä¸­å½¢æˆçš„äº®ç‚¹ 4. äºŒå€¼åŒ–ï¼šç»è¿‡ä¸Šè¿°é¢„å¤„ç†åï¼Œå°†æ‰€å¾—å›¾åƒè½¬æ¢ä¸ºç°åº¦å›¾åƒï¼Œç„¶åæ ¹æ®Otsué˜ˆå€¼è½¬æ¢ä¸ºäºŒè¿›åˆ¶å›¾åƒã€‚ åœ¨äºŒå€¼å›¾åƒä¸­ï¼Œâ€œ 0â€å’Œâ€œ 1â€åˆ†åˆ«è¡¨ç¤ºå¤´å‘åƒç´ å’Œå¤´çš®åƒç´ ã€‚ hair/scalp image analysis å¤´å‘æ£€æµ‹ æŠ€æœ¯ ä½¿ç”¨Cannyè¾¹ç¼˜æ£€æµ‹ç®—æ³•ä»äºŒè¿›åˆ¶å›¾åƒä¸­è·å–æ¯›å‘è½®å»“ã€‚ ç»“æœ - å›¾2æ˜¾ç¤ºäº†æ£€æµ‹å’Œå»ºæ¨¡å¤´å‘çš„æ‰€æœ‰æ­¥éª¤ã€‚å¯¹äºå›¾2ï¼ˆaï¼‰ä¸­çš„åŸå§‹æ˜¾å¾®é•œå›¾åƒï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—å‡ºå¤´å‘è½®å»“å’Œéª¨éª¼ã€‚ - é€šè¿‡ä½¿ç”¨äºŒè¿›åˆ¶å›¾åƒä¸Šçš„ç¨€ç–è¿ç®—ï¼ˆThinning operationï¼‰ æ¥è®¡ç®—å¤´å‘éª¨æ¶ã€‚Thinningæ˜¯ä¸€ç§å½¢æ€å­¦è¿ç®—ï¼Œå¯å»é™¤æ•´ä¸ªäºŒè¿›åˆ¶å›¾åƒä¸­çš„å‰æ™¯ã€‚ - å›¾2ï¼ˆdï¼‰æ˜¾ç¤ºäº†é€šè¿‡å åŠ å¤´å‘è½®å»“å’Œéª¨éª¼å¾—åˆ°çš„æœ€ç»ˆå›¾åƒã€‚ å¤´å‘åšåº¦è®¡ç®— å¤´å‘åšåº¦å¯ä»¥é€šè¿‡ä¸å¤´å‘å‚ç›´çº¿çš„é•¿åº¦æ¥å®šä¹‰ã€‚è¦è·å¾—å‚ç›´çº¿ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦è®¡ç®—å¤´å‘æ–¹å‘. é€šè¿‡è€ƒè™‘ç›¸é‚»åƒç´ å¹¶åº”ç”¨PCAï¼ˆä¸»æˆåˆ†åˆ†æï¼‰ç®—æ³•æ¥è®¡ç®—æ¯ä¸ªåƒç´ çš„æ–¹å‘. å½“è®¡ç®—å¤´å‘éª¨æ¶ä¸Šæ‰€æœ‰ç‚¹çš„æ–¹å‘æ—¶ï¼Œå¯ä»¥è®¡ç®—å‡ºæ¯ä¸ªç‚¹çš„å‚ç›´çº¿ã€‚ç„¶åï¼Œå‚ç›´çº¿ä¸å¤´å‘è¾¹ç•Œçš„äº¤ç‚¹ä¹‹é—´çš„è·ç¦»å°±æ˜¯å¤´å‘çš„åšåº¦ï¼Œå¯ä»¥é€šè¿‡ä½¿ç”¨æ¬§æ°è·ç¦»æ¥è®¡ç®—ï¼š \\[ \\rho = \\sqrt{\\smash[b]{(x_2-x_1)^2 + (y_2-y_1)^2}} \\] æ ¹æ®æ¬§å¼è·ç¦»\\(\\rho\\)å¯è®¡ç®—å‡ºå¤´å‘çš„å¹³å‡åšåº¦ï¼š \\[ Thinckness_{avg} =\\frac{1}{n}\\displaystyle\\sum_{i=1}^n\\sqrt{\\smash[b]{(x_{i2}-x_{i1})^2 + (y_{i2}-y_{i1})^2}} \\] è¿™é‡Œ\\(Thinckness_{avg}\\)çš„å•ä½æ˜¯åƒç´ ï¼Œå› æ­¤éœ€è¦ä½¿ç”¨ç­‰å¼å°†å…¶æ›´æ”¹ä¸ºä»ªè¡¨å•ä½: \\[ Thinckness_{actual}(um) = \\frac{Thinckness_{avg}(px) Ã—UL(um/px)}{mf} \\] \\(mf\\): æ˜¯ç›¸æœºçš„æ”¾å¤§å€ç‡ \\(UL\\): æ˜¯å•ä½é•¿åº¦ï¼Œè¡¨ç¤ºä¸€ä¸ªåƒç´ çš„å¾®ç±³é•¿åº¦ å®éªŒç»“æœ ä¸ºäº†è¯„ä¼°æˆ‘ä»¬çš„å¤´å‘åšåº¦è¯„ä¼°æ–¹æ³•çš„å‡†ç¡®æ€§ï¼Œæˆ‘ä»¬ä½¿ç”¨ç”µå­æ˜¾å¾®é•œæµ‹é‡äº†å®é™…çš„å¤´å‘åšåº¦ã€‚å¤´å‘åšåº¦æµ‹é‡çš„å‡†ç¡®æ€§å¦‚è¡¨1æ‰€ç¤ºã€‚ table_1_AVERAGE_HAIR_THICKNESS_AND_ERROR_RATE æ®æŠ¥é“ï¼ŒéŸ©å›½äººçš„å¹³å‡å¤´å‘åšåº¦ä¸º84.9Î¼mã€‚ä¸æ­¤ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„90.29Î¼mçš„ç»“æœç›¸å½“ä¸é”™ã€‚å®é™…å€¼ï¼ˆé€šè¿‡ç”µå­æ˜¾å¾®é•œè®¡ç®—ï¼‰ä¸ä¼°è®¡å€¼ä¹‹é—´çš„å·®å¼‚å¾ˆå°ã€‚ å¯èƒ½çš„åŸå› ä¹‹ä¸€æ˜¯é˜´å½±æ•ˆæœã€‚å¦ä¸€ä¸ªå¯èƒ½çš„åŸå› æ˜¯ç›¸æœºé•œå¤´å˜å½¢ã€‚ å›¾åƒå°ºå¯¸ä¸º640x480ã€‚ä½†æ˜¯ï¼Œç›¸æœºæ‰€è¦†ç›–åŒºåŸŸçš„çœŸå®å½¢çŠ¶å‡ ä¹æ˜¯æ¤­åœ†å½¢ã€‚å› æ­¤ï¼Œç›¸æœºæ”¾å¤§ç‡åœ¨è¡Œå’Œåˆ—ä¹‹é—´å…·æœ‰å·®å¼‚ã€‚æ ¹æ®æ‹æ‘„è§’åº¦ï¼Œæ”¾å¤§å€ç‡å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒã€‚ æ€»ç»“ é’ˆå¯¹å¤´å‘ç²—ç»†ï¼ˆåšåº¦ï¼‰è®¡ç®—é—®é¢˜ï¼Œä¸Šè¿°è®ºæ–‡æå‡ºäº†åŸºäºå¤´å‘è½®å»“å’Œéª¨éª¼å›¾ï¼Œé€šè¿‡è®¡ç®—æ¯ä¸ªåƒç´ ç‚¹çš„æ–¹å‘å’Œå‚çº¿ï¼Œè¿›ä¸€æ­¥ä½¿ç”¨æ¬§å¼è·ç¦»å…¬å¼æ¥è®¡ç®—å¤´å‘çš„å‚ç›´ç›´å¾„ï¼Œä½†å¯¹ç›¸å…³æŠ€æœ¯çš„åº”ç”¨ç»†èŠ‚æè¿°ä¸å¤šã€‚ å‚è€ƒæ–‡çŒ® Evalution of hair and scalp condition based on microscopy image analysis An Unsupervised Hair Segmentation and Counting System in Microscopy Images Euclidean distance Principal component analysis","categories":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Paper Smash","slug":"Technology/Paper-Smash","permalink":"https://littlelittlemoon.github.io/categories/Technology/Paper-Smash/"}],"tags":[{"name":"Digital Image Processing","slug":"Digital-Image-Processing","permalink":"https://littlelittlemoon.github.io/tags/Digital-Image-Processing/"},{"name":"Line Detection","slug":"Line-Detection","permalink":"https://littlelittlemoon.github.io/tags/Line-Detection/"},{"name":"Paper","slug":"Paper","permalink":"https://littlelittlemoon.github.io/tags/Paper/"},{"name":"Hair Thickness","slug":"Hair-Thickness","permalink":"https://littlelittlemoon.github.io/tags/Hair-Thickness/"}],"keywords":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Paper Smash","slug":"Technology/Paper-Smash","permalink":"https://littlelittlemoon.github.io/categories/Technology/Paper-Smash/"}]},{"title":"An Unsupervised Hair Segmentation and Counting System in Microscopy Images | Hair Counting - part 2","slug":"Technology/An Unsupervised Hair Segmentation and Counting System in Microscopy Images | Hair Counting - 2","date":"2019-12-28T15:51:27.000Z","updated":"2020-04-18T10:50:20.994Z","comments":true,"path":"2019/12/28/Technology/An Unsupervised Hair Segmentation and Counting System in Microscopy Images | Hair Counting - 2/","link":"","permalink":"https://littlelittlemoon.github.io/2019/12/28/Technology/An%20Unsupervised%20Hair%20Segmentation%20and%20Counting%20System%20in%20Microscopy%20Images%20|%20Hair%20Counting%20-%202/","excerpt":"","text":"Paper: An Unsupervised Hair Segmentation and Counting System in Microscopy Images &#x6458;&#x8981;&#x7FFB;&#x8BD1;&#xFF1A;&#x672C;&#x6587;&#x91CD;&#x70B9;&#x4ECB;&#x7ECD;&#x4F7F;&#x7528;&#x9AD8;&#x7EA7;&#x56FE;&#x50CF;&#x5904;&#x7406;&#x7B97;&#x6CD5;&#x5F00;&#x53D1;&#x7528;&#x4E8E;&#x4E34;&#x5E8A;&#x7684;&#x533B;&#x5B66;&#x8F6F;&#x4EF6;&#x3002;&#x672C;&#x6587;&#x8BA8;&#x8BBA;&#x4E86;&#x5934;&#x53D1;&#x5206;&#x5272;&#x548C;&#x8BA1;&#x6570;&#x7684;&#x4E09;&#x4E2A;&#x5173;&#x952E;&#x95EE;&#x9898;: - &#x9996;&#x5148;&#xFF0C;&#x53BB;&#x9664;&#x7531;&#x4E8E;&#x6CB9;&#x8102;&#x6216;&#x6C34;&#x5206;&#x5F15;&#x8D77;&#x7684;&#x4EFB;&#x4F55;&#x4EAE;&#x70B9;&#xFF0C;&#x8FD9;&#x4E9B;&#x4EAE;&#x70B9;&#x5728;&#x5934;&#x53D1;&#x7684;&#x4E2D;&#x90E8;&#x5F62;&#x6210;&#x5706;&#x5F62;&#x56FE;&#x6848;&#xFF0C;&#x5E76;&#x663E;&#x7740;&#x5F71;&#x54CD;&#x786E;&#x5B9A;&#x7EBF;&#x6761;&#x7684;&#x51C6;&#x786E;&#x6027;&#x3002; - &#x7B2C;&#x4E8C;&#xFF0C;&#x8BC6;&#x522B;&#x51FA;&#x4E24;&#x4E2A;&#x63A5;&#x89E6;&#x6216;&#x91CD;&#x53E0;&#x7684;&#x5934;&#x53D1;&#xFF0C;&#x5E76;&#x5C06;&#x5176;&#x89C6;&#x4E3A;&#x5355;&#x4E2A;&#x5934;&#x53D1;&#x3002;&#x4E3A;&#x4E86;&#x89E3;&#x51B3;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#xFF0C;&#x6211;&#x4EEC;&#x63D0;&#x51FA;&#x4E86;&#x4E00;&#x79CD;&#x5934;&#x53D1;&#x6346;&#x7ED1;&#x7B97;&#x6CD5;(hair-bundling algorithm)&#x6765;&#x8BA1;&#x7B97;&#x4EFB;&#x4F55;&#x9690;&#x85CF;&#x7684;&#x5934;&#x53D1;&#x3002; - &#x6700;&#x540E;&#xFF0C;&#x5934;&#x53D1;&#x53EF;&#x80FD;&#x5448;&#x6CE2;&#x6D6A;&#x72B6;&#x6216;&#x5377;&#x66F2;&#x72B6;&#xFF0C;&#x8FD9;&#x4F7F;&#x4F20;&#x7EDF;&#x7684;&#x57FA;&#x4E8E;Hough&#x7684;&#x7EBF;&#x68C0;&#x6D4B;&#x7B97;&#x6CD5;&#x4E0D;&#x5408;&#x9002;&#xFF0C;&#x56E0;&#x4E3A;&#x5B83;&#x4F1A;&#x53D7;&#x5230;&#x53C2;&#x6570;&#x9009;&#x62E9;&#x7684;&#x5F71;&#x54CD;&#xFF0C;&#x4F8B;&#x5982;&#x7EBF;&#x6BB5;&#x7684;&#x6700;&#x5C0F;&#x957F;&#x5EA6;&#x4EE5;&#x53CA;&#x7EBF;&#x6BB5;&#x4E4B;&#x95F4;&#x7684;&#x8DDD;&#x79BB;&#x3002;&#x6211;&#x4EEC;&#x63D0;&#x51FA;&#x7684;&#x6BDB;&#x53D1;&#x8BA1;&#x6570;&#x7B97;&#x6CD5;&#x6BD4;&#x57FA;&#x4E8E;Hough&#x7684;&#x6BDB;&#x53D1;&#x8BA1;&#x6570;&#x7B97;&#x6CD5;&#x8981;&#x51C6;&#x786E;&#x5F97;&#x591A;&#xFF0C;&#x5E76;&#x4E14;&#x5728;&#x5404;&#x79CD;&#x767D;&#x5E73;&#x8861;&#x4E0B;&#x5BF9;&#x5377;&#x53D1;&#xFF0C;&#x6CB9;&#x6027;&#x5934;&#x76AE;&#xFF0C;&#x566A;&#x58F0;&#x8150;&#x8680;&#x548C;&#x91CD;&#x53E0;&#x7684;&#x5934;&#x53D1;&#x90FD;&#x5177;&#x6709;&#x9002;&#x7528;&#x6027;&#x3002; - &#x5173;&#x952E;&#x8BCD;&#xFF1A;&#x6BDB;&#x53D1;&#x8BA1;&#x6570;&#xFF0C;&#x5934;&#x76AE;&#x8BCA;&#x65AD;&#xFF0C;&#x62A4;&#x53D1;&#x8BCA;&#x65AD;&#xFF0C;&#x6BDB;&#x56CA;&#x8BCA;&#x65AD;&#xFF0C;&#x7EBF;&#x6BB5;&#x68C0;&#x6D4B;&#x3002; System flowchart figure 1 System flowchart &#x9884;&#x5904;&#x7406;&#x9636;&#x6BB5; (Preprocessing Stage) &#x4F7F;&#x7528;&#x5BF9;&#x6BD4;&#x5EA6;&#x62C9;&#x4F38;&#x65B9;&#x6CD5;(the contrast-stretching method)&#x6765;&#x589E;&#x52A0;&#x5934;&#x76AE;&#x548C;&#x5934;&#x53D1;&#x50CF;&#x7D20;&#x4E4B;&#x95F4;&#x7684;&#x5BF9;&#x6BD4;&#x5EA6;; &#x4E3A;&#x4E86;&#x51CF;&#x5C11;&#x4EAE;&#x70B9;&#x7684;&#x5F71;&#x54CD;&#xFF0C;&#x63D0;&#x51FA;&#x4E86;&#x4E00;&#x79CD;&#x5065;&#x58EE;&#x7684;&#x989C;&#x8272;&#x5F62;&#x6001;&#x7B97;&#x6CD5;(morphological algorithm)&#xFF0C;&#x4EE5;&#x4F7F;&#x989C;&#x8272;&#x5E73;&#x6ED1;&#x5E76;&#x4FDD;&#x6301;&#x5934;&#x53D1;&#x7684;&#x4FDD;&#x771F;&#x5EA6;; &#x4E3A;&#x6BCF;&#x4E2A;&#x989C;&#x8272;&#x5206;&#x91CF;&#x5E94;&#x7528;&#x4E86;Karhunen-Lo&#xE8;ve&#x53D8;&#x6362;(KLT)&#xFF0C;&#x5E76;&#x4FDD;&#x7559;&#x4E86;&#x5177;&#x6709;&#x6700;&#x9AD8;&#x80FD;&#x91CF;&#x7684;&#x5206;&#x91CF;&#xFF0C;&#x5E76;&#x4F7F;&#x7528;Otsu&#x9608;&#x503C;&#x83B7;&#x5F97;&#x4E86;&#x53EF;&#x9760;&#x7684;&#x4E8C;&#x8FDB;&#x5236;&#x56FE;&#x50CF;&#x3002; &#x6570;&#x636E;&#x91C7;&#x96C6;&#x89C4;&#x5B9A; &#x8FD9;&#x9879;&#x7814;&#x7A76;&#x7684;&#x552F;&#x4E00;&#x5047;&#x8BBE;: &#x5934;&#x53D1;&#x7684;&#x989C;&#x8272;&#x6BD4;&#x76AE;&#x80A4;&#x7684;&#x989C;&#x8272;&#x6DF1;&#x3002; &#x5934;&#x53D1;&#x56FE;&#x50CF;&#x662F;&#x4ECE;&#x6570;&#x7801;&#x663E;&#x5FAE;&#x955C;&#x76F8;&#x673A;&#xFF08;DMC&#xFF09;&#x6355;&#x83B7;&#xFF0C;&#x5185;&#x7F6E;LED&#x589E;&#x5F3A;&#xFF0C;&#x53EF;&#x81EA;&#x52A8;&#x4FDD;&#x6301;&#x4EAE;&#x5EA6;&#x7A33;&#x5B9A;&#x3002;&#x5E94;&#x7528;85&#x500D;&#x7684;&#x53D8;&#x7126;&#x500D;&#x7387;&#x6355;&#x83B7;&#x56FE;&#x50CF;&#x3002;&#x901A;&#x5E38;&#xFF0C;&#x4F7F;&#x7528;&#x5206;&#x8FA8;&#x7387;&#x4E3A;1024&#xD7;768&#xFF0C;&#x76F8;&#x5F53;&#x4E8E;&#x5934;&#x76AE;&#x9762;&#x79EF;&#x662F;0.25&#xD7;0.19&#x82F1;&#x5BF8;&#x3002;&#x6B64;&#x5916;&#xFF0C;&#x57FA;&#x4E8E;DMC&#x7684;&#x767D;&#x5E73;&#x8861;&#x5C06;&#x6355;&#x83B7;&#x7684;&#x56FE;&#x50CF;&#x5206;&#x4E3A;&#x4E24;&#x7EC4;&#xFF1A; - &#x5177;&#x6709;&#x65E5;&#x5149;&#x7684;&#x56FE;&#x50CF;&#x88AB;&#x5206;&#x7C7B;&#x4E3A;&#x6570;&#x636E;&#x96C6;&#xFF03;1&#xFF0C; - &#x5177;&#x6709;&#x8367;&#x5149;&#x7684;&#x56FE;&#x50CF;&#x88AB;&#x5206;&#x7C7B;&#x4E3A;&#x6570;&#x636E;&#x96C6;&#xFF03;2&#x3002; &#x4F7F;&#x7528;&#x5BF9;&#x6BD4;&#x5EA6;&#x62C9;&#x4F38;(Contrast Stretching)&#x8FDB;&#x884C;&#x56FE;&#x50CF;&#x589E;&#x5F3A; &#x76EE;&#x7684; &#x589E;&#x52A0;&#x5934;&#x53D1;&#x548C;&#x5934;&#x76AE;&#x4E4B;&#x95F4;&#x7684;&#x5BF9;&#x6BD4;&#x5EA6;; &#x589E;&#x52A0;&#x5934;&#x53D1;&#x548C;&#x5934;&#x76AE;&#x50CF;&#x7D20;&#x4E4B;&#x95F4;&#x7684;&#x8272;&#x5DEE;&#x3002; &#x6280;&#x672F; &#x901A;&#x8FC7;&#x5206;&#x6BB5;&#x7EBF;&#x6027;&#x5BF9;&#x6BD4;&#x5EA6;&#x62C9;&#x4F38;(color transformation by means of piecewise linear contrast stretching)&#x8FDB;&#x884C;&#x989C;&#x8272;&#x53D8;&#x6362;&#x6765;&#x589E;&#x5F3A;&#x56FE;&#x50CF;&#xFF0C;&#x63D0;&#x9AD8;&#x5BF9;&#x6BD4;&#x5EA6;&#xFF1B; stretched the middle-intensity level, and kept the levels of the low-intensity and high-intensity so as to prevent creating false colors. &#x7ED3;&#x679C; figure_2_image_enhancement_for_the_datasets &#x8FDB;&#x884C;&#x5BF9;&#x6BD4;&#x5EA6;&#x62C9;&#x4F38;&#x65F6;&#xFF0C;&#x4E0D;&#x4F1A;&#x66F4;&#x6539;&#x539F;&#x59CB;&#x5934;&#x53D1;&#x50CF;&#x7D20;&#xFF0C;&#x4E5F;&#x4E0D;&#x4F1A;&#x5938;&#x5927;&#x6CB9;&#x4EAE;&#x50CF;&#x7D20;&#xFF1A; - &#x964D;&#x4F4E;&#x4E86;&#x5934;&#x76AE;&#x50CF;&#x7D20;&#x7684;&#x5F3A;&#x5EA6;; - &#x589E;&#x52A0;&#x4E86;&#x5934;&#x76AE;&#x548C;&#x5934;&#x53D1;&#x4E4B;&#x95F4;&#x7684;&#x8272;&#x5DEE;; - &#x4EAE;&#x70B9;&#x7684;&#x50CF;&#x7D20;&#x4FDD;&#x6301;&#x4E0D;&#x53D8;&#x3002; Bright Spot Removal (BSR) &#x76EE;&#x7684; &#x9664;&#x566A;: &#x53BB;&#x9664;&#x6CB9;&#x6027;&#x548C;&#x6E7F;&#x6DA6;&#x7684;&#x5934;&#x53D1;&#x5728;&#x5934;&#x53D1;&#x7684;&#x4E2D;&#x90E8;&#x4EA7;&#x751F;&#x7684;&#x4EAE;&#x70B9;: &#x6280;&#x672F; color morphological processing approach 1. &#x975E;&#x7EBF;&#x6027;&#x4E2D;&#x503C;&#x6EE4;&#x6CE2;&#x5668;(nonlinear median filter)&#x6D88;&#x9664;&#x767D;&#x70B9;; 2. &#x7A7A;&#x95F4;&#x5E73;&#x6ED1;&#x6EE4;&#x6CE2;&#x5668;(spatial smooth filter)&#x964D;&#x4F4E;&#x767D;&#x70B9;&#x7684;&#x5F3A;&#x5EA6;, &#x7F3A;&#x70B9;&#x662F;&#x6D4B;&#x8BD5;&#x56FE;&#x50CF;&#x7684;&#x975E;&#x6BDB;&#x53D1;&#x533A;&#x57DF;&#x4E5F;&#x5C06;&#x53D8;&#x5F97;&#x6A21;&#x7CCA;; 3. color-based mathematical morphology (MM) method, used it as an ordering process. adopted the MM opening operator to depress the bright spot in the middle of the hairs. - &#x4FB5;&#x8680;&#x56FE;&#x50CF; - &#x653E;&#x5927;&#x56FE;&#x50CF; - opening operation of image f : &#x3B3;M,nB(f) = &#x3C4;M,nB(&#x3B5;M,nB(f)), &#x5176;&#x4E2D;&#x3B5;M,nB&#x548C;&#x3C4;M,nB&#x5206;&#x522B;&#x8868;&#x793A;&#x7ED3;&#x6784;&#x5143;&#x7D20;B&#x5BF9;&#x5927;&#x5C0F;&#x4E3A;n&#x7684;&#x56FE;&#x50CF;f&#x7684;&#x5F62;&#x6001;&#x4FB5;&#x8680;&#x548C;&#x653E;&#x5927;, &#x5BF9;&#x4E8E;&#x50CF;&#x7D20;x: - &#x3B5;M,nB(f)(x) = {f(y) : f(y) = &#x2227;M[f(z)],z &#x2208; n(Bx)} - &#x3C4;M,nB(f)(x) = {f(y) : f(y) = &#x2228;M[f(z)],z &#x2208; n(Bx)} - &#x2227;M&#x548C;&#x2228;M&#x5206;&#x522B;&#x8868;&#x793A;M-ordering&#x7684;&#x6700;&#x9AD8;&#x548C;&#x6700;&#x5C0F;&#x5CF0; 4. &#x4F7F;&#x7528;KLT&#x5C06;&#x5F69;&#x8272;&#x56FE;&#x50CF;&#x8F6C;&#x6362;&#x4E3A;&#x7070;&#x5EA6;&#x56FE;&#x50CF;&#xFF1B; 5. &#x56FE;&#x50CF;&#x4E8C;&#x503C;&#x5316;&#x6B65;&#x9AA4;&#x4E2D;&#xFF0C;&#x4F7F;&#x7528;&#x4E86;Otsu&#x9608;&#x503C;&#xFF08;&#x6307;&#x4EAE;&#x5EA6;&#x7684;&#x80FD;&#x91CF;&#xFF09;&#x4EE5;&#x83B7;&#x5F97;&#x53EF;&#x9760;&#x7684;&#x4E8C;&#x503C;&#x56FE;&#x50CF;&#xFF1B; &#x7ED3;&#x679C; &#x56FE;3&#x793A;&#x51FA;&#x4E86;&#x53BB;&#x9664;&#x6CB9;&#x6027;&#x4EAE;&#x70B9;&#x7684;&#x7ED3;&#x679C;&#xFF1A; &#x56FE;4&#x6BD4;&#x8F83;&#x4E86;&#x4F7F;&#x7528;BSR&#x64CD;&#x4F5C;&#x65F6;&#x7684;&#x7EBF;&#x8DEF;&#x68C0;&#x6D4B;&#xFF0C;&#x5E76;&#x663E;&#x793A;&#x4E86;&#x5BF9;&#x4E8C;&#x503C;&#x5316;&#x548C;&#x7EC6;&#x5316;&#x64CD;&#x4F5C;&#x7684;&#x660E;&#x663E;&#x5F71;&#x54CD;&#x3002;&#x5E26;&#x6709;BSR&#x7684;&#x4E8C;&#x503C;&#x5316;&#x56FE;&#x50CF;&#x5177;&#x6709;&#x51CF;&#x5C11;&#x7684;&#x4EAE;&#x70B9;&#x53CD;&#x5C04;&#xFF0C;&#x5E76;&#x4E14;&#x5728;&#x7EC6;&#x5316;&#x56FE;&#x50CF;&#x4E2D;&#xFF0C;&#x4EAE;&#x70B9;&#x88AB;&#x8F6C;&#x6362;&#x4E3A;&#x5C0F;&#x5706;&#x5708;&#x3002;&#x56FE;4&#xFF08;f&#xFF09;&#x663E;&#x793A;&#xFF0C;&#x5728;&#x7EBF;&#x68C0;&#x6D4B;&#x9636;&#x6BB5;&#xFF0C;&#x4F7F;&#x7528;BSR&#x751F;&#x6210;&#x7684;&#x56FE;&#x50CF;&#x5177;&#x6709;&#x8F83;&#x5C11;&#x7684;&#x4E0D;&#x5FC5;&#x8981;&#x7684;&#x7EBF;&#x6BB5;&#xFF1A; figure_4_comparisons_of_the_hair_thining_and_line_detection Multi-scale Line Detection Stage (MSLD) &#x91C7;&#x7528;&#x6539;&#x8FDB;&#x7684;&#x970D;&#x592B;&#x53D8;&#x6362;(the Hough transform)&#x7B97;&#x6CD5;&#x6765;&#x68C0;&#x6D4B;&#x4E0D;&#x540C;&#x7684;&#x5934;&#x53D1;&#x957F;&#x5EA6;&#xFF0C;&#x5E76;&#x51CF;&#x5C11;&#x7531;&#x4E8E;&#x566A;&#x58F0;&#x5F15;&#x8D77;&#x7684;&#x4EFB;&#x4F55;&#x9519;&#x8BEF;&#x68C0;&#x6D4B;; &#x5C06;&#x5F2F;&#x66F2;&#x7684;&#x5934;&#x53D1;&#x89C6;&#x4E3A;&#x591A;&#x6761;&#x76F4;&#x7EBF;; &#x4E3A;&#x4E86;&#x907F;&#x514D;&#x5728;&#x5E94;&#x7528;&#x7A00;&#x758F;&#x8FC7;&#x7A0B;&#x65F6;&#x4E22;&#x5931;&#x5934;&#x53D1;&#xFF0C;&#x6211;&#x4EEC;&#x4F7F;&#x7528;&#x8FB9;&#x7F18;&#x4FE1;&#x606F;(edge information)&#x6765;&#x53D1;&#x73B0;&#x4EFB;&#x4F55;&#x9690;&#x85CF;&#x6216;&#x91CD;&#x53E0;&#x7684;&#x5934;&#x53D1;&#x3002; &#x603B;&#x4F53;&#x7ED3;&#x6784;&#x5206;&#x6790; &#x76EE;&#x7684; &#x63D0;&#x51FA;&#x591A;&#x5C3A;&#x5EA6;&#x6846;&#x67B6;&#x6765;&#x662F;&#x4E3A;&#x4E86;&#x63D0;&#x9AD8;&#x5934;&#x53D1;&#x68C0;&#x6D4B;&#x7684;&#x51C6;&#x786E;&#x6027;&#xFF1B; &#x5E94;&#x7528;&#x5E73;&#x884C;&#x7EBF;&#x6346;&#x7ED1;&#xFF08;PLB&#xFF09;&#x7B97;&#x6CD5;&#xFF08;parallel line bundling algorithm&#xFF09;&#x6765;&#x8FD8;&#x539F;&#x4EFB;&#x4F55;&#x9690;&#x85CF;&#x6216;&#x91CD;&#x53E0;&#x7684;&#x5934;&#x53D1;&#x3002; &#x6700;&#x540E;&#xFF0C;&#x5C06;&#x77E2;&#x91CF;&#x5316;&#x7684;&#x7EBF;&#x6BB5;&#x7528;&#x4F5C;&#x6BDB;&#x53D1;&#x6807;&#x8BB0;&#x548C;&#x8BA1;&#x6570;&#x6A21;&#x5757;&#x7684;&#x8F93;&#x5165;&#x6570;&#x636E;&#x3002; &#x6280;&#x672F; &#x5BF9;HT&#x5E94;&#x7528;&#x4E86;&#x4E09;&#x4E2A;&#x6BD4;&#x4F8B;&#x7684;&#x56FE;&#x50CF;&#xFF1A;1024&#xD7;768&#xFF08;&#x539F;&#x59CB;&#x6BD4;&#x4F8B;&#xFF09;&#xFF0C;512&#xD7;384&#x548C;256&#xD7;192&#x3002;&#x5BF9;&#x7F29;&#x653E;&#x6BD4;&#x4F8B;&#x56FE;&#x50CF;&#x5E94;&#x7528;&#x4E86;&#x4E24;&#x79CD;&#x5904;&#x7406;&#x65B9;&#x6CD5;&#xFF1A;&#x8FB9;&#x7F18;&#x68C0;&#x6D4B;&#x548C;&#x7EC6;&#x5316;&#x5904;&#x7406;&#x3002; PLB&#x7B97;&#x6CD5;&#x5E94;&#x7528;&#x4E8E;&#x8FB9;&#x7F18;&#x56FE;&#x50CF;&#x4EE5;&#x53D1;&#x73B0;&#x7F3A;&#x5931;&#x7684;&#x7EBF;&#x6BB5; HT&#x88AB;&#x5E94;&#x7528;&#x4E8E;&#x7EC6;&#x5316;&#x56FE;&#x50CF;&#x4EE5;&#x63D0;&#x53D6;&#x7EBF;&#x6BB5;&#x3002;&#x901A;&#x8FC7;&#x5229;&#x7528;PLB&#x7B97;&#x6CD5;&#xFF0C;&#x53EF;&#x4EE5;&#x6062;&#x590D;&#x9690;&#x85CF;&#x548C;&#x91CD;&#x53E0;&#x7684;&#x5934;&#x53D1;&#x3002; &#x6700;&#x540E;&#xFF0C;&#x5C06;&#x77E2;&#x91CF;&#x5316;&#x7684;&#x7EBF;&#x6BB5;&#x91CD;&#x65B0;&#x7F29;&#x653E;&#x4E3A;&#x539F;&#x59CB;&#x5C3A;&#x5BF8;1024&#xD7;768&#xFF0C;&#x5E76;&#x7531;&#x903B;&#x8F91;&#x6216;&#x8FD0;&#x7B97;&#x7B26;&#x8FDB;&#x884C;&#x6574;&#x5408;&#x3002; &#x7ED3;&#x679C; &#x5982;&#x56FE;5&#x6240;&#x793A;&#xFF0C;&#x7531;&#x4E8E;&#x5934;&#x53D1;&#x7684;&#x957F;&#x5EA6;&#x548C;&#x5377;&#x66F2;&#x5EA6;&#x7684;&#x53D8;&#x5316;&#xFF0C;&#x4F7F;&#x7528;&#x5355;&#x5C3A;&#x5EA6;HT&#x4E0D;&#x80FD;&#x68C0;&#x6D4B;&#x6240;&#x6709;&#x7684;&#x5934;&#x53D1;&#xFF1A; figure_5_comparison_of_the_single_scale_and_muti-scale_line_detection &#x56FE;5&#xFF08;a&#xFF09;&#x663E;&#x793A;&#xFF0C;&#x5F53;&#x4E00;&#x6839;&#x5934;&#x53D1;&#x51E0;&#x4E4E;&#x5E73;&#x884C;&#x51FA;&#x73B0;&#xFF0C;&#x4E0E;&#x5176;&#x4ED6;&#x5934;&#x53D1;&#x91CD;&#x53E0;&#x65F6;&#xFF0C;&#x6216;&#x8005;&#x5982;&#x679C;&#x5934;&#x53D1;&#x7684;&#x66F2;&#x7387;&#x8D85;&#x8FC7;HT&#x7684;&#x5BB9;&#x9650;&#xFF0C;&#x90A3;&#x4E48;&#x6700;&#x7EC8;&#x4F1A;&#x9057;&#x6F0F;&#x5927;&#x91CF;&#x7684;&#x5934;&#x53D1;&#xFF0C;&#x8BB8;&#x591A;&#x7EBF;&#x6BB5;&#x6807;&#x7B7E;&#x9519;&#x8BEF;&#x3002; &#x56FE;5&#xFF08;b&#xFF09;&#x793A;&#x51FA;&#x4E86;&#x4F7F;&#x7528;&#x6765;&#x81EA;&#x6240;&#x6709;&#x7F29;&#x653E;&#x56FE;&#x7684;&#x7EBF;&#x6BB5;&#x7684;&#x7ED3;&#x679C;&#xFF0C;&#x4ECE;&#x800C;&#x6539;&#x5584;&#x4E86;&#x5355;&#x4E2A;&#x523B;&#x5EA6;&#x7684;&#x4E0D;&#x8DB3;&#x3002; Parallel Line Bundling (PLB) &#x539F;&#x7406; &#x5E94;&#x7528;Canny&#x8FB9;&#x7F18;&#x68C0;&#x6D4B;&#x5668;&#x83B7;&#x5F97;&#x8FB9;&#x7F18;&#x56FE;&#x3002;&#x5728;&#x56FE;6&#x4E2D;&#xFF0C;&#x5047;&#x8BBE;&#x68C0;&#x6D4B;&#x5230;&#x4E24;&#x6761;&#x5E73;&#x884C;&#x7EBF;A&#x548C;B&#xFF0C;&#x7528;ax+by+ca=0ax + by + c_a = 0ax+by+ca&#x200B;=0&#x548C;ax+by+cb=0ax + by + c_b = 0ax+by+cb&#x200B;=0&#x8868;&#x793A;, d=&#x2223;ca&#x2212;cb&#x2223;a2+b2d=\\frac{|c_a - c_b|} {\\sqrt{a^2 + b^2}}d=a2+b2&#x200B;&#x2223;ca&#x200B;&#x2212;cb&#x200B;&#x2223;&#x200B;&#x8868;&#x793A;&#x7EBF;&#x6BB5;A,B&#x4E4B;&#x95F4;&#x7684;&#x8DDD;&#x79BB;; figure_6_Thining_line_sandwiched_by_two_parallel_lines_with_the_distances_d &#x8BA1;&#x7B97;&#x51FA;&#x5939;&#x6709;&#x7EC6;&#x7EBF;&#x7684;&#x5E73;&#x884C;&#x7EBF;&#x4E4B;&#x95F4;&#x7684;&#x5E73;&#x5747;&#x8DDD;&#x79BB;davgd_{avg}davg&#x200B;&#x3002; &#x5982;&#x679C;d&gt;davgd &gt; d_{avg}d&gt;davg&#x200B;&#xFF0C;&#x5219;&#x5F53;(ddavg)&gt;wth(dd_{avg})&gt;w_{th}(ddavg&#x200B;)&gt;wth&#x200B;&#x65F6;&#xFF0C;&#x5C06;&#x53D1;&#x73B0;&#x9690;&#x85CF;&#x7684;&#x5934;&#x53D1;&#xFF0C;&#x5176;&#x4E2D;wthw_{th}wth&#x200B;&#x8868;&#x793A;&#x8FB9;&#x754C;&#x56E0;&#x5B50;&#xFF0C;&#x5C06;&#x901A;&#x8FC7;&#x5934;&#x76AE;&#x56FE;&#x50CF;&#x7684;&#x5206;&#x8FA8;&#x7387;&#x6839;&#x636E;&#x7ECF;&#x9A8C;&#x8FDB;&#x884C;&#x4FEE;&#x6539;&#x3002; &#x7ED3;&#x679C; &#x5728;&#x56FE;7&#xFF08;a&#xFF09;&#x4E2D;&#xFF0C;&#x5706;&#x5708;&#x8868;&#x793A;&#x9690;&#x85CF;&#x7684;&#x5934;&#x53D1;&#xFF0C;&#x5982;&#x56FE;7&#xFF08;b&#xFF09;&#x6240;&#x793A;&#xFF1A; Hair Labling and Counting &#x4F7F;&#x7528;MSLD&#x6A21;&#x5757;&#xFF0C;&#x5F97;&#x51FA;&#x4E86;&#x4E00;&#x7EC4;&#x7EBF;&#x6BB5;&#x3002;&#x6839;&#x636E;&#x5934;&#x53D1;&#x7684;&#x66F2;&#x7387;&#x548C;&#x65B9;&#x5411;&#xFF0C;&#x5C06;&#x5934;&#x53D1;&#x5B9E;&#x73B0;&#x4E3A;&#x5177;&#x6709;&#x4E0D;&#x540C;&#x957F;&#x5EA6;&#x7684;&#x5206;&#x6BB5;&#x7EBF;&#x5411;&#x91CF;&#x7C07;&#x3002;&#x8FD9;&#x9879;&#x7814;&#x7A76;&#x7684;&#x76EE;&#x7684;&#x662F;&#x51C6;&#x786E;&#x8BA1;&#x7B97;&#x5934;&#x76AE;&#x4E0A;&#x7684;&#x6BDB;&#x53D1;&#x6570;&#x91CF;&#x3002;&#x8FD9;&#x53EF;&#x4EE5;&#x770B;&#x4F5C;&#x662F;&#x805A;&#x7C7B;&#x548C;&#x6807;&#x8BB0;&#x95EE;&#x9898;&#x3002;&#x76EE;&#x6807;&#x662F;&#x5C06;&#x4E00;&#x7EC4;&#x7EBF;&#x6BB5;&#x7EC4;&#x5408;&#x6210;&#x8BED;&#x4E49;&#x201C;&#x5934;&#x53D1;&#x201D;&#x5E76;&#x5206;&#x914D;&#x552F;&#x4E00;&#x7684;&#x6807;&#x7B7E;&#x3002;&#x7531;&#x4E8E;&#x6BCF;&#x6839;&#x5934;&#x53D1;&#x90FD;&#x7531;&#x76F8;&#x4E92;&#x5173;&#x8054;&#x7684;&#x7EBF;&#x6BB5;&#x7EC4;&#x6210;&#xFF0C;&#x56E0;&#x6B64;&#x6211;&#x4EEC;&#x4E3A;&#x6BCF;&#x4E2A;&#x7C07;&#x5206;&#x914D;&#x4E86;&#x552F;&#x4E00;&#x7684;&#x6807;&#x7B7E;&#x3002; &#x6211;&#x4EEC;&#x91C7;&#x7528;&#x4E86;&#x677E;&#x5F1B;&#x6807;&#x8BB0;&#x7B97;&#x6CD5;(Relaxation labeling algorithm)&#x6765;&#x8BC6;&#x522B;&#x6BCF;&#x4E2A;&#x5355;&#x72EC;&#x7684;&#x7EBF;&#x6BB5;&#xFF0C;&#x4EE5;&#x786E;&#x5B9A;&#x4E0E;&#x54EA;&#x4E2A;&#x7EBF;&#x6BB5;&#x76F8;&#x5173;&#x8054;&#x3002; &#x56FE;8&#xFF08;a&#xFF09;&#x663E;&#x793A;&#x4E86;10&#x4E2A;&#x5355;&#x72EC;&#x7684;&#x7EBF;&#x6BB5;&#x7684;&#x793A;&#x4F8B;&#xFF0C;&#x8FD9;&#x4E9B;&#x7EBF;&#x6BB5;&#x88AB;&#x6807;&#x8BB0;&#x4E3A;&#x6765;&#x81EA;&#x540C;&#x4E00;&#x6839;&#x5934;&#x53D1;&#xFF0C;&#x7136;&#x540E;&#x7ED8;&#x5236;&#x5230;&#xFF08;&#x3C1;&#xFF0C;&#x3B8;&#xFF09;&#xFF08;&#x3C1;&#xFF0C;&#x3B8;&#xFF09;&#xFF08;&#x3C1;&#xFF0C;&#x3B8;&#xFF09;&#x5750;&#x6807;&#x7CFB;&#x4E0A;&#xFF0C;&#x5982;&#x56FE;8&#xFF08;b&#xFF09;&#x6240;&#x793A;&#x3002; &#x4EA4;&#x53C9;&#x70B9;&#x5904;&#x7D2F;&#x79EF;&#x56FE;&#x7684;&#x7ED3;&#x679C;&#x5CF0;&#x503C;&#x4E3A;10&#x3002; figure_8_Example_of_line_segment_labeling Relaxation Labeling (RL) &#x677E;&#x5F1B;&#x6807;&#x6CE8;&#xFF08;RL&#xFF09;&#x662F;&#x4E00;&#x79CD;&#x76F8;&#x4E92;&#x5173;&#x8054;&#x7684;&#x56DE;&#x5F52;&#x65B9;&#x6CD5;&#xFF0C;&#x5B83;&#x4F7F;&#x7528;&#x7B26;&#x53F7;&#x6765;&#x63CF;&#x8FF0;&#x6A21;&#x578B;&#x7684;&#x5F62;&#x72B6;&#x3002; &#x5B83;&#x65E8;&#x5728;&#x5C06;&#x76EE;&#x6807;&#x5BF9;&#x8C61;&#xFF08;&#x5373;&#x672C;&#x6587;&#x4E2D;&#x7684;&#x7EBF;&#x6BB5;&#xFF09;&#x4E0E;&#x7B26;&#x53F7;&#x6216;&#x6240;&#x8C13;&#x7684;&#x6807;&#x8BB0;&#xFF08;&#x5373;&#x5934;&#x53D1;&#x6807;&#x7B7E;&#xFF09;&#x8FDB;&#x884C;&#x5339;&#x914D;&#x3002;RL&#x7B97;&#x6CD5;&#x9996;&#x5148;&#x5206;&#x914D;&#x4E00;&#x7EC4;&#x968F;&#x673A;&#x6807;&#x8BB0;&#x3002;&#x7136;&#x540E;&#xFF0C;&#x901A;&#x8FC7;&#x8FED;&#x4EE3;&#x8BA1;&#x7B97;&#xFF0C;&#x53EF;&#x4EE5;&#x83B7;&#x5F97;&#x66F4;&#x51C6;&#x786E;&#xFF0C;&#x66F4;&#x7CBE;&#x786E;&#x7684;&#x6807;&#x8BB0;&#x96C6;&#x3002;&#x5728;&#x672C;&#x7814;&#x7A76;&#x4E2D;&#xFF0C;RL&#x7B97;&#x6CD5;&#x88AB;&#x89C6;&#x4E3A;&#x7528;&#x4E8E;&#x6807;&#x8BB0;&#x6BCF;&#x4E2A;&#x7EBF;&#x6BB5;&#x7684;&#x805A;&#x7C7B;&#x65B9;&#x6CD5;&#x3002; &#x539F;&#x7406; figure_9_Conceptual_schematics_of_the_labeling_algorithm &#x4EE4;C(i&#xFF0C;&#x3BB;&#xFF0C;j&#xFF0C;&#x3BB;&#x2032;)C(i&#xFF0C;&#x3BB;&#xFF0C;j&#xFF0C;&#x3BB;&apos;)C(i&#xFF0C;&#x3BB;&#xFF0C;j&#xFF0C;&#x3BB;&#x2032;)&#x8868;&#x793A;&#x7EA6;&#x675F;&#x4E3A;&#x3BB;&#x7684;&#x7EBF;&#x6BB5;&#x4E0E;&#x7EA6;&#x675F;&#x4E3A;&#x3BB;&apos;&#x7684;&#x7EBF;&#x6BB5;j&#x7684;&#x517C;&#x5BB9;&#x6027;&#xFF0C;&#x5176;&#x7EA6;&#x675F;&#x4E3A;: &#x2211;&#x3BB;C(i&#xFF0C;&#x3BB;&#xFF0C;j&#xFF0C;&#x3BB;&#x2032;)=1\\displaystyle\\sum_{&#x3BB;}C(i&#xFF0C;&#x3BB;&#xFF0C;j&#xFF0C;&#x3BB;&apos;) = 1&#x3BB;&#x2211;&#x200B;C(i&#xFF0C;&#x3BB;&#xFF0C;j&#xFF0C;&#x3BB;&#x2032;)=1 for &#x2200;i,j,&#x3BB;,&#x3BB;&apos;&#x3002; &#x517C;&#x5BB9;&#x6027;C&#x8868;&#x793A;&#x6807;&#x8BB0;&#x4E3A;&#x3BB;&apos;&#x7684;&#x7EBF;&#x6BB5;j&#x548C;&#x6807;&#x8BB0;&#x4E3A;&#x3BB;&#x7684;&#x7EBF;&#x6BB5;i&#x4E4B;&#x95F4;&#x7684;&#x76F8;&#x4E92;&#x4F9D;&#x8D56;&#x6027;&#x3002; &#x5982;&#x679C;&#x517C;&#x5BB9;&#x6027;&#x4EC5;&#x7531;&#x5230;&#x539F;&#x70B9;&#x7684;&#x8DDD;&#x79BB;&#x51B3;&#x5B9A;&#xFF0C;&#x5219;&#x53EF;&#x80FD;&#x4F1A;&#x51FA;&#x73B0;&#x9519;&#x8BEF;&#x7684;&#x89E3;&#x91CA;&#x3002; &#x56E0;&#x6B64;&#x5C06;&#x517C;&#x5BB9;&#x6027;&#x5B9A;&#x4E49;&#x5982;&#x4E0B;&#xFF1A; C(i&#xFF0C;&#x3BB;&#xFF0C;j&#xFF0C;&#x3BB;&#x2032;)={&#x2212;1if&#xA0;i&#x2209;Sj&#x3B5;&#x2223;cos&#x2061;[&#x3B8;i(&#x3BB;)&#x2212;&#x3B8;j(&#x3BB;&#x2032;)]&#x2223;+(1&#x2212;&#x3B5;)&#x3C1;i(&#x3BB;)&#x3C1;j(&#x3BB;&#x2032;)if&#xA0;i&#x2208;Sj&#x2229;&#x3BB;=/&#x2009;&#x3BB;&#x2032;0otherwise&#xA0; C(i&#xFF0C;&#x3BB;&#xFF0C;j&#xFF0C;&#x3BB;&apos;) = \\begin{cases} -1 &amp;\\text{if } i \\notin S_j \\\\ \\varepsilon |\\cos[\\theta_i(\\lambda) - \\theta_j(&#x3BB;&apos;)]| + (1-\\varepsilon) \\frac{\\rho_i(\\lambda)}{\\rho_j(&#x3BB;&apos;)} &amp;\\text{if } i&#x2208;S_j&#x2229;&#x3BB;{=}\\mathllap{/\\,}&#x3BB;&apos; \\\\ 0 &amp;\\text{otherwise } \\end{cases} C(i&#xFF0C;&#x3BB;&#xFF0C;j&#xFF0C;&#x3BB;&#x2032;)=&#x23A9;&#x23AA;&#x23A8;&#x23AA;&#x23A7;&#x200B;&#x2212;1&#x3B5;&#x2223;cos[&#x3B8;i&#x200B;(&#x3BB;)&#x2212;&#x3B8;j&#x200B;(&#x3BB;&#x2032;)]&#x2223;+(1&#x2212;&#x3B5;)&#x3C1;j&#x200B;(&#x3BB;&#x2032;)&#x3C1;i&#x200B;(&#x3BB;)&#x200B;0&#x200B;if&#xA0;i&#x2208;/&#x200B;Sj&#x200B;if&#xA0;i&#x2208;Sj&#x200B;&#x2229;&#x3BB;=/&#x200B;&#x3BB;&#x2032;otherwise&#xA0;&#x200B; &#x4E0A;&#x5F0F;&#x4E2D;&#xFF1A; &#x3B5;&#x8868;&#x793A;&#x8DDD;&#x79BB;&#x548C;&#x65B9;&#x5411;&#x7F6E;&#x4FE1;&#x5EA6;&#x4E4B;&#x95F4;&#x7684;&#x52A0;&#x6743;&#x56E0;&#x5B50; SjS_jSj&#x200B;&#x8868;&#x793A;&#x7EBF;&#x6BB5;j&#x7684;&#x76F8;&#x90BB;&#x5047;&#x8BBE; &#x3B8;i(&#x3BB;)&#x3B8;_i(&#x3BB;)&#x3B8;i&#x200B;(&#x3BB;)&#x8868;&#x793A;&#x4ECE;&#x7EBF;&#x6BB5;i&#x5230;&#x6807;&#x8BB0;&#x4E3A;&#x3BB;&#x7684;&#x7EBF;&#x6BB5;j&#x7684;&#x65B9;&#x5411; &#x3C1;i(&#x3BB;)&#x3C1;_i(&#x3BB;)&#x3C1;i&#x200B;(&#x3BB;)&#x8868;&#x793A;&#x539F;&#x70B9;&#x5230;&#x7EBF;&#x6BB5;i&#x548C;&#x6807;&#x8BB0;&#x4E3A;&#x3BB;&#x7684;&#x7EBF;&#x6BB5;j&#x4E4B;&#x95F4;&#x7684;&#x8DDD;&#x79BB; &#x5982;&#x679C;&#x3C1;j(&#x3BB;)&#x3C1;_j(&#x3BB;)&#x3C1;j&#x200B;(&#x3BB;)&#x9AD8;, &#x4E14;C(i&#xFF0C;&#x3BB;&#xFF0C;j&#xFF0C;&#x3BB;&#x2032;)C(i&#xFF0C;&#x3BB;&#xFF0C;j&#xFF0C;&#x3BB;&apos;)C(i&#xFF0C;&#x3BB;&#xFF0C;j&#xFF0C;&#x3BB;&#x2032;)&#x4E3A;&#x6B63;&#xFF0C;&#x5219;&#x3C1;i(&#x3BB;)&#x3C1;_i(&#x3BB;)&#x3C1;i&#x200B;(&#x3BB;)&#x589E;&#x52A0;&#x3002; &#x6B64;&#x6807;&#x8BB0;&#x7B97;&#x6CD5;&#x662F;&#x4E00;&#x4E2A;&#x8FED;&#x4EE3;&#x5E76;&#x884C;&#x8FC7;&#x7A0B;&#xFF0C;&#x7C7B;&#x4F3C;&#x4E8E;&#x6982;&#x7387;&#x677E;&#x5F1B;&#x4E2D;&#x4F7F;&#x7528;&#x7684;&#x6807;&#x8BB0;&#x4E22;&#x5F03;&#x89C4;&#x5219;&#xFF0C;&#x64CD;&#x4F5C;&#x5458;&#x6839;&#x636E;&#x5176;&#x4ED6;&#x91CD;&#x91CF;&#x548C;&#x517C;&#x5BB9;&#x6027;&#x53CD;&#x590D;&#x8C03;&#x6574;&#x6807;&#x7B7E;&#x91CD;&#x91CF;&#x3002; &#x5BF9;&#x4E8E;&#x6BCF;&#x4E2A;&#x7EBF;&#x6BB5;&#x548C;&#x6BCF;&#x4E2A;&#x6807;&#x7B7E;&#xFF0C;&#x65B0;&#x6743;&#x91CD;qi(r)(&#x3BB;)q_i^{(r)}(\\lambda)qi(r)&#x200B;(&#x3BB;)&#x7684;&#x8BA1;&#x7B97;&#x5982;&#x4E0B;&#xFF1A; qi(r)(&#x3BB;)=&#x2211;j,j=/&#x2009;i&#x2211;&#x3BB;&#x2032;C(i&#xFF0C;&#x3BB;&#xFF0C;j&#xFF0C;&#x3BB;&#x2032;)pj(r)(&#x3BB;&#x2032;) q_i^{(r)}(\\lambda) = \\sum_{\\mathclap{j, j{=}\\mathllap{/\\,}i}} \\sum_{\\mathclap{&#x3BB;&apos;}}C(i&#xFF0C;&#x3BB;&#xFF0C;j&#xFF0C;&#x3BB;&apos;)p_j^{(r)}(&#x3BB;&apos;) qi(r)&#x200B;(&#x3BB;)=j,j=/&#x200B;i&#x200B;&#x2211;&#x200B;&#x3BB;&#x2032;&#x2211;&#x200B;C(i&#xFF0C;&#x3BB;&#xFF0C;j&#xFF0C;&#x3BB;&#x2032;)pj(r)&#x200B;(&#x3BB;&#x2032;) &#x5176;&#x4E2D;: r&#x8868;&#x793A;&#x7B2C;r&#x6B21;&#x8FED;&#x4EE3; &#x5728;&#x7B49;&#x5F0F;&#x4E2D;&#xFF0C;&#x4E58;&#x79EF;&#x548C;&#x662F;&#x88AB;&#x6807;&#x8BB0;&#x4E3A;&#x3BB;&#x7684;&#x7ED9;&#x5B9A;&#x7EBF;&#x6BB5;i&#x7684;&#x671F;&#x671B; qi(r)(&#x3BB;)q_i^{(r)}(\\lambda)qi(r)&#x200B;(&#x3BB;)&#x662F;&#x5F53;&#x524D;&#x8D4B;&#x503C;pj(r)(&#x3BB;&#x2032;)p_j^{(r)}(&#x3BB;&apos;)pj(r)&#x200B;(&#x3BB;&#x2032;)&#x7684;&#x52A0;&#x6743;&#x548C;&#x3002; &#x65B0;&#x4EFB;&#x52A1;&#x53EF;&#x4EE5;&#x7528;&#x5DF2;&#x4E0B;&#x516C;&#x5F0F;&#x66F4;&#x65B0;&#xFF1A; pi(r+1)(&#x3BB;)=pi(r)(&#x3BB;)[1+qi(r)(&#x3BB;)]&#x2211;j=1mpi(r)(&#x3BB;&#x2032;)[1+qi(r)(&#x3BB;&#x2032;)] p_i^{(r+1)}(\\lambda) = \\frac{p_i^{(r)}(&#x3BB;)[1+q_i^{(r)}(&#x3BB;)]}{\\displaystyle\\sum_{j=1}^mp_i^{(r)}(&#x3BB;&apos;)[1+q_i^{(r)}(&#x3BB;&apos;)]} pi(r+1)&#x200B;(&#x3BB;)=j=1&#x2211;m&#x200B;pi(r)&#x200B;(&#x3BB;&#x2032;)[1+qi(r)&#x200B;(&#x3BB;&#x2032;)]pi(r)&#x200B;(&#x3BB;)[1+qi(r)&#x200B;(&#x3BB;)]&#x200B; &#x5728;&#x8FD9;&#x91CC;&#xFF0C;&#x53EA;&#x9009;&#x62E9;pi(r)(&#x3BB;)p_i^{(r)}(\\lambda)pi(r)&#x200B;(&#x3BB;)&#x548C;C(i&#xFF0C;&#x3BB;&#xFF0C;j&#xFF0C;&#x3BB;&#x2032;)C(i&#xFF0C;&#x3BB;&#xFF0C;j&#xFF0C;&#x3BB;&apos;)C(i&#xFF0C;&#x3BB;&#xFF0C;j&#xFF0C;&#x3BB;&#x2032;)&#x5E76;&#x5E94;&#x7528;&#x8BE5;&#x7B49;&#x5F0F;&#x9012;&#x5F52;&#x66F4;&#x65B0;pi(r)(&#x3BB;)p_i^{(r)}(\\lambda)pi(r)&#x200B;(&#x3BB;)&#xFF0C;&#x76F4;&#x5230;&#x5B83;&#x4EEC;&#x505C;&#x6B62;&#x53D8;&#x5316;&#x6216;&#x6536;&#x655B;&#x5230;1&#x3002;&#x5BF9;&#x6BCF;&#x4E2A;&#x7EBF;&#x6BB5;&#x8FDB;&#x884C;&#x8FED;&#x4EE3;&#x9A8C;&#x8BC1;&#xFF0C;&#x76F4;&#x5230;&#x5C06;&#x5176;&#x5206;&#x914D;&#x7ED9;&#x6B63;&#x786E;&#x7684;&#x8BED;&#x4E49;&#x6807;&#x7B7E;&#x201C; hair&#x201D;&#x4E3A;&#x6B62;&#x3002; &#x5B9E;&#x9A8C;&#x7ED3;&#x679C; &#x4E3A;&#x4E86;&#x8BC4;&#x4F30;&#x8BE5;&#x7CFB;&#x7EDF;&#xFF0C;&#x6211;&#x4EEC;&#x4ECE;UPMOST&#xFF08;UPG622&#xFF09;DMC&#x6355;&#x83B7;&#x4E86;40&#x4E2A;&#x5206;&#x8FA8;&#x7387;&#x4E3A;1024&#xD7;768&#x7684;&#x6BD4;&#x4F8B;&#x5C3A;&#x56FE;&#x50CF;&#x4F5C;&#x4E3A;&#x6D4B;&#x8BD5;&#x6570;&#x636E;&#x96C6;&#x3002;&#x6839;&#x636E;DMC&#x7684;&#x767D;&#x5E73;&#x8861;&#xFF0C;&#x6211;&#x4EEC;&#x5C06;&#x6D4B;&#x8BD5;&#x56FE;&#x50CF;&#x5206;&#x4E3A;&#x4E24;&#x7EC4;&#xFF0C;&#x5206;&#x522B;&#x662F;&#x6570;&#x636E;&#x96C6;1&#x548C;&#x6570;&#x636E;&#x96C6;2&#x3002; Experiment 1: Cross-Validation of the Line Detection figure_10_result_images_for_line_detection &#x56FE;10&#xFF08;b&#xFF09;-&#xFF08;d&#xFF09;&#x663E;&#x793A;&#x4E86;&#x9884;&#x5904;&#x7406;&#x6A21;&#x5757;&#x7684;&#x7ED3;&#x679C;&#xFF0C;&#x5305;&#x62EC;&#x4EAE;&#x70B9;&#x53BB;&#x9664;&#xFF08;BSR&#xFF09;&#xFF0C;&#x4E8C;&#x503C;&#x5316;&#x548C;&#x7A00;&#x5316;&#x8FC7;&#x7A0B;&#x3002; &#x4E3A;&#x4E86;&#x8BC4;&#x4F30;&#x591A;&#x5C3A;&#x5EA6;&#x7EBF;&#x68C0;&#x6D4B;&#x7B97;&#x6CD5;&#x7684;&#x6027;&#x80FD;&#xFF0C;&#x6D4B;&#x8BD5;&#x56FE;&#x50CF;&#x6211;&#x4EEC;&#x5C06;HT&#x5E94;&#x7528;&#x4E8E;&#x4E09;&#x79CD;&#x4E0D;&#x540C;&#x5C3A;&#x5EA6;&#xFF0C;&#x4EE5;&#x63D0;&#x53D6;&#x7EBF;&#x6BB5;&#x3002; &#x7136;&#x540E;&#x4F7F;&#x7528;&#x5934;&#x53D1;&#x6807;&#x7B7E;&#x673A;&#x5236;&#x786E;&#x5B9A;&#x5934;&#x53D1;&#x7684;&#x6570;&#x91CF;&#x3002; &#x5982;&#x56FE;10&#xFF08;e&#xFF09;-&#xFF08;f&#xFF09;&#x6240;&#x793A;&#xFF0C;&#x5F69;&#x8272;&#x7EBF;&#x4EE3;&#x8868;&#x5934;&#x53D1;&#x7684;&#x6807;&#x7B7E;&#x3002; &#x6362;&#x53E5;&#x8BDD;&#x8BF4;&#xFF0C;&#x5373;&#x4F7F;&#x5934;&#x53D1;&#x4EA4;&#x53C9;&#x6216;&#x91CD;&#x53E0;&#xFF0C;&#x4E5F;&#x53EF;&#x4EE5;&#x51C6;&#x786E;&#x5730;&#x6807;&#x8BB0;&#x5934;&#x53D1;&#x3002; &#x4EE5;&#x4E0B;&#x90E8;&#x5206;&#x6F14;&#x793A;&#x4E86;&#x6709;&#x5173;&#x7CBE;&#x786E;&#x5EA6;&#x548C;&#x53EC;&#x56DE;&#x7387;&#x7684;&#x6BDB;&#x53D1;&#x8BA1;&#x6570;&#x7684;&#x5BA2;&#x89C2;&#x6D4B;&#x91CF;&#x3002; &#x6211;&#x4EEC;&#x6BD4;&#x8F83;&#x4E86;&#x4F7F;&#x7528;BSR&#x548C;MSLD&#x6A21;&#x5757;&#x7EC4;&#x5408;&#x7684;&#x56DB;&#x79CD;&#x60C5;&#x51B5;&#xFF0C;&#x5305;&#x62EC;BSR + MSLD&#xFF0C;&#x800C;&#x6CA1;&#x6709;&#x540C;&#x65F6;&#x4F7F;&#x7528;BSR&#x548C;MSLD&#xFF0C;&#x4EC5;BSR&#x548C;&#x4EC5;MSLD&#x3002; table_1_comarison_of_the_system_sensitivity_forthe_module_usages_in_the_line_detection &#x8868;I&#x6BD4;&#x8F83;&#x4E86;&#x57FA;&#x4E8E;&#x6A21;&#x5757;&#x4F7F;&#x7528;&#x60C5;&#x51B5;&#x7684;&#x7CFB;&#x7EDF;&#x654F;&#x611F;&#x6027;&#x3002;&#x57FA;&#x4E8E;&#x5F62;&#x6001;&#x5B66;&#x7684;BSR&#x548C;MSLD&#x673A;&#x5236;&#xFF0C;&#x4EE5;&#x63D0;&#x9AD8;&#x5934;&#x53D1;&#x68C0;&#x6D4B;&#x7684;&#x6027;&#x80FD;&#xFF0C;&#x5176;&#x51C6;&#x786E;&#x7387;&#x5206;&#x522B;&#x4E3A;94.98&#xFF05;&#x548C;98.05&#xFF05;&#x3002;&#x4E0E;&#x4F20;&#x7EDF;&#x7684;HT&#x7EBF;&#x68C0;&#x6D4B;&#x65B9;&#x6CD5;&#x76F8;&#x6BD4;&#xFF0C;&#x6570;&#x636E;&#x96C6;1&#x548C;&#x6570;&#x636E;&#x96C6;2&#x5206;&#x522B;&#x63D0;&#x9AD8;&#x4E86;2&#xFF05;&#x548C;1.5&#xFF05;&#x3002;&#x4ECE;&#x53EC;&#x56DE;&#x7387;&#x7684;&#x89D2;&#x5EA6;&#x6765;&#x770B;&#xFF0C;&#x5B83;&#x4E5F;&#x9AD8;&#x4E8E;&#x5176;&#x4ED6;&#x6A21;&#x5757;&#x7EC4;&#x5408;&#x3002; &#x5E73;&#x5747;&#x800C;&#x8A00;&#xFF0C;&#x6211;&#x4EEC;&#x7684;&#x53EC;&#x56DE;&#x7387;&#x5206;&#x522B;&#x4E3A;9&#xFF05;&#x548C;10&#xFF05;&#x3002;&#x6839;&#x636E;&#x6211;&#x4EEC;&#x7684;&#x89C2;&#x5BDF;&#xFF0C;&#x5E94;&#x7528;BSR&#x540E;&#xFF0C;&#x51C6;&#x786E;&#x7387;&#x5F97;&#x5230;&#x4E86;&#x63D0;&#x9AD8;&#x3002; &#x4F46;&#x662F;&#xFF0C;&#x5C06;MSLD&#x5E94;&#x7528;&#x4E8E;&#x6570;&#x636E;&#x96C6;&#xFF03;2&#x65F6;&#xFF0C;&#x51C6;&#x786E;&#x7387;&#x4E0B;&#x964D;&#xFF0C;&#x56E0;&#x4E3A;&#x5B83;&#x5728;&#x6CB9;&#x6027;&#x5934;&#x76AE;&#x533A;&#x57DF;&#x4E2D;&#x4EA7;&#x751F;&#x4E86;&#x5927;&#x91CF;&#x7684;&#x5149;&#x53CD;&#x5C04;&#x3002;&#x540C;&#x6837;&#xFF0C;&#x5934;&#x53D1;&#x4E2D;&#x90E8;&#x7684;&#x4EAE;&#x70B9;&#x4E5F;&#x88AB;&#x5927;&#x5927;&#x589E;&#x5F3A;&#xFF0C;&#x5BFC;&#x81F4;&#x7CBE;&#x786E;&#x5EA6;&#x964D;&#x4F4E;&#x3002; Experiment 2: System Refinement Using the PLB Algorithm table_2_system_performance_for_with_or_without_PLB &#x8868;II&#x663E;&#x793A;&#x4E86;PLB&#x7B97;&#x6CD5;&#x7684;&#x6548;&#x7387;&#x3002;PLB&#x65B9;&#x6CD5;&#x4F7F;&#x7CFB;&#x7EDF;&#x80FD;&#x591F;&#x63D0;&#x53D6;&#x7F3A;&#x5931;&#x7684;&#x6BDB;&#x53D1;&#xFF0C;&#x7CBE;&#x786E;&#x7387;&#x63D0;&#x9AD8;&#x4E86;0.5&#xFF05;&#xFF0C;&#x53EC;&#x56DE;&#x7387;&#x63D0;&#x9AD8;&#x4E86;5&#xFF05;&#x3002; PLB&#x7B97;&#x6CD5;&#x53EF;&#x4EE5;&#x7528;&#x4F5C;&#x7CFB;&#x7EDF;&#x5FAE;&#x8C03;&#x8FC7;&#x7A0B;&#xFF0C;&#x5C06;&#x7CFB;&#x7EDF;&#x6027;&#x80FD;&#x5E73;&#x5747;&#x63D0;&#x9AD8;&#x5230;96.89&#xFF05;&#x3002;&#x8FD9;&#x662F;&#x5408;&#x7406;&#x7684;&#xFF0C;&#x56E0;&#x4E3A;&#x9690;&#x85CF;&#x7684;&#x5934;&#x53D1;&#x4E0D;&#x7ECF;&#x5E38;&#x51FA;&#x73B0;&#x3002; &#x6B64;&#x5916;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x663E;&#x5FAE;&#x955C;&#x63A7;&#x5236;&#x5934;&#x53D1;&#x56FE;&#x50CF;&#x7684;&#x5206;&#x8FA8;&#x7387;&#x548C;&#x89D2;&#x5EA6;&#xFF0C;&#x4EE5;&#x907F;&#x514D;&#x8FD9;&#x79CD;&#x60C5;&#x51B5;&#x3002; Experiment 3: Complexity Analysis table_3_time_occupancy_of_each_module_compared_with_total_execution &#x5F53;&#x6D89;&#x53CA;&#x5230;&#x7CFB;&#x7EDF;&#x590D;&#x6742;&#x6027;&#x5206;&#x6790;&#x65F6;&#xFF0C;&#x6211;&#x4EEC;&#x77E5;&#x9053;&#x62DF;&#x8BAE;&#x7684;&#x5934;&#x53D1;&#x8BA1;&#x6570;&#x7CFB;&#x7EDF;&#x4F1A;&#x82B1;&#x8D39;&#x66F4;&#x591A;&#x65F6;&#x95F4;&#x3002;&#x5E73;&#x5747;&#x800C;&#x8A00;&#xFF0C;&#x9AD8;&#x5206;&#x8FA8;&#x7387;&#x6D4B;&#x8BD5;&#x56FE;&#x50CF;&#x9700;&#x8981;&#x4E0D;&#x5230;4&#x79D2;&#x7684;&#x65F6;&#x95F4;&#x5373;&#x53EF;&#x5F97;&#x51FA;&#x6BDB;&#x53D1;&#x8BA1;&#x6570;&#x4FE1;&#x606F;&#x3002; &#x8868;III&#x5217;&#x51FA;&#x4E86;&#x6BCF;&#x4E2A;&#x6A21;&#x5757;&#x6240;&#x9700;&#x7684;&#x65F6;&#x95F4;&#x4E0E;&#x603B;&#x6267;&#x884C;&#x65F6;&#x95F4;&#x7684;&#x6BD4;&#x8F83;&#x3002; MSLD&#x4F7F;&#x7528;&#x4E09;&#x4E2A;&#x6BD4;&#x4F8B;&#x5C3A;&#x6765;&#x83B7;&#x53D6;&#x4E00;&#x7EC4;&#x7EBF;&#x6BB5;&#xFF0C;&#x8FD9;&#x9700;&#x8981;&#x5927;&#x90E8;&#x5206;&#x6267;&#x884C;&#x65F6;&#x95F4;&#x3002; HT&#x5C06;&#x8FB9;&#x7F18;&#x6295;&#x5F71;&#x5230;&#xFF08;&#x3C1;&#xFF0C;&#x3B8;&#xFF09;&#x7A7A;&#x95F4;&#x4EE5;&#x63D0;&#x53D6;&#x5C40;&#x90E8;&#x6700;&#x5927;&#x503C;&#x7684;&#x8FC7;&#x7A0B;&#x975E;&#x5E38;&#x8017;&#x65F6;&#x3002; &#x4E3A;&#x4E86;&#x514B;&#x670D;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#xFF0C;&#x6211;&#x4EEC;&#x5728;MSLD&#x4E2D;&#x4EC5;&#x4F7F;&#x7528;&#x4E86;&#x4E24;&#x4E2A;&#x6807;&#x5EA6;&#x3002;&#x4F46;&#x662F;&#xFF0C;&#x6B64;&#x5C1D;&#x8BD5;&#x5BFC;&#x81F4;&#x6027;&#x80FD;&#x4E0B;&#x964D;&#x3002; &#x6B64;&#x5916;&#xFF0C;&#x7EC6;&#x5316;&#x8FC7;&#x7A0B;&#x5360;&#x7528;&#x4E86;&#x603B;&#x5904;&#x7406;&#x65F6;&#x95F4;&#x7684;&#x56DB;&#x5206;&#x4E4B;&#x4E00;&#x4EE5;&#x4E0A;&#x3002;&#x8FD9;&#x662F;&#x6267;&#x884C;&#x65F6;&#x95F4;&#x548C;&#x7CFB;&#x7EDF;&#x7CBE;&#x5EA6;&#x4E4B;&#x95F4;&#x7684;&#x6743;&#x8861;&#x3002; &#x603B;&#x7ED3; &#x8FD9;&#x9879;&#x7814;&#x7A76;&#x63D0;&#x51FA;&#x4E86;&#x4E00;&#x79CD;&#x81EA;&#x52A8;&#x7684;&#x5934;&#x53D1;&#x5206;&#x5272;&#x548C;&#x8BA1;&#x6570;&#x7CFB;&#x7EDF;&#xFF0C;&#x4EE5;&#x51CF;&#x5C11;&#x4EBA;&#x5DE5;&#x8BC4;&#x4F30;&#x8005;&#x8FDB;&#x884C;&#x8BE6;&#x7EC6;&#x5934;&#x76AE;&#x8BC4;&#x4F30;&#x6240;&#x9700;&#x7684;&#x65F6;&#x95F4;&#x3002; 1. &#x9996;&#x5148;&#xFF0C;&#x6CB9;&#x6027;&#x548C;&#x6E7F;&#x6DA6;&#x7684;&#x5934;&#x53D1;&#x4F1A;&#x5728;&#x5934;&#x53D1;&#x4E2D;&#x95F4;&#x4EA7;&#x751F;&#x4EAE;&#x70B9;&#x3002;&#x5728;&#x8BA1;&#x7B97;&#x5934;&#x53D1;&#x6570;&#x4E4B;&#x524D;&#xFF0C;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x6D88;&#x9664;&#x5934;&#x53D1;&#x4E0A;&#x7684;&#x4EAE;&#x70B9;&#xFF0C;&#x4EE5;&#x907F;&#x514D;&#x91CD;&#x590D;&#x8BA1;&#x7B97;&#x4E00;&#x4E9B;&#x5934;&#x53D1;&#x7684;&#x95EE;&#x9898;&#x3002; 2. &#x7B2C;&#x4E8C;&#xFF0C;&#x6CE2;&#x6D6A;&#x72B6;&#x548C;&#x5377;&#x53D1;&#x5BB9;&#x6613;&#x5BFC;&#x81F4;&#x7EBF;&#x68C0;&#x6D4B;&#x6545;&#x969C;&#x3002;&#x5F53;&#x5934;&#x53D1;&#x4E0D;&#x76F4;&#x65F6;&#xFF0C;&#x5E38;&#x89C4;&#x7684;&#x7EBF;&#x68C0;&#x6D4B;&#x7B97;&#x6CD5;&#x65E0;&#x6548;&#x3002; 3. &#x7B2C;&#x4E09;&#xFF0C;&#x5F53;&#x5934;&#x53D1;&#x76F8;&#x4E92;&#x4EA4;&#x53C9;&#x5E76;&#x4E92;&#x76F8;&#x54AC;&#x5408;&#x65F6;&#xFF0C;&#x4F1A;&#x51FA;&#x73B0;&#x5BF9;&#x5934;&#x53D1;&#x6570;&#x91CF;&#x7684;&#x4F4E;&#x4F30;&#xFF0C;&#x8FD9;&#x4F7F;&#x5F97;&#x7CBE;&#x786E;&#x5B9A;&#x4F4D;&#x6240;&#x6709;&#x5934;&#x53D1;&#x975E;&#x5E38;&#x56F0;&#x96BE;&#x3002; 4. &#x6700;&#x540E;&#xFF0C;&#x7531;&#x4E8E;&#x5934;&#x76AE;&#x76F8;&#x5BF9;&#x672A;&#x66DD;&#x5149;&#xFF0C;&#x56E0;&#x6B64;&#x5934;&#x76AE;&#x7684;&#x56FE;&#x50CF;&#x901A;&#x5E38;&#x6A21;&#x7CCA;&#x6216;&#x96BE;&#x4EE5;&#x770B;&#x89C1;&#x3002;&#x53E6;&#x5916;&#xFF0C;&#x5934;&#x76AE;&#x901A;&#x5E38;&#x7167;&#x660E;&#x4E0D;&#x8DB3;&#x6216;&#x66DD;&#x5149;&#x8FC7;&#x5EA6;&#x3002; &#x8BA1;&#x6570;&#x601D;&#x8DEF; &#x901A;&#x8FC7;&#x5BF9;&#x4E0D;&#x540C;&#x7F29;&#x7565;&#x56FE;&#x4E2D;&#x7684;&#x5934;&#x53D1;&#x505A;HT&#x7EBF;&#x6BB5;&#x68C0;&#x6D4B;&#xFF0C;&#x7136;&#x540E;&#x5C06;&#x6240;&#x6709;&#x68C0;&#x6D4B;&#x7ED3;&#x679C;&#x8FDB;&#x884C;&#x201C;&#x903B;&#x8F91;&#x6216;&#x201D;&#x6574;&#x5408;&#xFF0C;&#x4EE5;&#x51CF;&#x5C11;&#x7F3A;&#x5931;&#x5934;&#x53D1;&#x7684;&#x8BA1;&#x6570;&#xFF0C;&#x89E3;&#x51B3;&#x91CD;&#x53E0;&#x5934;&#x53D1;&#x7684;&#x6F0F;&#x8BA1;&#x6570;&#x7684;&#x95EE;&#x9898;&#x3002; &#x672C;&#x6587;&#x7684;&#x6846;&#x67B6;&#x53EF;&#x4EE5;&#x88AB;&#x89C6;&#x4E3A;&#x8FC8;&#x5411;&#x5316;&#x5986;&#x54C1;&#x548C;&#x5934;&#x76AE;&#x6CBB;&#x7597;&#x5E94;&#x7528;&#x7684;&#x667A;&#x80FD;&#x8BA1;&#x7B97;&#x673A;&#x8F85;&#x52A9;&#x533B;&#x5B66;&#x56FE;&#x50CF;&#x5904;&#x7406;&#x7684;&#x7B2C;&#x4E00;&#x6B65;&#x3002; &#x6280;&#x672F;&#x603B;&#x7ED3; &#x9884;&#x5904;&#x7406;&#x9636;&#x6BB5; &#x5BF9;&#x8F93;&#x5165;&#x6570;&#x636E;&#xFF08;&#x5934;&#x76AE;&#x56FE;&#x7247;&#xFF09;&#x8FDB;&#x884C;&#x9884;&#x5904;&#x7406;&#xFF0C;&#x4E3A;&#x4E0B;&#x4E00;&#x9636;&#x6BB5;&#x5BF9;&#x56FE;&#x7247;&#x4E2D;&#x5934;&#x53D1;&#x8FDB;&#x884C;&#x7CBE;&#x51C6;&#x8BA1;&#x6570;&#x7B49;&#x529F;&#x80FD;&#x6027;&#x64CD;&#x4F5C;&#x505A;&#x597D;&#x94FA;&#x57AB;&#x3002;&#x4E3B;&#x8981;&#x7528;&#x5230;&#x4EE5;&#x4E0B;&#x6280;&#x672F;&#xFF1A; Contrast Stretching (Normalization): &#x5BF9;&#x6BD4;&#x5EA6;&#x62C9;&#x4F38;&#xFF08;&#x901A;&#x5E38;&#x79F0;&#x4E3A;&#x5F52;&#x4E00;&#x5316;&#xFF09;&#x662F;&#x4E00;&#x79CD;&#x7B80;&#x5355;&#x7684;&#x56FE;&#x50CF;&#x589E;&#x5F3A;&#x6280;&#x672F;,&#x65E8;&#x5728;&#x901A;&#x8FC7;&#x201C;&#x62C9;&#x4F38;&#x201D;&#x56FE;&#x50CF;&#x6240;&#x5305;&#x542B;&#x7684;&#x5F3A;&#x5EA6;&#x503C;&#x8303;&#x56F4;&#x4EE5;&#x8986;&#x76D6;&#x6240;&#x9700;&#x7684;&#x503C;&#x8303;&#x56F4;&#x6765;&#x6539;&#x5584;&#x56FE;&#x50CF;&#x7684;&#x5BF9;&#x6BD4;&#x5EA6;&#x3002; &#x6280;&#x672F;&#x5E94;&#x7528;&#xFF1A;&#x589E;&#x52A0;&#x5934;&#x76AE;&#x4E0E;&#x5934;&#x53D1;&#x4E4B;&#x95F4;&#x7684;&#x5BF9;&#x6BD4;&#x5EA6;&#xFF0C;&#x65B9;&#x4FBF;&#x4E0B;&#x9636;&#x6BB5;&#x5BF9;&#x5934;&#x53D1;&#x8FDB;&#x884C;&#x8BED;&#x4E49;&#x5206;&#x5272;&#x3002; Color Morphology EXTENDING MATHEMATICAL MORPHOLOGY TO COLOR IMAGE PROCESSING &#x6280;&#x672F;&#x5E94;&#x7528;&#xFF1A; &#x9664;&#x566A;&#xFF0C;&#x53BB;&#x9664;&#x6CB9;&#x6027;&#x548C;&#x6E7F;&#x6DA6;&#x7684;&#x5934;&#x53D1;&#x5728;&#x5934;&#x53D1;&#x7684;&#x4E2D;&#x90E8;&#x4EA7;&#x751F;&#x7684;&#x4EAE;&#x70B9; Karhunen-Loeve Transform (KLT) Karhunen-Loeve&#x53D8;&#x6362;&#xFF08;KLT&#xFF09;&#xFF08;&#x4E5F;&#x79F0;&#x4E3A;Hotelling&#x53D8;&#x6362;&#x548C;&#x7279;&#x5F81;&#x5411;&#x91CF;&#x53D8;&#x6362;&#xFF09;&#xFF0C;&#x5B83;&#x4E0E;&#x4E3B;&#x6210;&#x5206;&#x5206;&#x6790;&#xFF08;PCA&#xFF09;&#x5BC6;&#x5207;&#x76F8;&#x5173;&#xFF0C;&#x5E76;&#x5E7F;&#x6CDB;&#x7528;&#x4E8E;&#x8BB8;&#x591A;&#x9886;&#x57DF;&#x7684;&#x6570;&#x636E;&#x5206;&#x6790;&#x4E2D;, KL&#x53D8;&#x6362;&#x57FA;&#x4E8E;&#x56FE;&#x50CF;&#x7684;&#x7EDF;&#x8BA1;&#x5C5E;&#x6027;&#xFF0C;&#x5E76;&#x5177;&#x6709;&#x4E00;&#x4E9B;&#x91CD;&#x8981;&#x7684;&#x5C5E;&#x6027;&#xFF0C;&#x4F7F;&#x5176;&#x53EF;&#x7528;&#x4E8E;&#x56FE;&#x50CF;&#x5904;&#x7406;&#xFF0C;&#x7279;&#x522B;&#x662F;&#x56FE;&#x50CF;&#x538B;&#x7F29;&#x3002; &#x6280;&#x672F;&#x5E94;&#x7528;&#xFF1A; &#x5C06;&#x5F69;&#x8272;&#x56FE;&#x50CF;&#x8F6C;&#x6362;&#x4E3A;&#x7070;&#x5EA6;&#x56FE;&#x50CF;&#x3002; Otsu thresholding Otsu thresholding&#xFF1A;&#x7B80;&#x5355;&#x8BF4;&#x6765;&#x8BE5;&#x65B9;&#x6CD5;&#x53EF;&#x5C06;&#x7070;&#x5EA6;&#x56FE;&#x50CF;&#x8FD8;&#x539F;&#x4E3A;&#x4E8C;&#x8FDB;&#x5236;&#x56FE;&#x50CF;&#x3002;&#x5728;&#x56FE;&#x50CF;&#x5904;&#x7406;&#x548C;&#x5206;&#x6790;&#x4E2D;&#xFF0C;&#x6709;&#x65F6;&#x9700;&#x8981;&#x4E00;&#x79CD;&#x65B9;&#x6CD5;&#x6765;&#x5206;&#x79BB;&#x4E24;&#x4E2A;&#x76F8;&#x5173;&#x6570;&#x636E;&#xFF0C;&#x4F8B;&#x5982;&#x80CC;&#x666F;&#x548C;&#x524D;&#x666F;&#x3002;Otsu&#x9608;&#x503C;&#x662F;&#x4E00;&#x79CD;&#x6570;&#x636E;&#x9A71;&#x52A8;&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x8BE5;&#x65B9;&#x6CD5;&#x53EF;&#x4EE5;&#x81EA;&#x9002;&#x5E94;&#x5730;&#x627E;&#x5230;&#x6700;&#x4F73;&#x9608;&#x503C;&#x4EE5;&#x533A;&#x5206;&#x4E24;&#x7C7B;&#x6570;&#x636E;&#x3002; &#x6280;&#x672F;&#x5E94;&#x7528;&#xFF1A; &#x56FE;&#x50CF;&#x5206;&#x5272;&#x548C;&#x56FE;&#x50CF;&#x4E8C;&#x503C;&#x5316;&#x3002; &#x591A;&#x5C3A;&#x5EA6;&#x7EBF;&#x68C0;&#x6D4B;&#x9636;&#x6BB5;&#xFF08;MSLD&#xFF09; &#x8BE5;&#x9636;&#x6BB5;&#x4E3B;&#x8981;&#x662F;&#x901A;&#x8FC7;&#x5404;&#x79CD;&#x6280;&#x672F;&#xFF0C;&#x514B;&#x670D;&#x91CD;&#x53E0;&#x5934;&#x53D1;&#x65E0;&#x6CD5;&#x8BA1;&#x6570;&#xFF0C;&#x4EE5;&#x53CA;&#x76F8;&#x90BB;&#x5934;&#x53D1;&#x4E4B;&#x95F4;&#x7684;&#x5934;&#x76AE;&#x88AB;&#x8BC6;&#x522B;&#x4E3A;&#x5934;&#x53D1;&#x7B49;&#x5F71;&#x54CD;&#x5934;&#x53D1;&#x8BA1;&#x6570;&#x7684;&#x76F8;&#x5173;&#x95EE;&#x9898;&#x3002;&#x4E3A;&#x4E0B;&#x9636;&#x6BB5;&#x5BF9;&#x5934;&#x53D1;&#x8FDB;&#x884C;&#x7CBE;&#x51C6;&#x8BA1;&#x6570;&#x7684;&#x505A;&#x597D;&#x94FA;&#x57AB;&#x3002;&#x4E3B;&#x8981;&#x7528;&#x5230;&#x4EE5;&#x4E0B;&#x6280;&#x672F;&#xFF1A; &#x970D;&#x592B;&#x53D8;&#x6362;&#xFF08;HT) &#x970D;&#x592B;&#x53D8;&#x6362;&#xFF08;HT&#xFF09; &#x970D;&#x592B;&#x53D8;&#x6362;&#x662F;&#x4E00;&#x79CD;&#x53EF;&#x7528;&#x4E8E;&#x9694;&#x79BB;&#x56FE;&#x50CF;&#x4E2D;&#x7279;&#x5B9A;&#x5F62;&#x72B6;&#x7684;&#x7279;&#x5F81;&#x7684;&#x6280;&#x672F;&#x3002;&#x56E0;&#x4E3A;&#x5B83;&#x8981;&#x6C42;&#x4EE5;&#x67D0;&#x79CD;&#x53C2;&#x6570;&#x5F62;&#x5F0F;&#x6307;&#x5B9A;&#x6240;&#x9700;&#x7684;&#x7279;&#x5F81;&#xFF0C;&#x6240;&#x4EE5;&#x7ECF;&#x5178;&#x7684;Hough&#x53D8;&#x6362;&#x6700;&#x5E38;&#x7528;&#x4E8E;&#x68C0;&#x6D4B;&#x89C4;&#x5219;&#x66F2;&#x7EBF;&#xFF08;&#x4F8B;&#x5982;&#x76F4;&#x7EBF;&#xFF0C;&#x5706;&#xFF0C;&#x692D;&#x5706;&#x7B49;&#xFF09;&#x3002; &#x6280;&#x672F;&#x5E94;&#x7528;&#xFF1A; HT&#x662F;&#x6700;&#x5E38;&#x7528;&#x7684;&#x7EBF;&#x68C0;&#x6D4B;&#x6846;&#x67B6;&#x4E4B;&#x4E00;&#x3002;&#x4F46;&#x662F;&#x5F53;&#x4F7F;&#x7528;&#x5E38;&#x89C4;&#x7684;&#x5355;&#x5C3A;&#x5EA6;HT&#x65F6;&#xFF0C;&#x53EF;&#x80FD;&#x4F1A;&#x4E22;&#x5931;&#x5927;&#x91CF;&#x7684;&#x5934;&#x53D1;&#x6BB5;&#x3002;&#x6545;&#x63D0;&#x51FA;&#x5C06;HT&#x5E94;&#x7528;&#x4E8E;&#x4E09;&#x4E2A;&#x6BD4;&#x4F8B;&#x7684;&#x56FE;&#x50CF;&#xFF0C;&#x5305;&#x62EC;1024&#xD7;768&#xFF08;&#x539F;&#x59CB;&#x6BD4;&#x4F8B;&#xFF09;&#xFF0C;512&#xD7;384&#x548C;256&#xD7;192&#xFF0C;&#x6700;&#x540E;&#x901A;&#x8FC7;&#x903B;&#x8F91;&#x6216;&#x5C06;&#x4E09;&#x4E2A;&#x6BD4;&#x4F8B;&#x56FE;&#x50CF;&#x4E2D;&#x7684;&#x88AB;&#x68C0;&#x6D4B;&#x51FA;&#x7684;&#x5934;&#x53D1;&#x8FDB;&#x884C;&#x6574;&#x5408;&#xFF0C;&#x4EE5;&#x63D0;&#x9AD8;&#x5934;&#x53D1;&#x8BA1;&#x6570;&#x51C6;&#x786E;&#x5EA6;&#x3002; Canny Edge Detection Canny&#x8FB9;&#x7F18;&#x68C0;&#x6D4B;&#x662F;&#x4E00;&#x79CD;&#x591A;&#x6B65;&#x9AA4;&#x7B97;&#x6CD5;&#xFF0C;&#x53EF;&#x4EE5;&#x540C;&#x65F6;&#x68C0;&#x6D4B;&#x5230;&#x566A;&#x58F0;&#x88AB;&#x6291;&#x5236;&#x7684;&#x8FB9;&#x7F18;&#x3002;&#x5728;&#x56FE;&#x50CF;&#x4E8C;&#x503C;&#x5316;&#x6B65;&#x9AA4;&#x4E2D;&#xFF0C;&#x7531;&#x4E8E;&#x9519;&#x8BEF;&#x5730;&#x5047;&#x5B9A;&#x4E86;&#x4E24;&#x6839;&#x5355;&#x72EC;&#x7684;&#x5934;&#x53D1;&#x7684;&#x8FDE;&#x63A5;&#xFF0C;&#x4F4D;&#x4E8E;&#x4E24;&#x6839;&#x5934;&#x53D1;&#x4E4B;&#x95F4;&#x7684;&#x5934;&#x76AE;&#x50CF;&#x7D20;&#x88AB;&#x6807;&#x8BB0;&#x4E3A;&#x5934;&#x53D1;&#x7684;&#x4E00;&#x90E8;&#x5206;&#x3002;&#x800C;&#x4E14;&#xFF0C;&#x5F53;&#x4E24;&#x6839;&#x5934;&#x53D1;&#x592A;&#x9760;&#x8FD1;&#x6216;&#x5F7C;&#x6B64;&#x91CD;&#x53E0;&#x65F6;&#xFF0C;&#x5982;&#x679C;&#x76F4;&#x63A5;&#x5E94;&#x7528;&#x7A00;&#x758F;&#x7B97;&#x6CD5;&#xFF0C;&#x5219;&#x4F1A;&#x9519;&#x8FC7;&#x4E00;&#x6839;&#x6216;&#x4E24;&#x6839;&#x5934;&#x53D1;&#x3002; &#x6280;&#x672F;&#x5E94;&#x7528;&#xFF1A; &#x4F7F;&#x7528;&#x8FB9;&#x7F18;&#x4FE1;&#x606F;&#x6765;&#x627E;&#x51FA;&#x9690;&#x85CF;&#x6216;&#x91CD;&#x53E0;&#x7684;&#x5934;&#x53D1;&#x3002;&#x53EF;&#x4EE5;&#x4ECE;&#x9690;&#x85CF;&#x7684;&#x5934;&#x53D1;&#x6216;&#x91CD;&#x53E0;&#x7684;&#x591A;&#x6839;&#x5934;&#x53D1;&#x4E2D;&#x63D0;&#x53D6;&#x4E24;&#x4E2A;&#x5E73;&#x884C;&#x7684;&#x8FB9;&#x7F18;&#x3002; Thinning Parallel Line Bundling (PLB) &#x5934;&#x53D1;&#x6807;&#x8BB0;&#x548C;&#x8BA1;&#x6570;&#x9636;&#x6BB5;&#xFF08;Hair Labling and Counting&#xFF09; &#x8BE5;&#x9636;&#x6BB5;&#x7684;&#x76EE;&#x7684;&#x662F;&#x51C6;&#x786E;&#x8BA1;&#x7B97;&#x5934;&#x76AE;&#x4E0A;&#x7684;&#x6BDB;&#x53D1;&#x6570;&#x91CF;&#x3002;&#x8FD9;&#x53EF;&#x4EE5;&#x770B;&#x4F5C;&#x662F;&#x805A;&#x7C7B;&#x548C;&#x6807;&#x8BB0;&#x95EE;&#x9898;&#x3002;&#x76EE;&#x6807;&#x662F;&#x5C06;&#x4E00;&#x7EC4;&#x7EBF;&#x6BB5;&#x7EC4;&#x5408;&#x6210;&#x8BED;&#x4E49;&#x201C;&#x5934;&#x53D1;&#x201D;&#x5E76;&#x5206;&#x914D;&#x552F;&#x4E00;&#x7684;&#x6807;&#x7B7E;&#x3002; &#x4E3B;&#x8981;&#x7528;&#x5230;&#x4EE5;&#x4E0B;&#x6280;&#x672F;&#xFF1A; Relaxation Labeling &#x677E;&#x5F1B;&#x6807;&#x8BB0;&#x662F;&#x4E00;&#x79CD;&#x56FE;&#x50CF;&#x5904;&#x7406;&#x65B9;&#x6CD5;&#x3002;&#x5176;&#x76EE;&#x6807;&#x662F;&#x5C06;&#x6807;&#x7B7E;&#x4E0E;&#x7ED9;&#x5B9A;&#x56FE;&#x50CF;&#x7684;&#x50CF;&#x7D20;&#x6216;&#x7ED9;&#x5B9A;&#x56FE;&#x7684;&#x8282;&#x70B9;&#x76F8;&#x5173;&#x8054;&#x3002; &#x6280;&#x672F;&#x5E94;&#x7528;&#xFF1A; &#x5728;&#x672C;&#x7814;&#x7A76;&#x4E2D;&#xFF0C;RL&#x7B97;&#x6CD5;&#x88AB;&#x89C6;&#x4E3A;&#x7528;&#x4E8E;&#x6807;&#x8BB0;&#x6BCF;&#x4E2A;&#x7EBF;&#x6BB5;&#x7684;&#x805A;&#x7C7B;&#x65B9;&#x6CD5;&#x3002; &#x53C2;&#x8003;&#x6587;&#x732E; An Unsupervised Hair Segmentation and Counting System in Microscopy Images Contrast Stretching (Normalization) Color Morphology EXTENDING MATHEMATICAL MORPHOLOGY TO COLOR IMAGE PROCESSING Karhunen-Loeve Transform (KLT) Otsu thresholding Hough Transform&#xFF08;HT) Canny Edge Detection Thinning Evaluation of a Bundling Technique for Parallel Coordinates Relaxation Labeling","categories":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Paper Smash","slug":"Technology/Paper-Smash","permalink":"https://littlelittlemoon.github.io/categories/Technology/Paper-Smash/"}],"tags":[{"name":"Hair Counting","slug":"Hair-Counting","permalink":"https://littlelittlemoon.github.io/tags/Hair-Counting/"},{"name":"Digital Image Processing","slug":"Digital-Image-Processing","permalink":"https://littlelittlemoon.github.io/tags/Digital-Image-Processing/"},{"name":"Line Detection","slug":"Line-Detection","permalink":"https://littlelittlemoon.github.io/tags/Line-Detection/"},{"name":"Paper","slug":"Paper","permalink":"https://littlelittlemoon.github.io/tags/Paper/"}],"keywords":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Paper Smash","slug":"Technology/Paper-Smash","permalink":"https://littlelittlemoon.github.io/categories/Technology/Paper-Smash/"}]},{"title":"Evalution of hair and scalp condition based on microscopy image analysis | Hair Counting - part 1","slug":"Technology/Evalution of hair and scalp condition based on microscopy image analysis  | Hair Counting - 1","date":"2019-12-24T12:35:33.000Z","updated":"2020-04-12T13:06:54.541Z","comments":true,"path":"2019/12/24/Technology/Evalution of hair and scalp condition based on microscopy image analysis  | Hair Counting - 1/","link":"","permalink":"https://littlelittlemoon.github.io/2019/12/24/Technology/Evalution%20of%20hair%20and%20scalp%20condition%20based%20on%20microscopy%20image%20analysis%20%20|%20Hair%20Counting%20-%201/","excerpt":"","text":"Paper: Evalution of hair and scalp condition based on microscopy image analysis è®¡æ•°æ–¹æ³• å…¸å‹çš„ä¾¿æºå¼æ˜¾å¾®é•œç›¸æœºé€šå¸¸è¦†ç›–5mm x 5mmçš„çŸ©å½¢ã€‚å› æ­¤ï¼Œå¦‚æœä¸€æ ¹å¤´å‘é•¿äº5æ¯«ç±³ï¼Œåˆ™å®ƒå¿…é¡»è¶…å‡ºçŸ©å½¢ã€‚åŸºäºæ­¤è§‚å¯Ÿï¼Œæˆ‘ä»¬å¯¹æ¯›å‘è®¡æ•°æœ‰ä¸¤ä¸ªå‡è®¾ï¼š 1. æ¯æ ¹å¤´å‘ç”±ä¸€ä¸ªèµ·ç‚¹å’Œä¸€ä¸ªç»ˆç‚¹è¡¨ç¤º; 2. èµ·ç‚¹ä½äºçŸ©å½¢å†…éƒ¨ï¼Œç»ˆç‚¹ä½äºå›¾åƒçš„è¾¹ç•Œä¸Šã€‚ å¤´å‘è®¡æ•°ï¼šä½¿ç”¨é¢„å¤„ç†é˜¶æ®µè·å¾—çš„éª¨æ¶å›¾åƒï¼ŒåŸºäºä¸Šè¿°ä¸¤ç‚¹å‡è®¾ï¼Œå¦‚æœå¤´å‘çš„éª¨æ¶çº¿çš„ä¸€ä¸ªç‚¹åœ¨çŸ©å½¢å†…è€Œå¦ä¸€ç‚¹åœ¨è¾¹ç•Œä¸Šï¼Œåˆ™æˆ‘ä»¬å¯¹å¤´å‘è¿›è¡Œè®¡æ•°ã€‚ fig_3_Example_of_hair_counting å›¾3ç¤ºå‡ºäº†å¤´å‘è®¡æ•°çš„ç¤ºä¾‹ã€‚åœ¨å›¾ä¸­ï¼Œè®¡æ•°çš„åƒç´ ç”¨çº¢è‰²ç‚¹æ ‡è®°ï¼Œå¹¶ä¸”è¿™äº›ç‚¹å åŠ åœ¨åŸå§‹å›¾åƒä¸Šã€‚ç„¶åï¼Œå¯ä»¥é€šè¿‡å°†è®¡æ•°çš„åƒç´ æ•°é™¤ä»¥å›¾åƒå°ºå¯¸æ¥è®¡ç®—å¤´å‘å¯†åº¦ã€‚ å®éªŒç»“æœ ä¸ºäº†è¯„ä¼°å¤´å‘è®¡æ•°ç®—æ³•ï¼Œæˆ‘ä»¬å¯¹200ä¸ªå¤´çš®å›¾åƒçš„æ•°æ®é›†è¿›è¡Œäº†å®éªŒã€‚ è¡¨2åˆ—å‡ºäº†æ ¹æ®æˆ‘ä»¬çš„ç®—æ³•è®¡ç®—å‡ºçš„å®é™…æ¯›å‘æ•°ä¸ä¼°è®¡æ¯›å‘æ•°ä¹‹é—´çš„ç²¾ç¡®åº¦/å¬å›ç‡ã€‚ å¹³å‡å‡†ç¡®åº¦å’Œå¬å›ç‡åˆ†åˆ«ä¸º91.35ï¼…å’Œ92.01ï¼…ã€‚å³ä½¿æ€§èƒ½ç›¸å½“å¥½ï¼Œç²¾åº¦/è°ƒç”¨ç‡ä¹Ÿå¯ä»¥è¿›ä¸€æ­¥æé«˜ã€‚é”™è¯¯çš„ä¸€ä¸ªå…³é”®åŸå› æ˜¯é¢„å¤„ç†å’ŒåŸå§‹å›¾åƒçš„è´¨é‡ã€‚åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œä¸€æ—¦å›¾åƒä¸­å‡ºç°æ¨¡ç³Šç‚¹ï¼Œå°±ä¸å¯èƒ½åœ¨é¢„å¤„ç†æ­¥éª¤ä¸­æ¶ˆé™¤æ‰€æœ‰å™ªéŸ³ã€‚å› æ­¤ï¼Œè€ƒè™‘åˆ°ç›¸æœºå™ªå£°ï¼Œç²¾åº¦éå¸¸å¥½ã€‚ åŒæ ·ï¼Œæˆ‘ä»¬æµ‹è¯•äº†æ¯›å­”è®¡æ•°ç®—æ³•ï¼Œç»“æœæ˜¾ç¤ºå¹³å‡å‡†ç¡®ç‡çº¦ä¸º90ï¼…ã€‚ æ€»ç»“ è®¡æ•°æ€è·¯ å°†å›¾ç‰‡è¾¹ç¼˜çœ‹ä½œä¸€çŸ©å½¢ï¼› å¯¹æ»¡è¶³â€œå¤´å‘ç”±ä¸€ä¸ªèµ·ç‚¹å’Œä¸€ä¸ªç»ˆç‚¹è¡¨ç¤ºï¼Œä¸”èµ·ç‚¹ä½äºçŸ©å½¢å†…éƒ¨ï¼Œç»ˆç‚¹ä½äºå›¾åƒçš„è¾¹ç•Œä¸Šâ€æ¡ä»¶çš„å¤´å‘è¿›è¡Œè®¡æ•°ï¼› ä½¿ç”¨é€šè¿‡ç»†åŒ–æ“ä½œè·å¾—çš„å¤´å‘éª¨æ¶å›¾åƒå¯¹æ»¡è¶³æ¡ä»¶çš„å¤´å‘è¿›è¡Œè®¡æ•°ï¼› é€šè¿‡å°†è®¡æ•°çš„åƒç´ æ•°é™¤ä»¥å›¾åƒå°ºå¯¸æ¥è®¡ç®—å¤´å‘å¯†åº¦ã€‚ å‚è€ƒæ–‡çŒ® Evalution of hair and scalp condition based on microscopy image analysis","categories":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Paper Smash","slug":"Technology/Paper-Smash","permalink":"https://littlelittlemoon.github.io/categories/Technology/Paper-Smash/"}],"tags":[{"name":"Hair Counting","slug":"Hair-Counting","permalink":"https://littlelittlemoon.github.io/tags/Hair-Counting/"},{"name":"Digital Image Processing","slug":"Digital-Image-Processing","permalink":"https://littlelittlemoon.github.io/tags/Digital-Image-Processing/"},{"name":"Line Detection","slug":"Line-Detection","permalink":"https://littlelittlemoon.github.io/tags/Line-Detection/"},{"name":"Paper","slug":"Paper","permalink":"https://littlelittlemoon.github.io/tags/Paper/"}],"keywords":[{"name":"Technology","slug":"Technology","permalink":"https://littlelittlemoon.github.io/categories/Technology/"},{"name":"Paper Smash","slug":"Technology/Paper-Smash","permalink":"https://littlelittlemoon.github.io/categories/Technology/Paper-Smash/"}]}]}